---
title: "Transformações e Esperanças"
---

:::{.chapter-intro}
"Nós queremos algo mais do que mera teoria e pregação agora, no entanto."

:::{.chapter-intro-quote}
**Sherlock Holmes**
*Um Estudo em Vermelho*
:::

:::

Frequentemente, se somos capazes de modelar um fenômeno em termos de uma variável aleatória $X$ com fda $F_X(x)$, também estaremos interessados no comportamento de funções de $X$. Neste capítulo, estudamos técnicas que nos permitem obter informações sobre funções de $X$ que podem ser de interesse, informações que podem variar desde muito completas (as distribuições dessas funções) até mais vagas (o comportamento médio).

## 2.1 Distribuições de Funções de uma Variável Aleatória

Se $X$ é uma variável aleatória com fda $F_X(x)$, então qualquer função de $X$, digamos $g(X)$, também é uma variável aleatória. Frequentemente, $g(X)$ é de interesse por si só e escrevemos $Y = g(X)$ para denotar a nova variável aleatória $g(X)$. Como $Y$ é uma função de $X$, podemos descrever o comportamento probabilístico de $Y$ em termos do comportamento de $X$. Isto é, para qualquer conjunto $A$,

$$
P(Y \in A) = P(g(X) \in A),
$$

mostrando que a distribuição de $Y$ depende das funções $F_X$ e $g$. Dependendo da escolha de $g$, às vezes é possível obter uma expressão tratável para essa probabilidade.

Formalmente, se escrevermos $y = g(x)$, a função $g(x)$ define um mapeamento do espaço amostral original de $X$, $\mathcal{X}$, para um novo espaço amostral, $\mathcal{Y}$, o espaço amostral da variável aleatória $Y$. Isto é,

$$
g(x): \mathcal{X} \to \mathcal{Y}.
$$

Associamos a $g$ um mapeamento inverso, denotado por $g^{-1}$, que é um mapeamento de subconjuntos de $\mathcal{Y}$ para subconjuntos de $\mathcal{X}$, e é definido por

$$
g^{-1}(A) = \{x \in \mathcal{X} : g(x) \in A\}.
$$ {#eq-2.1.1}

Note que o mapeamento $g^{-1}$ leva conjuntos em conjuntos, ou seja, $g^{-1}(A)$ é o conjunto de pontos em $\mathcal{X}$ que $g(x)$ leva para o conjunto $A$. É possível que $A$ seja um conjunto de um único ponto, digamos $A = \{y\}$. Então

$$
g^{-1}(\{y\}) = \{x \in \mathcal{X} : g(x) = y\}.
$$

Neste caso, frequentemente escrevemos $g^{-1}(y)$ em vez de $g^{-1}(\{y\})$. A quantidade $g^{-1}(y)$ ainda pode ser um conjunto, no entanto, se houver mais de um $x$ para o qual $g(x) = y$. Se houver apenas um $x$ para o qual $g(x) = y$, então $g^{-1}(y)$ é o conjunto de ponto $\{x\}$, e escreveremos $g^{-1}(y) = x$. Se a variável aleatória $Y$ for agora definida por $Y = g(X)$, podemos escrever para qualquer conjunto $A \subset \mathcal{Y}$,

$$
\begin{aligned}
P(Y \in A) &= P(g(X) \in A) \\
&= P(\{x \in \mathcal{X} : g(x) \in A\}) \\
&= P(X \in g^{-1}(A)).
\end{aligned}
$$ {#eq-2.1.2}

Isto define a distribuição de probabilidade de $Y$. É imediato mostrar que esta distribuição de probabilidade satisfaz os Axiomas de Kolmogorov.

Se $X$ é uma variável aleatória discreta, então $\mathcal{X}$ é enumerável. O espaço amostral para $Y = g(X)$ é $\mathcal{Y} = \{y : y = g(x), x \in \mathcal{X}\}$, que também é um conjunto enumerável. Assim, $Y$ também é uma variável aleatória discreta. Usando @eq-2.1.2, a fmp para $Y$ é

$$
f_Y(y) = P(Y = y) = \sum_{x \in g^{-1}(y)} P(X = x) = \sum_{x \in g^{-1}(y)} f_X(x), \text{ para } y \in \mathcal{Y},
$$

e $f_Y(y) = 0$ para $y \notin \mathcal{Y}$. Neste caso, encontrar a fmp de $Y$ envolve simplesmente identificar $g^{-1}(y)$, para cada $y \in \mathcal{Y}$, e somar as probabilidades apropriadas.

:::{.example}
### Exemplo 2.1.1 (Transformação binomial)
Uma variável aleatória discreta $X$ tem uma *distribuição binomial* se sua fmp for da forma

$$
f_X(x) = P(X = x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad x = 0, 1, \dots, n,
$$ {#eq-2.1.3}

onde $n$ é um inteiro positivo e $0 \leq p \leq 1$. Valores como $n$ e $p$ que podem ser ajustados para diferentes valores, produzindo diferentes distribuições de probabilidade, são chamados de *parâmetros*. Considere a variável aleatória $Y = g(X)$, onde $g(x) = n - x$. Isto é, $Y = n - X$. Aqui $\mathcal{X} = \{0, 1, \dots, n\}$ e $\mathcal{Y} = \{y : y = g(x), x \in \mathcal{X}\} = \{0, 1, \dots, n\}$. Para qualquer $y \in \mathcal{Y}$, $n - x = g(x) = y$ se, e somente se, $x = n - y$. Assim, $g^{-1}(y)$ é o ponto único $x = n - y$, e

$$
\begin{aligned}
f_Y(y) &= \sum_{x \in g^{-1}(y)} f_X(x) \\
&= f_X(n-y) \\
&= \binom{n}{n-y} p^{n-y} (1-p)^{n-(n-y)} \\
&= \binom{n}{y} (1-p)^y p^{n-y}.
\end{aligned}
$$

(A Definição 1.2.17 implica que $\binom{n}{y} = \binom{n}{n-y}$). Assim, vemos que $Y$ também tem uma distribuição binomial, mas com parâmetros $n$ e $1-p$. ||
:::

Se $X$ e $Y$ são variáveis aleatórias contínuas, então em alguns casos é possível encontrar fórmulas simples para a fda e fdp de $Y$ em termos da fda e fdp de $X$ e da função $g$. No restante desta seção, consideramos alguns desses casos.

A fda de $Y = g(X)$ é

$$
\begin{aligned}
F_Y(y) &= P(Y \leq y) \\
&= P(g(X) \leq y) \\
&= P(\{x \in \mathcal{X} : g(x) \leq y\}) \\
&= \int_{\{x \in \mathcal{X} : g(x) \leq y\}} f_X(x) dx.
\end{aligned}
$$ {#eq-2.1.4}

Às vezes, pode haver dificuldade em identificar $\{x \in \mathcal{X} : g(x) \leq y\}$ e realizar a integração de $f_X(x)$ sobre esta região, como mostra o próximo exemplo.

:::{.example}
### Exemplo 2.1.2 (Transformação uniforme)
 Suponha que $X$ tenha uma distribuição uniforme no intervalo $(0, 2\pi)$, isto é,

$$
f_X(x) = 
\begin{cases} 
1/(2\pi) & 0 < x < 2\pi \\
0 & \text{caso contrário}.
\end{cases}
$$

Considere $Y = \sin^2(X)$. Então (veja a @fig-2.1.1)

$$
P(Y \leq y) = P(X \leq x_1) + P(x_2 \leq X \leq x_3) + P(X \geq x_4).
$$ {#eq-2.1.5}

![Figura 2.1.1 - Gráfico da transformação $y = \sin^2(x)$ do Exemplo 2.1.2](fig/fig-2_1_1.png){#fig-2.1.1 width=70%}

Pela simetria da função $\sin^2(x)$, e pelo fato de $X$ ter uma distribuição uniforme, temos

$$
P(X \leq x_1) = P(X \geq x_4) \quad \text{e} \quad P(x_2 \leq X \leq x_3) = 2P(x_2 \leq X \leq \pi),
$$

então

$$
P(Y \leq y) = 2P(X \leq x_1) + 2P(x_2 \leq X \leq \pi)
$$ {#eq-2.1.6}

onde $x_1$ e $x_2$ são as duas soluções para

$$
\sin^2(x) = y, \quad 0 < x < \pi.
$$

Assim, embora este exemplo tenha tratado de uma situação aparentemente simples, a expressão resultante para a fda de $Y$ não foi simples. ||
:::

Ao realizar transformações, é importante manter o controle sobre os espaços amostrais das variáveis aleatórias; caso contrário, muita confusão pode surgir. Ao fazer uma transformação de $X$ para $Y = g(X)$, é mais conveniente usar

$$
\mathcal{X} = \{x : f_X(x) > 0\} \quad \text{e} \quad \mathcal{Y} = \{y : y = g(x) \text{ para algum } x \in \mathcal{X}\}.
$$ {#eq-2.1.7}

A fdp da variável aleatória $X$ é positiva apenas no conjunto $\mathcal{X}$ e é zero em outros lugares. Tal conjunto é chamado de *conjunto suporte* de uma distribuição ou, mais informalmente, o *suporte* de uma distribuição. Esta terminologia também pode ser aplicada a uma fmp ou, em geral, a qualquer função não negativa.

É mais fácil lidar com funções $g(x)$ que são *monotônicas*, isto é, aquelas que satisfazem ou

$$
u > v \implies g(u) > g(v) \quad \text{(crescente)} \quad \text{ou} \quad u < v \implies g(u) > g(v) \quad \text{(decrescente)}.
$$

Se a transformação $x \to g(x)$ é monotônica, então ela é um-para-um (injetora) e sobre $\mathcal{X} \to \mathcal{Y}$ (sobrejetora). Isto é, cada $x$ vai para apenas um $y$ e cada $y$ vem de no máximo um $x$ (um-para-um). Além disso, para $\mathcal{Y}$ definido como em @eq-2.1.7, para cada $y \in \mathcal{Y}$ existe um $x \in \mathcal{X}$ tal que $g(x) = y$ (sobre). Assim, a transformação $g$ associa exclusivamente $xs$ e $ys$. Se $g$ for monotônica, então $g^{-1}$ terá um único valor, isto é, $g^{-1}(y) = x$ se, e somente se, $y = g(x)$. Se $g$ for crescente, isso implica que

$$
\{x \in \mathcal{X} : g(x) \leq y\} = \{x \in \mathcal{X} : g^{-1}(g(x)) \leq g^{-1}(y)\} = \{x \in \mathcal{X} : x \leq g^{-1}(y)\}.
$$ {#eq-2.1.8}

Se $g$ for decrescente, isso implica que

$$
\{x \in \mathcal{X} : g(x) \leq y\} = \{x \in \mathcal{X} : g^{-1}(g(x)) \geq g^{-1}(y)\} = \{x \in \mathcal{X} : x \geq g^{-1}(y)\}.
$$ {#eq-2.1.9}

(Um gráfico ilustrará por que a desigualdade se inverte no caso decrescente.) Se $g(x)$ for uma função crescente, então usando @eq-2.1.4, podemos escrever

$$
F_Y(y) = \int_{\{x \in \mathcal{X} : x \leq g^{-1}(y)\}} f_X(x) dx = \int_{-\infty}^{g^{-1}(y)} f_X(x) dx = F_X(g^{-1}(y)).
$$

Se $g(x)$ for decrescente, temos

$$
F_Y(y) = \int_{g^{-1}(y)}^{\infty} f_X(x) dx = 1 - F_X(g^{-1}(y)).
$$

A continuidade de $X$ é usada para obter a segunda igualdade. Resumimos esses resultados no seguinte teorema.

:::{.theorem}

### Teorema 2.1.3
Seja $X$ com fda $F_X(x)$, seja $Y = g(X)$, e sejam $\mathcal{X}$ e $\mathcal{Y}$ definidos como em @eq-2.1.7.

a. Se $g$ é uma função crescente em $\mathcal{X}$, $F_Y(y) = F_X(g^{-1}(y))$ para $y \in \mathcal{Y}$.
b. Se $g$ é uma função decrescente em $\mathcal{X}$ e $X$ é uma variável aleatória contínua, $F_Y(y) = 1 - F_X(g^{-1}(y))$ para $y \in \mathcal{Y}$.
:::
:::{.example}
### Exemplo 2.1.4 (Relação uniforme-exponencial—I)
 Suponha que $X \sim f_X(x) = 1$ se $0 < x < 1$ e $0$ caso contrário, a distribuição uniforme(0,1). É imediato verificar que $F_X(x) = x, 0 < x < 1$. Fazemos agora a transformação $Y = g(X) = -\log X$. Como

$$
\frac{d}{dx}g(x) = \frac{d}{dx}(-\log x) = -\frac{1}{x} < 0, \quad \text{para } 0 < x < 1,
$$

$g(x)$ é uma função decrescente. Conforme $X$ varia entre 0 e 1, $-\log x$ varia entre 0 e $\infty$, isto é, $\mathcal{Y} = (0, \infty)$. Para $y > 0$, $y = -\log x$ implica $x = e^{-y}$, logo $g^{-1}(y) = e^{-y}$. Portanto, para $y > 0$,

$$
F_Y(y) = 1 - F_X(g^{-1}(y)) = 1 - F_X(e^{-y}) = 1 - e^{-y}. \quad (F_X(x) = x)
$$

Naturalmente, $F_Y(y) = 0$ para $y \leq 0$. Note que foi necessário apenas verificar que $g(x) = -\log x$ é monotônica em (0,1), o suporte de $X$. ||
:::

Se a fdp de $Y$ for contínua, ela pode ser obtida diferenciando a fda. O resultado da expressão é dado no seguinte teorema.

:::{.theorem}
### Teorema 2.1.5
Seja $X$ com fdp $f_X(x)$ e seja $Y = g(X)$, onde $g$ é uma função monotônica. Sejam $\mathcal{X}$ e $\mathcal{Y}$ definidos por @eq-2.1.7. Suponha que $f_X(x)$ seja contínua em $\mathcal{X}$ e que $g^{-1}(y)$ tenha uma derivada contínua em $\mathcal{Y}$. Então a fdp de $Y$ é dada por

$$
f_Y(y) = 
\begin{cases} 
f_X(g^{-1}(y)) \left| \frac{d}{dy} g^{-1}(y) \right| & y \in \mathcal{Y} \\
0 & \text{caso contrário}.
\end{cases}
$$ {#eq-2.1.10}
:::

:::{.proof}
Pelo Teorema 2.1.3 temos, pela regra da cadeia,

$$
f_Y(y) = \frac{d}{dy} F_Y(y) = 
\begin{cases} 
f_X(g^{-1}(y)) \frac{d}{dy} g^{-1}(y) & \text{se } g \text{ é crescente}, \\
-f_X(g^{-1}(y)) \frac{d}{dy} g^{-1}(y) & \text{se } g \text{ é decrescente},
\end{cases}
$$

que pode ser expresso concisamente como @eq-2.1.10. $\square$
:::

:::{.example}
### Exemplo 2.1.6 (fdp gama invertida)
Seja $f_X(x)$ a fdp *gama*
$$
f(x) = \frac{1}{(n-1)!\beta^n} x^{n-1} e^{-x/\beta}, \quad 0 < x < \infty,
$$

onde $\beta$ é uma constante positiva e $n$ é um inteiro positivo. Suponha que queiramos encontrar a fdp de $g(X) = 1/X$. Note que aqui os conjuntos suporte $\mathcal{X}$ e $\mathcal{Y}$ são ambos o intervalo $(0, \infty)$. Se fizermos $y = g(x)$, então $g^{-1}(y) = 1/y$ e $\frac{d}{dy} g^{-1}(y) = -1/y^2$. Aplicando o teorema acima, para $y \in (0, \infty)$,

$$
\begin{aligned}
f_Y(y) &= f_X(g^{-1}(y)) \left| \frac{d}{dy} g^{-1}(y) \right| \\
&= \frac{1}{(n-1)!\beta^n} \left(\frac{1}{y}\right)^{n-1} e^{-1/(\beta y)} \frac{1}{y^2} \\
&= \frac{1}{(n-1)!\beta^n} \left(\frac{1}{y}\right)^{n+1} e^{-1/(\beta y)},
\end{aligned}
$$

um caso especial de uma fdp conhecida como a *fdp gama invertida*. ||
:::
Em muitas aplicações, a função $g$ pode não ser nem crescente nem decrescente, portanto os resultados acima não se aplicarão. No entanto, é frequente o caso em que $g$ será monotônica em certos intervalos, e isso nos permite obter uma expressão para $Y = g(X)$.

:::{.example}
### Exemplo 2.1.7 (Transformação quadrática)
Suponha que $X$ seja uma variável aleatória contínua. Para $y > 0$, a fda de $Y = X^2$ é

$$
F_Y(y) = P(Y \leq y) = P(X^2 \leq y) = P(-\sqrt{y} \leq X \leq \sqrt{y}).
$$

Como $x$ é contínuo, podemos descartar a igualdade do endpoint esquerdo e obter

$$
F_Y(y) = P(-\sqrt{y} < X \leq \sqrt{y}) = P(X \leq \sqrt{y}) - P(X \leq -\sqrt{y}) = F_X(\sqrt{y}) - F_X(-\sqrt{y}).
$$

A fdp de $Y$ agora pode ser obtida da fda por diferenciação:

$$
\begin{aligned}
f_Y(y) &= \frac{d}{dy} F_Y(y) \\
&= \frac{d}{dy} [F_X(\sqrt{y}) - F_X(-\sqrt{y})] \\
&= \frac{1}{2\sqrt{y}} f_X(\sqrt{y}) + \frac{1}{2\sqrt{y}} f_X(-\sqrt{y}),
\end{aligned}
$$

onde usamos a regra da cadeia para diferenciar $F_X(\sqrt{y})$ e $F_X(-\sqrt{y})$. Portanto, a fdp é

$$
f_Y(y) = \frac{1}{2\sqrt{y}} (f_X(\sqrt{y}) + f_X(-\sqrt{y})).
$$ {#eq-2.1.11}
:::
Note que a fdp de $Y$ em @eq-2.1.11 é expressa como a soma de duas partes, partes que representam os intervalos onde $g(x) = x^2$ é monotônica. Em geral, este será o caso. ||

:::{.theorem}
### Teorema 2.1.8
Seja $X$ com fdp $f_X(x)$, seja $Y = g(X)$, e defina o espaço amostral $\mathcal{X}$ como em @eq-2.1.7. Suponha que exista uma partição, $A_0, A_1, \dots, A_k$, de $\mathcal{X}$ tal que $P(X \in A_0) = 0$ e $f_X(x)$ seja contínua em cada $A_i$. Além disso, suponha que existam funções $g_1(x), \dots, g_k(x)$, definidas em $A_1, \dots, A_k$, respectivamente, satisfazendo:

i. $g(x) = g_i(x)$, para $x \in A_i$,
ii. $g_i(x)$ é monotônica em $A_i$,
iii. o conjunto $\mathcal{Y} = \{y : y = g_i(x) \text{ para algum } x \in A_i\}$ é o mesmo para cada $i = 1, \dots, k$, e
iv. $g_i^{-1}(y)$ tem uma derivada contínua em $\mathcal{Y}$, para cada $i = 1, \dots, k$.

Então
$$
f_Y(y) = 
\begin{cases} 
\sum_{i=1}^{k} f_X(g_i^{-1}(y)) \left| \frac{d}{dy} g_i^{-1}(y) \right| & y \in \mathcal{Y} \\
0 & \text{caso contrário}.
\end{cases}
$$
:::

O ponto importante no Teorema 2.1.8 é que $\mathcal{X}$ pode ser dividido em conjuntos $A_1, \dots, A_k$ tais que $g(x)$ é monotônica em cada $A_i$. Podemos ignorar o "conjunto excepcional" $A_0$ já que $P(X \in A_0) = 0$.

:::{.example}
### Exemplo 2.1.9 (Relação Normal-qui quadrado)
Seja $X$ com distribuição normal padrão,

$$
f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}, \quad -\infty < x < \infty.
$$

Considere $Y = X^2$. A função $g(x) = x^2$ é monotônica em $(-\infty, 0)$ e em $(0, \infty)$. O conjunto $\mathcal{Y} = (0, \infty)$. Aplicando o Teorema 2.1.8, tomamos

$$
\begin{aligned}
A_0 &= \{0\}; \\
A_1 &= (-\infty, 0), \quad g_1(x) = x^2, \quad g_1^{-1}(y) = -\sqrt{y}; \\
A_2 &= (0, \infty), \quad g_2(x) = x^2, \quad g_2^{-1}(y) = \sqrt{y}.
\end{aligned}
$$

A fdp de $Y$ é

$$
\begin{aligned}
f_Y(y) &= \frac{1}{\sqrt{2\pi}} e^{-(-\sqrt{y})^2/2} \left| -\frac{1}{2\sqrt{y}} \right| + \frac{1}{\sqrt{2\pi}} e^{-(\sqrt{y})^2/2} \left| \frac{1}{2\sqrt{y}} \right| \\
&= \frac{1}{\sqrt{2\pi}} \frac{1}{\sqrt{y}} e^{-y/2}, \quad 0 < y < \infty.
\end{aligned}
$$

A fdp de $Y$ é uma que encontraremos frequentemente, a de uma variável aleatória **qui-quadrado** com 1 grau de liberdade. ||
:::
Encerramos esta seção com uma transformação especial e muito útil.

:::{.theorem}
### Teorema 2.1.10 (Transformação integral de probabilidade)
Seja $X$ com fda contínua $F_X(x)$ e defina a variável aleatória $Y$ como $Y = F_X(X)$. Então $Y$ é uniformemente distribuída em $(0, 1)$, isto é, $P(Y \leq y) = y, 0 < y < 1$.
:::

Antes de provarmos este teorema, faremos uma breve digressão para analisar $F_X^{-1}$, o inverso da fda $F_X$, em mais detalhes. Se $F_X$ for estritamente crescente, então $F_X^{-1}$ é bem definida por

$$
F_X^{-1}(y) = x \iff F_X(x) = y.
$$ {#eq-2.1.12}

No entanto, se $F_X$ for constante em algum intervalo, então $F_X^{-1}$ não é bem definida por @eq-2.1.12, como ilustra a @fig-2.1.2. Esse problema é evitado definindo $F_X^{-1}(y)$ para $0 < y < 1$ por

$$
F_X^{-1}(y) = \inf\{x : F_X(x) \geq y\}.
$$ {#eq-2.1.13}

![Figura 2.1.2 - (a) $F(x)$ estritamente crescente; (b) $F(x)$ não decrescente](fig/fig-2_1_2.png){#fig-2.1.2 width=70%}

:::{.proof}
Para $Y = F_X(X)$ temos, para $0 < y < 1$,

$$
\begin{aligned}
P(Y \leq y) &= P(F_X(X) \leq y) \\
&= P(F_X^{-1}[F_X(X)] \leq F_X^{-1}(y)) && (F_X^{-1} \text{ é crescente}) \\
&= P(X \leq F_X^{-1}(y)) && (\text{veja o texto abaixo}) \\
&= F_X(F_X^{-1}(y)) && (\text{definição de } F_X) \\
&= y. && (\text{continuidade de } F_X)
\end{aligned}
$$

Nos pontos extremos temos $P(Y \leq y) = 1$ para $y \geq 1$ e $P(Y \leq y) = 0$ para $y \leq 0$, mostrando que $Y$ tem uma distribuição uniforme. $\square$
:::

Nos pontos extremos, temos $P(Y \leq y) = 1$ para $y \geq 1$ e $P(Y \leq y) = 0$ para $y \leq 0$, mostrando que $Y$ possui uma distribuição uniforme.

O raciocínio por trás da igualdade

$$P(F_X^{-1}(F_X(X)) \leq F_X^{-1}(y)) = P(X \leq F_X^{-1}(y))$$

é um tanto sutil e merece atenção adicional. Se $F_X$ for estritamente crescente, então é verdade que $F_X^{-1}(F_X(x)) = x$ (consulte a @fig-2.1.2(a)). No entanto, se $F_X$ for constante (plana), pode ser que $F_X^{-1}(F_X(x)) \neq x$. Suponha que $F_X$ seja como na @fig-2.1.2(b) e considere $x \in [x_1, x_2]$. Então $F_X^{-1}(F_X(x)) = x_1$ para qualquer $x$ neste intervalo. Mesmo neste caso, a igualdade de probabilidade se mantém, visto que $P(X \leq x) = P(X \leq x_1)$ para qualquer $x \in [x_1, x_2]$. A função de distribuição acumulada (cdf) plana denota uma região de probabilidade zero ($P(x_1 < X \leq x) = F_X(x) - F_X(x_1) = 0$).

Uma aplicação do Teorema 2.1.10 está na geração de amostras aleatórias de uma distribuição específica. Se for necessário gerar uma observação $X$ de uma população com cdf $F_X$, precisamos apenas gerar um número aleatório uniforme $U$, entre 0 e 1, e resolver para $x$ na equação $F_X(x) = u$. (Para muitas distribuições, existem outros métodos de geração de observações que consomem menos tempo computacional, mas este método ainda é útil devido à sua aplicabilidade geral.)


## 2.2 Valores Esperados

O valor esperado, ou esperança, de uma variável aleatória é meramente seu valor médio, onde falamos de valor "médio" como aquele que é ponderado de acordo com a distribuição de probabilidade. O valor esperado de uma distribuição pode ser pensado como uma medida de centro, pois pensamos em médias como sendo valores centrais. Ao ponderar os valores da variável aleatória de acordo com a distribuição de probabilidade, esperamos obter um número que resuma um valor típico ou esperado de uma observação da variável aleatória.

:::{.definition}
### Definição 2.2.1
O *valor esperado* ou *média* de uma variável aleatória $g(X)$, denotado por $Eg(X)$, é

$$
Eg(X) = 
\begin{cases} 
\int_{-\infty}^{\infty} g(x) f_X(x) dx & \text{se } X \text{ é contínua} \\
\sum_{x \in \mathcal{X}} g(x) f_X(x) = \sum_{x \in \mathcal{X}} g(x) P(X = x) & \text{se } X \text{ é discreta},
\end{cases}
$$

desde que a integral ou a soma exista. Se $E|g(X)| = \infty$, dizemos que $Eg(X)$ não existe. (Ross (1988) refere-se a isso como a "lei do estatístico inconsciente". Não achamos isso divertido.)
:::

:::{.example}
### Exemplo 2.2.2 (Média exponencial)
Suponha que $X$ tenha uma distribuição exponencial($\lambda$), ou seja, ela tem fdp dada por

$$
f_X(x) = \frac{1}{\lambda} e^{-x/\lambda}, \quad 0 \leq x < \infty, \quad \lambda > 0.
$$

Então $EX$ é dado por

$$
\begin{aligned}
EX &= \int_{0}^{\infty} \frac{1}{\lambda} x e^{-x/\lambda} dx \\
&= -xe^{-x/\lambda} \Big|_0^\infty + \int_{0}^{\infty} e^{-x/\lambda} dx && \text{(integração por partes)} \\
&= \int_{0}^{\infty} e^{-x/\lambda} dx = \lambda.
\end{aligned}
$$ ||
:::

:::{.example}
### Exemplo 2.2.3 (Média binomial)
Se $X$ tem uma distribuição binomial, sua fmp é dada por

$$
P(X = x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad x = 0, 1, \dots, n
$$

onde $n$ é um inteiro positivo, $0 \leq p \leq 1$, e para cada par fixo $n$ e $p$ a fmp soma 1. O valor esperado de uma variável aleatória binomial é dado por

$$
EX = \sum_{x=0}^{n} x \binom{n}{x} p^x (1-p)^{n-x} = \sum_{x=1}^{n} x \binom{n}{x} p^x (1-p)^{n-x}
$$

(o termo $x = 0$ é 0). Usando a identidade $x \binom{n}{x} = n \binom{n-1}{x-1}$, temos

$$
\begin{aligned}
EX &= \sum_{x=1}^{n} n \binom{n-1}{x-1} p^x (1-p)^{n-x} \\
&= \sum_{y=0}^{n-1} n \binom{n-1}{y} p^{y+1} (1-p)^{n-(y+1)} && \text{(substitua } y = x-1\text{)} \\
&= np \sum_{y=0}^{n-1} \binom{n-1}{y} p^y (1-p)^{n-1-y} \\
&= np,
\end{aligned}
$$

visto que a última soma deve ser 1, sendo a soma de todos os valores possíveis de uma fmp binomial($n-1, p$). ||
:::

:::{.example}
### Exemplo 2.2.4 (Média de Cauchy)
Um exemplo clássico de uma variável aleatória cujo valor esperado não existe é a variável aleatória de Cauchy, ou seja, aquela com fdp

$$
f_X(x) = \frac{1}{\pi} \frac{1}{1+x^2}, \quad -\infty < x < \infty.
$$

É imediato verificar que $\int_{-\infty}^{\infty} f_X(x) dx = 1$, mas $E|X| = \infty$. Escreva

$$
E|X| = \int_{-\infty}^{\infty} \frac{|x|}{\pi} \frac{1}{1+x^2} dx = \frac{2}{\pi} \int_{0}^{\infty} \frac{x}{1+x^2} dx.
$$

Para qualquer número positivo $M$,

$$
\int_{0}^{M} \frac{x}{1+x^2} dx = \frac{\log(1+x^2)}{2} \Big|_0^M = \frac{\log(1+M^2)}{2}.
$$

Assim,

$$
E|X| = \lim_{M \to \infty} \frac{2}{\pi} \int_{0}^{M} \frac{x}{1+x^2} dx = \frac{1}{\pi} \lim_{M \to \infty} \log(1+M^2) = \infty
$$

e $EX$ não existe. ||
:::

O processo de tomar expectativas é uma operação linear, o que significa que a expectativa de uma função linear de $X$ pode ser facilmente avaliada notando que para quaisquer constantes $a$ e $b$,

$$
E(aX + b) = aEX + b.
$$ {#eq-2.2.1}

Por exemplo, se $X$ é binomial($n, p$), então $EX = np$, logo

$$
E(X - np) = EX - np = np - np = 0.
$$

O operador esperança, de fato, possui muitas propriedades que podem ajudar a facilitar o esforço de cálculo. A maioria dessas propriedades decorre das propriedades da integral ou da soma e está resumida no teorema a seguir.

:::{.theorem}
### Teorema 2.2.5
Seja $X$ uma variável aleatória e sejam $a, b$ e $c$ constantes. Então, para quaisquer funções $g_1(x)$ e $g_2(x)$ cujas expectativas existam,

a. $E(ag_1(X) + bg_2(X) + c) = aEg_1(X) + bEg_2(X) + c$.
b. Se $g_1(x) \geq 0$ para todo $x$, então $Eg_1(X) \geq 0$.
c. Se $g_1(x) \geq g_2(x)$ para todo $x$, então $Eg_1(X) \geq Eg_2(X)$.
d. Se $a \leq g_1(x) \leq b$ para todo $x$, então $a \leq Eg_1(X) \leq b$.
:::

:::{.proof}
Forneceremos detalhes apenas para o caso contínuo, sendo o caso discreto similar. Por definição,

$$
\begin{aligned}
E(ag_1(X) + bg_2(X) + c) &= \int_{-\infty}^{\infty} (ag_1(x) + bg_2(x) + c)f_X(x) dx \\
&= \int_{-\infty}^{\infty} ag_1(x)f_X(x) dx + \int_{-\infty}^{\infty} bg_2(x)f_X(x) dx + \int_{-\infty}^{\infty} c f_X(x) dx
\end{aligned}
$$

pela aditividade da integral. Como $a, b$ e $c$ são constantes, eles saem de suas respectivas integrais e temos

$$
\begin{aligned}
E(ag_1(X) + bg_2(X) + c) &= a \int_{-\infty}^{\infty} g_1(x)f_X(x) dx + b \int_{-\infty}^{\infty} g_2(x)f_X(x) dx + c \int_{-\infty}^{\infty} f_X(x) dx \\
&= aEg_1(X) + bEg_2(x) + c,
\end{aligned}
$$

estabelecendo (a). As outras três propriedades são provadas de maneira semelhante. $\square$
:::

:::{.example}
### Exemplo 2.2.6 (Minimizando a distância)
O valor esperado de uma variável aleatória tem outra propriedade, que podemos pensar como relacionada à interpretação de $EX$ como um bom palpite para um valor de $X$.

Suponha que meçamos a distância entre uma variável aleatória $X$ e uma constante $b$ por $(X - b)^2$. Quanto mais próximo $b$ estiver de $X$, menor será essa quantidade. Podemos agora determinar o valor de $b$ que minimiza $E(X - b)^2$ e, portanto, nos fornecerá um bom preditor de $X$. (Note que não adianta procurar um valor de $b$ que minimize $(X - b)^2$, pois a resposta dependeria de $X$, tornando-o um preditor inútil de $X$.)

Poderíamos prosseguir com a minimização de $E(X - b)^2$ usando cálculo, mas há um método mais simples. (Veja o Exercício 2.19 para uma prova baseada em cálculo.) Usando a crença de que há algo especial sobre $EX$, escreva

$$
\begin{aligned}
E(X - b)^2 &= E(X - EX + EX - b)^2 && \text{(adicione } \pm EX \\
&= E((X - EX) + (EX - b))^2 && \text{(agrupe os termos)} \\
&= E(X - EX)^2 + (EX - b)^2 + 2E((X - EX)(EX - b)),
\end{aligned}
$$

onde expandimos o quadrado. Agora, note que

$$
E((X - EX)(EX - b)) = (EX - b)E(X - EX) = 0,
$$

visto que $(EX - b)$ é constante e sai da expectativa, e $E(X - EX) = EX - EX = 0$. Isso significa que

$$
E(X - b)^2 = E(X - EX)^2 + (EX - b)^2.
$$ {#eq-2.2.2}

Não temos controle sobre o primeiro termo no lado direito de @eq-2.2.2 e o segundo termo, que é sempre maior ou igual a 0, pode ser feito igual a 0 escolhendo $b = EX$. Logo,

$$
\min_b E(X - b)^2 = E(X - EX)^2.
$$ {#eq-2.2.3}

Veja o Exercício 2.18 para um resultado semelhante sobre a mediana. ||
:::

Ao avaliar expectativas de funções não lineares de $X$, podemos proceder de uma de duas maneiras. Pela definição de $Eg(X)$, poderíamos calcular diretamente

$$
Eg(X) = \int_{-\infty}^{\infty} g(x)f_X(x) dx.
$$ {#eq-2.2.4}

Mas também poderíamos encontrar a fdp $f_Y(y)$ de $Y = g(X)$ e teríamos

$$
Eg(X) = EY = \int_{-\infty}^{\infty} y f_Y(y) dy.
$$ {#eq-2.2.5}

:::{.example}
### Exemplo 2.2.7 (Relação uniforme-exponencial—II)
Seja $X$ com uma distribuição uniforme(0,1), ou seja, a fdp de $X$ é dada por

$$
f_X(x) = 
\begin{cases} 
1 & \text{se } 0 \leq x \leq 1 \\
0 & \text{caso contrário},
\end{cases}
$$

e defina uma nova variável aleatória $g(X) = -\log X$. Então

$$
Eg(X) = E(-\log X) = \int_{0}^{1} -\log x dx = x - x \log x \Big|_0^1 = 1.
$$

Mas também vimos no Exemplo 2.1.4 que $Y = -\log X$ tem fda $1 - e^{-y}$ e, portanto, fdp $f_Y(y) = \frac{d}{dy}(1 - e^{-y}) = e^{-y}, 0 < y < \infty$, que é um caso especial da fdp exponencial com $\lambda = 1$. Assim, pelo Exemplo 2.2.2, $EY = 1$. ||
:::

## 2.3 Momentos e Funções Geradoras de Momentos

Os vários momentos de uma distribuição são uma classe importante de expectativas.

:::{.definition}
### Definição 2.3.1
Para cada inteiro $n$, o *$n$-ésimo momento* de $X$ (ou $F_X(x)$), $\mu'_n$, é

$$
\mu'_n = EX^n.
$$

O *$n$-ésimo momento central* de $X$, $\mu_n$, é

$$
\mu_n = E(X - \mu)^n,
$$

onde $\mu = \mu'_1 = EX$.
:::

Além da média, $EX$, de uma variável aleatória, talvez o momento mais importante seja o segundo momento central, mais comumente conhecido como a variância.

:::{.definition}
### Definição 2.3.2
A *variância* de uma variável aleatória $X$ é seu segundo momento central, $Var X = E(X - EX)^2$. A raiz quadrada positiva de $Var X$ é o *desvio padrão* de $X$.
:::

A variância fornece uma medida do grau de dispersão de uma distribuição em torno de sua média. Vimos anteriormente no Exemplo 2.2.6 que a quantidade $E(X - b)^2$ é minimizada escolhendo $b = EX$. Agora consideramos o tamanho absoluto desse mínimo. A interpretação atribuída à variância é que valores maiores significam que $X$ é mais variável. No extremo, se $Var X = E(X - EX)^2 = 0$, então $X$ é igual a $EX$ com probabilidade 1, e não há variação em $X$. O desvio padrão tem a mesma interpretação qualitativa: valores pequenos significam que é muito provável que $X$ esteja próximo de $EX$, e valores grandes significam que $X$ é muito variável. O desvio padrão é mais fácil de interpretar no sentido de que a unidade de medida no desvio padrão é a mesma da variável original $X$. A unidade de medida na variância é o quadrado da unidade original.


![Densidades exponenciais para $\lambda = 1, \frac{1}{3}, \frac{1}{5}$](fig/fig-2_3_1.png){#fig-2.3.1 width="50%"}

:::{.example}
### Exemplo 2.3.3 (Variância exponencial)
Seja $X$ com a distribuição exponencial($\lambda$), definida no Exemplo 2.2.2. Calculamos $EX = \lambda$, e agora podemos calcular a variância por

$$
\begin{aligned}
Var X = E(X - \lambda)^2 &= \int_{0}^{\infty} (x - \lambda)^2 \frac{1}{\lambda} e^{-x/\lambda} dx \\
&= \int_{0}^{\infty} (x^2 - 2x\lambda + \lambda^2) \frac{1}{\lambda} e^{-x/\lambda} dx.
\end{aligned}
$$

Para completar a integração, podemos integrar cada um dos termos separadamente, usando integração por partes nos termos que envolvem $x$ e $x^2$. Ao fazer isso, descobrimos que $Var X = \lambda^2$. ||
:::

Vemos que a variância de uma distribuição exponencial está diretamente relacionada ao parâmetro $\lambda$. A @fig-2.3.1 mostra várias distribuições exponenciais correspondentes a diferentes valores de $\lambda$. Note como a distribuição é mais concentrada em torno de sua média para valores menores de $\lambda$. O comportamento da variância de uma exponencial, como função de $\lambda$, é um caso especial do comportamento da variância resumido no teorema a seguir.

:::{.theorem}
### Teorema 2.3.4
Se $X$ é uma variável aleatória com variância finita, então para quaisquer constantes $a$ e $b$,

$$
Var(aX + b) = a^2 Var X.
$$
:::

:::{.proof}
Da definição, temos

$$
\begin{aligned}
Var(aX + b) &= E((aX + b) - E(aX + b))^2 \\
&= E(aX - aEX)^2 && (E(aX + b) = aEX + b) \\
&= a^2 E(X - EX)^2 \\
&= a^2 Var X.
\end{aligned}
$$ $\square$
:::

Às vezes é mais fácil usar uma fórmula alternativa para a variância, dada por

$$
Var X = EX^2 - (EX)^2,
$$ {#eq-2.3.1}

que é facilmente estabelecida notando que

$$
\begin{aligned}
Var X &= E(X - EX)^2 = E[X^2 - 2XEX + (EX)^2] \\
&= EX^2 - 2(EX)^2 + (EX)^2 \\
&= EX^2 - (EX)^2,
\end{aligned}
$$

onde usamos o fato de que $E(X EX) = (EX)(EX) = (EX)^2$, visto que $EX$ é uma constante. Ilustramos agora alguns cálculos de momentos com uma distribuição discreta.

:::{.example}
### Exemplo 2.3.5 (Variância binomial)
Seja $X \sim$ binomial($n, p$), ou seja,

$$
P(X = x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad x = 0, 1, \dots, n.
$$

Vimos anteriormente que $EX = np$. Para calcular $Var X$, primeiro calculamos $EX^2$. Temos

$$
EX^2 = \sum_{x=0}^{n} x^2 \binom{n}{x} p^x (1-p)^{n-x}.
$$ {#eq-2.3.2}

Para somar esta série, devemos primeiro manipular o coeficiente binomial de maneira semelhante à usada para $EX$ (Exemplo 2.2.3). Escrevemos

$$
x^2 \binom{n}{x} = x \frac{n!}{(x-1)!(n-x)!} = xn \binom{n-1}{x-1}.
$$ {#eq-2.3.3}

O termo no somatório em @eq-2.3.2 correspondente a $x = 0$ é zero e, usando @eq-2.3.3, temos

$$
\begin{aligned}
EX^2 &= n \sum_{x=1}^{n} x \binom{n-1}{x-1} p^x (1-p)^{n-x} \\
&= n \sum_{y=0}^{n-1} (y+1) \binom{n-1}{y} p^{y+1} (1-p)^{n-1-y} && \text{(ajustando } y = x-1\text{)} \\
&= np \sum_{y=0}^{n-1} y \binom{n-1}{y} p^y (1-p)^{n-1-y} + np \sum_{y=0}^{n-1} \binom{n-1}{y} p^y (1-p)^{n-1-y}.
\end{aligned}
$$

Agora é fácil ver que a primeira soma é igual a $(n-1)p$ (já que é a média de uma binomial($n-1, p$)), enquanto a segunda soma é igual a 1. Logo,

$$
EX^2 = n(n-1)p^2 + np.
$$ {#eq-2.3.4}

Usando @eq-2.3.1, temos

$$
Var X = n(n-1)p^2 + np - (np)^2 = -np^2 + np = np(1-p).
$$ ||
:::

O cálculo de momentos de ordem superior prossegue de maneira análoga, mas geralmente as manipulações matemáticas tornam-se bastante complexas. Em aplicações, momentos de ordem 3 ou 4 são às vezes de interesse, mas geralmente há pouca razão estatística para examinar momentos superiores a estes.

Introduzimos agora uma nova função que está associada a uma distribuição de probabilidade, a *função geradora de momentos* (fgm). Como o próprio nome sugere, a fgm pode ser usada para gerar momentos. Na prática, é mais fácil em muitos casos calcular momentos diretamente do que usar a fgm. No entanto, o principal uso da fgm não é gerar momentos, mas ajudar a caracterizar uma distribuição. Essa propriedade pode levar a resultados extremamente poderosos quando usada adequadamente.

:::{.definition}
### Definição 2.3.6
Seja $X$ uma variável aleatória com fda $F_X$. A *função geradora de momentos* (fgm) de $X$ (ou $F_X$), denotada por $M_X(t)$, é

$$
M_X(t) = Ee^{tX},
$$

desde que a esperança exista para $t$ em alguma vizinhança de 0. Ou seja, existe um $h > 0$ tal que, para todo $t$ em $-h < t < h$, $Ee^{tX}$ existe. Se a esperança não existir em uma vizinhança de 0, dizemos que a função geradora de momentos não existe.
:::

Mais explicitamente, podemos escrever a fgm de $X$ como

$$
M_X(t) = \int_{-\infty}^{\infty} e^{tx} f_X(x) dx \quad \text{se } X \text{ é contínua}.
$$

ou

$$
M_X(t) = \sum_{x} e^{tx} P(X = x) \quad \text{se } X \text{ é discreta}.
$$

É muito fácil ver como a fgm gera momentos. Resumimos o resultado no seguinte teorema.

:::{.theorem}
### Teorema 2.3.7
Se $X$ tem fgm $M_X(t)$, então

$$
EX^n = M_X^{(n)}(0),
$$

onde definimos
$$
M_X^{(n)}(0) = \frac{d^n}{dt^n} M_X(t) \Big|_{t=0}.
$$

Ou seja, o $n$-ésimo momento é igual à $n$-ésima derivada de $M_X(t)$ avaliada em $t = 0$.
:::

:::{.proof}
Assumindo que podemos diferenciar sob o sinal da integral (veja a próxima seção), temos

$$
\begin{aligned}
\frac{d}{dt} M_X(t) &= \frac{d}{dt} \int_{-\infty}^{\infty} e^{tx} f_X(x) dx \\
&= \int_{-\infty}^{\infty} \left( \frac{d}{dt} e^{tx} \right) f_X(x) dx \\
&= \int_{-\infty}^{\infty} (xe^{tx}) f_X(x) dx \\
&= E X e^{tX}.
\end{aligned}
$$

Assim,
$$
\frac{d}{dt} M_X(t) \Big|_{t=0} = E X e^{tX} \Big|_{t=0} = EX.
$$

Procedendo de maneira análoga, podemos estabelecer que
$$
\frac{d^n}{dt^n} M_X(t) \Big|_{t=0} = E X^n e^{tX} \Big|_{t=0} = EX^n.
$$ $\square$
:::

:::{.example}
### Exemplo 2.3.8 (fgm Gama)
No Exemplo 2.1.6 encontramos um caso especial da fdp gama

$$
f(x) = \frac{1}{\Gamma(\alpha)\beta^\alpha} x^{\alpha-1} e^{-x/\beta}, \quad 0 < x < \infty, \quad \alpha > 0, \quad \beta > 0,
$$

onde $\Gamma(\alpha)$ denota a função gama. A fgm é dada por

$$
\begin{aligned}
M_X(t) &= \frac{1}{\Gamma(\alpha)\beta^\alpha} \int_{0}^{\infty} e^{tx} x^{\alpha-1} e^{-x/\beta} dx \\
&= \frac{1}{\Gamma(\alpha)\beta^\alpha} \int_{0}^{\infty} x^{\alpha-1} e^{-(1/\beta - t)x} dx \\
&= \frac{1}{\Gamma(\alpha)\beta^\alpha} \int_{0}^{\infty} x^{\alpha-1} e^{-x/(\frac{\beta}{1-\beta t})} dx.
\end{aligned}
$$ {#eq-2.3.5}

Reconhecemos agora o integrando em @eq-2.3.5 como o *núcleo* de outra fdp gama. (O núcleo de uma função é a parte principal da função, a parte que permanece quando as constantes são desconsideradas.) Usando o fato de que, para quaisquer constantes positivas $a$ e $b$,

$$
f(x) = \frac{1}{\Gamma(a)b^a} x^{a-1} e^{-x/b}
$$

é uma fdp, temos que

$$
\int_{0}^{\infty} \frac{1}{\Gamma(a)b^a} x^{a-1} e^{-x/b} dx = 1
$$

e, portanto,
$$
\int_{0}^{\infty} x^{a-1} e^{-x/b} dx = \Gamma(a)b^a.
$$ {#eq-2.3.6}

Aplicando @eq-2.3.6 a @eq-2.3.5, temos

$$
M_X(t) = \frac{1}{\Gamma(\alpha)\beta^\alpha} \Gamma(\alpha) \left( \frac{\beta}{1-\beta t} \right)^\alpha = \left( \frac{1}{1-\beta t} \right)^\alpha \quad \text{se } t < \frac{1}{\beta}.
$$

Se $t \geq 1/\beta$, então a quantidade $(1/\beta) - t$, no integrando de @eq-2.3.5, é não positiva e a integral em @eq-2.3.6 é infinita. Assim, a fgm da distribuição gama existe apenas se $t < 1/\beta$.

A média da distribuição gama é dada por
$$
EX = \frac{d}{dt} M_X(t) \Big|_{t=0} = \frac{\alpha\beta}{(1-\beta t)^{\alpha+1}} \Big|_{t=0} = \alpha\beta.
$$

Outros momentos podem ser calculados de maneira semelhante. ||
:::

:::{.example}
### Exemplo 2.3.9 (fgm Binomial)
Para uma segunda ilustração do cálculo de uma função geradora de momentos, consideramos uma distribuição discreta, a distribuição binomial. A fmp binomial($n, p$) é dada em @eq-2.1.3. Então

$$
M_X(t) = \sum_{x=0}^{n} e^{tx} \binom{n}{x} p^x (1-p)^{n-x} = \sum_{x=0}^{n} \binom{n}{x} (pe^t)^x (1-p)^{n-x}.
$$

A fórmula binomial dá

$$
\sum_{x=0}^{n} \binom{n}{x} u^x v^{n-x} = (u+v)^n.
$$ {#eq-2.3.7}

Logo, fazendo $u = pe^t$ e $v = 1-p$, temos
$$
M_X(t) = [pe^t + (1-p)]^n.
$$ ||
:::


Como mencionado anteriormente, a utilidade principal da função geradora de momentos não está em sua capacidade de gerar momentos. Em vez disso, sua utilidade decorre do fato de que, em muitos casos, a função geradora de momentos pode caracterizar uma distribuição. Existem, no entanto, algumas dificuldades técnicas associadas ao uso de momentos para caracterizar uma distribuição, que investigaremos agora.

Se a fgm existe, ela caracteriza um conjunto infinito de momentos. A questão natural é se a caracterização do conjunto infinito de momentos determina exclusivamente uma função de distribuição. A resposta a essa pergunta, infelizmente, é não. Caracterizar o conjunto de momentos não é suficiente para determinar uma distribuição de forma única porque pode haver duas variáveis aleatórias distintas tendo os mesmos momentos.

:::{.example}
### Exemplo 2.3.10 (Momentos não únicos)
Considere as duas fdps dadas por

$$
f_1(x) = \frac{1}{\sqrt{2\pi}x} e^{-(\log x)^2/2}, \quad 0 \leq x < \infty,
$$

$$
f_2(x) = f_1(x)[1 + \sin(2\pi \log x)], \quad 0 \leq x < \infty.
$$

(A fdp $f_1$ é um caso especial de uma fdp lognormal.)
Pode-se mostrar que se $X_1 \sim f_1(x)$, então
$$
EX_1^r = e^{r^2/2}, \quad r = 0, 1, \dots,
$$

logo $X_1$ possui todos os seus momentos. Agora suponha que $X_2 \sim f_2(x)$. Temos
$$
EX_2^r = \int_{0}^{\infty} x^r f_1(x)[1 + \sin(2\pi \log x)] dx = EX_1^r + \int_{0}^{\infty} x^r f_1(x) \sin(2\pi \log x) dx.
$$

No entanto, a transformação $y = \log x - r$ mostra que esta última integral é a de uma função ímpar sobre $(-\infty, \infty)$ e, portanto, é igual a 0 para $r = 0, 1, \dots$. Assim, embora $X_1$ e $X_2$ tenham fdps distintas, elas têm os mesmos momentos para todo $r$. As duas fdps estão ilustradas na @fig-2.3.2. ||

![Duas fdps com os mesmos momentos: $f_1(x) = \frac{1}{\sqrt{2\pi}x} e^{-(\log x)^2/2}$ e $f_2(x) = f_1(x)[1+\sin(2\pi \log x)]$](fig/fig-2_3_2.png){#fig-2.3.2 width="50%"}
:::

O problema da não unicidade dos momentos não ocorre se as variáveis aleatórias tiverem suporte limitado. Se esse for o caso, então a sequência infinita de momentos determina unicamente a distribuição. Além disso, se a fgm existe em uma vizinhança de zero, então a distribuição é unicamente determinada, não importa qual seja o seu suporte. Assim, a existência de todos os momentos não é equivalente à existência da função geradora de momentos. O teorema a seguir mostra como uma distribuição pode ser caracterizada.

:::{.theorem}
### Teorema 2.3.11
Sejam $F_X(x)$ e $F_Y(y)$ duas fdas cujos momentos todos existem.

a. Se $X$ e $Y$ têm suporte limitado, então $F_X(u) = F_Y(u)$ para todo $u$ se, e somente se, $EX^r = EY^r$ para todos os inteiros $r = 0, 1, 2, \dots$.
b. Se as funções geradoras de momentos existem e $M_X(t) = M_Y(t)$ para todo $t$ em alguma vizinhança de 0, então $F_X(u) = F_Y(u)$ para todo $u$.
:::

No próximo teorema, que trata de uma sequência de fgms que converge, não tratamos o caso de suporte limitado separadamente. Note que a suposição de unicidade é automaticamente satisfeita se a fgm limite existir em uma vizinhança de 0 (Assuntos Diversos 2.6.1).

:::{.theorem}
### Teorema 2.3.12 (Convergência de fgms)
Suponha que $\{X_i, i = 1, 2, \dots\}$ seja uma sequência de variáveis aleatórias, cada uma com fgm $M_{X_i}(t)$. Além disso, suponha que
$$
\lim_{i \to \infty} M_{X_i}(t) = M_X(t), \quad \text{para todo } t \text{ em uma vizinhança de 0},
$$

e $M_X(t)$ seja uma fgm. Então existe uma única fda $F_X$ cujos momentos são determinados por $M_X(t)$ e, para todo $x$ onde $F_X(x)$ é contínua, temos
$$
\lim_{i \to \infty} F_{X_i}(x) = F_X(x).
$$
:::

Ou seja, a convergência das fgms para uma fgm em $|t| < h$ implica a convergência das fdas.

As provas dos Teoremas 2.3.11 e 2.3.12 baseiam-se na teoria das *transformadas de Laplace*. A equação definidora para $M_X(t)$, ou seja,
$$
M_X(t) = \int_{-\infty}^{\infty} e^{tx} f_X(x) dx,
$$ {#eq-2.3.8}

define uma transformada de Laplace ($M_X(t)$ é a transformada de Laplace de $f_X(x)$). Um fato fundamental sobre as transformadas de Laplace é a sua unicidade. Se @eq-2.3.8 for válida para todo $t$ tal que $|t| < h$, onde $h$ é algum número positivo, então dada $M_X(t)$ existe apenas uma função $f_X(x)$ que satisfaz @eq-2.3.8.

:::{.example}
### Exemplo 2.3.13 (Aproximação de Poisson)
Uma aproximação que geralmente é ensinada em cursos elementares de estatística é que as probabilidades binomiais (veja o Exemplo 2.3.5) podem ser aproximadas por probabilidades de *Poisson*, que são geralmente mais fáceis de calcular. A distribuição binomial é caracterizada por duas quantidades, denotadas por $n$ e $p$. Ensina-se que a aproximação de Poisson é válida "quando $n$ é grande e $np$ é pequeno" e regras práticas às vezes são fornecidas.

A fmp Poisson($\lambda$) é dada por
$$
P(X = x) = \frac{e^{-\lambda} \lambda^x}{x!}, \quad x = 0, 1, 2, \dots,
$$

onde $\lambda$ é uma constante positiva. A aproximação afirma que se $X \sim$ binomial($n, p$) e $Y \sim$ Poisson($\lambda$), com $\lambda = np$, então
$$
P(X = x) \approx P(Y = x)
$$ {#eq-2.3.9}

para $n$ grande e $np$ pequeno. Mostramos agora que as fgms convergem, dando crédito a essa aproximação. Lembre-se que $M_X(t) = [pe^t + (1-p)]^n$. Para a distribuição Poisson($\lambda$), podemos calcular $M_Y(t) = e^{\lambda(e^t - 1)}$, e se definirmos $p = \lambda/n$, então $M_X(t) \to M_Y(t)$ quando $n \to \infty$. A validade da aproximação em @eq-2.3.9 seguirá então do Teorema 2.3.12.

Primeiro devemos abrir um parêntese e mencionar um resultado de limite importante, um que tem ampla aplicabilidade em estatística.

:::{.theorem}
### Lema 2.3.14
Seja $a_1, a_2, \dots$ uma sequência de números convergindo para $a$, ou seja, $\lim_{n \to \infty} a_n = a$. Então
$$
\lim_{n \to \infty} \left( 1 + \frac{a_n}{n} \right)^n = e^a.
$$
:::

Retornando ao exemplo, temos
$$
M_X(t) = [pe^t + (1-p)]^n = \left[ 1 + \frac{1}{n}(e^t - 1)(np) \right]^n = \left[ 1 + \frac{1}{n}(e^t - 1)\lambda \right]^n,
$$

porque $\lambda = np$. Agora defina $a_n = a = (e^t - 1)\lambda$, e aplique o Lema 2.3.14 para obter
$$
\lim_{n \to \infty} M_X(t) = e^{\lambda(e^t - 1)} = M_Y(t),
$$

a função geradora de momentos da Poisson. A aproximação de Poisson pode ser bastante boa mesmo para valores moderados de $p$ e $n$. Na @fig-2.3.3 mostramos uma função de massa de probabilidade binomial junto com sua aproximação de Poisson, com $\lambda = np$. A aproximação parece ser satisfatória.

![Figura 2.3.3 - Aproximação de Poisson (linha pontilhada) para a binomial (linha sólida), n = 15, p = .3](fig/fig-2_3_3.png){#fig-2.3.3 width="50%"}

||
:::

Encerramos esta seção com um resultado útil relativo às fgms.

:::{.theorem}
### Teorema 2.3.15
Para quaisquer constantes $a$ e $b$, a fgm da variável aleatória $aX + b$ é dada por
$$
M_{aX+b}(t) = e^{bt} M_X(at).
$$
:::

:::{.proof}
Por definição,
$$
\begin{aligned}
M_{aX+b}(t) &= E(e^{(aX+b)t}) \\
&= E(e^{aXt} e^{bt}) && \text{(propriedades de exponenciais)} \\
&= e^{bt} E(e^{(at)X}) && (e^{bt} \text{ é constante}) \\
&= e^{bt} M_X(at), && \text{(definição de fgm)}
\end{aligned}
$$
provando o teorema. $\square$
:::

## 2.4 Diferenciando sob o Sinal de Integral

Na seção anterior, encontramos uma instância em que desejamos permutar a ordem de integração e diferenciação. Esta situação é encontrada frequentemente em estatística teórica. O propósito desta seção é caracterizar as condições sob as quais esta operação é legítima. Também discutiremos a permuta da ordem de diferenciação e somatório.

Muitas dessas condições podem ser estabelecidas usando teoremas padrão do cálculo e provas detalhadas podem ser encontradas na maioria dos livros de cálculo. Portanto, provas detalhadas não serão apresentadas aqui. Primeiro, queremos estabelecer o método de cálculo de

$$
\frac{d}{d\theta} \int_{a(\theta)}^{b(\theta)} f(x, \theta) dx
$$ {#eq-2.4.1}

onde $-\infty < a(\theta), b(\theta) < \infty$ para todo $\theta$. A regra para diferenciar @eq-2.4.1 é chamada de *Regra de Leibnitz* e é uma aplicação do Teorema Fundamental do Cálculo e da regra da cadeia.

:::{.theorem}
### Teorema 2.4.1 (Regra de Leibnitz)
Se $f(x, \theta)$, $a(\theta)$ e $b(\theta)$ são diferenciáveis em relação a $\theta$, então
$$
\frac{d}{d\theta} \int_{a(\theta)}^{b(\theta)} f(x, \theta) dx = f(b(\theta), \theta) \frac{d}{d\theta} b(\theta) - f(a(\theta), \theta) \frac{d}{d\theta} a(\theta) + \int_{a(\theta)}^{b(\theta)} \frac{\partial}{\partial \theta} f(x, \theta) dx.
$$
:::

Observe que se $a(\theta)$ e $b(\theta)$ são constantes, temos um caso especial da Regra de Leibnitz:

$$
\frac{d}{d\theta} \int_{a}^{b} f(x, \theta) dx = \int_{a}^{b} \frac{\partial}{\partial \theta} f(x, \theta) dx.
$$

Assim, em geral, se tivermos a integral de uma função diferenciável sobre um intervalo finito, a diferenciação da integral não representa problemas. Se o intervalo de integração for infinito, no entanto, podem surgir problemas. Note que a permuta de derivada e integral na equação acima iguala uma derivada parcial com uma derivada ordinária. Formalmente, este deve ser o caso, pois o lado esquerdo é uma função apenas de $\theta$, enquanto o integrando no lado direito é uma função de ambos $\theta$ e $x$.

A questão de saber se a permuta da ordem de diferenciação e integração é justificada é, na verdade, uma questão de saber se limites e integração podem ser permutados, já que uma derivada é um tipo especial de limite. Lembre-se que se $f(x, \theta)$ é diferenciável, então

$$
\frac{\partial}{\partial \theta} f(x, \theta) = \lim_{\delta \to 0} \frac{f(x, \theta + \delta) - f(x, \theta)}{\delta},
$$

então temos

$$
\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta} f(x, \theta) dx = \int_{-\infty}^{\infty} \lim_{\delta \to 0} \left[ \frac{f(x, \theta + \delta) - f(x, \theta)}{\delta} \right] dx,
$$

enquanto

$$
\frac{d}{d\theta} \int_{-\infty}^{\infty} f(x, \theta) dx = \lim_{\delta \to 0} \int_{-\infty}^{\infty} \left[ \frac{f(x, \theta + \delta) - f(x, \theta)}{\delta} \right] dx.
$$

Portanto, se pudermos justificar a permuta da ordem de limites e integração, a diferenciação sob o sinal da integral será justificada. O tratamento deste problema em total generalidade exigirá, infelizmente, o uso da teoria da medida, um tópico que não será abordado neste livro. No entanto, as declarações e conclusões de alguns resultados importantes podem ser dadas. Os seguintes teoremas são todos corolários do Teorema da Convergência Dominada de Lebesgue (veja, por exemplo, Rudin (1976)).

:::{.theorem}
### Teorema 2.4.2
Suponha que a função $h(x, y)$ seja contínua em $y_0$ para cada $x$, e exista uma função $g(x)$ satisfazendo
i. $|h(x, y)| \leq g(x)$ para todos $x$ e $y$
ii. $\int_{-\infty}^{\infty} g(x) dx < \infty$.
Então
$$
\lim_{y \to y_0} \int_{-\infty}^{\infty} h(x, y) dx = \int_{-\infty}^{\infty} \lim_{y \to y_0} h(x, y) dx.
$$
:::

A condição chave neste teorema é a existência de uma função dominante $g(x)$, com uma integral finita, que garanta que as integrais não se comportem muito mal. Podemos agora aplicar este teorema ao caso que estamos considerando, identificando $h(x, y)$ com a diferença $(f(x, \theta + \delta) - f(x, \theta))/\delta$.

:::{.theorem}
### Teorema 2.4.3
Suponha que $f(x, \theta)$ seja diferenciável em $\theta = \theta_0$, isto é,
$$
\lim_{\delta \to 0} \frac{f(x, \theta_0 + \delta) - f(x, \theta_0)}{\delta} = \frac{\partial}{\partial \theta} f(x, \theta) \Big|_{\theta = \theta_0}
$$
exista para cada $x$, e exista uma função $g(x, \theta_0)$ e uma constante $\delta_0 > 0$ tal que
i. $\left| \frac{f(x, \theta_0 + \delta) - f(x, \theta_0)}{\delta} \right| \leq g(x, \theta_0)$, para todos $x$ e $|\delta| \leq \delta_0$,
ii. $\int_{-\infty}^{\infty} g(x, \theta_0) dx < \infty$.
Então
$$
\frac{d}{d\theta} \int_{-\infty}^{\infty} f(x, \theta) dx \Big|_{\theta = \theta_0} = \int_{-\infty}^{\infty} \left[ \frac{\partial}{\partial \theta} f(x, \theta) \Big|_{\theta = \theta_0} \right] dx.
$$ {#eq-2.4.2}
:::

A condição (i) é semelhante ao que é conhecido como uma *condição de Lipschitz*, uma condição que impõe suavidade a uma função. Aqui, a condição (i) está efetivamente limitando a variabilidade na primeira derivada; outras restrições de suavidade podem limitar essa variabilidade por uma constante (em vez de uma função $g$), ou colocar um limite na variabilidade da segunda derivada de $f$.

A conclusão do Teorema 2.4.3 é um pouco pesada, mas é importante perceber que, embora pareçamos estar tratando $\theta$ como uma variável, a declaração do teorema é para um valor de $\theta$. Isto é, para cada valor $\theta_0$ para o qual $f(x, \theta)$ é diferenciável em $\theta_0$ e satisfaz as condições (i) e (ii), a ordem de integração e diferenciação pode ser permutada. Frequentemente, a distinção entre $\theta$ e $\theta_0$ não é enfatizada e @eq-2.4.2 é escrita como

$$
\frac{d}{d\theta} \int_{-\infty}^{\infty} f(x, \theta) dx = \int_{-\infty}^{\infty} \frac{\partial}{\partial \theta} f(x, \theta) dx.
$$ {#eq-2.4.3}

Tipicamente, $f(x, \theta)$ é diferenciável em todos os $\theta$, não apenas em um valor $\theta_0$. Neste caso, a condição (i) do Teorema 2.4.3 pode ser substituída por outra condição que muitas vezes se mostra mais fácil de verificar. Por uma aplicação do teorema do valor médio, segue que, para $x$ e $\theta_0$ fixos, e $|\delta| \leq \delta_0$,

$$
\frac{f(x, \theta_0 + \delta) - f(x, \theta_0)}{\delta} = \frac{\partial}{\partial \theta} f(x, \theta) \Big|_{\theta = \theta_0 + \delta^*(x)}
$$

para algum número $\delta^*(x), |\delta^*(x)| \leq \delta_0$. Portanto, a condição (i) será satisfeita se encontrarmos uma $g(x, \theta)$ que satisfaça a condição (ii) e

$$
\left| \frac{\partial}{\partial \theta} f(x, \theta) \Big|_{\theta = \theta'} \right| \leq g(x, \theta) \quad \text{para todos } \theta' \text{ tais que } |\theta' - \theta| \leq \delta_0.
$$ {#eq-2.4.4}

Note que em @eq-2.4.4 $\delta_0$ é implicitamente uma função de $\theta$, como é o caso no Teorema 2.4.3. Isto é permitido, já que o teorema é aplicado a cada valor de $\theta$ individualmente. De @eq-2.4.4 obtemos o seguinte corolário.

:::{.theorem}
### Corolário 2.4.4
Suponha que $f(x, \theta)$ seja diferenciável em $\theta$ e exista uma função $g(x, \theta)$ tal que @eq-2.4.4 seja satisfeita e $\int_{-\infty}^{\infty} g(x, \theta) dx < \infty$. Então @eq-2.4.3 se mantém.
:::

Observe que tanto a condição (i) do Teorema 2.4.3 quanto @eq-2.4.4 impõem um requisito de uniformidade nas funções a serem limitadas; algum tipo de uniformidade é geralmente necessário antes que derivadas e integrais possam ser permutadas.

:::{.example}
### Exemplo 2.4.5 (Intercambiando integração e diferenciação—I)
Seja $X$ com a fdp exponencial($\lambda$) dada por $f(x) = (1/\lambda)e^{-x/\lambda}, 0 < x < \infty$, e suponha que queiramos calcular

$$
\frac{d}{d\lambda} EX^n = \frac{d}{d\lambda} \int_{0}^{\infty} x^n \left( \frac{1}{\lambda} \right) e^{-x/\lambda} dx,
$$ {#eq-2.4.5}

para um inteiro $n > 0$. Se pudéssemos mover a diferenciação para dentro da integral, teríamos

$$
\begin{aligned}
\frac{d}{d\lambda} EX^n &= \int_{0}^{\infty} \frac{\partial}{\partial \lambda} x^n \left( \frac{1}{\lambda} \right) e^{-x/\lambda} dx \\
&= \int_{0}^{\infty} \frac{x^n}{\lambda^2} \left( \frac{x}{\lambda} - 1 \right) e^{-x/\lambda} dx \\
&= \frac{1}{\lambda^2} EX^{n+1} - \frac{1}{\lambda} EX^n.
\end{aligned}
$$ {#eq-2.4.6}

Para justificar a permuta de integração e diferenciação, limitamos a derivada de $x^n(1/\lambda)e^{-x/\lambda}$. Agora

$$
\left| \frac{\partial}{\partial \lambda} \frac{x^n e^{-x/\lambda}}{\lambda} \right| = \frac{x^n e^{-x/\lambda}}{\lambda^2} \left| \frac{x}{\lambda} - 1 \right| \leq \frac{x^n e^{-x/\lambda}}{\lambda^2} \left( \frac{x}{\lambda} + 1 \right). \quad (\text{visto que } \frac{x}{\lambda} > 0)
$$

Para alguma constante $\delta_0$ satisfazendo $0 < \delta_0 < \lambda$, tome

$$
g(x, \lambda) = \frac{x^n e^{-x/(\lambda + \delta_0)}}{(\lambda - \delta_0)^2} \left( \frac{x}{\lambda - \delta_0} + 1 \right).
$$

Temos então

$$
\left| \frac{\partial}{\partial \lambda} \left( \frac{x^n e^{-x/\lambda}}{\lambda} \right) \Big|_{\lambda = \lambda'} \right| \leq g(x, \lambda) \quad \text{para todos } \lambda' \text{ tais que } |\lambda' - \lambda| \leq \delta_0.
$$

Como a distribuição exponencial possui todos os seus momentos, $\int_{-\infty}^{\infty} g(x, \lambda) dx < \infty$ contanto que $\lambda - \delta_0 > 0$, então a permuta de integração e diferenciação é justificada. ||
:::

A propriedade ilustrada para a distribuição exponencial vale para uma grande classe de densidades, que serão abordadas na Seção 3.4.
Observe que @eq-2.4.6 nos dá uma relação de recorrência para os momentos da distribuição exponencial,

$$
EX^{n+1} = \lambda EX^n + \lambda^2 \frac{d}{d\lambda} EX^n,
$$ {#eq-2.4.7}

tornando o cálculo do $(n+1)$-ésimo momento relativamente fácil. Este tipo de relacionamento existe para outras distribuições. Em particular, se $X$ tem uma distribuição normal com média $\mu$ e variância 1, então ela tem fdp $f(x) = (1/\sqrt{2\pi})e^{-(x-\mu)^2/2}$, então

$$
EX^{n+1} = \mu EX^n + \frac{d}{d\mu} EX^n.
$$

Ilustramos mais uma permuta de diferenciação e integração, uma envolvendo a função geradora de momentos.

:::{.example}
### Exemplo 2.4.6 (Intercambiando integração e diferenciação—II)
Novamente, seja $X$ com uma distribuição normal com média $\mu$ e variância 1, e considere a fgm de $X$,

$$
M_X(t) = Ee^{tX} = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{tx} e^{-(x-\mu)^2/2} dx.
$$

Na Seção 2.3 foi afirmado que podemos calcular momentos por diferenciação de $M_X(t)$, e a diferenciação sob o sinal da integral foi justificada:

$$
\frac{d}{dt} M_X(t) = \frac{d}{dt} Ee^{tX} = E \frac{\partial}{\partial t} e^{tX} = E(X e^{tX}).
$$ {#eq-2.4.8}

Podemos aplicar os resultados desta seção para justificar as operações em @eq-2.4.8. Observe que ao aplicar o Teorema 2.4.3 ou o Corolário 2.4.4 aqui, identificamos $t$ com a variável $\theta$ no Teorema 2.4.3. O parâmetro $\mu$ é tratado como uma constante.
Pelo Corolário 2.4.4, devemos encontrar uma função $g(x, t)$, com integral finita, que satisfaça

$$
\left| \frac{\partial}{\partial t} e^{tx} e^{-(x-\mu)^2/2} \Big|_{t=t'} \right| \leq g(x, t) \quad \text{para todos } t' \text{ tais que } |t' - t| \leq \delta_0.
$$ {#eq-2.4.9}

Fazendo o óbvio, temos

$$
\left| \frac{\partial}{\partial t} e^{tx} e^{-(x-\mu)^2/2} \right| = |x e^{tx} e^{-(x-\mu)^2/2}| \leq |x| e^{tx} e^{-(x-\mu)^2/2}.
$$

É mais fácil definir nossa função $g(x, t)$ separadamente para $x \geq 0$ e $x < 0$. Tomamos

$$
g(x, t) = 
\begin{cases}
|x| e^{(t-\delta_0)x} e^{-(x-\mu)^2/2} & \text{se } x < 0 \\
|x| e^{(t+\delta_0)x} e^{-(x-\mu)^2/2} & \text{se } x \geq 0.
\end{cases}
$$

É claro que esta função satisfaz @eq-2.4.9; resta verificar que sua integral é finita. Para $x \geq 0$ temos

$$
g(x, t) = x e^{-(x^2 - 2x(\mu+t+\delta_0) + \mu^2)/2}.
$$

Agora completamos o quadrado no expoente, ou seja, escrevemos

$$
\begin{aligned}
x^2 - 2x(\mu + t + \delta_0) + \mu^2 &= x^2 - 2x(\mu + t + \delta_0) + (\mu + t + \delta_0)^2 - (\mu + t + \delta_0)^2 + \mu^2 \\
&= (x - (\mu + t + \delta_0))^2 + \mu^2 - (\mu + t + \delta_0)^2,
\end{aligned}
$$

e assim, para $x \geq 0$,

$$
g(x, t) = x e^{-[x - (\mu + t + \delta_0)]^2/2} e^{-[\mu^2 - (\mu + t + \delta_0)^2]/2}.
$$

Como o último fator exponencial nesta expressão não depende de $x$, $\int_{0}^{\infty} g(x, t) dx$ é essencialmente o cálculo da média de uma distribuição normal com média $\mu + t + \delta_0$, exceto que a integração é apenas sobre $[0, \infty)$. No entanto, segue que a integral é finita porque a distribuição normal tem uma média finita (a ser mostrada no Capítulo 3). Um desenvolvimento semelhante para $x < 0$ mostra que $\int_{-\infty}^{0} g(x, t) dx < \infty$. Portanto, encontramos uma função integrável satisfazendo @eq-2.4.9 e a operação em @eq-2.4.8 é justificada. ||
:::

Voltamo-nos agora para a questão de quando é possível permutar diferenciação e somatório, uma operação que desempenha um papel importante em distribuições discretas. É claro que estamos preocupados apenas com somas infinitas, já que uma derivada sempre pode ser levada para dentro de uma soma finita.

:::{.example}
### Exemplo 2.4.7 (Intercambiando somatório e diferenciação)
Seja $X$ uma variável aleatória discreta com a distribuição geométrica

$$
P(X = x) = \theta(1-\theta)^x, \quad x = 0, 1, \dots, \quad 0 < \theta < 1.
$$

Temos que $\sum_{x=0}^{\infty} \theta(1-\theta)^x = 1$ e, desde que as operações sejam justificadas,

$$
\begin{aligned}
\frac{d}{d\theta} \sum_{x=0}^{\infty} \theta(1-\theta)^x &= \sum_{x=0}^{\infty} \frac{d}{d\theta} \theta(1-\theta)^x \\
&= \sum_{x=0}^{\infty} [(1-\theta)^x - \theta x(1-\theta)^{x-1}] \\
&= \frac{1}{\theta} \sum_{x=0}^{\infty} \theta(1-\theta)^x - \frac{1}{1-\theta} \sum_{x=0}^{\infty} x\theta(1-\theta)^x.
\end{aligned}
$$

Como $\sum_{x=0}^{\infty} \theta(1-\theta)^x = 1$ para todo $0 < \theta < 1$, sua derivada é zero. Então temos

$$
\frac{1}{\theta} \sum_{x=0}^{\infty} \theta(1-\theta)^x - \frac{1}{1-\theta} \sum_{x=0}^{\infty} x\theta(1-\theta)^x = 0.
$$ {#eq-2.4.10}

Agora a primeira soma em @eq-2.4.10 é igual a 1 e a segunda soma é $EX$, logo @eq-2.4.10 torna-se

$$
\frac{1}{\theta} - \frac{1}{1-\theta} EX = 0,
$$

ou

$$
EX = \frac{1-\theta}{\theta}.
$$

Nós, em essência, somamos a série $\sum_{x=0}^{\infty} x\theta(1-\theta)^x$ por diferenciação. ||
:::

A justificativa de levar a derivada para dentro do somatório é mais direta do que o caso da integração. O teorema a seguir fornece os detalhes.

:::{.theorem}
### Teorema 2.4.8
Suponha que a série $\sum_{x=0}^{\infty} h(\theta, x)$ convirja para todos os $\theta$ em um intervalo $(a, b)$ de números reais e
i. $\frac{\partial}{\partial \theta} h(\theta, x)$ seja contínua em $\theta$ para cada $x$,
ii. $\sum_{x=0}^{\infty} \frac{\partial}{\partial \theta} h(\theta, x)$ convirja uniformemente em cada subintervalo fechado e limitado de $(a, b)$.
Então
$$
\frac{d}{d\theta} \sum_{x=0}^{\infty} h(\theta, x) = \sum_{x=0}^{\infty} \frac{\partial}{\partial \theta} h(\theta, x).
$$ {#eq-2.4.11}
:::

A condição de convergência uniforme é a chave a ser verificada para estabelecer que a diferenciação pode ser levada para dentro do somatório. Lembre-se que uma série converge uniformemente se sua sequência de somas parciais convergir uniformemente, um fato que usamos no exemplo a seguir.

:::{.example}
### Exemplo 2.4.9 (Continuação do Exercício 2.4.7)
Para aplicar o Teorema 2.4.8 identificamos

$$
h(\theta, x) = \theta(1-\theta)^x,
$$

e

$$
\frac{\partial}{\partial \theta} h(\theta, x) = (1-\theta)^x - \theta x(1-\theta)^{x-1},
$$

e verificamos que $\sum_{x=0}^{\infty} \frac{\partial}{\partial \theta} h(\theta, x)$ converge uniformemente. Defina $S_n(\theta)$ por

$$
S_n(\theta) = \sum_{x=0}^{n} [(1-\theta)^x - \theta x(1-\theta)^{x-1}].
$$

A convergência será uniforme em $[c, d] \subset (0, 1)$ se, dado $\varepsilon > 0$, pudermos encontrar um $N$ tal que

$$
n > N \implies |S_n(\theta) - S_{\infty}(\theta)| < \varepsilon \quad \text{para todos } \theta \in [c, d].
$$

Lembre-se da soma parcial da série geométrica (1.5.3). Se $y \neq 1$, então podemos escrever

$$
\sum_{k=0}^{n} y^k = \frac{1 - y^{n+1}}{1 - y}.
$$

Aplicando isto, temos

$$
\sum_{x=0}^{n} (1-\theta)^x = \frac{1 - (1-\theta)^{n+1}}{\theta}
$$

$$
\sum_{x=0}^{n} \theta x(1-\theta)^{x-1} = \theta \sum_{x=0}^{n} - \frac{\partial}{\partial \theta} (1-\theta)^x = -\theta \frac{d}{d\theta} \sum_{x=0}^{n} (1-\theta)^x = -\theta \frac{d}{d\theta} \left[ \frac{1 - (1-\theta)^{n+1}}{\theta} \right].
$$

Aqui nós (justificadamente) puxamos a derivada através da soma finita. Calcular esta derivada resulta em

$$
\sum_{x=0}^{n} \theta x(1-\theta)^{x-1} = \frac{(1 - (1-\theta)^{n+1}) - (n+1)\theta(1-\theta)^n}{\theta},
$$

e, consequentemente,

$$
\begin{aligned}
S_n(\theta) &= \frac{1 - (1-\theta)^{n+1}}{\theta} - \frac{(1 - (1-\theta)^{n+1}) - (n+1)\theta(1-\theta)^n}{\theta} \\
&= (n+1)(1-\theta)^n.
\end{aligned}
$$

É claro que, para $0 < \theta < 1$, $S_{\infty} = \lim_{n \to \infty} S_n(\theta) = 0$. Como $S_n(\theta)$ é contínua, a convergência é uniforme em qualquer intervalo limitado e fechado. Portanto, a série de derivadas converge uniformemente e a permuta de diferenciação e somatório é justificada. ||
:::

Encerramos esta seção com um teorema que é semelhante ao Teorema 2.4.8, mas trata do caso de permutar a ordem de somatório e integração.

:::{.theorem}
### Teorema 2.4.10
Suponha que a série $\sum_{x=0}^{\infty} h(\theta, x)$ convirja uniformemente em $[a, b]$ e que, para cada $x$, $h(\theta, x)$ seja uma função contínua de $\theta$. Então
$$
\int_{a}^{b} \sum_{x=0}^{\infty} h(\theta, x) d\theta = \sum_{x=0}^{\infty} \int_{a}^{b} h(\theta, x) d\theta.
$$
:::

## 2.5 Exercícios

**2.1** Em cada um dos seguintes itens, encontre a fdp de $Y$. Mostre que a fdp integra 1.
(a) $Y = X^3$ e $f_X(x) = 42x^5(1-x), 0 < x < 1$.
(b) $Y = 4X + 3$ e $f_X(x) = 7e^{-7x}, 0 < x < \infty$.
(c) $Y = X^2$ e $f_X(x) = 30x^2(1-x)^2, 0 < x < 1$.
(Veja o Exemplo 12.6.2 no apêndice de Álgebra Computacional.)

**2.2** Em cada um dos seguintes itens, encontre a fdp de $Y$.
(a) $Y = X^2$ e $f_X(x) = 1, 0 < x < 1$.
(b) $Y = -\log X$ e $X$ tem fdp
$$
f_X(x) = \frac{(n+m+1)!}{n!m!} x^n (1-x)^m, \quad 0 < x < 1, \quad m, n \text{ inteiros positivos}.
$$
(c) $Y = e^X$ e $X$ tem fdp
$$
f_X(x) = \frac{1}{\sigma^2} x e^{-(x/\sigma)^2/2}, \quad 0 < x < \infty, \quad \sigma^2 \text{ uma constante positiva}.
$$

**2.3** Suponha que $X$ tenha a fmp geométrica, $f_X(x) = \frac{1}{3} \left(\frac{2}{3}\right)^x, x = 0, 1, 2, \dots$. Determine a distribuição de probabilidade de $Y = X/(X+1)$. Note que aqui tanto $X$ quanto $Y$ são variáveis aleatórias discretas. Para especificar a distribuição de probabilidade de $Y$, especifique sua fmp.

**2.4** Seja $\lambda$ uma constante positiva fixa, e defina a função $f(x)$ por $f(x) = \frac{1}{2}\lambda e^{-\lambda x}$ se $x \geq 0$ e $f(x) = \frac{1}{2}\lambda e^{\lambda x}$ se $x < 0$.
(a) Verifique que $f(x)$ é uma fdp.
(b) Se $X$ é uma variável aleatória com fdp dada por $f(x)$, encontre $P(X < t)$ para todo $t$. Avalie todas as integrais.
(c) Encontre $P(|X| < t)$ para todo $t$. Avalie todas as integrais.

**2.5** Use o Teorema 2.1.8 para encontrar a fdp de $Y$ no Exemplo 2.1.2. Mostre que a mesma resposta é obtida diferenciando a fda dada em (2.1.6).

**2.6** Em cada um dos seguintes itens, encontre a fdp de $Y$ e mostre que a fdp integra 1.
(a) $f_X(x) = \frac{1}{2} e^{-|x|}, -\infty < x < \infty; Y = |X|^3$.
(b) $f_X(x) = \frac{3}{8}(x+1)^2, -1 < x < 1; Y = 1 - X^2$.
(c) $f_X(x) = \frac{3}{8}(x+1)^2, -1 < x < 1; Y = 1 - X^2$ se $X \leq 0$ e $Y = 1 - X$ se $X > 0$.

**2.7** Seja $X$ com fdp $f_X(x) = \frac{2}{9}(x+1), -1 \leq x \leq 2$.
(a) Encontre a fdp de $Y = X^2$. Note que o Teorema 2.1.8 não é diretamente aplicável neste problema.
(b) Mostre que o Teorema 2.1.8 permanece válido se os conjuntos $A_0, A_1, \dots, A_k$ contiverem $\mathcal{X}$, e aplique a extensão para resolver a parte (a) usando $A_0 = \emptyset, A_1 = (-2, 0)$ e $A_2 = (0, 2)$.

**2.8** Em cada um dos seguintes itens, mostre que a função dada é uma fda e encontre $F_X^{-1}(y)$.
(a) $F_X(x) = \begin{cases} 0 & \text{se } x < 0 \\ 1 - e^{-x} & \text{se } x \geq 0. \end{cases}$
(b) $F_X(x) = \begin{cases} e^x/2 & \text{se } x < 0 \\ 1/2 & \text{se } 0 \leq x < 1 \\ 1 - (e^{1-x}/2) & \text{se } 1 \leq x. \end{cases}$
(c) $F_X(x) = \begin{cases} e^x/4 & \text{se } x < 0 \\ 1 - (e^{-x}/4) & \text{se } x \geq 0. \end{cases}$
Note que, na parte (c), $F_X(x)$ é descontínua, mas (2.1.13) ainda é a definição apropriada de $F_X^{-1}(y)$.

**2.9** Se a variável aleatória $X$ tem fdp
$$
f(x) = \begin{cases} \frac{x-1}{2} & 1 < x < 3 \\ 0 & \text{caso contrário}, \end{cases}
$$
encontre uma função monotônica $u(x)$ tal que a variável aleatória $Y = u(X)$ tenha uma distribuição uniforme(0,1).

**2.10** No Teorema 2.1.10, a transformação integral de probabilidade foi provada, relacionando a fda uniforme a qualquer fda contínua. Neste exercício, investigamos a relação entre variáveis aleatórias discretas e variáveis aleatórias uniformes. Seja $X$ uma variável aleatória discreta com fda $F_X(x)$ e defina a variável aleatória $Y$ como $Y = F_X(X)$.
(a) Prove que $Y$ é estocasticamente maior que uma uniforme(0,1); isto é, se $U \sim \text{uniforme}(0,1)$, então
$$
P(Y > y) \geq P(U > y) = 1 - y, \quad \text{para todo } y, 0 < y < 1,
$$
$$
P(Y > y) > P(U > y) = 1 - y, \quad \text{para algum } y, 0 < y < 1.
$$
(Lembre-se que *estocasticamente maior* foi definido no Exercício 1.49.)
(b) Equivalentemente, mostre que a fda de $Y$ satisfaz $F_Y(y) \leq y$ para todo $0 < y < 1$ e $F_Y(y) < y$ para algum $0 < y < 1$. (*Dica*: Seja $x_0$ um ponto de salto de $F_X$, e defina $y_0 = F_X(x_0)$. Mostre que $P(Y \leq y_0) = y_0$. Agora estabeleça a desigualdade considerando $y = y_0 + \varepsilon$. Imagens das fdas ajudarão.)

**2.11** Seja $X$ com a fdp normal padrão, $f_X(x) = (1/\sqrt{2\pi})e^{-x^2/2}$.
(a) Encontre $EX^2$ diretamente, e então usando a fdp de $Y = X^2$ do Exemplo 2.1.7 e calculando $EY$.
(b) Encontre a fdp de $Y = |X|$, e encontre sua média e variância.

**2.12** Um triângulo retângulo aleatório pode ser construído da seguinte maneira. Seja $X$ um ângulo aleatório cuja distribuição é uniforme em $(0, \pi/2)$. Para cada $X$, construa um triângulo como ilustrado abaixo. Aqui, $Y = \text{altura do triângulo retângulo}$. Para uma constante fixa $d$, encontre a distribuição de $Y$ e $EY$.

![Figura 2.5.1 - Triângulo retângulo aleatório](fig/fig-2_12.png){#fig-2.5.1 width=40%}

**2.13** Considere uma sequência de lançamentos de moedas independentes, cada um com probabilidade $p$ de ser Cara. Defina uma variável aleatória $X$ como o comprimento da sequência (de Caras ou Coras) iniciada pela primeira tentativa. (Por exemplo, $X = 3$ se TTTC ou CCCK for observado.) Encontre a distribuição de $X$ e encontre $EX$.

**2.14** (a) Seja $X$ uma variável aleatória contínua e não negativa [$f(x) = 0$ para $x < 0$]. Mostre que
$$
EX = \int_0^\infty [1 - F_X(x)] dx,
$$
onde $F_X(x)$ é a fda de $X$.
(b) Seja $X$ uma variável aleatória discreta cujo intervalo são os inteiros não negativos. Mostre que
$$
EX = \sum_{k=0}^\infty (1 - F_X(k)),
$$
onde $F_X(k) = P(X \leq k)$. Compare isso com a parte (a).

**2.15** Betteley (1977) fornece uma lei de adição interessante para expectativas. Sejam $X$ e $Y$ duas variáveis aleatórias quaisquer e defina
$$
X \land Y = \min(X, Y) \quad \text{e} \quad X \lor Y = \max(X, Y).
$$
De forma análoga à lei de probabilidade $P(A \cup B) = P(A) + P(B) - P(A \cap B)$, mostre que
$$
E(X \lor Y) = EX + EY - E(X \land Y).
$$
(*Dica*: Estabeleça que $X + Y = (X \lor Y) + (X \land Y)$.)

**2.16** Use o resultado do Exercício 2.14 para encontrar a duração média de certas chamadas telefônicas, onde assumimos que a duração, $T$, de uma chamada particular pode ser descrita probabilisticamente por $P(T > t) = ae^{-\lambda t} + (1-a)e^{-\mu t}$, onde $a, \lambda$ e $\mu$ são constantes, $0 < a < 1, \lambda > 0, \mu > 0$.

**2.17** Uma *mediana* de uma distribuição é um valor $m$ tal que $P(X \leq m) \geq 1/2$ e $P(X \geq m) \geq 1/2$. (Se $X$ é contínua, $m$ satisfaz $\int_{-\infty}^m f(x) dx = \int_m^\infty f(x) dx = 1/2$.) Encontre a mediana das seguintes distribuições.
(a) $f(x) = 3x^2, 0 < x < 1$
(b) $f(x) = \frac{1}{\pi(1+x^2)}, -\infty < x < \infty$

**2.18** Mostre que se $X$ é uma variável aleatória contínua, então
$$
\min_a E|X - a| = E|X - m|,
$$
onde $m$ é a mediana de $X$ (veja o Exercício 2.17).

**2.19** Prove que
$$
\frac{d}{da} E(X - a)^2 = 0 \iff EX = a,
$$
diferenciando a integral. Verifique, usando cálculo, que $a = EX$ é de fato um mínimo. Liste as suposições sobre $F_X$ e $f_X$ que são necessárias.

**2.20** Um casal decide continuar a ter filhos até que uma filha nasça. Qual é o número esperado de filhos deste casal? (*Dica*: Veja o Exemplo 1.5.4.)

**2.21** Prove a regra de "duas vias" para expectativas, equação (2.2.5), que diz $Eg(X) = EY$, onde $Y = g(X)$. Assuma que $g(x)$ é uma função monotônica.

**2.22** Seja $X$ com a fdp
$$
f(x) = \frac{4}{\beta^3\sqrt{\pi}} x^2 e^{-x^2/\beta^2}, \quad 0 < x < \infty, \quad \beta > 0.
$$
(a) Verifique que $f(x)$ é uma fdp.
(b) Encontre $EX$ e $Var X$.

**2.23** Seja $X$ com a fdp
$$
f(x) = \frac{1}{2}(1+x), \quad -1 < x < 1.
$$
(a) Encontre a fdp de $Y = X^2$.
(b) Encontre $EY$ e $Var Y$.

**2.24** Calcule $EX$ e $Var X$ para cada uma das seguintes distribuições de probabilidade.
(a) $f_X(x) = ax^{a-1}, 0 < x < 1, a > 0$
(b) $f_X(x) = 1/n, x = 1, 2, \dots, n, n > 0$ um inteiro
(c) $f_X(x) = \frac{3}{2}(x-1)^2, 0 < x < 2$

**2.25** Suponha que a fdp $f_X(x)$ de uma variável aleatória $X$ seja uma *função par*. ($f_X(x)$ é uma função par se $f_X(x) = f_X(-x)$ para todo $x$.) Mostre que
(a) $X$ e $-X$ são identicamente distribuídas.
(b) $M_X(t)$ é simétrica em torno de zero.

**2.26** Seja $f(x)$ uma fdp e seja $a$ um número tal que, para todo $\varepsilon > 0, f(a+\varepsilon) = f(a-\varepsilon)$. Tal fdp é dita ser *simétrica em torno do ponto a*.
(a) Dê três exemplos de fdps simétricas.
(b) Mostre que se $X \sim f(x)$, simétrica, então a mediana de $X$ (veja o Exercício 2.17) é o número $a$.
(c) Mostre que se $X \sim f(x)$, simétrica, e $EX$ existe, então $EX = a$.
(d) Mostre que $f(x) = e^{-x}, x \geq 0$, não é uma fdp simétrica.
(e) Mostre que para a fdp na parte (d), a mediana é menor que a média.

**2.27** Seja $f(x)$ uma fdp e seja $a$ um número tal que, se $a \geq x \geq y$ então $f(a) \geq f(x) \geq f(y)$ e, se $a \leq x \leq y$ então $f(a) \geq f(x) \geq f(y)$. Tal fdp é chamada de *unimodal* com um *moda* igual a $a$.
(a) Dê um exemplo de uma fdp unimodal para a qual a moda é única.
(b) Dê um exemplo de uma fdp unimodal para a qual a moda não é única.
(c) Mostre que se $f(x)$ é tanto simétrica (veja o Exercício 2.26) quanto unimodal, então o ponto de simetria é uma moda.
(d) Considere a fdp $f(x) = e^{-x}, x \geq 0$. Mostre que esta fdp é unimodal. Qual é sua moda?

**2.28** Seja $\mu_n$ o $n$-ésimo momento central de uma variável aleatória $X$. Duas quantidades de interesse, além da média e variância, são
$$
\alpha_3 = \frac{\mu_3}{(\mu_2)^{3/2}} \quad \text{e} \quad \alpha_4 = \frac{\mu_4}{\mu_2^2}.
$$
O valor $\alpha_3$ é chamado de *assimetria* e $\alpha_4$ é chamado de *curtose*. A assimetria mede a falta de simetria na fdp (veja o Exercício 2.26). A curtose, embora mais difícil de interpretar, mede o pico ou achatamento da fdp.
(a) Mostre que se uma fdp é simétrica em torno de um ponto $a$, então $\alpha_3 = 0$.
(b) Calcule $\alpha_3$ para $f(x) = e^{-x}, x \geq 0$, uma fdp que é *assimétrica à direita*.
(c) Calcule $\alpha_4$ para cada uma das seguintes fdps e comente sobre o pico de cada uma.
$$
f(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}, \quad -\infty < x < \infty
$$
$$
f(x) = \frac{1}{2}, \quad -1 < x < 1
$$
$$
f(x) = \frac{1}{2} e^{-|x|}, \quad -\infty < x < \infty
$$
Ruppert (1987) usa *funções de influência* (Seção 10.6.4) para explorar ainda mais o significado de curtose e Groeneveld (1991) as usa para explorar a assimetria; veja também Balanda e MacGillivray (1988) para mais sobre a interpretação de $\alpha_4$.

**2.29** Ao calcular momentos de distribuições discretas, muitas vezes é mais fácil trabalhar com os *momentos fatoriais* (veja Assuntos Diversos 2.6.2).
(a) Calcule o momento fatorial $E[X(X-1)]$ para as distribuições binomial e Poisson.
(b) Use os resultados da parte (a) para calcular as variâncias da distribuição binomial e Poisson.
(c) Uma distribuição discreta particularmente desagradável é a beta-binomial, com fmp
$$
P(Y = y) = \binom{n}{y} \frac{\Gamma(y+a)\Gamma(n-y+b)\Gamma(a+b)}{\Gamma(a)\Gamma(b)\Gamma(n+a+b)}, \quad y = 0, 1, \dots, n.
$$
onde $n, a$ e $b$ são inteiros positivos. Use momentos fatoriais para calcular a variância da beta binomial. (Veja o Exercício 4.34 para outra abordagem deste cálculo.)

**2.30** Encontre a função geradora de momentos correspondente a
(a) $f(x) = \frac{1}{c}, 0 < x < c$
(b) $f(x) = \frac{2x}{c^2}, 0 < x < c$
(c) $f(x) = \frac{1}{2\beta} e^{-|x-\alpha|/\beta}, -\infty < x < \infty, -\infty < \alpha < \infty, \beta > 0$
(d) $P(X = x) = \binom{r+x-1}{x} p^r(1-p)^x, x = 0, 1, \dots, 0 < p < 1, r > 0$ um inteiro

**2.31** Existe uma distribuição para a qual $M_X(t) = t/(1-t), |t| < 1$? Se sim, encontre-a. Se não, prove.

**2.32** Seja $M_X(t)$ a função geradora de momentos de $X$, e defina $S(t) = \log(M_X(t))$. Mostre que
$$
\frac{d}{dt} S(t) \Big|_{t=0} = EX \quad \text{e} \quad \frac{d^2}{dt^2} S(t) \Big|_{t=0} = Var X.
$$

**2.33** Em cada um dos seguintes casos, verifique a expressão dada para a função geradora de momentos e, em cada caso, use a fgm para calcular $EX$ e $Var X$.
(a) $P(X = x) = \frac{e^{-\lambda} \lambda^x}{x!}, M_X(t) = e^{\lambda(e^t-1)}, x = 0, 1, \dots; \lambda > 0$
(b) $P(X = x) = p(1-p)^x, M_X(t) = \frac{p}{1-(1-p)e^t}, x = 0, 1, \dots; 0 < p < 1$
(c) $f_X(x) = \frac{e^{-(x-\mu)^2/(2\sigma^2)}}{\sqrt{2\pi}\sigma}, M_X(t) = e^{\mu t + \sigma^2t^2/2}, -\infty < x < \infty; -\infty < \mu < \infty, \sigma > 0$

**2.34** Uma distribuição não pode ser unicamente determinada por uma coleção finita de momentos, como mostra este exemplo de Romano e Siegel (1986). Seja $X$ com distribuição normal, ou seja, $X$ tem fdp
$$
f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}, \quad -\infty < x < \infty.
$$
Defina uma variável aleatória discreta $Y$ por
$$
P(Y = \sqrt{3}) = P(Y = -\sqrt{3}) = 1/6, \quad P(Y = 0) = 2/3.
$$
Mostre que
$$
EX^r = EY^r \quad \text{para } r = 1, 2, 3, 4, 5.
$$
(Romano e Siegel (1986) apontam que para qualquer $n$ finito existe uma variável aleatória discreta, e portanto não normal, cujos primeiros $n$ momentos são iguais aos de $X$.)

**2.35** Preencha as lacunas no Exemplo 2.3.10.
(a) Mostre que se $X_1 \sim f_1(x)$, então
$$
EX_1^r = e^{r^2/2}, \quad r = 0, 1, \dots.
$$
Logo $f_1(x)$ possui todos os seus momentos, e todos os momentos são finitos.
(b) Agora mostre que
$$
\int_0^\infty x^r f_1(x) \sin(2\pi \log x) dx = 0,
$$
para todos os inteiros positivos $r$, logo $EX_1^r = EX_2^r$ para todo $r$. (Romano e Siegel (1986) discutem uma versão extrema deste exemplo, onde uma classe inteira de fdps distintas tem os mesmos momentos. Além disso, Berg (1988) mostrou que este comportamento de momentos pode surgir com transformadas mais simples da distribuição normal, como $X^3$.)

**2.36** A *distribuição lognormal*, na qual o Exemplo 2.3.10 se baseia, tem uma propriedade interessante. Se tivermos a fdp
$$
f(x) = \frac{1}{\sqrt{2\pi}x} e^{-(\log x)^2/2}, \quad 0 \leq x < \infty,
$$
então o Exercício 2.35 mostra que todos os momentos existem e são finitos. No entanto, esta distribuição não possui uma função geradora de momentos, isto é,
$$
M_X(t) = \int_0^\infty \frac{e^{tx}}{\sqrt{2\pi}x} e^{-(\log x)^2/2} dx
$$
não existe. Prove isso.

**2.37** Referindo-se à situação descrita em Assuntos Diversos 2.6.3:
(a) Trace as fdps $f_1$ e $f_2$ para ilustrar sua diferença.
(b) Trace as funções geradoras de cumulantes $K_1$ e $K_2$ para ilustrar sua semelhança.
(c) Calcule as funções geradoras de momentos das fdps $f_1$ e $f_2$. Elas são semelhantes ou diferentes?
(d) Como as fdps $f_1$ e $f_2$ se relacionam com as fdps descritas no Exemplo 2.3.10?

**2.38** Seja $X$ com a distribuição binomial negativa com fmp
$$
f(x) = \binom{r+x-1}{x} p^r(1-p)^x, \quad x = 0, 1, 2, \dots
$$
onde $0 < p < 1$ e $r > 0$ é um inteiro.
(a) Calcule a fgm de $X$.
(b) Defina uma nova variável aleatória por $Y = 2pX$. Mostre que, conforme $p \downarrow 0$, a fgm de $Y$ converge para a de uma variável aleatória qui-quadrado com $2r$ graus de liberdade, mostrando que
$$
\lim_{p \to 0} M_Y(t) = \left( \frac{1}{1-2t} \right)^r, \quad |t| < 1/2.
$$

**2.39** Em cada um dos seguintes casos, calcule as derivadas indicadas, justificando todas as operações.
(a) $\frac{d}{dx} \int_0^x e^{-\lambda t} dt$
(b) $\frac{d}{d\lambda} \int_0^\infty e^{-\lambda t} dt$
(c) $\frac{d}{dt} \int_t^1 \frac{1}{x^2} dx$
(d) $\frac{d}{dt} \int_1^\infty \frac{1}{(x-t)^2} dx$

**2.40** Prove
$$
\sum_{k=0}^x \binom{n}{k} p^k(1-p)^{n-k} = (n-x) \binom{n}{x} \int_0^{1-p} t^{n-x-1}(1-t)^x dt.
$$
(*Dica*: Integre por partes ou diferencie ambos os lados em relação a $p$.)

## 2.6 Assuntos Diversos

### 2.6.1 Unicidade de Sequências de Momentos

Uma distribuição não é necessariamente determinada por seus momentos. Mas se $\sum_{r=1}^{\infty} \mu'_r t^r/r!$ possui um raio de convergência positivo, onde $X \sim F_X$ e $EX^r = \mu'_r$, então a sequência de momentos é única e, portanto, a distribuição é unicamente determinada (Billingsley 1995, Seção 30). A convergência desta soma também implica que a função geradora de momentos existe em um intervalo e, portanto, a função geradora de momentos determina a distribuição.

Uma condição suficiente para que a sequência de momentos seja única é a *Condição de Carleman* (Chung 1974). Se $X \sim F_X$ e denotamos $EX^r = \mu'_r$, então a sequência de momentos é única se

$$
\sum_{r=1}^{\infty} \frac{1}{(\mu'_{2r})^{1/(2r)}} = +\infty.
$$ {#eq-2.6.1}

Esta condição é, em geral, difícil de verificar.

Feller (1971) apresenta um desenvolvimento muito completo das transformadas de Laplace, das quais as fgms são um caso especial. Em particular, Feller mostra (similarmente a Billingsley) que sempre que

$$
M_X(t) = \sum_{r=0}^{\infty} \frac{\mu'_r t^r}{r!}
$$

converge em um intervalo $-t_0 \leq t < t_0, t_0 > 0$, a distribuição $F_X$ é unicamente determinada. Assim, quando a fgm existe, a sequência de momentos determina a distribuição $F_X$ univocamente.

Deve estar claro que usar a fgm para determinar a distribuição é uma tarefa difícil. Um método melhor é através do uso de *funções características*, que são explicadas abaixo. Embora as funções características simplifiquem a caracterização de uma distribuição, elas necessitam da compreensão de análise complexa. Ganha-se por um lado e perde-se por outro.

### 2.6.2 Outras Funções Geradoras

Além da função geradora de momentos, há uma série de outras funções geradoras disponíveis. Na maioria dos casos, a função característica é a mais útil destas. Exceto por circunstâncias raras, as outras funções geradoras são menos úteis, mas há situações em que elas podem facilitar os cálculos.

**Função geradora de cumulantes** Para uma variável aleatória $X$, a função geradora de cumulantes é a função $\log[M_X(t)]$. Esta função pode ser usada para gerar os *cumulantes* de $X$, que são definidos (de forma um tanto indireta) como os coeficientes na série de Taylor da função geradora de cumulantes (veja o Exercício 2.32).

**Função geradora de momentos fatoriais** A função geradora de momentos fatoriais de $X$ é definida como $Et^X$, se a esperança existir. O nome advém do fato de que esta função satisfaz

$$
\frac{d^r}{dt^r} Et^X \Big|_{t=1} = E\{X(X-1)\dots(X-r+1)\},
$$

onde o lado direito é um *momento fatorial*. Se $X$ é uma variável aleatória discreta, então podemos escrever

$$
Et^X = \sum_{x} t^x P(X = x),
$$

e a função geradora de momentos fatoriais é chamada de *função geradora de probabilidades*, visto que os coeficientes da série de potências fornecem as probabilidades. Isto é, para obter a probabilidade de que $X = k$, calcula-se

$$
\frac{1}{k!} \frac{d^k}{dt^k} Et^X \Big|_{t=0} = P(X = k).
$$

### 2.6.3 A Função Geradora de Momentos Caracteriza uma Distribuição?

Em um artigo com o título acima, McCullagh (1994) analisa um par de densidades semelhantes às do Exemplo 2.3.10, mas que possuem fgms:

$$
f_1 = n(0,1) \quad \text{e} \quad f_2 = f_1(x) \left[ 1 + \frac{1}{2} \sin(2\pi x) \right]
$$

com funções geradoras de cumulantes

$$
K_1(t) = t^2/2 \quad \text{e} \quad K_2(t) = K_1(t) + \log \left[ 1 + \frac{1}{2} e^{-2\pi^2} \sin(2\pi t) \right].
$$

Ele observa que, embora as densidades sejam visivelmente dessemelhantes, as cgfs são virtualmente idênticas, com diferença máxima inferior a $1,34 \times 10^{-9}$ em todo o intervalo (menos que o tamanho de um pixel). Portanto, a resposta à pergunta feita no título é "sim para fins matemáticos, mas um retumbante não para fins numéricos". Em contraste, Waller (1995) ilustra que, embora as fgms falhem em distinguir numericamente as distribuições, as *funções características* fazem um excelente trabalho. (Waller et al. (1995) e Luceño (1997) investigam mais a fundo a utilidade da função característica na obtenção numérica das fdas.) Veja o Exercício 2.37 para detalhes.

**Função característica** Talvez a mais útil de todos esses tipos de funções seja a função característica. A função característica de $X$ é definida por

$$
\phi_X(t) = Ee^{itX},
$$

onde $i$ é o número complexo $\sqrt{-1}$, portanto a esperança acima requer integração complexa. A função característica faz muito mais do que a fgm faz. Quando os momentos de $F_X$ existem, $\phi_X$ pode ser usada para gerá-los, de forma muito semelhante a uma fgm. A função característica sempre existe e determina completamente a distribuição. Isto é, cada fda tem uma única função característica. Assim, podemos enunciar um teorema como o Teorema 2.3.11, por exemplo, mas sem ressalvas.

:::{.theorem}
### Teorema 2.6.1 (Convergência de Funções Características)
Suponha que $X_k, k = 1, 2, \dots$, seja uma sequência de variáveis aleatórias, cada uma com função característica $\phi_{X_k}(t)$. Além disso, suponha que
$$
\lim_{k \to \infty} \phi_{X_k}(t) = \phi_X(t), \quad \text{para todo } t \text{ em uma vizinhança de 0}
$$
e $\phi_X(t)$ seja uma função característica. Então, para todo $X$ onde $F_X(x)$ é contínua,
$$
\lim_{k \to \infty} F_{X_k}(x) = F_X(x).
$$
:::

Um tratamento completo das funções geradoras é dado por Feller (1968). Funções características podem ser encontradas em quase qualquer texto avançado de probabilidade; veja Billingsley (1995) ou Resnick (1999).