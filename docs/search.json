[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "",
    "text": "Sobre Este Livro\nEste projeto √© uma tradu√ß√£o n√£o oficial para o portugu√™s brasileiro do livro Statistical Inference, de George Casella e Roger L. Berger. Seu √∫nico objetivo √© facilitar o acesso de estudantes de estat√≠stica de l√≠ngua portuguesa. Para uso acad√™mico e profissional, recomendamos fortemente a aquisi√ß√£o da obra original em ingl√™s.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Infer√™ncia Estat√≠stica</span>"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-livro",
    "href": "index.html#estrutura-do-livro",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "Estrutura do Livro",
    "text": "Estrutura do Livro\nO livro est√° organizado em 12 cap√≠tulos:\n\nCap√≠tulo 1: Teoria da Probabilidade\nEstabelece os fundamentos matem√°ticos necess√°rios para o restante do livro, incluindo:\n\nTeoria dos Conjuntos\nFundamentos da Teoria da Probabilidade\n\nFunda√ß√µes Axiom√°ticas\nO C√°lculo de Probabilidades\nContagem\nEnumerando Resultados\n\nProbabilidade Condicional e Independ√™ncia\nVari√°veis Aleat√≥rias\nFun√ß√µes de Distribui√ß√£o\nFun√ß√µes de Densidade e de Massa\n\n\n\nCap√≠tulo 2: Transforma√ß√µes e Esperan√ßas\n\nDistribui√ß√µes de Fun√ß√µes de uma Vari√°vel Aleat√≥ria\nValores Esperados (Esperan√ßa)\nMomentos e Fun√ß√µes Geradoras de Momentos\nDiferencia√ß√£o sob o Sinal de Integral\n\n\n\nCap√≠tulo 3: Fam√≠lias Comuns de Distribui√ß√µes\n\nIntrodu√ß√£o\nDistribui√ß√µes Discretas\nDistribui√ß√µes Cont√≠nuas\nFam√≠lias Exponenciais\nFam√≠lias de Localiza√ß√£o e Escala\nDesigualdades e Identidades\n\n\n\nCap√≠tulo 4: M√∫ltiplas Vari√°veis Aleat√≥rias\n\nDistribui√ß√µes Conjuntas e Marginais\nDistribui√ß√µes Condicionais e Independ√™ncia\nTransforma√ß√µes Bivariadas\nModelos Hier√°rquicos e Distribui√ß√µes de Mistura\nCovari√¢ncia e Correla√ß√£o\nDistribui√ß√µes Multivariadas\nDesigualdades\n\n\n\nCap√≠tulo 5: Propriedades de uma Amostra Aleat√≥ria\n\nConceitos B√°sicos de Amostras Aleat√≥rias\nSomas de Vari√°veis Aleat√≥rias de uma Amostra Aleat√≥ria\nAmostragem da Distribui√ß√£o Normal\nEstat√≠sticas de Ordem\nConceitos de Converg√™ncia\n\nConverg√™ncia em Probabilidade\nConverg√™ncia Quase Certa\nConverg√™ncia em Distribui√ß√£o\nO M√©todo Delta\n\nGerando uma Amostra Aleat√≥ria\n\n\n\nCap√≠tulo 6: Princ√≠pios de Redu√ß√£o de Dados\n\nO Princ√≠pio da Sufici√™ncia\n\nEstat√≠sticas Suficientes\nEstat√≠sticas Suficientes M√≠nimas\nEstat√≠sticas Ancilares\nEstat√≠sticas Suficientes, Completas e Ancilares\n\nO Princ√≠pio da Verossimilhan√ßa\n\nA Fun√ß√£o de Verossimilhan√ßa\nO Princ√≠pio da Verossimilhan√ßa Formal\n\nO Princ√≠pio da Equivari√¢ncia\n\n\n\nCap√≠tulo 7: Estima√ß√£o Pontual\n\nM√©todos para Encontrar Estimadores\n\nM√©todo dos Momentos\nEstimadores de M√°xima Verossimilhan√ßa\nEstimadores de Bayes\nO Algoritmo EM\n\nM√©todos de Avalia√ß√£o de Estimadores\n\nErro Quadr√°tico M√©dio\nMelhores Estimadores N√£o Viesados\nSufici√™ncia e N√£o-viesamento\nOtimalidade da Fun√ß√£o de Perda\n\n\n\n\nCap√≠tulo 8: Teste de Hip√≥teses\n\nM√©todos para Encontrar Testes\n\nTestes de Raz√£o de Verossimilhan√ßa\nTestes Bayesianos\nTestes de Uni√£o-Interse√ß√£o e Interse√ß√£o-Uni√£o\n\nM√©todos de Avalia√ß√£o de Testes\n\nProbabilidades de Erro e Fun√ß√£o Poder\nTestes Mais Poderosos\nTamanhos de Testes de Uni√£o-Interse√ß√£o\nP-valores\n\n\n\n\nCap√≠tulo 9: Estima√ß√£o por Intervalo\n\nM√©todos para Encontrar Estimadores de Intervalo\n\nInvertendo uma Estat√≠stica de Teste\nQuantidades Pivotais\nPivotando a FDA\nIntervalos Bayesianos\n\nM√©todos de Avalia√ß√£o de Estimadores de Intervalo\n\nTamanho e Probabilidade de Cobertura\nOtimalidade Relacionada a Testes\nOtimalidade Bayesiana\nOtimalidade da Fun√ß√£o de Perda\n\n\n\n\nCap√≠tulo 10: Avalia√ß√µes Assint√≥ticas\n\nEstima√ß√£o Pontual\n\nConsist√™ncia\nEfici√™ncia\nC√°lculos e Compara√ß√µes\nBootstrap\n\nRobustez\n\nA M√©dia e a Mediana\nM-Estimadores\n\nTeste de Hip√≥teses\n\nDistribui√ß√£o Assint√≥tica de TRVs\nOutros Testes com Grandes Amostras\n\nEstima√ß√£o por Intervalo\n\nIntervalos de Verossimilhan√ßa Aproximada\nOutros Intervalos Aproximados (e Robustos)\n\n\n\n\nCap√≠tulo 11: An√°lise de Vari√¢ncia e Regress√£o\n\nAn√°lise de Vari√¢ncia (ANOVA) de Um Fator\nRegress√£o Linear Simples\n\n\n\nCap√≠tulo 12: Modelos de Regress√£o\n\nIntrodu√ß√£o aos Modelos de Regress√£o\nEstima√ß√£o e Teste com Erros Normais\nEstima√ß√£o e Predi√ß√£o em um Dado \\(x = x_0\\)\nInfer√™ncia Simult√¢nea",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Infer√™ncia Estat√≠stica</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-os-autores",
    "href": "index.html#sobre-os-autores",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "Sobre os Autores",
    "text": "Sobre os Autores\nGeorge Casella (1951‚Äì2012) foi um estat√≠stico americano e professor da Universidade da Fl√≥rida. Reconhecido por suas contribui√ß√µes em infer√™ncia estat√≠stica, estat√≠stica bayesiana e m√©todos de Monte Carlo, foi eleito Fellow da American Statistical Association e do Institute of Mathematical Statistics.\nRoger L. Berger √© professor em√©rito da Universidade Estadual da Carolina do Norte. Suas √°reas de pesquisa incluem infer√™ncia estat√≠stica, bioestat√≠stica e educa√ß√£o estat√≠stica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Infer√™ncia Estat√≠stica</span>"
    ]
  },
  {
    "objectID": "index.html#como-navegar",
    "href": "index.html#como-navegar",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "Como Navegar",
    "text": "Como Navegar\nUtilize o menu lateral para acessar os cap√≠tulos dispon√≠veis. Esta tradu√ß√£o est√° em andamento, e novos cap√≠tulos ser√£o adicionados progressivamente.\n\nüìö Refer√™ncia Original\nCasella, G., & Berger, R. L. (2002). Statistical Inference (2nd ed.). Duxbury/Thomson Learning.\nISBN: 0-534-24312-6",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Infer√™ncia Estat√≠stica</span>"
    ]
  },
  {
    "objectID": "cap-1.html",
    "href": "cap-1.html",
    "title": "Teoria da Probabilidade",
    "section": "",
    "text": "1.1 Teoria dos Conjuntos\nO tema da teoria da probabilidade √© a funda√ß√£o sobre a qual toda a estat√≠stica √© constru√≠da, fornecendo um meio para modelar popula√ß√µes, experimentos ou quase qualquer outra coisa que possa ser considerada um fen√¥meno aleat√≥rio. Por meio desses modelos, os estat√≠sticos s√£o capazes de tirar infer√™ncias sobre popula√ß√µes, infer√™ncias baseadas no exame de apenas uma parte do todo.\nA teoria da probabilidade tem uma hist√≥ria longa e rica, que remonta pelo menos ao s√©culo XVII, quando, a pedido de seu amigo, o Chevalier de M√©r√©, Pascal e Fermat desenvolveram uma formula√ß√£o matem√°tica para as probabilidades em jogos de azar.\nO objetivo deste cap√≠tulo n√£o √© fornecer uma introdu√ß√£o exaustiva √† teoria da probabilidade; tal tentativa seria imprudente em um espa√ßo t√£o curto. Em vez disso, tentamos delinear algumas das ideias b√°sicas da teoria da probabilidade que s√£o fundamentais para o estudo da estat√≠stica.\nAssim como a estat√≠stica se baseia na funda√ß√£o da teoria da probabilidade, a teoria da probabilidade, por sua vez, se baseia na teoria dos conjuntos, que √© onde come√ßamos.\nUm dos principais objetivos de um estat√≠stico √© tirar conclus√µes sobre uma popula√ß√£o de objetos realizando um experimento. O primeiro passo nesse esfor√ßo √© identificar os poss√≠veis resultados ou, na terminologia estat√≠stica, o espa√ßo amostral.\nSe o experimento consiste em lan√ßar uma moeda, o espa√ßo amostral cont√©m dois resultados, cara e coroa; portanto,\n\\[\nS = \\{H, T\\}.\n\\]\nSe, por outro lado, o experimento consiste em observar as notas do SAT reportadas de alunos selecionados aleatoriamente em uma certa universidade, o espa√ßo amostral seria o conjunto de inteiros positivos entre 200 e 800 que s√£o m√∫ltiplos de dez ‚Äî isto √©, \\(S = \\{200, 210, 220, \\dots, 780, 790, 800\\}\\). Finalmente, considere um experimento onde a observa√ß√£o √© o tempo de rea√ß√£o a um determinado est√≠mulo. Aqui, o espa√ßo amostral consistiria em todos os n√∫meros positivos, isto √©, \\(S = (0, \\infty)\\).\nPodemos classificar os espa√ßos amostrais em dois tipos, de acordo com o n√∫mero de elementos que eles cont√™m. Espa√ßos amostrais podem ser enumer√°veis ou n√£o enumer√°veis; se os elementos de um espa√ßo amostral podem ser colocados em correspond√™ncia biun√≠voca (1 para 1) com um subconjunto dos inteiros, o espa√ßo amostral √© enumer√°vel. √â claro que, se o espa√ßo amostral cont√©m apenas um n√∫mero finito de elementos, ele √© enumer√°vel. Assim, os espa√ßos amostrais do lan√ßamento da moeda e das notas do SAT s√£o ambos enumer√°veis (de fato, finitos), enquanto o espa√ßo amostral do tempo de rea√ß√£o √© n√£o enumer√°vel, uma vez que os n√∫meros reais positivos n√£o podem ser colocados em correspond√™ncia biun√≠voca com os inteiros. Se, no entanto, med√≠ssemos o tempo de rea√ß√£o arredondando para o segundo mais pr√≥ximo, ent√£o o espa√ßo amostral seria (em segundos) \\(S = \\{0, 1, 2, 3, \\dots\\}\\), que √© ent√£o enumer√°vel.\nEssa distin√ß√£o entre espa√ßos amostrais enumer√°veis e n√£o enumer√°veis √© importante apenas na medida em que dita a maneira pela qual as probabilidades podem ser atribu√≠das. Na maior parte das vezes, isso n√£o causa problemas, embora o tratamento matem√°tico das situa√ß√µes seja diferente. Em um n√≠vel filos√≥fico, poderia ser argumentado que s√≥ podem existir espa√ßos amostrais enumer√°veis, uma vez que as medi√ß√µes n√£o podem ser feitas com precis√£o infinita. (Um espa√ßo amostral consistindo, digamos, de todos os n√∫meros de dez d√≠gitos √© um espa√ßo amostral enumer√°vel.) Embora na pr√°tica isso seja verdade, m√©todos probabil√≠sticos e estat√≠sticos associados a espa√ßos amostrais n√£o enumer√°veis s√£o, em geral, menos trabalhosos do que aqueles para espa√ßos amostrais enumer√°veis e fornecem uma aproxima√ß√£o pr√≥xima da situa√ß√£o verdadeira (enumer√°vel).\nUma vez definido o espa√ßo amostral, estamos em posi√ß√£o de considerar cole√ß√µes de poss√≠veis resultados de um experimento.\nSeja \\(A\\) um evento, um subconjunto de \\(S\\). Dizemos que o evento \\(A\\) ocorre se o resultado do experimento estiver no conjunto \\(A\\). Ao falar de probabilidades, geralmente falamos da probabilidade de um evento, em vez de um conjunto. Mas podemos usar os termos de forma intercambi√°vel.\nPrimeiro, precisamos definir formalmente as duas rela√ß√µes a seguir, que nos permitem ordenar e igualar conjuntos:\n\\[\n\\begin{align*}\nA \\subset B &\\iff x \\in A \\Rightarrow x \\in B; &(\\text{contin√™ncia}) \\\\\nA = B &\\iff A \\subset B \\text{ e } B \\subset A. &(\\text{igualdade})\n\\end{align*}\n\\]\nDados dois eventos (ou conjuntos) \\(A\\) e \\(B\\), temos as seguintes opera√ß√µes elementares de conjuntos:\nUni√£o: A uni√£o de \\(A\\) e \\(B\\), escrita \\(A \\cup B\\), √© o conjunto de elementos que pertencem a \\(A\\) ou a \\(B\\) ou a ambos:\n\\[\nA \\cup B = \\{x : x \\in A \\text{ ou } x \\in B\\}.\n\\]\nInterse√ß√£o: A interse√ß√£o de \\(A\\) e \\(B\\), escrita \\(A \\cap B\\), √© o conjunto de elementos que pertencem a ambos \\(A\\) e \\(B\\):\n\\[\nA \\cap B = \\{x : x \\in A \\text{ e } x \\in B\\}.\n\\]\nComplementar: O complementar de \\(A\\), escrito \\(A^c\\), √© o conjunto de todos os elementos que n√£o est√£o em \\(A\\):\n\\[\nA^c = \\{x : x \\notin A\\}.\n\\]\nAs opera√ß√µes elementares de conjuntos podem ser combinadas, de certa forma semelhante √† maneira como a adi√ß√£o e a multiplica√ß√£o podem ser combinadas. Desde que tenhamos cuidado, podemos tratar conjuntos como se fossem n√∫meros. Podemos agora enunciar as seguintes propriedades √∫teis das opera√ß√µes de conjuntos.\nAs opera√ß√µes de uni√£o e interse√ß√£o podem ser estendidas para cole√ß√µes infinitas de conjuntos tamb√©m. Se \\(A_1, A_2, A_3, \\dots\\) √© uma cole√ß√£o de conjuntos, todos definidos em um espa√ßo amostral \\(S\\), ent√£o\n\\[\n\\bigcup_{i=1}^{\\infty} A_i = \\{x \\in S : x \\in A_i \\text{ para algum } i\\},\n\\] \\[\n\\bigcap_{i=1}^{\\infty} A_i = \\{x \\in S : x \\in A_i \\text{ para todo } i\\}.\n\\]\nPor exemplo, seja \\(S = (0, 1]\\) e defina \\(A_i = [(1/i), 1]\\). Ent√£o\n\\[\n\\begin{align*}\n\\bigcup_{i=1}^{\\infty} A_i &= \\bigcup_{i=1}^{\\infty} [(1/i), 1] &&= \\{x \\in (0, 1] : x \\in [(1/i), 1] \\text{ para algum } i\\} \\\\\n& &&= \\{x \\in (0, 1]\\} &&= (0, 1]; \\\\\n\\bigcap_{i=1}^{\\infty} A_i &= \\bigcap_{i=1}^{\\infty} [(1/i), 1] &&= \\{x \\in (0, 1] : x \\in [(1/i), 1] \\text{ para todo } i\\} \\\\\n& &&= \\{x \\in (0, 1] : x \\in [1, 1]\\} &&= \\{1\\}. \\quad \\text{(o ponto 1)}\n\\end{align*}\n\\]\nTamb√©m √© poss√≠vel definir uni√µes e interse√ß√µes sobre cole√ß√µes n√£o enumer√°veis de conjuntos. Se \\(\\Gamma\\) √© um conjunto de √≠ndices (um conjunto de elementos a serem usados como √≠ndices), ent√£o\n\\[\n\\bigcup_{\\alpha \\in \\Gamma} A_{\\alpha} = \\{x \\in S : x \\in A_{\\alpha} \\text{ para algum } \\alpha\\},\n\\] \\[\n\\bigcap_{\\alpha \\in \\Gamma} A_{\\alpha} = \\{x \\in S : x \\in A_{\\alpha} \\text{ para todo } \\alpha\\}.\n\\]\nSe, por exemplo, tomarmos \\(\\Gamma = \\{\\text{todos os n√∫meros reais positivos}\\}\\) e \\(A_{\\alpha} = (0, \\alpha]\\), ent√£o \\(\\cup_{\\alpha \\in \\Gamma} A_{\\alpha} = (0, \\infty)\\) √© uma uni√£o n√£o enumer√°vel. Embora uni√µes e interse√ß√µes n√£o enumer√°veis n√£o desempenhem um papel importante na estat√≠stica, elas √†s vezes fornecem um mecanismo √∫til para obter uma resposta (veja a Se√ß√£o 8.2.3).\nFinalmente, discutimos a ideia de uma parti√ß√£o do espa√ßo amostral.\nConjuntos disjuntos s√£o conjuntos sem pontos em comum. Se desenharmos um diagrama de Venn para dois conjuntos disjuntos, os conjuntos n√£o se sobrep√µem. A cole√ß√£o\n\\[\nA_i = [i, i+1), \\quad i = 0, 1, 2, \\dots,\n\\]\nconsiste em conjuntos disjuntos dois a dois. Note ainda que \\(\\cup_{i=0}^{\\infty} A_i = [0, \\infty)\\).\nOs conjuntos \\(A_i = [i, i+1)\\) formam uma parti√ß√£o de \\([0, \\infty)\\). Em geral, parti√ß√µes s√£o muito √∫teis, permitindo-nos dividir o espa√ßo amostral em peda√ßos pequenos e n√£o sobrepostos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#teoria-dos-conjuntos",
    "href": "cap-1.html#teoria-dos-conjuntos",
    "title": "Teoria da Probabilidade",
    "section": "",
    "text": "Defini√ß√£o 1.1.1 - Espa√ßo Amostral\nO conjunto, \\(S\\), de todos os resultados poss√≠veis de um experimento particular √© chamado de espa√ßo amostral do experimento.\n\n\n\n\n\n\n\n\nDefini√ß√£o 1.1.2 - Evento\nUm evento √© qualquer cole√ß√£o de poss√≠veis resultados de um experimento, isto √©, qualquer subconjunto de \\(S\\) (incluindo o pr√≥prio \\(S\\)).\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo 1.1.3 (Opera√ß√µes com eventos)\nConsidere o experimento de selecionar uma carta aleatoriamente de um baralho padr√£o e anotar seu naipe: paus (C), ouros (D), copas (H) ou espadas (S). O espa√ßo amostral √©\n\\[\nS = \\{C, D, H, S\\},\n\\]\ne alguns eventos poss√≠veis s√£o\n\\[\nA = \\{C, D\\} \\quad \\text{e} \\quad B = \\{D, H, S\\}.\n\\]\nA partir desses eventos, podemos formar\n\\[\nA \\cup B = \\{C, D, H, S\\}, \\quad A \\cap B = \\{D\\}, \\quad \\text{e} \\quad A^c = \\{H, S\\}.\n\\]\nAl√©m disso, note que \\(A \\cup B = S\\) (o evento \\(S\\)) e \\((A \\cup B)^c = \\emptyset\\), onde \\(\\emptyset\\) denota o conjunto vazio (o conjunto que n√£o consiste em nenhum elemento).\n\n\n\nTeorema 1.1.4\nPara quaisquer tr√™s eventos, \\(A, B\\) e \\(C\\), definidos em um espa√ßo amostral \\(S\\),\n\na. Comutatividade \\[\n\\begin{align*}\nA \\cup B &= B \\cup A, \\\\\nA \\cap B &= B \\cap A;\n\\end{align*}\n\\]\nb. Associatividade \\[\n\\begin{align*}\nA \\cup (B \\cup C) &= (A \\cup B) \\cup C, \\\\\nA \\cap (B \\cap C) &= (A \\cap B) \\cap C;\n\\end{align*}\n\\]\nc.¬†Leis Distributivas \\[\n\\begin{align*}\nA \\cap (B \\cup C) &= (A \\cap B) \\cup (A \\cap C), \\\\\nA \\cup (B \\cap C) &= (A \\cup B) \\cap (A \\cup C);\n\\end{align*}\n\\]\nd.¬†Leis de DeMorgan \\[\n\\begin{align*}\n(A \\cup B)^c &= A^c \\cap B^c, \\\\\n(A \\cap B)^c &= A^c \\cup B^c.\n\\end{align*}\n\\]\n\n\n\nComprova√ß√£o. A prova de grande parte deste teorema √© deixada como Exerc√≠cio 1.3. Al√©m disso, os Exerc√≠cios 1.9 e 1.10 generalizam o teorema. Para ilustrar a t√©cnica, no entanto, provaremos a Lei Distributiva:\n\\[\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C).\n\\]\n(Voc√™ pode estar familiarizado com o uso de diagramas de Venn para ‚Äúprovar‚Äù teoremas na teoria dos conjuntos. Advertimos que, embora os diagramas de Venn sejam √†s vezes √∫teis para visualizar uma situa√ß√£o, eles n√£o constituem uma prova formal.) Para provar que dois conjuntos s√£o iguais, deve-se demonstrar que cada conjunto cont√©m o outro. Formalmente, ent√£o,\n\\[\n\\begin{align*}\nA \\cap (B \\cup C) &= \\{x \\in S : x \\in A \\text{ e } x \\in (B \\cup C)\\}; \\\\\n(A \\cap B) \\cup (A \\cap C) &= \\{x \\in S : x \\in (A \\cap B) \\text{ ou } x \\in (A \\cap C)\\}.\n\\end{align*}\n\\]\nPrimeiro mostramos que \\(A \\cap (B \\cup C) \\subset (A \\cap B) \\cup (A \\cap C)\\). Seja \\(x \\in (A \\cap (B \\cup C))\\). Pela defini√ß√£o de interse√ß√£o, deve ser que \\(x \\in A\\) e \\(x \\in (B \\cup C)\\), isto √©, \\(x \\in B\\) ou \\(x \\in C\\). Como \\(x\\) tamb√©m deve estar em \\(A\\), temos que \\(x \\in (A \\cap B)\\) ou \\(x \\in (A \\cap C)\\); portanto,\n\\[\nx \\in ((A \\cap B) \\cup (A \\cap C)),\n\\]\ne a contin√™ncia est√° estabelecida. Agora assuma \\(x \\in ((A \\cap B) \\cup (A \\cap C))\\). Isso implica que \\(x \\in (A \\cap B)\\) ou \\(x \\in (A \\cap C)\\). Se \\(x \\in (A \\cap B)\\), ent√£o \\(x\\) est√° em ambos \\(A\\) e \\(B\\). Visto que \\(x \\in B, x \\in (B \\cup C)\\) e assim \\(x \\in (A \\cap (B \\cup C))\\). Se, por outro lado, \\(x \\in (A \\cap C)\\), o argumento √© similar, e novamente conclu√≠mos que \\(x \\in (A \\cap (B \\cup C))\\). Assim, estabelecemos \\((A \\cap B) \\cup (A \\cap C) \\subset A \\cap (B \\cup C)\\), mostrando a contin√™ncia na outra dire√ß√£o e, portanto, provando a Lei Distributiva. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\nDefini√ß√£o 1.1.5 - Disjuntos\nDois eventos \\(A\\) e \\(B\\) s√£o disjuntos (ou mutuamente exclusivos) se \\(A \\cap B = \\emptyset\\). Os eventos \\(A_1, A_2, \\dots\\) s√£o disjuntos dois a dois (ou mutuamente exclusivos) se \\(A_i \\cap A_j = \\emptyset\\) para todo \\(i \\ne j\\).\n\n\n\n\n\nDefini√ß√£o 1.1.6 - Parti√ß√£o\nSe \\(A_1, A_2, \\dots\\) s√£o disjuntos dois a dois e \\(\\cup_{i=1}^{\\infty} A_i = S\\), ent√£o a cole√ß√£o \\(A_1, A_2, \\dots\\) forma uma parti√ß√£o de \\(S\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#fundamentos-da-probabilidade",
    "href": "cap-1.html#fundamentos-da-probabilidade",
    "title": "Teoria da Probabilidade",
    "section": "1.2 Fundamentos da Probabilidade",
    "text": "1.2 Fundamentos da Probabilidade\nQuando um experimento √© realizado, a realiza√ß√£o do experimento √© um resultado no espa√ßo amostral. Se o experimento √© realizado um n√∫mero de vezes, diferentes resultados podem ocorrer a cada vez ou alguns resultados podem se repetir. Essa ‚Äúfrequ√™ncia de ocorr√™ncia‚Äù de um resultado pode ser pensada como uma probabilidade. Resultados mais prov√°veis ocorrem com mais frequ√™ncia. Se os resultados de um experimento podem ser descritos probabilisticamente, estamos a caminho de analisar o experimento estatisticamente.\nNesta se√ß√£o, descrevemos alguns dos fundamentos da teoria da probabilidade. N√£o definimos probabilidades em termos de frequ√™ncias, mas, em vez disso, adotamos a abordagem axiom√°tica matematicamente mais simples. Como ser√° visto, a abordagem axiom√°tica n√£o se preocupa com as interpreta√ß√µes das probabilidades, mas preocupa-se apenas que as probabilidades sejam definidas por uma fun√ß√£o que satisfa√ßa os axiomas. Interpreta√ß√µes das probabilidades s√£o outra quest√£o. A ‚Äúfrequ√™ncia de ocorr√™ncia‚Äù de um evento √© um exemplo de uma interpreta√ß√£o particular de probabilidade. Outra interpreta√ß√£o poss√≠vel √© subjetiva, onde, em vez de pensar em probabilidade como frequ√™ncia, podemos pensar nela como uma cren√ßa na chance de um evento ocorrer.\n\n1.2.1 Funda√ß√µes Axiom√°ticas\nPara cada evento \\(A\\) no espa√ßo amostral \\(S\\), queremos associar a \\(A\\) um n√∫mero entre zero e um que ser√° chamado de probabilidade de \\(A\\), denotado por \\(P(A)\\). Pareceria natural definir o dom√≠nio de \\(P\\) (o conjunto onde os argumentos da fun√ß√£o \\(P(\\cdot)\\) s√£o definidos) como todos os subconjuntos de \\(S\\); isto √©, para cada \\(A \\subset S\\) definimos \\(P(A)\\) como a probabilidade de que \\(A\\) ocorra. Infelizmente, as coisas n√£o s√£o t√£o simples. Existem algumas dificuldades t√©cnicas a serem superadas. N√£o nos deteremos nessas tecnicalidades; embora sejam importantes, geralmente s√£o de maior interesse para probabilistas do que para estat√≠sticos. No entanto, uma compreens√£o firme de estat√≠stica requer pelo menos uma familiaridade passageira com o seguinte.\n\n\nDefini√ß√£o 1.2.1 - Sigma-√°lgebra\nUma cole√ß√£o de subconjuntos de \\(S\\) √© chamada de sigma-√°lgebra (ou corpo de Borel), denotada por \\(\\mathcal{B}\\), se satisfaz as tr√™s propriedades a seguir: a. \\(\\emptyset \\in \\mathcal{B}\\) (o conjunto vazio √© um elemento de \\(\\mathcal{B}\\)). b. Se \\(A \\in \\mathcal{B}\\), ent√£o \\(A^c \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) √© fechada sob complementa√ß√£o). c.¬†Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\), ent√£o \\(\\cup_{i=1}^{\\infty} A_i \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) √© fechada sob uni√µes enumer√°veis).\n\nO conjunto vazio \\(\\emptyset\\) √© um subconjunto de qualquer conjunto. Assim, \\(\\emptyset \\subset S\\). A propriedade (a) afirma que este subconjunto est√° sempre em uma sigma-√°lgebra. Uma vez que \\(S = \\emptyset^c\\), as propriedades (a) e (b) implicam que \\(S\\) est√° sempre em \\(\\mathcal{B}\\) tamb√©m. Al√©m disso, das Leis de DeMorgan, segue-se que \\(\\mathcal{B}\\) √© fechada sob interse√ß√µes enumer√°veis. Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\), ent√£o \\(A_1^c, A_2^c, \\dots \\in \\mathcal{B}\\) pela propriedade (b), e portanto \\(\\cup_{i=1}^{\\infty} A_i^c \\in \\mathcal{B}\\). No entanto, usando a Lei de DeMorgan (como no Exerc√≠cio 1.9), temos\n\\[\n\\left( \\bigcup_{i=1}^{\\infty} A_i^c \\right)^c = \\bigcap_{i=1}^{\\infty} A_i.\n\\]\nAssim, novamente pela propriedade (b), \\(\\cap_{i=1}^{\\infty} A_i \\in \\mathcal{B}\\). Associadas ao espa√ßo amostral \\(S\\), podemos ter muitas sigma-√°lgebras diferentes. Por exemplo, a cole√ß√£o dos dois conjuntos \\(\\{\\emptyset, S\\}\\) √© uma sigma-√°lgebra, geralmente chamada de sigma-√°lgebra trivial. A √∫nica sigma-√°lgebra com a qual nos preocuparemos √© a menor que cont√©m todos os conjuntos abertos em um dado espa√ßo amostral \\(S\\).\n\nExemplo 1.2.2 (Sigma-√°lgebra‚ÄîI)\nSe \\(S\\) √© finito ou enumer√°vel, essas tecnicalidades realmente n√£o surgem, pois definimos para um dado espa√ßo amostral \\(S\\),\n\\[\n\\mathcal{B} = \\{\\text{todos os subconjuntos de } S, \\text{ incluindo } S \\text{ ele mesmo}\\}.\n\\]\nSe \\(S\\) tem \\(n\\) elementos, existem \\(2^n\\) conjuntos em \\(\\mathcal{B}\\) (veja Exerc√≠cio 1.14). Por exemplo, se \\(S = \\{1, 2, 3\\}\\), ent√£o \\(\\mathcal{B}\\) √© a seguinte cole√ß√£o de \\(2^3 = 8\\) conjuntos:\n\\[\n\\begin{matrix}\n\\{1\\} & \\{1, 2\\} & \\{1, 2, 3\\} \\\\\n\\{2\\} & \\{1, 3\\} & \\emptyset \\\\\n\\{3\\} & \\{2, 3\\} &\n\\end{matrix}\n\\]\n\nEm geral, se \\(S\\) √© n√£o enumer√°vel, n√£o √© uma tarefa f√°cil descrever \\(\\mathcal{B}\\). No entanto, \\(\\mathcal{B}\\) √© escolhida para conter qualquer conjunto de interesse.\n\nExemplo 1.2.3 (Sigma-√°lgebra‚ÄîII)\nSeja \\(S = (-\\infty, \\infty)\\), a reta real. Ent√£o \\(\\mathcal{B}\\) √© escolhida para conter todos os conjuntos da forma\n\\[\n[a, b], \\quad (a, b], \\quad (a, b), \\quad \\text{e} \\quad [a, b)\n\\]\npara todos os n√∫meros reais \\(a\\) e \\(b\\). Al√©m disso, pelas propriedades de \\(\\mathcal{B}\\), segue-se que \\(\\mathcal{B}\\) cont√©m todos os conjuntos que podem ser formados tomando uni√µes (possivelmente infinitas enumer√°veis) e interse√ß√µes de conjuntos das variedades acima.\n\nEstamos agora em posi√ß√£o de definir uma fun√ß√£o de probabilidade.\n\nDefini√ß√£o 1.2.4 - Fun√ß√£o de Probabilidade\nDado um espa√ßo amostral \\(S\\) e uma sigma-√°lgebra associada \\(\\mathcal{B}\\), uma fun√ß√£o de probabilidade √© uma fun√ß√£o \\(P\\) com dom√≠nio \\(\\mathcal{B}\\) que satisfaz 1. \\(P(A) \\ge 0\\) para todo \\(A \\in \\mathcal{B}\\). 2. \\(P(S) = 1\\). 3. Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\) s√£o disjuntos dois a dois, ent√£o \\(P(\\cup_{i=1}^{\\infty} A_i) = \\sum_{i=1}^{\\infty} P(A_i)\\).\n\nAs tr√™s propriedades dadas na Defini√ß√£o 1.2.4 s√£o geralmente referidas como os Axiomas da Probabilidade (ou os Axiomas de Kolmogorov, em homenagem a A. Kolmogorov, um dos pais da teoria da probabilidade). Qualquer fun√ß√£o \\(P\\) que satisfa√ßa os Axiomas de Probabilidade √© chamada de fun√ß√£o de probabilidade. A defini√ß√£o axiom√°tica n√£o tenta dizer qual fun√ß√£o particular \\(P\\) escolher; ela apenas requer que \\(P\\) satisfa√ßa os axiomas. Para qualquer espa√ßo amostral, muitas fun√ß√µes de probabilidade diferentes podem ser definidas. Qual delas reflete o que √© prov√°vel de ser observado em um experimento particular ainda precisa ser discutido.\n\nExemplo 1.2.5 (Definindo probabilidades‚ÄîI)\nConsidere o experimento simples de lan√ßar uma moeda justa, ent√£o \\(S = \\{H, T\\}\\). Por uma moeda ‚Äújusta‚Äù, queremos dizer uma moeda balanceada que tem igual probabilidade de cair com a face para cima ou para baixo, e, portanto, a fun√ß√£o de probabilidade razo√°vel √© aquela que atribui probabilidades iguais a cara e coroa, isto √©,\n\\[\nP(\\{H\\}) = P(\\{T\\}).\n\\]\nNote que (1.2.2) n√£o decorre dos Axiomas de Probabilidade, mas √© de fora dos axiomas. Usamos uma interpreta√ß√£o de simetria da probabilidade (ou apenas intui√ß√£o) para impor o requisito de que cara e coroa sejam igualmente prov√°veis. Como \\(S = \\{H\\} \\cup \\{T\\}\\), temos, pelo Axioma 1, \\(P(\\{H\\} \\cup \\{T\\}) = 1\\). Al√©m disso, \\(\\{H\\}\\) e \\(\\{T\\}\\) s√£o disjuntos, ent√£o \\(P(\\{H\\} \\cup \\{T\\}) = P(\\{H\\}) + P(\\{T\\})\\) e\n\\[\nP(\\{H\\}) + P(\\{T\\}) = 1.\n\\]\nResolvendo simultaneamente (1.2.2) e (1.2.3), temos \\(P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}\\). Como (1.2.2) √© baseado em nosso conhecimento do experimento particular, e n√£o nos axiomas, quaisquer valores n√£o negativos para \\(P(\\{H\\})\\) e \\(P(\\{T\\})\\) que satisfa√ßam (1.2.3) definem uma fun√ß√£o de probabilidade leg√≠tima. Por exemplo, poder√≠amos escolher \\(P(\\{H\\}) = \\frac{1}{9}\\) e \\(P(\\{T\\}) = \\frac{8}{9}\\).\n\nPrecisamos de m√©todos gerais para definir fun√ß√µes de probabilidade que saibamos que sempre satisfar√£o os Axiomas de Kolmogorov. N√£o queremos ter que verificar os Axiomas para cada nova fun√ß√£o de probabilidade, como fizemos no Exemplo 1.2.5. O seguinte fornece um m√©todo comum de definir uma fun√ß√£o de probabilidade leg√≠tima.\n\nTeorema 1.2.6\nSeja \\(S = \\{s_1, \\dots, s_n\\}\\) um conjunto finito. Seja \\(\\mathcal{B}\\) qualquer sigma-√°lgebra de subconjuntos de \\(S\\). Sejam \\(p_1, \\dots, p_n\\) n√∫meros n√£o negativos que somam 1. Para qualquer \\(A \\in \\mathcal{B}\\), defina \\(P(A)\\) por\n\\[\nP(A) = \\sum_{\\{i : s_i \\in A\\}} p_i.\n\\]\n(A soma sobre um conjunto vazio √© definida como 0.) Ent√£o \\(P\\) √© uma fun√ß√£o de probabilidade em \\(\\mathcal{B}\\). Isso permanece verdadeiro se \\(S = \\{s_1, s_2, \\dots\\}\\) √© um conjunto enumer√°vel.\n\n\nComprova√ß√£o. Daremos a prova para \\(S\\) finito. Para qualquer \\(A \\in \\mathcal{B}, P(A) = \\sum_{\\{i : s_i \\in A\\}} p_i \\ge 0\\), porque todo \\(p_i \\ge 0\\). Assim, o Axioma 1 √© verdadeiro. Agora,\n\\[\nP(S) = \\sum_{\\{i : s_i \\in S\\}} p_i = \\sum_{i=1}^n p_i = 1.\n\\]\nAssim, o Axioma 2 √© verdadeiro. Sejam \\(A_1, \\dots, A_k\\) eventos disjuntos dois a dois. (\\(\\mathcal{B}\\) cont√©m apenas um n√∫mero finito de conjuntos, ent√£o precisamos considerar apenas uni√µes disjuntas finitas.) Ent√£o,\n\\[\nP\\left( \\bigcup_{i=1}^k A_i \\right) = \\sum_{\\{j : s_j \\in \\cup_{i=1}^k A_i\\}} p_j = \\sum_{i=1}^k \\sum_{\\{j : s_j \\in A_i\\}} p_j = \\sum_{i=1}^k P(A_i).\n\\]\nA primeira e a terceira igualdades s√£o verdadeiras pela defini√ß√£o de \\(P(A)\\). A disjun√ß√£o dos \\(A_i\\)s garante que a segunda igualdade √© verdadeira, porque os mesmos \\(p_j\\)s aparecem exatamente uma vez em cada lado da igualdade. Assim, o Axioma 3 √© verdadeiro e os Axiomas de Kolmogorov s√£o satisfeitos. \\(\\square\\)\n\nA realidade f√≠sica do experimento pode ditar a atribui√ß√£o de probabilidade, como o pr√≥ximo exemplo ilustra.\n\nExemplo 1.2.7 (Definindo probabilidades‚ÄîII)\nO jogo de dardos √© jogado lan√ßando um dardo em um alvo e recebendo uma pontua√ß√£o correspondente ao n√∫mero atribu√≠do √† regi√£o em que o dardo cai. Para um jogador novato, parece razo√°vel assumir que a probabilidade de o dardo atingir uma regi√£o espec√≠fica √© proporcional √† √°rea da regi√£o. Assim, uma regi√£o maior tem uma probabilidade maior de ser atingida. Referindo-se √† Figura 1.2.1, vemos que o alvo de dardos tem raio \\(r\\) e a dist√¢ncia entre os an√©is √© \\(r/5\\). Se fizermos a suposi√ß√£o de que o alvo √© sempre atingido (veja o Exerc√≠cio 1.7 para uma varia√ß√£o sobre isso), ent√£o temos\n\\[\nP(\\text{marcar } i \\text{ pontos}) = \\frac{\\text{√Årea da regi√£o } i}{\\text{√Årea do alvo de dardos}}.\n\\]\n\n\n\nFigura 1.2.1 - Alvo de dardos para o Exemplo 1.2.7\n\n\nPor exemplo,\n\\[\nP(\\text{marcar } 1 \\text{ ponto}) = \\frac{\\pi r^2 - \\pi(4r/5)^2}{\\pi r^2} = 1 - \\left( \\frac{4}{5} \\right)^2.\n\\]\n√â f√°cil derivar a f√≥rmula geral, e descobrimos que\n\\[\nP(\\text{marcar } i \\text{ pontos}) = \\frac{(6-i)^2 - (5-i)^2}{5^2}, \\quad i = 1, \\dots, 5,\n\\]\nindependente de \\(\\pi\\) e \\(r\\). A soma das √°reas das regi√µes disjuntas √© igual √† √°rea do alvo de dardos. Assim, as probabilidades que foram atribu√≠das aos cinco resultados somam 1, e, pelo Teorema 1.2.6, esta √© uma fun√ß√£o de probabilidade (veja Exerc√≠cio 1.8).\n\nAntes de deixarmos o desenvolvimento axiom√°tico da probabilidade, h√° mais um ponto a considerar. O Axioma 3 da Defini√ß√£o 1.2.4, que √© comumente conhecido como o Axioma da Aditividade Enumer√°vel, n√£o √© universalmente aceito entre os estat√≠sticos. De fato, pode-se argumentar que os axiomas devem ser simples, autoevidentes. Comparando o Axioma 3 com os outros axiomas, que s√£o simples e autoevidentes, isso pode nos levar a duvidar se √© razo√°vel assumir a verdade do Axioma 3.\nO Axioma da Aditividade Enumer√°vel √© rejeitado por uma escola de estat√≠sticos liderada por deFinetti (1972), que opta por substituir este axioma pelo Axioma da Aditividade Finita.\nAxioma da Aditividade Finita: Se \\(A \\in \\mathcal{B}\\) e \\(B \\in \\mathcal{B}\\) s√£o disjuntos, ent√£o\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nEmbora este axioma possa n√£o ser inteiramente autoevidente, √© certamente mais simples do que o Axioma da Aditividade Enumer√°vel (e √© implicado por ele ‚Äì veja Exerc√≠cio 1.12).\nAssumir apenas a aditividade finita, embora talvez mais plaus√≠vel, pode levar a complica√ß√µes inesperadas na teoria estat√≠stica ‚Äì complica√ß√µes que, a este n√≠vel, n√£o necessariamente aumentam a compreens√£o do assunto. Portanto, prosseguimos sob a suposi√ß√£o de que o Axioma da Aditividade Enumer√°vel √© v√°lido.\n\n1.2.2 O C√°lculo de Probabilidades\nA partir dos Axiomas da Probabilidade, podemos construir muitas propriedades da fun√ß√£o de probabilidade, propriedades que s√£o bastante √∫teis no c√°lculo de probabilidades mais complicadas. Algumas dessas manipula√ß√µes ser√£o discutidas em detalhes nesta se√ß√£o; outras ser√£o deixadas como exerc√≠cios.\nCome√ßamos com algumas propriedades (bastante autoevidentes) da fun√ß√£o de probabilidade quando aplicadas a um √∫nico evento.\n\n\nTeorema 1.2.8\nSe P √© uma fun√ß√£o de probabilidade e A √© qualquer conjunto em \\(\\mathcal{B}\\), ent√£o\n\na. \\(P(\\emptyset) = 0\\), onde \\(\\emptyset\\) √© o conjunto vazio;\nb. \\(P(A) \\le 1\\);\nc. \\(P(A^c) = 1 - P(A)\\).\n\n\n\nComprova√ß√£o. √â mais f√°cil provar (c) primeiro. Os conjuntos \\(A\\) e \\(A^c\\) formam uma parti√ß√£o do espa√ßo amostral, isto √©, \\(S = A \\cup A^c\\). Portanto,\n\\[\nP(A \\cup A^c) = P(S) = 1\n\\]\npelo segundo axioma. Al√©m disso, \\(A\\) e \\(A^c\\) s√£o disjuntos, ent√£o pelo terceiro axioma,\n\\[\nP(A \\cup A^c) = P(A) + P(A^c).\n\\]\nCombinando (1.2.4) e (1.2.5) obtemos (c). Como \\(P(A^c) \\ge 0\\), (b) √© imediatamente implicado por (c). Para provar (a), usamos um argumento semelhante em \\(S = S \\cup \\emptyset\\). (Lembre-se que tanto \\(S\\) quanto \\(\\emptyset\\) est√£o sempre em \\(\\mathcal{B}\\).) Como \\(S\\) e \\(\\emptyset\\) s√£o disjuntos, temos\n\\[\n1 = P(S) = P(S \\cup \\emptyset) = P(S) + P(\\emptyset),\n\\]\ne assim \\(P(\\emptyset) = 0\\). \\(\\square\\)\n\nO Teorema 1.2.8 cont√©m propriedades que s√£o t√£o b√°sicas que tamb√©m t√™m o sabor de axiomas, embora tenhamos provado formalmente usando apenas os Axiomas de Kolmogorov originais. O pr√≥ximo teorema, que √© semelhante em esp√≠rito ao Teorema 1.2.8, cont√©m afirma√ß√µes que n√£o s√£o t√£o autoevidentes.\n\nTeorema 1.2.9\nSe P √© uma fun√ß√£o de probabilidade e A e B s√£o quaisquer conjuntos em \\(\\mathcal{B}\\), ent√£o\n\na. \\(P(B \\cap A^c) = P(B) - P(A \\cap B)\\);\nb. \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\);\nc. Se \\(A \\subset B\\), ent√£o \\(P(A) \\le P(B)\\).\n\n\n\nComprova√ß√£o. Para estabelecer (a), note que para quaisquer conjuntos \\(A\\) e \\(B\\) temos\n\\[\nB = \\{B \\cap A\\} \\cup \\{B \\cap A^c\\},\n\\]\ne portanto\n\\[\nP(B) = P(\\{B \\cap A\\} \\cup \\{B \\cap A^c\\}) = P(B \\cap A) + P(B \\cap A^c),\n\\]\nonde a √∫ltima igualdade em (1.2.6) decorre do fato de que \\(B \\cap A\\) e \\(B \\cap A^c\\) s√£o disjuntos. Reorganizando (1.2.6) obtemos (a). Para estabelecer (b), usamos a identidade\n\\[\nA \\cup B = A \\cup \\{B \\cap A^c\\}.\n\\]\nUm diagrama de Venn mostrar√° por que (1.2.7) √© v√°lida, embora uma prova formal n√£o seja dif√≠cil (veja Exerc√≠cio 1.2). Usando (1.2.7) e o fato de que \\(A\\) e \\(B \\cap A^c\\) s√£o disjuntos (visto que \\(A\\) e \\(A^c\\) o s√£o), temos\n\\[\nP(A \\cup B) = P(A) + P(B \\cap A^c) = P(A) + P(B) - P(A \\cap B)\n\\]\na partir de (a). Se \\(A \\subset B\\), ent√£o \\(A \\cap B = A\\). Portanto, usando (a), temos\n\\[\n0 \\le P(B \\cap A^c) = P(B) - P(A),\n\\]\nestabelecendo (c). \\(\\square\\)\n\nA f√≥rmula (b) do Teorema 1.2.9 fornece uma desigualdade √∫til para a probabilidade de uma interse√ß√£o. Como \\(P(A \\cup B) \\le 1\\), temos de (1.2.8), ap√≥s algum rearranjo,\n\\[\nP(A \\cap B) \\ge P(A) + P(B) - 1.\n\\]\nEsta desigualdade √© um caso especial do que √© conhecido como Desigualdade de Bonferroni (Miller 1981 √© uma boa refer√™ncia). A Desigualdade de Bonferroni nos permite limitar a probabilidade de um evento simult√¢neo (a interse√ß√£o) em termos das probabilidades dos eventos individuais.\n\nExemplo 1.2.10 (Desigualdade de Bonferroni)\nA Desigualdade de Bonferroni √© particularmente √∫til quando √© dif√≠cil (ou at√© imposs√≠vel) calcular a probabilidade da interse√ß√£o, mas se deseja alguma ideia do tamanho dessa probabilidade. Suponha que \\(A\\) e \\(B\\) sejam dois eventos e cada um tenha probabilidade 0,95. Ent√£o a probabilidade de que ambos ocorram √© limitada inferiormente por\n\\[\nP(A \\cap B) \\ge P(A) + P(B) - 1 = 0,95 + 0,95 - 1 = 0,90.\n\\]\nNote que, a menos que as probabilidades dos eventos individuais sejam suficientemente grandes, o limite de Bonferroni √© um n√∫mero negativo in√∫til (embora correto!).\n\nEncerramos esta se√ß√£o com um teorema que fornece alguns resultados √∫teis para lidar com uma cole√ß√£o de conjuntos.\n\nTeorema 1.2.11\nSe P √© uma fun√ß√£o de probabilidade, ent√£o\n\na. \\(P(A) = \\sum_{i=1}^{\\infty} P(A \\cap C_i)\\) para qualquer parti√ß√£o \\(C_1, C_2, \\dots\\);\nb. \\(P(\\cup_{i=1}^{\\infty} A_i) \\le \\sum_{i=1}^{\\infty} P(A_i)\\) para quaisquer conjuntos \\(A_1, A_2, \\dots\\). (Desigualdade de Boole)\n\n\n\nComprova√ß√£o. Visto que \\(C_1, C_2, \\dots\\) formam uma parti√ß√£o, temos que \\(C_i \\cap C_j = \\emptyset\\) para todo \\(i \\ne j\\), e \\(S = \\cup_{i=1}^{\\infty} C_i\\). Portanto,\n\\[\nA = A \\cap S = A \\cap \\left( \\bigcup_{i=1}^{\\infty} C_i \\right) = \\bigcup_{i=1}^{\\infty} (A \\cap C_i),\n\\]\nonde a √∫ltima igualdade segue da Lei Distributiva (Teorema 1.1.4). N√≥s, portanto, temos\n\\[\nP(A) = P\\left( \\bigcup_{i=1}^{\\infty} (A \\cap C_i) \\right).\n\\]\nAgora, como os \\(C_i\\) s√£o disjuntos, os conjuntos \\(A \\cap C_i\\) tamb√©m s√£o disjuntos, e das propriedades de uma fun√ß√£o de probabilidade temos\n\\[\nP\\left( \\bigcup_{i=1}^{\\infty} (A \\cap C_i) \\right) = \\sum_{i=1}^{\\infty} P(A \\cap C_i),\n\\]\nestabelecendo (a). Para estabelecer (b), primeiro constru√≠mos uma cole√ß√£o disjunta \\(A_1^*, A_2^*, \\dots\\), com a propriedade de que \\(\\cup_{i=1}^{\\infty} A_i^* = \\cup_{i=1}^{\\infty} A_i\\). Definimos \\(A_i^*\\) por\n\\[\nA_1^* = A_1, \\quad A_i^* = A_i \\setminus \\left( \\bigcup_{j=1}^{i-1} A_j \\right), \\quad i = 2, 3, \\dots,\n\\]\nonde a nota√ß√£o \\(A \\setminus B\\) denota a parte de \\(A\\) que n√£o intersecta com \\(B\\). Em s√≠mbolos mais familiares, \\(A \\setminus B = A \\cap B^c\\). Deve ser f√°cil ver que \\(\\cup_{i=1}^{\\infty} A_i^* = \\cup_{i=1}^{\\infty} A_i\\), e portanto temos\n\\[\nP\\left( \\bigcup_{i=1}^{\\infty} A_i \\right) = P\\left( \\bigcup_{i=1}^{\\infty} A_i^* \\right) = \\sum_{i=1}^{\\infty} P(A_i^*),\n\\]\nonde a √∫ltima igualdade segue uma vez que os \\(A_i^*\\) s√£o disjuntos. Para ver isso, escrevemos\n\\[\n\\begin{align*}\nA_i^* \\cap A_k^* &= \\left\\{ A_i \\cap \\left( \\bigcup_{j=1}^{i-1} A_j \\right)^c \\right\\} \\cap \\left\\{ A_k \\cap \\left( \\bigcup_{j=1}^{k-1} A_j \\right)^c \\right\\} \\quad (\\text{defini√ß√£o de } A_i^*) \\\\\n&= \\left\\{ A_i \\cap \\left( \\bigcap_{j=1}^{i-1} A_j^c \\right) \\right\\} \\cap \\left\\{ A_k \\cap \\left( \\bigcap_{j=1}^{k-1} A_j^c \\right) \\right\\} \\quad (\\text{Leis de DeMorgan})\n\\end{align*}\n\\]\nAgora, se \\(i &gt; k\\), a primeira interse√ß√£o acima estar√° contida no conjunto \\(A_k^c\\), que ter√° uma interse√ß√£o vazia com \\(A_k\\). Se \\(k &gt; i\\), o argumento √© semelhante. Al√©m disso, por constru√ß√£o \\(A_i^* \\subset A_i\\), ent√£o \\(P(A_i^*) \\le P(A_i)\\) e temos\n\\[\n\\sum_{i=1}^{\\infty} P(A_i^*) \\le \\sum_{i=1}^{\\infty} P(A_i),\n\\]\nestabelecendo (b). \\(\\square\\)\n\nExiste uma similaridade entre a Desigualdade de Boole e a Desigualdade de Bonferroni. De fato, elas s√£o essencialmente a mesma coisa. Se aplicarmos a Desigualdade de Boole a \\(A^c\\), temos\n\\[\nP\\left( \\bigcup_{i=1}^n A_i^c \\right) \\le \\sum_{i=1}^n P(A_i^c),\n\\]\ne usando os fatos de que \\(\\cup A_i^c = (\\cap A_i)^c\\) e \\(P(A_i^c) = 1 - P(A_i)\\), obtemos\n\\[\n1 - P\\left( \\bigcap_{i=1}^n A_i \\right) \\le n - \\sum_{i=1}^n P(A_i).\n\\]\nIsso se torna, ao reorganizar os termos,\n\\[\nP\\left( \\bigcap_{i=1}^n A_i \\right) \\ge \\sum_{i=1}^n P(A_i) - (n-1),\n\\]\nque √© uma vers√£o mais geral da Desigualdade de Bonferroni de (1.2.9).\n\n1.2.3 Contagem\nO processo elementar de contagem pode se tornar bastante sofisticado quando colocado nas m√£os de um estat√≠stico. Na maioria das vezes, m√©todos de contagem s√£o usados para construir atribui√ß√µes de probabilidade em espa√ßos amostrais finitos, embora possam ser usados para responder a outras perguntas tamb√©m.\n\n\nExemplo 1.2.12 (Loteria-I)\nPor v√°rios anos, a loteria do estado de Nova York operou de acordo com o seguinte esquema. A partir dos n√∫meros \\(1, 2, \\dots, 44\\), uma pessoa pode escolher quaisquer seis para seu bilhete. O n√∫mero vencedor √© ent√£o decidido selecionando aleatoriamente seis n√∫meros dentre os quarenta e quatro. Para calcular a probabilidade de ganhar, devemos primeiro contar quantos grupos diferentes de seis n√∫meros podem ser escolhidos a partir dos quarenta e quatro.\n\n\nExemplo 1.2.13 (Torneio)\nEm um torneio de elimina√ß√£o simples, como o torneio de t√™nis U.S. Open, os jogadores avan√ßam apenas se vencerem (ao contr√°rio de torneios de elimina√ß√£o dupla ou todos contra todos). Se tivermos 16 participantes, podemos estar interessados no n√∫mero de caminhos que um jogador em particular pode tomar para a vit√≥ria, onde um caminho √© considerado uma sequ√™ncia de oponentes.\n\nProblemas de contagem, em geral, parecem complicados, e muitas vezes devemos fazer nossa contagem sujeita a muitas restri√ß√µes. A maneira de resolver tais problemas √© dividi-los em uma s√©rie de tarefas simples que s√£o f√°ceis de contar, e empregar regras conhecidas de combina√ß√£o de tarefas. O teorema a seguir √© um primeiro passo em tal processo e √†s vezes √© conhecido como o Teorema Fundamental da Contagem.\n\nTeorema 1.2.14\nSe um trabalho consiste em \\(k\\) tarefas separadas, a i-√©sima das quais pode ser feita de \\(n_i\\) maneiras, \\(i = 1, \\dots, k\\), ent√£o o trabalho inteiro pode ser feito de \\(n_1 \\times n_2 \\times \\dots \\times n_k\\) maneiras.\n\n\nComprova√ß√£o. Basta provar o teorema para \\(k=2\\) (veja Exerc√≠cio 1.15). A prova √© apenas uma quest√£o de contagem cuidadosa. A primeira tarefa pode ser feita de \\(n_1\\) maneiras, e para cada uma dessas maneiras temos \\(n_2\\) escolhas para a segunda tarefa. Assim, podemos fazer o trabalho em\n\\[\n\\underbrace{(1 \\times n_2) + (1 \\times n_2) + \\dots + (1 \\times n_2)}_{n_1 \\text{ termos}} = n_1 \\times n_2\n\\]\nmaneiras, estabelecendo o teorema para \\(k=2\\). \\(\\square\\)\n\n\nExemplo 1.2.15 (Loteria‚ÄîII)\nEmbora o Teorema Fundamental da Contagem seja um lugar razo√°vel para come√ßar, em aplica√ß√µes geralmente h√° mais aspectos de um problema a considerar. Por exemplo, na loteria do estado de Nova York, o primeiro n√∫mero pode ser escolhido de 44 maneiras e o segundo n√∫mero de 43 maneiras, totalizando \\(44 \\times 43 = 1.892\\) maneiras de escolher os dois primeiros n√∫meros. No entanto, se uma pessoa tem permiss√£o para escolher o mesmo n√∫mero duas vezes, ent√£o os dois primeiros n√∫meros podem ser escolhidos de \\(44 \\times 44 = 1.936\\) maneiras.\n\nA distin√ß√£o feita no Exemplo 1.2.15 √© entre contar com reposi√ß√£o e contar sem reposi√ß√£o. H√° um segundo elemento crucial em qualquer problema de contagem: se a ordem das tarefas √© importante. Para ilustrar com o exemplo da loteria, suponha que os n√∫meros vencedores sejam selecionados na ordem 12, 37, 35, 9, 13, 22. Uma pessoa que selecionou 9, 12, 13, 22, 35, 37 se qualifica como vencedora? Em outras palavras, a ordem na qual a tarefa √© realizada realmente importa? Levando todas essas considera√ß√µes em conta, podemos construir uma tabela \\(2 \\times 2\\) de possibilidades:\n\nPossivel M√©todo de Contar\n\n\n\nSem reposi√ß√£o\nCom reposi√ß√£o\n\n\n\n\nOrdenado\n\n\n\n\nN√£o ordenado\n\n\n\n\n\nAntes de come√ßarmos a contar, a seguinte defini√ß√£o nos d√° uma nota√ß√£o extremamente √∫til.\n\nDefini√ß√£o 1.2.16\nPara um inteiro positivo \\(n\\), \\(n!\\) (l√™-se \\(n\\) fatorial) √© o produto de todos os inteiros positivos menores ou iguais a \\(n\\). Isto √©, \\[\nn! = n \\times (n-1) \\times (n-2) \\times \\dots \\times 3 \\times 2 \\times 1.\n\\] Al√©m disso, definimos \\(0! = 1\\).\n\nVamos agora considerar todos os poss√≠veis bilhetes de loteria sob cada um desses quatro casos.\n\nOrdenado, sem reposi√ß√£o: Pelo Teorema Fundamental da Contagem, o primeiro n√∫mero pode ser selecionado de 44 maneiras, o segundo de 43 maneiras, etc. Portanto, existem \\[\n44 \\times 43 \\times 42 \\times 41 \\times 40 \\times 39 = \\frac{44!}{38!} = 5.082.517.440\n\\] bilhetes poss√≠veis.\nOrdenado, com reposi√ß√£o: Como cada n√∫mero pode agora ser selecionado de 44 maneiras (porque o n√∫mero escolhido √© reposto), existem \\[\n44 \\times 44 \\times 44 \\times 44 \\times 44 \\times 44 = 44^6 = 7.256.313.856\n\\] bilhetes poss√≠veis.\nN√£o ordenado, sem reposi√ß√£o: Sabemos o n√∫mero de bilhetes poss√≠veis quando a ordem deve ser considerada, ent√£o o que devemos fazer √© dividir as ordena√ß√µes redundantes. Novamente pelo Teorema Fundamental, seis n√∫meros podem ser organizados de \\(6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1\\) maneiras, ent√£o o n√∫mero total de bilhetes n√£o ordenados √©\n\n\\[\n\\frac{44 \\times 43 \\times 42 \\times 41 \\times 40 \\times 39}{6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1} = \\frac{44!}{6! 38!} = 7.059.052.\n\\] Esta forma de contar desempenha um papel central em grande parte da estat√≠stica ‚Äî tanto, de fato, que ganhou sua pr√≥pria nota√ß√£o.\n\nDefini√ß√£o 1.2.17\nPara inteiros n√£o negativos \\(n\\) e \\(r\\), onde \\(n \\ge r\\), definimos o s√≠mbolo \\(\\binom{n}{r}\\), lido \\(n\\) escolhe \\(r\\), como \\[\n\\binom{n}{r} = \\frac{n!}{r!(n-r)!}.\n\\]\n\nEm nosso exemplo da loteria, o n√∫mero de bilhetes poss√≠veis (n√£o ordenados, sem reposi√ß√£o) √© \\(\\binom{44}{6}\\). Esses n√∫meros tamb√©m s√£o referidos como coeficientes binomiais, por raz√µes que ficar√£o claras no Cap√≠tulo 3.\n\nN√£o ordenado, com reposi√ß√£o: Este √© o caso mais dif√≠cil de contar. Voc√™ pode primeiro supor que a resposta √© \\(44^6 / (6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1)\\), mas isso n√£o est√° correto (√© muito pequeno). Para contar neste caso, √© mais f√°cil pensar em colocar 6 marcadores nos 44 n√∫meros. De fato, podemos pensar nos 44 n√∫meros definindo compartimentos nos quais podemos colocar os seis marcadores, M, como mostrado nesta figura.\n\n\n\n\nFigura representando marcadores (M) em compartimentos numerados\n\n\nO n√∫mero de bilhetes poss√≠veis √© ent√£o igual ao n√∫mero de maneiras que podemos colocar os 6 marcadores nos 44 compartimentos. Mas isso pode ser ainda mais reduzido observando que tudo o que precisamos acompanhar √© o arranjo dos marcadores e das paredes dos compartimentos. Note ainda que as duas paredes mais externas n√£o desempenham nenhum papel. Assim, temos que contar todos os arranjos de 43 paredes (44 compartimentos geram 45 paredes, mas desconsideramos as duas paredes das extremidades) e 6 marcadores. Temos \\(43 + 6 = 49\\) objetos, que podem ser arranjados de \\(49!\\) maneiras. No entanto, para eliminar as ordena√ß√µes redundantes, devemos dividir tanto por \\(6!\\) quanto por \\(43!\\), de modo que o n√∫mero total de arranjos √©\n\\[\n\\frac{49!}{6! 43!} = 13.983.816.\n\\]\nEmbora todas as deriva√ß√µes precedentes tenham sido feitas em termos de um exemplo, deve ser f√°cil ver que elas valem em geral. Por completude, podemos resumir essas situa√ß√µes na Tabela 1.2.1.\nTabela 1.2.1. N√∫mero de arranjos poss√≠veis de tamanho \\(r\\) a partir de \\(n\\) objetos\n\n\n\n\nSem reposi√ß√£o\nCom reposi√ß√£o\n\n\n\n\nOrdenado\n\\(\\frac{n!}{(n-r)!}\\)\n\\(n^r\\)\n\n\nN√£o ordenado\n\\(\\binom{n}{r}\\)\n\\(\\binom{n+r-1}{r}\\)\n\n\n\n\n1.2.4 Enumerando Resultados\nAs t√©cnicas de contagem da se√ß√£o anterior s√£o √∫teis quando o espa√ßo amostral \\(S\\) √© um conjunto finito e todos os resultados em \\(S\\) s√£o igualmente prov√°veis. Ent√£o, probabilidades de eventos podem ser calculadas simplesmente contando o n√∫mero de resultados no evento. Para ver isso, suponha que \\(S = \\{s_1, \\dots, s_N\\}\\) √© um espa√ßo amostral finito. Dizer que todos os resultados s√£o igualmente prov√°veis significa que \\(P(\\{s_i\\}) = 1/N\\) para cada resultado \\(s_i\\). Ent√£o, usando o Axioma 3 da Defini√ß√£o 1.2.4, temos, para qualquer evento \\(A\\),\n\\[\nP(A) = \\sum_{s_i \\in A} P(\\{s_i\\}) = \\sum_{s_i \\in A} \\frac{1}{N} = \\frac{ \\text{ N√∫mero de elementos em } A}{ \\text{ N√∫mero de elementos em } S}.\n\\]\nPara grandes espa√ßos amostrais, as t√©cnicas de contagem podem ser usadas para calcular tanto o numerador quanto o denominador desta express√£o.\n\n\nExemplo 1.2.18 (P√¥quer)\nConsidere escolher uma m√£o de p√¥quer de cinco cartas de um baralho padr√£o de 52 cartas de baralho. Obviamente, estamos amostrando sem reposi√ß√£o do baralho. Mas para especificar os resultados poss√≠veis (m√£os poss√≠veis), devemos decidir se pensamos na m√£o sendo dada sequencialmente (ordenada) ou toda de uma vez (n√£o ordenada). Se desejamos calcular probabilidades para eventos que dependem da ordem, como a probabilidade de um √°s nas duas primeiras cartas, ent√£o devemos usar os resultados ordenados. Mas se nossos eventos n√£o dependem da ordem, podemos usar os resultados n√£o ordenados. Para este exemplo, usaremos os resultados n√£o ordenados, ent√£o o espa√ßo amostral consiste em todas as m√£os de cinco cartas que podem ser escolhidas do baralho de 52 cartas. Existem \\(\\binom{52}{5} = 2.598.960\\) m√£os poss√≠veis. Se o baralho for bem embaralhado e as cartas forem dadas aleatoriamente, √© razo√°vel atribuir probabilidade \\(1/2.598.960\\) a cada m√£o poss√≠vel. Calculamos agora algumas probabilidades contando resultados em eventos. Qual √© a probabilidade de ter quatro ases? Quantas m√£os diferentes existem com quatro ases? Se especificarmos que quatro das cartas s√£o ases, ent√£o h√° 48 maneiras diferentes de especificar a quinta carta. Assim,\n\\[\nP(\\text{quatro ases}) = \\frac{48}{2.598.960},\n\\]\nmenos de 1 chance em 50.000. Apenas uma contagem ligeiramente mais complicada, usando o Teorema 1.2.14, nos permite calcular a probabilidade de ter uma quadra (quatro cartas do mesmo valor). Existem 13 maneiras de especificar qual denomina√ß√£o haver√° quatro. Depois de especificarmos esses quatro, existem 48 maneiras de especificar a quinta. Assim, o n√∫mero total de m√£os com uma quadra √© \\((13)(48)\\) e\n\\[\nP(\\text{quadra}) = \\frac{(13)(48)}{2.598.960} = \\frac{624}{2.598.960}.\n\\]\nPara calcular a probabilidade de exatamente um par (n√£o dois pares, n√£o trinca, etc.) combinamos algumas das t√©cnicas de contagem. O n√∫mero de m√£os com exatamente um par √©\n\\[\n13 \\binom{4}{2} \\binom{12}{3} 4^3 = 1.098.240.\n\\]\nA express√£o (1.2.11) vem do Teorema 1.2.14 porque:\n\n\\(13\\) √© o n√∫mero de maneiras de especificar a denomina√ß√£o para o par,\n\\(\\binom{4}{2}\\) √© o n√∫mero de maneiras de especificar as duas cartas daquela denomina√ß√£o,\n\\(\\binom{12}{3}\\) √© o n√∫mero de maneiras de especificar as outras tr√™s denomina√ß√µes,\n\\(4^3\\) √© o n√∫mero de maneiras de especificar as outras tr√™s cartas dessas denomina√ß√µes.\n\nAssim,\n\\[\nP(\\text{exatamente um par}) = \\frac{1.098.240}{2.598.960}.\n\\]\n\nAo amostrar sem reposi√ß√£o, como no Exemplo 1.2.18, se queremos calcular a probabilidade de um evento que n√£o depende da ordem, podemos usar tanto o espa√ßo amostral ordenado quanto o n√£o ordenado. Cada resultado no espa√ßo amostral n√£o ordenado corresponde a \\(r!\\) resultados no espa√ßo amostral ordenado. Assim, ao contar resultados no espa√ßo amostral ordenado, usamos um fator de \\(r!\\) tanto no numerador quanto no denominador que cancelar√° para dar a mesma probabilidade como se cont√°ssemos no espa√ßo amostral n√£o ordenado. A situa√ß√£o √© diferente se amostramos com reposi√ß√£o. Cada resultado no espa√ßo amostral n√£o ordenado corresponde a alguns resultados no espa√ßo amostral ordenado, mas o n√∫mero de resultados difere.\n\nExemplo 1.2.19 (Amostragem com reposi√ß√£o)\nConsidere amostrar \\(r=2\\) itens de \\(n=3\\) itens, com reposi√ß√£o. Os resultados nos espa√ßos amostrais ordenados e n√£o ordenados s√£o estes:\n\n\n\n\n\n\n\n\n\n\n\n\nN√£o ordenado\n\\(\\{1,1\\}\\)\n\\(\\{2,2\\}\\)\n\\(\\{3,3\\}\\)\n\\(\\{1,2\\}\\)\n\\(\\{1,3\\}\\)\n\\(\\{2,3\\}\\)\n\n\nOrdenado\n\\((1,1)\\)\n\\((2,2)\\)\n\\((3,3)\\)\n\\((1,2), (2,1)\\)\n\\((1,3), (3,1)\\)\n\\((2,3), (3,2)\\)\n\n\nProbabilidade\n\\(1/9\\)\n\\(1/9\\)\n\\(1/9\\)\n\\(2/9\\)\n\\(2/9\\)\n\\(2/9\\)\n\n\n\nAs probabilidades v√™m da considera√ß√£o dos nove resultados no espa√ßo amostral ordenado como sendo igualmente prov√°veis. Isto corresponde √† interpreta√ß√£o comum de ‚Äúamostragem com reposi√ß√£o‚Äù; a saber, um dos tr√™s itens √© escolhido, cada um com probabilidade 1/3; o item √© anotado e reposto; os itens s√£o misturados e novamente um dos tr√™s itens √© escolhido, cada um com probabilidade 1/3. V√™-se que os seis resultados no espa√ßo amostral n√£o ordenado n√£o s√£o igualmente prov√°veis sob este tipo de amostragem. A f√≥rmula para o n√∫mero de resultados no espa√ßo amostral n√£o ordenado √© √∫til para enumerar os resultados, mas os resultados ordenados devem ser usados para calcular probabilidades corretamente.\n\nAlguns autores argumentam que √© apropriado atribuir probabilidades iguais aos resultados n√£o ordenados quando ‚Äúdistribuindo aleatoriamente \\(r\\) bolas indistingu√≠veis em \\(n\\) urnas distingu√≠veis‚Äù. Isto √©, uma urna √© escolhida aleatoriamente e uma bola colocada nela, e isso √© repetido \\(r\\) vezes. A ordem em que as bolas s√£o colocadas n√£o √© registrada, ent√£o, no final, um resultado como \\(\\{1,3\\}\\) significa uma bola na urna 1 e uma bola na urna 3. Mas aqui est√° o problema com essa interpreta√ß√£o. Suponha que duas pessoas observem este processo, e o Observador 1 registra a ordem em que as bolas s√£o colocadas, mas o Observador 2 n√£o. O Observador 1 atribuir√° probabilidade \\(2/9\\) ao evento \\(\\{1,3\\}\\). O Observador 2, que est√° observando exatamente o mesmo processo, tamb√©m deve atribuir probabilidade \\(2/9\\) a este evento. Mas se os seis resultados n√£o ordenados s√£o escritos em peda√ßos de papel id√™nticos e um √© escolhido aleatoriamente para determinar a coloca√ß√£o das bolas, ent√£o os resultados n√£o ordenados t√™m, cada um, probabilidade \\(1/6\\). Ent√£o o Observador 2 atribuir√° probabilidade \\(1/6\\) ao evento \\(\\{1,3\\}\\). A confus√£o surge porque a frase ‚Äúcom reposi√ß√£o‚Äù tipicamente ser√° interpretada com o tipo sequencial de amostragem que descrevemos acima, levando a atribuir uma probabilidade \\(2/9\\) ao evento \\(\\{1,3\\}\\). Esta √© a maneira correta de proceder, pois as probabilidades devem ser determinadas pelo mecanismo de amostragem, n√£o se as bolas s√£o distingu√≠veis ou indistingu√≠veis.\n\nExemplo 1.2.20 (Calculando uma m√©dia)\nComo uma ilustra√ß√£o da abordagem distingu√≠vel/indistingu√≠vel, suponha que vamos calcular todas as m√©dias poss√≠veis de quatro n√∫meros selecionados de\n\\[\n2, 4, 9, 12\n\\]\nonde sorteamos os n√∫meros com reposi√ß√£o. Por exemplo, poss√≠veis sorteios s√£o \\(\\{2, 4, 4, 9\\}\\) com m√©dia 4,75 e \\(\\{4, 4, 9, 9\\}\\) com m√©dia 6,5. Se estamos interessados apenas na m√©dia dos n√∫meros amostrados, a ordena√ß√£o n√£o √© importante e, assim, o n√∫mero total de amostras distintas √© obtido contando de acordo com amostragem n√£o ordenada, com reposi√ß√£o. O n√∫mero total de amostras distintas √© \\(\\binom{4+4-1}{4}\\). Mas agora, para calcular a distribui√ß√£o de probabilidade das m√©dias amostrais, devemos contar as diferentes maneiras que uma m√©dia particular pode ocorrer. O valor 4,75 pode ocorrer apenas se a amostra contiver um 2, dois 4s e um 9. O n√∫mero de amostras poss√≠veis que t√™m esta configura√ß√£o √© dado na seguinte tabela:\n\n\n\nFigura 1.2.2 - Histograma das m√©dias de amostras com reposi√ß√£o dos quatro n√∫meros {2, 4, 4, 9}\n\n\n\n\n\n\n\n\n\nN√£o ordenado\nOrdenado\n\n\n\n\n\\(\\{2, 4, 4, 9\\}\\)\n\\((2, 4, 4, 9), (2, 4, 9, 4), (2, 9, 4, 4), (4, 2, 4, 9),\\)  \\((4, 2, 9, 4), (4, 4, 2, 9), (4, 4, 9, 2), (4, 9, 2, 4),\\)  \\((4, 9, 4, 2), (9, 2, 4, 4), (9, 4, 2, 4), (9, 4, 4, 2)\\)\n\n\n\nO n√∫mero total de amostras ordenadas √© \\(n^n = 4^4 = 256\\), ent√£o a probabilidade de sortear a amostra n√£o ordenada \\(\\{2, 4, 4, 9\\}\\) √© 12/256. Compare isso com a probabilidade que ter√≠amos obtido se consider√°ssemos as amostras n√£o ordenadas como igualmente prov√°veis ‚Äî ter√≠amos atribu√≠do probabilidade \\(1/\\binom{n+n-1}{n} = 1/\\binom{7}{4} = 1/35\\) a \\(\\{2, 4, 4, 9\\}\\) e a qualquer outra amostra n√£o ordenada. Para contar o n√∫mero de amostras ordenadas que resultariam em \\(\\{2, 4, 4, 9\\}\\), argumentamos da seguinte forma. Precisamos enumerar as ordens poss√≠veis dos quatro n√∫meros \\(\\{2, 4, 4, 9\\}\\), ent√£o estamos essencialmente usando o m√©todo de contagem 1 da Se√ß√£o 1.2.3. Podemos ordenar a amostra de \\(4 \\times 3 \\times 2 \\times 1 = 24\\) maneiras. Mas h√° um pouco de contagem dupla aqui, j√° que n√£o podemos distinguir os dois 4s. Por exemplo, as 24 maneiras contariam \\(\\{9, 4, 2, 4\\}\\) duas vezes (o que estaria OK se os 4s fossem diferentes). Para corrigir isso, dividimos por \\(2!\\) (existem \\(2!\\) maneiras de organizar os dois 4s) e obtemos \\(24/2 = 12\\) amostras ordenadas. Em geral, se existem \\(k\\) lugares e temos \\(m\\) n√∫meros diferentes repetidos \\(k_1, k_2, \\dots, k_m\\) vezes, ent√£o o n√∫mero de amostras ordenadas √© \\[\n\\frac{k!}{k_1! k_2! \\dots k_m!}.\n\\] Este tipo de contagem est√° relacionado √† distribui√ß√£o multinomial, que veremos na Se√ß√£o 4.6. A Figura 1.2.2 √© um histograma da distribui√ß√£o de probabilidade das m√©dias amostrais, refletindo a contagem multinomial das amostras. H√° tamb√©m mais um refinamento que √© refletido na Figura 1.2.2. √â poss√≠vel que duas amostras n√£o ordenadas diferentes resultem na mesma m√©dia. Por exemplo, as amostras n√£o ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\) ambas resultam em uma m√©dia de 8. A primeira amostra tem probabilidade 6/256 e a segunda tem probabilidade 12/256, dando ao valor 8 uma probabilidade de \\(18/256 = .07\\). Veja o Exemplo A.0.1 no Ap√™ndice A para detalhes sobre a constru√ß√£o de tal histograma. O c√°lculo que fizemos neste exemplo √© uma vers√£o elementar de uma t√©cnica estat√≠stica muito importante conhecida como bootstrap (Efron e Tibshirani 1993). Voltaremos ao bootstrap na Se√ß√£o 10.1.4.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#probabilidade-condicional-e-independ√™ncia",
    "href": "cap-1.html#probabilidade-condicional-e-independ√™ncia",
    "title": "Teoria da Probabilidade",
    "section": "1.3 Probabilidade Condicional e Independ√™ncia",
    "text": "1.3 Probabilidade Condicional e Independ√™ncia\nTodas as probabilidades com as quais lidamos at√© agora foram probabilidades incondicionais. Um espa√ßo amostral foi definido e todas as probabilidades foram calculadas com respeito a esse espa√ßo amostral. Em muitos casos, no entanto, estamos em uma posi√ß√£o de atualizar o espa√ßo amostral com base em novas informa√ß√µes. Nesses casos, queremos ser capazes de atualizar os c√°lculos de probabilidade para calcular probabilidades condicionais.\n\nExemplo 1.3.1 (Quatro ases)\nQuatro cartas s√£o distribu√≠das do topo de um baralho bem embaralhado. Qual √© a probabilidade de que sejam os quatro ases? Podemos calcular essa probabilidade pelos m√©todos da se√ß√£o anterior. O n√∫mero de grupos distintos de quatro cartas √© \\[\n\\binom{52}{4} = 270.725.\n\\] Apenas um desses grupos consiste nos quatro ases e cada grupo √© igualmente prov√°vel, ent√£o a probabilidade de serem distribu√≠dos os quatro ases √© \\(1/270.725\\). Tamb√©m podemos calcular essa probabilidade por um argumento de ‚Äúatualiza√ß√£o‚Äù, como segue. A probabilidade de que a primeira carta seja um √°s √© \\(4/52\\). Dado que a primeira carta √© um √°s, a probabilidade de que a segunda carta seja um √°s √© \\(3/51\\) (h√° 3 ases e 51 cartas restantes). Continuando com esse argumento, obtemos a probabilidade desejada como \\[\n\\frac{4}{52} \\times \\frac{3}{51} \\times \\frac{2}{50} \\times \\frac{1}{49} = \\frac{1}{270.725}.\n\\]\n\nEm nosso segundo m√©todo de resolver o problema, atualizamos o espa√ßo amostral ap√≥s cada distribui√ß√£o de uma carta; calculamos probabilidades condicionais.\n\nDefini√ß√£o 1.3.2\nSe \\(A\\) e \\(B\\) s√£o eventos em \\(S\\), e \\(P(B) &gt; 0\\), ent√£o a probabilidade condicional de \\(A\\) dado \\(B\\), escrita \\(P(A|B)\\), √© \\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}.\n\\]\n\nNote que o que acontece no c√°lculo da probabilidade condicional √© que \\(B\\) se torna o espa√ßo amostral: \\(P(B|B) = 1\\). A intui√ß√£o √© que nosso espa√ßo amostral original, \\(S\\), foi atualizado para \\(B\\). Todas as outras ocorr√™ncias s√£o ent√£o calibradas com respeito √† sua rela√ß√£o com \\(B\\). Em particular, note o que acontece com probabilidades condicionais de conjuntos disjuntos. Suponha que \\(A\\) e \\(B\\) sejam disjuntos, ent√£o \\(P(A \\cap B) = 0\\). Segue ent√£o que \\(P(A|B) = P(B|A) = 0\\).\n\nExemplo 1.3.3 (Continua√ß√£o do Exemplo 1.3.1)\nEmbora a probabilidade de obter todos os quatro ases seja bem pequena, vejamos como as probabilidades condicionais mudam dado que alguns ases j√° foram retirados. Quatro cartas ser√£o novamente distribu√≠das de um baralho bem embaralhado, e agora calculamos \\[\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}), \\quad i = 1, 2, 3.\n\\] O evento \\(\\{4 \\text{ ases em 4 cartas}\\}\\) √© um subconjunto do evento \\(\\{i \\text{ ases em } i \\text{ cartas}\\}\\). Assim, da defini√ß√£o de probabilidade condicional, (1.3.1), sabemos que \\[\n\\begin{align*}\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}) &= \\frac{P(\\{4 \\text{ ases em 4 cartas}\\} \\cap \\{i \\text{ ases em } i \\text{ cartas}\\})}{P(i \\text{ ases em } i \\text{ cartas})} \\\\\n&= \\frac{P(4 \\text{ ases em 4 cartas})}{P(i \\text{ ases em } i \\text{ cartas})}.\n\\end{align*}\n\\] O numerador j√° foi calculado, e o denominador pode ser calculado com um argumento semelhante. O n√∫mero de grupos distintos de \\(i\\) cartas √© \\(\\binom{52}{i}\\), e \\[\nP(i \\text{ ases em } i \\text{ cartas}) = \\frac{\\binom{4}{i}}{\\binom{52}{i}}.\n\\] Portanto, a probabilidade condicional √© dada por \\[\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}) = \\frac{\\frac{\\binom{4}{4}}{\\binom{52}{4}}}{\\frac{\\binom{4}{i}}{\\binom{52}{i}}} = \\frac{(4-i)! 48!}{(52-i)!} = \\frac{1}{\\binom{52-i}{4-i}}.\n\\] Para \\(i = 1, 2\\) e \\(3\\), as probabilidades condicionais s√£o \\(.00005, .00082\\) e \\(.02041\\), respectivamente.\n\nPara qualquer \\(B\\) para o qual \\(P(B) &gt; 0\\), √© simples verificar que a fun√ß√£o de probabilidade \\(P(\\cdot|B)\\) satisfaz os Axiomas de Kolmogorov (veja Exerc√≠cio 1.35). Voc√™ pode suspeitar que exigir \\(P(B) &gt; 0\\) √© redundante. Quem iria querer condicionar em um evento de probabilidade 0? Curiosamente, √†s vezes essa √© uma maneira particularmente √∫til de pensar nas coisas. No entanto, adiaremos essas considera√ß√µes at√© o Cap√≠tulo 4. Probabilidades condicionais podem ser entidades particularmente escorregadias e, √†s vezes, requerem reflex√£o cuidadosa. Considere o seguinte conto frequentemente narrado.\n\nExemplo 1.3.4 (Tr√™s prisioneiros)\nTr√™s prisioneiros, A, B e C, est√£o no corredor da morte. O governador decide perdoar um dos tr√™s e escolhe aleatoriamente o prisioneiro a ser perdoado. Ele informa o diretor da pris√£o de sua escolha, mas solicita que o nome seja mantido em segredo por alguns dias. No dia seguinte, A tenta fazer com que o diretor lhe diga quem foi perdoado. O diretor se recusa. A ent√£o pergunta qual de B ou C ser√° executado. O diretor pensa por um momento, depois diz a A que B ser√° executado. Racioc√≠nio do diretor: Cada prisioneiro tem uma chance de \\(\\frac{1}{3}\\) de ser perdoado. Claramente, ou B ou C deve ser executado, ent√£o n√£o dei a A nenhuma informa√ß√£o sobre se A ser√° perdoado. Racioc√≠nio de A: Dado que B ser√° executado, ent√£o ou A ou C ser√° perdoado. Minha chance de ser perdoado aumentou para \\(\\frac{1}{2}\\). Deve ficar claro que o racioc√≠nio do diretor est√° correto, mas vejamos o porqu√™. Sejam \\(A, B\\) e \\(C\\) os eventos de que A, B ou C √© perdoado, respectivamente. Sabemos que \\(P(A) = P(B) = P(C) = \\frac{1}{3}\\). Seja \\(\\mathcal{W}\\) o evento de que o diretor diz que B morrer√°. Usando (1.3.1), A pode atualizar sua probabilidade de ser perdoado para \\[\nP(A|\\mathcal{W}) = \\frac{P(A \\cap \\mathcal{W})}{P(\\mathcal{W})}.\n\\] O que est√° acontecendo pode ser resumido nesta tabela:\n\n\n\nPrisioneiro perdoado\nDiretor diz a A\n\n\n\n\n\nA\nB morre\ncada um com igual\n\n\nA\nC morre\nprobabilidade\n\n\nB\nC morre\n\n\n\nC\nB morre\n\n\n\n\nUsando esta tabela, podemos calcular \\[\n\\begin{align*}\nP(\\mathcal{W}) &= P(\\text{diretor diz B morre}) \\\\\n&= P(\\text{diretor diz B morre e A perdoado}) \\\\\n&\\quad + P(\\text{diretor diz B morre e C perdoado}) \\\\\n&\\quad + P(\\text{diretor diz B morre e B perdoado}) \\\\\n&= \\frac{1}{6} + \\frac{1}{3} + 0 = \\frac{1}{2}.\n\\end{align*}\n\\] Assim, usando o racioc√≠nio do diretor, temos \\[\nP(A|\\mathcal{W}) = \\frac{P(A \\cap \\mathcal{W})}{P(\\mathcal{W})} = \\frac{P(\\text{diretor diz B morre e A perdoado})}{P(\\text{diretor diz B morre})} = \\frac{1/6}{1/2} = \\frac{1}{3}.\n\\] No entanto, um A interpreta falsamente o evento \\(\\mathcal{W}\\) como igual ao evento \\(B^c\\) e calcula \\[\nP(A|B^c) = \\frac{P(A \\cap B^c)}{P(B^c)} = \\frac{1/3}{2/3} = \\frac{1}{2}.\n\\] Vemos que probabilidades condicionais podem ser bastante escorregadias e exigem interpreta√ß√£o cuidadosa. Para algumas outras varia√ß√µes deste problema, veja o Exerc√≠cio 1.37.\n\nReexpressando (1.3.1) d√° uma forma √∫til para calcular probabilidades de interse√ß√£o, \\[\nP(A \\cap B) = P(A|B)P(B), \\quad (1.3.3)\n\\] que √© essencialmente a f√≥rmula que foi usada no Exemplo 1.3.1. Podemos tirar proveito da simetria de (1.3.3) e tamb√©m escrever \\[\nP(A \\cap B) = P(B|A)P(A). \\quad (1.3.4)\n\\] Quando confrontados com c√°lculos aparentemente dif√≠ceis, podemos dividir nossos c√°lculos de acordo com (1.3.3) ou (1.3.4), o que for mais f√°cil. Al√©m disso, podemos igualar os lados direitos dessas equa√ß√µes para obter (ap√≥s rearranjo) \\[\nP(A|B) = P(B|A)\\frac{P(A)}{P(B)}, \\quad (1.3.5)\n\\] que nos d√° uma f√≥rmula para ‚Äúinverter‚Äù probabilidades condicionais. A Equa√ß√£o (1.3.5) √© frequentemente chamada de Regra de Bayes por seu descobridor, Sir Thomas Bayes (embora veja Stigler 1983). A Regra de Bayes tem uma forma mais geral do que (1.3.5), uma que se aplica a parti√ß√µes de um espa√ßo amostral. Tomamos, portanto, o seguinte como a defini√ß√£o da Regra de Bayes.\n\nTeorema 1.3.5 (Regra de Bayes)\nSeja \\(A_1, A_2, \\dots\\) uma parti√ß√£o do espa√ßo amostral, e seja \\(B\\) qualquer conjunto. Ent√£o, para cada \\(i = 1, 2, \\dots\\), \\[\nP(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{j=1}^{\\infty} P(B|A_j)P(A_j)}.\n\\]\n\n\nExemplo 1.3.6 (Codifica√ß√£o)\nQuando mensagens codificadas s√£o enviadas, √†s vezes ocorrem erros na transmiss√£o. Em particular, o c√≥digo Morse usa ‚Äúpontos‚Äù e ‚Äútra√ßos‚Äù, que s√£o conhecidos por ocorrer na propor√ß√£o de 3:4. Isso significa que para qualquer s√≠mbolo dado, \\[\nP(\\text{ponto enviado}) = \\frac{3}{7} \\quad \\text{e} \\quad P(\\text{tra√ßo enviado}) = \\frac{4}{7}.\n\\] Suponha que h√° interfer√™ncia na linha de transmiss√£o e, com probabilidade \\(\\frac{1}{8}\\), um ponto √© erroneamente recebido como um tra√ßo, e vice-versa. Se recebermos um ponto, podemos ter certeza de que um ponto foi enviado? Usando a Regra de Bayes, podemos escrever \\[\nP(\\text{ponto enviado} | \\text{ponto recebido}) = P(\\text{ponto recebido} | \\text{ponto enviado}) \\frac{P(\\text{ponto enviado})}{P(\\text{ponto recebido})}.\n\\] Agora, a partir da informa√ß√£o dada, sabemos que \\(P(\\text{ponto enviado}) = \\frac{3}{7}\\) e \\(P(\\text{ponto recebido} | \\text{ponto enviado}) = \\frac{7}{8}\\). Al√©m disso, tamb√©m podemos escrever \\[\n\\begin{align*}\nP(\\text{ponto recebido}) &= P(\\text{ponto recebido} \\cap \\text{ponto enviado}) + P(\\text{ponto recebido} \\cap \\text{tra√ßo enviado}) \\\\\n&= P(\\text{ponto recebido} | \\text{ponto enviado})P(\\text{ponto enviado}) \\\\\n&\\quad + P(\\text{ponto recebido} | \\text{tra√ßo enviado})P(\\text{tra√ßo enviado}) \\\\\n&= \\frac{7}{8} \\times \\frac{3}{7} + \\frac{1}{8} \\times \\frac{4}{7} = \\frac{25}{56}.\n\\end{align*}\n\\] Combinando esses resultados, temos que a probabilidade de receber corretamente um ponto √© \\[\nP(\\text{ponto enviado} | \\text{ponto recebido}) = \\frac{(7/8) \\times (3/7)}{25/56} = \\frac{21}{25}.\n\\]\n\nEm alguns casos, pode acontecer que a ocorr√™ncia de um evento particular, \\(B\\), n√£o tenha efeito sobre a probabilidade de outro evento, \\(A\\). Simbolicamente, estamos dizendo que \\[\nP(A|B) = P(A). \\quad (1.3.6)\n\\] Se isso vale, ent√£o pela Regra de Bayes (1.3.5) e usando (1.3.6) temos \\[\nP(B|A) = P(A|B)\\frac{P(B)}{P(A)} = P(A)\\frac{P(B)}{P(A)} = P(B), \\quad (1.3.7)\n\\] ent√£o a ocorr√™ncia de \\(A\\) n√£o tem efeito sobre \\(B\\). Al√©m disso, como \\(P(B|A)P(A) = P(A \\cap B)\\), segue-se que \\[\nP(A \\cap B) = P(A)P(B),\n\\] o que tomamos como a defini√ß√£o de independ√™ncia estat√≠stica.\n\nDefini√ß√£o 1.3.7\nDois eventos, \\(A\\) e \\(B\\), s√£o estatisticamente independentes se \\[\nP(A \\cap B) = P(A)P(B). \\quad (1.3.8)\n\\]\n\nNote que a independ√™ncia poderia ter sido equivalentemente definida por (1.3.6) ou (1.3.7) (desde que \\(P(A) &gt; 0\\) ou \\(P(B) &gt; 0\\)). A vantagem de (1.3.8) √© que ela trata os eventos simetricamente e ser√° mais f√°cil de generalizar para mais de dois eventos. Muitos jogos de azar fornecem modelos de eventos independentes. Os giros de uma roleta e os lan√ßamentos de um par de dados s√£o ambas s√©ries de eventos independentes.\n\nExemplo 1.3.8 (Chevalier de M√©r√©)\nO jogador introduzido no in√≠cio do cap√≠tulo, o Chevalier de M√©r√©, estava particularmente interessado no evento de que ele poderia lan√ßar pelo menos um 6 em 4 lan√ßamentos de um dado. N√≥s temos \\[\n\\begin{align*}\nP(\\text{pelo menos um 6 em 4 lan√ßamentos}) &= 1 - P(\\text{nenhum seis em 4 lan√ßamentos}) \\\\\n&= 1 - \\prod_{i=1}^4 P(\\text{nenhum seis no lan√ßamento } i),\n\\end{align*}\n\\] onde a √∫ltima igualdade decorre da independ√™ncia dos lan√ßamentos. Em qualquer lan√ßamento, a probabilidade de n√£o rolar um seis √© \\(\\frac{5}{6}\\), ent√£o \\[\nP(\\text{pelo menos um 6 em 4 lan√ßamentos}) = 1 - \\left( \\frac{5}{6} \\right)^4 = .518.\n\\]\n\nA independ√™ncia de \\(A\\) e \\(B\\) implica independ√™ncia dos complementos tamb√©m. De fato, temos o seguinte teorema.\n\nTeorema 1.3.9\nSe A e B s√£o eventos independentes, ent√£o os seguintes pares tamb√©m s√£o independentes: * a. \\(A\\) e \\(B^c\\), * b. \\(A^c\\) e \\(B\\), * c. \\(A^c\\) e \\(B^c\\).\n\n\nComprova√ß√£o. Provaremos apenas (a), deixando o restante como Exerc√≠cio 1.40. Para provar (a) devemos mostrar que \\(P(A \\cap B^c) = P(A)P(B^c)\\). Do Teorema 1.2.9a temos \\[\n\\begin{align*}\nP(A \\cap B^c) &= P(A) - P(A \\cap B) \\\\\n&= P(A) - P(A)P(B) \\quad (A \\text{ e } B \\text{ s√£o independentes}) \\\\\n&= P(A)(1 - P(B)) \\\\\n&= P(A)P(B^c). \\quad \\square\n\\end{align*}\n\\]\n\nA independ√™ncia de mais de dois eventos pode ser definida de maneira semelhante a (1.3.8), mas devemos ter cuidado. Por exemplo, podemos pensar que poder√≠amos dizer \\(A, B\\) e \\(C\\) s√£o independentes se \\(P(A \\cap B \\cap C) = P(A)P(B)P(C)\\). No entanto, esta n√£o √© a condi√ß√£o correta.\n\nExemplo 1.3.10 (Lan√ßando dois dados)\nSeja um experimento consistindo em lan√ßar dois dados. Para este experimento, o espa√ßo amostral √© \\[\nS = \\{(1,1), (1,2), \\dots, (1,6), (2,1), \\dots, (2,6), \\dots, (6,1), \\dots, (6,6)\\};\n\\] isto √©, \\(S\\) consiste nos 36 pares ordenados formados a partir dos n√∫meros 1 a 6. Defina os seguintes eventos: * \\(A = \\{\\text{duplas aparecem}\\} = \\{(1,1), (2,2), (3,3), (4,4), (5,5), (6,6)\\}\\), * \\(B = \\{\\text{a soma est√° entre 7 e 10}\\}\\), * \\(C = \\{\\text{a soma √© 2 ou 7 ou 8}\\}\\).\nAs probabilidades podem ser calculadas contando entre os 36 resultados poss√≠veis. N√≥s temos \\[\nP(A) = \\frac{1}{6}, \\quad P(B) = \\frac{1}{2}, \\quad \\text{e} \\quad P(C) = \\frac{1}{3}.\n\\] Al√©m disso, \\[\n\\begin{align*}\nP(A \\cap B \\cap C) &= P(\\text{a soma √© 8, composta de duplos 4s}) \\\\\n&= \\frac{1}{36} \\\\\n&= \\frac{1}{6} \\times \\frac{1}{2} \\times \\frac{1}{3} \\\\\n&= P(A)P(B)P(C).\n\\end{align*}\n\\] No entanto, \\[\nP(B \\cap C) = P(\\text{soma igual a 7 ou 8}) = \\frac{11}{36} \\ne P(B)P(C).\n\\] Similarmente, pode ser mostrado que \\(P(A \\cap B) \\ne P(A)P(B)\\); portanto, o requisito \\(P(A \\cap B \\cap C) = P(A)P(B)P(C)\\) n√£o √© uma condi√ß√£o forte o suficiente para garantir independ√™ncia dois a dois.\n\nUma segunda tentativa de uma defini√ß√£o geral de independ√™ncia, √† luz do exemplo anterior, pode ser definir \\(A, B\\) e \\(C\\) como independentes se todos os pares forem independentes. Infelizmente, esta condi√ß√£o tamb√©m falha.\n\nExemplo 1.3.11 (Letras)\nSeja o espa√ßo amostral \\(S\\) consistindo nas \\(3!\\) permuta√ß√µes das letras a, b e c junto com as tr√™s triplas de cada letra. Assim, \\[\nS = \\begin{Bmatrix} \\text{aaa} & \\text{bbb} & \\text{ccc} \\\\ \\text{abc} & \\text{bca} & \\text{cba} \\\\ \\text{acb} & \\text{bac} & \\text{cab} \\end{Bmatrix}.\n\\] Al√©m disso, seja cada elemento de \\(S\\) ter probabilidade \\(\\frac{1}{9}\\). Defina \\[\nA_i = \\{\\text{o } i\\text{-√©simo lugar na tripla √© ocupado por a}\\}.\n\\] √â ent√£o f√°cil contar que \\[\nP(A_i) = \\frac{1}{3}, \\quad i = 1, 2, 3,\n\\] e \\[\nP(A_1 \\cap A_2) = P(A_1 \\cap A_3) = P(A_2 \\cap A_3) = \\frac{1}{9},\n\\] ent√£o os \\(A_i\\)s s√£o independentes dois a dois. Mas \\[\nP(A_1 \\cap A_2 \\cap A_3) = \\frac{1}{9} \\ne P(A_1)P(A_2)P(A_3),\n\\] ent√£o os \\(A_i\\)s n√£o satisfazem o requisito de probabilidade.\n\nOs dois exemplos anteriores mostram que a independ√™ncia simult√¢nea (ou m√∫tua) de uma cole√ß√£o de eventos requer uma defini√ß√£o extremamente forte. A seguinte defini√ß√£o funciona.\n\nDefini√ß√£o 1.3.12\nUma cole√ß√£o de eventos \\(A_1, \\dots, A_n\\) s√£o mutuamente independentes se para qualquer subcole√ß√£o \\(A_{i_1}, \\dots, A_{i_k}\\), temos \\[\nP\\left( \\bigcap_{j=1}^k A_{i_j} \\right) = \\prod_{j=1}^k P(A_{i_j}).\n\\]\n\n\nExemplo 1.3.13 (Tr√™s lan√ßamentos de moeda‚ÄîI)\nConsidere o experimento de lan√ßar uma moeda tr√™s vezes. Um ponto amostral para este experimento deve indicar o resultado de cada lan√ßamento. Por exemplo, HHT poderia indicar que duas caras e depois uma coroa foram observadas. O espa√ßo amostral para este experimento tem oito pontos, a saber,\n\\[\n\\{\\text{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT}\\}.\n\\]\nSeja \\(H_i, i = 1, 2, 3\\), o evento de que o \\(i\\)-√©simo lan√ßamento √© uma cara. Por exemplo,\n\\[\nH_1 = \\{\\text{HHH, HHT, HTH, HTT}\\}.\n\\]\nSe atribuirmos probabilidade \\(\\frac{1}{8}\\) a cada ponto amostral, ent√£o, usando enumera√ß√µes como (1.3.9), vemos que \\(P(H_1) = P(H_2) = P(H_3) = \\frac{1}{2}\\). Isso diz que a moeda √© justa e tem igual probabilidade de dar cara ou coroa em cada lan√ßamento. Sob este modelo de probabilidade, os eventos \\(H_1, H_2\\) e \\(H_3\\) tamb√©m s√£o mutuamente independentes. Para verificar isso, notamos que\n\\[\nP(H_1 \\cap H_2 \\cap H_3) = P(\\{\\text{HHH}\\}) = \\frac{1}{8} = \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} = P(H_1)P(H_2)P(H_3).\n\\]\nPara verificar a condi√ß√£o na Defini√ß√£o 1.3.12, devemos tamb√©m verificar cada par. Por exemplo,\n\\[\nP(H_1 \\cap H_2) = P(\\{\\text{HHH, HHT}\\}) = \\frac{2}{8} = \\frac{1}{2} \\cdot \\frac{1}{2} = P(H_1)P(H_2).\n\\]\nA igualdade tamb√©m √© verdadeira para os outros dois pares. Assim, \\(H_1, H_2\\) e \\(H_3\\) s√£o mutuamente independentes. Ou seja, a ocorr√™ncia de uma cara em qualquer lan√ßamento n√£o tem efeito em nenhum dos outros lan√ßamentos. Pode ser verificado que a atribui√ß√£o de probabilidade \\(\\frac{1}{8}\\) para cada ponto amostral √© o √∫nico modelo de probabilidade que tem \\(P(H_1) = P(H_2) = P(H_3) = \\frac{1}{2}\\) e \\(H_1, H_2\\) e \\(H_3\\) mutuamente independentes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#vari√°veis-aleat√≥rias",
    "href": "cap-1.html#vari√°veis-aleat√≥rias",
    "title": "Teoria da Probabilidade",
    "section": "1.4 Vari√°veis Aleat√≥rias",
    "text": "1.4 Vari√°veis Aleat√≥rias\nEm muitos experimentos, √© mais f√°cil lidar com uma vari√°vel resumo do que com a estrutura de probabilidade original. Por exemplo, em uma pesquisa de opini√£o, podemos decidir perguntar a 50 pessoas se elas concordam ou discordam de uma certa quest√£o. Se registrarmos um ‚Äú1‚Äù para concordo e ‚Äú0‚Äù para discordo, o espa√ßo amostral para este experimento tem \\(2^{50}\\) elementos, cada um uma string ordenada de 1s e 0s de comprimento 50. Devemos ser capazes de reduzir isso a um tamanho razo√°vel! Pode ser que a √∫nica quantidade de interesse seja o n√∫mero de pessoas que concordam (equivalentemente, discordam) de 50, e, se definirmos uma vari√°vel \\(X\\) = n√∫mero de 1s registrados em 50, capturamos a ess√™ncia do problema. Note que o espa√ßo amostral para \\(X\\) √© o conjunto de inteiros \\(\\{0, 1, 2, \\dots, 50\\}\\) e √© muito mais f√°cil de lidar do que o espa√ßo amostral original. Ao definir a quantidade \\(X\\), definimos um mapeamento (uma fun√ß√£o) do espa√ßo amostral original para um novo espa√ßo amostral, geralmente um conjunto de n√∫meros reais. Em geral, temos a seguinte defini√ß√£o.\n\nDefini√ß√£o 1.4.1 - Vari√°vel Aleat√≥ria\nUma vari√°vel aleat√≥ria √© uma fun√ß√£o de um espa√ßo amostral \\(S\\) para os n√∫meros reais.\n\n\nExemplo 1.4.2 (Vari√°veis aleat√≥rias)\nEm alguns experimentos, vari√°veis aleat√≥rias s√£o usadas implicitamente; alguns exemplos s√£o:\nExemplos de vari√°veis aleat√≥rias\n\n\n\n\n\n\n\nExperimento\nVari√°vel aleat√≥ria\n\n\n\n\nLan√ßar dois dados\n\\(X =\\) soma dos n√∫meros\n\n\nLan√ßar uma moeda 25 vezes\n\\(X =\\) n√∫mero de caras em 25 lan√ßamentos\n\n\nAplicar diferentes quantidades de fertilizante em plantas de milho\n\\(X =\\) produtividade/acre\n\n\n\nAo definir uma vari√°vel aleat√≥ria, tamb√©m definimos um novo espa√ßo amostral (a imagem da vari√°vel aleat√≥ria). Devemos verificar formalmente se nossa fun√ß√£o de probabilidade, definida no espa√ßo amostral original, pode ser usada para a vari√°vel aleat√≥ria. Suponha que temos um espa√ßo amostral \\[\nS = \\{s_1, \\dots, s_n\\}\n\\] com uma fun√ß√£o de probabilidade \\(P\\) e definimos uma vari√°vel aleat√≥ria \\(X\\) com imagem \\(\\mathcal{X} = \\{x_1, \\dots, x_m\\}\\). Definimos uma fun√ß√£o de probabilidade \\(P_X\\) em \\(\\mathcal{X}\\) da seguinte maneira. Observaremos \\(X = x_i\\) se e somente se o resultado do experimento aleat√≥rio for um \\(s_j \\in S\\) tal que \\(X(s_j) = x_i\\). Assim, \\[\nP_X(X = x_i) = P(\\{s_j \\in S : X(s_j) = x_i\\}). \\quad (1.4.1)\n\\] Note que o lado esquerdo de (1.4.1), a fun√ß√£o \\(P_X\\), √© uma probabilidade induzida em \\(\\mathcal{X}\\), definida em termos da fun√ß√£o original \\(P\\). A Equa√ß√£o (1.4.1) define formalmente uma fun√ß√£o de probabilidade, \\(P_X\\), para a vari√°vel aleat√≥ria \\(X\\). √â claro que temos que verificar se \\(P_X\\) satisfaz os Axiomas de Kolmogorov, mas essa √© uma tarefa muito dif√≠cil (veja o Exerc√≠cio 1.45). Devido √† equival√™ncia em (1.4.1), simplesmente escreveremos \\(P(X = x_i)\\) em vez de \\(P_X(X = x_i)\\). Uma nota sobre nota√ß√£o: Vari√°veis aleat√≥rias sempre ser√£o denotadas com letras mai√∫sculas e os valores realizados da vari√°vel (ou sua imagem) ser√£o denotados pelas letras min√∫sculas correspondentes. Assim, a vari√°vel aleat√≥ria \\(X\\) pode assumir o valor \\(x\\).\n\n\nExemplo 1.4.3 (Tr√™s lan√ßamentos de moeda‚ÄîII)\nConsidere novamente o experimento de lan√ßar uma moeda honesta tr√™s vezes do Exemplo 1.3.13. Defina a vari√°vel aleat√≥ria \\(X\\) como o n√∫mero de caras obtidas nos tr√™s lan√ßamentos. Uma enumera√ß√£o completa do valor de \\(X\\) para cada ponto no espa√ßo amostral √©\n\n\n\n\\(s\\)\nHHH\nHHT\nHTH\nTHH\nTTH\nTHT\nHTT\nTTT\n\n\n\n\n\\(X(s)\\)\n3\n2\n2\n2\n1\n1\n1\n0\n\n\n\nA imagem da vari√°vel aleat√≥ria \\(X\\) √© \\(\\mathcal{X} = \\{0, 1, 2, 3\\}\\). Assumindo que todos os oito pontos em \\(S\\) t√™m probabilidade \\(\\frac{1}{8}\\), simplesmente contando na exibi√ß√£o acima vemos que a fun√ß√£o de probabilidade induzida em \\(\\mathcal{X}\\) √© dada por\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\n\n\n\n\n\\(P_X(X=x)\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{3}{8}\\)\n\\(\\frac{3}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\nPor exemplo, \\(P_X(X=1) = P(\\{\\text{HTT, THT, TTH}\\}) = \\frac{3}{8}\\).\n\n\nExemplo 1.4.4 (Distribui√ß√£o de uma vari√°vel aleat√≥ria)\nPode ser poss√≠vel determinar \\(P_X\\) mesmo se uma listagem completa, como no Exemplo 1.4.3, n√£o for poss√≠vel. Seja \\(S\\) as \\(2^{50}\\) strings de 50 zeros e uns, \\(X =\\) n√∫mero de 1s, e \\(\\mathcal{X} = \\{0, 1, 2, \\dots, 50\\}\\), como mencionado no in√≠cio desta se√ß√£o. Suponha que cada uma das \\(2^{50}\\) strings seja igualmente prov√°vel. A probabilidade de que \\(X = 27\\) pode ser obtida contando todas as strings com 27 uns no espa√ßo amostral original. Como cada string √© igualmente prov√°vel, segue-se que \\[\nP_X(X = 27) = \\frac{\\# \\text{ strings com 27 1s}}{\\# \\text{ strings}} = \\frac{\\binom{50}{27}}{2^{50}}.\n\\] Em geral, para qualquer \\(i \\in \\mathcal{X}\\), \\[\nP_X(X = i) = \\frac{\\binom{50}{i}}{2^{50}}.\n\\]\n\nAs ilustra√ß√µes anteriores tinham tanto um \\(S\\) finito quanto um \\(\\mathcal{X}\\) finito, e a defini√ß√£o de \\(P_X\\) foi direta. Tal tamb√©m √© o caso se \\(\\mathcal{X}\\) √© enumer√°vel. Se \\(\\mathcal{X}\\) √© n√£o enumer√°vel, definimos a fun√ß√£o de probabilidade induzida, \\(P_X\\), de uma maneira semelhante a (1.4.1). Para qualquer conjunto \\(A \\subset \\mathcal{X}\\), \\[\nP_X(X \\in A) = P(\\{s \\in S : X(s) \\in A\\}). \\quad (1.4.2)\n\\] Isso define uma fun√ß√£o de probabilidade leg√≠tima para a qual os Axiomas de Kolmogorov podem ser verificados. (Para ser preciso, usamos (1.4.2) para definir probabilidades apenas para uma certa sigma-√°lgebra de subconjuntos de \\(\\mathcal{X}\\). Mas n√£o nos preocuparemos com essas tecnicalidades.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#fun√ß√µes-de-distribui√ß√£o",
    "href": "cap-1.html#fun√ß√µes-de-distribui√ß√£o",
    "title": "Teoria da Probabilidade",
    "section": "1.5 Fun√ß√µes de Distribui√ß√£o",
    "text": "1.5 Fun√ß√µes de Distribui√ß√£o\nA cada vari√°vel aleat√≥ria \\(X\\), associamos uma fun√ß√£o chamada fun√ß√£o de distribui√ß√£o acumulada de \\(X\\).\n\nDefini√ß√£o 1.5.1\nA fun√ß√£o de distribui√ß√£o acumulada ou fda (cdf - cumulative distribution function em ingl√™s) de uma vari√°vel aleat√≥ria \\(X\\), denotada por \\(F_X(x)\\), √© definida por \\[\nF_X(x) = P_X(X \\le x), \\quad \\text{para todo } x.\n\\]\n\n\nExemplo 1.5.2 (Lan√ßando tr√™s moedas)\nConsidere o experimento de lan√ßar tr√™s moedas justas, e seja \\(X =\\) n√∫mero de caras observadas. A fda de \\(X\\) √©\n\\[\nF_X(x) = \\begin{cases}\n0 & \\text{se } -\\infty &lt; x &lt; 0 \\\\\n\\frac{1}{8} & \\text{se } 0 \\le x &lt; 1 \\\\\n\\frac{1}{2} & \\text{se } 1 \\le x &lt; 2 \\\\\n\\frac{7}{8} & \\text{se } 2 \\le x &lt; 3 \\\\\n1 & \\text{se } 3 \\le x &lt; \\infty.\n\\end{cases} \\quad (1.5.1)\n\\]\nA fun√ß√£o escada \\(F_X(x)\\) √© grafada na Figura 1.5.1. H√° v√°rios pontos a notar na Figura 1.5.1. \\(F_X\\) √© definida para todos os valores de \\(x\\), n√£o apenas aqueles em \\(\\mathcal{X} = \\{0, 1, 2, 3\\}\\). Assim, por exemplo,\n\\[\nF_X(2.5) = P(X \\le 2.5) = P(X = 0, 1, \\text{ou } 2) = \\frac{7}{8}.\n\\]\nNote que \\(F_X\\) tem saltos nos valores de \\(x_i \\in \\mathcal{X}\\) e o tamanho do salto em \\(x_i\\) √© igual a \\(P(X = x_i)\\). Al√©m disso, \\(F_X(x) = 0\\) para \\(x &lt; 0\\) uma vez que \\(X\\) n√£o pode ser negativo, e \\(F_X(x) = 1\\) para \\(x \\ge 3\\) uma vez que \\(x\\) √© certo ser menor ou igual a tal valor.\n\n\n\nFigura 1.5.1 - Cdf do Exemplo 1.5.2\n\n\nComo √© aparente na Figura 1.5.1, \\(F_X\\) pode ser descont√≠nua, com saltos em certos valores de \\(x\\). A prop√≥sito, na maneira como \\(F_X\\) √© definida, no entanto, nos pontos de salto \\(F_X\\) assume o valor no topo do salto. (Note as diferentes desigualdades em (1.5.1).) Isso √© conhecido como continuidade √† direita ‚Äî a fun√ß√£o √© cont√≠nua quando um ponto √© abordado pela direita. A propriedade de continuidade √† direita √© uma consequ√™ncia da defini√ß√£o da fda. Em contraste, se tiv√©ssemos definido \\(F_X(x) = P_X(X &lt; x)\\) (note a desigualdade estrita), \\(F_X\\) seria ent√£o cont√≠nua √† esquerda. O tamanho do salto em qualquer ponto \\(x\\) √© igual a \\(P(X = x)\\). Toda fda satisfaz certas propriedades, algumas das quais s√£o √≥bvias quando pensamos na defini√ß√£o de \\(F_X(x)\\) em termos de probabilidades.\n\n\nTeorema 1.5.3\nA fun√ß√£o \\(F(x)\\) √© uma fda se e somente se as tr√™s condi√ß√µes seguintes forem satisfeitas: * a. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) e \\(\\lim_{x \\to \\infty} F(x) = 1\\). * b. \\(F(x)\\) √© uma fun√ß√£o n√£o decrescente de \\(x\\). * c. \\(F(x)\\) √© cont√≠nua √† direita; isto √©, para todo n√∫mero \\(x_0\\), \\(\\lim_{x \\downarrow x_0} F(x) = F(x_0)\\).\n\n\nComprova√ß√£o. Esbo√ßo da prova: Para provar a necessidade, as tr√™s propriedades podem ser verificadas escrevendo \\(F\\) em termos da fun√ß√£o de probabilidade (veja Exerc√≠cio 1.48). Para provar a sufici√™ncia, ou seja, que se uma fun√ß√£o \\(F\\) satisfaz as tr√™s condi√ß√µes do teorema ent√£o existe alguma vari√°vel aleat√≥ria, √© muito mais dif√≠cil. Deve ser estabelecido que existe um espa√ßo amostral \\(S\\), uma fun√ß√£o de probabilidade \\(P\\) em \\(S\\), e uma vari√°vel aleat√≥ria \\(X\\) definida em \\(S\\) tal que \\(F\\) √© a fda de \\(X\\). \\(\\square\\)\n\n\nExemplo 1.5.4 (Lan√ßando at√© obter uma cara)\nSuponha que fazemos um experimento que consiste em lan√ßar uma moeda at√© que uma cara apare√ßa. Seja \\(p =\\) probabilidade de uma cara em qualquer lan√ßamento dado, e defina uma vari√°vel aleat√≥ria \\(X =\\) n√∫mero de lan√ßamentos necess√°rios para obter uma cara. Ent√£o, para qualquer \\(x = 1, 2, \\dots\\),\n\\[\nP(X = x) = (1-p)^{x-1}p, \\quad (1.5.2)\n\\]\numa vez que devemos obter \\(x-1\\) coroas seguidas por uma cara para que o evento ocorra e todas as tentativas s√£o independentes. A partir de (1.5.2) calculamos, para qualquer inteiro positivo \\(x\\),\n\\[\nP(X \\le x) = \\sum_{i=1}^x P(X=i) = \\sum_{i=1}^x (1-p)^{i-1}p. \\quad (1.5.3)\n\\]\nA soma parcial da s√©rie geom√©trica √©\n\\[\n\\sum_{k=1}^n t^{k-1} = \\frac{1-t^n}{1-t}, \\quad t \\ne 1, \\quad (1.5.4)\n\\]\num fato que pode ser estabelecido por indu√ß√£o (veja Exerc√≠cio 1.50). Aplicando (1.5.4) √† nossa probabilidade, descobrimos que a fda da vari√°vel aleat√≥ria \\(X\\) √©\n\\[\n\\begin{align*}\nF_X(x) &= P(X \\le x) \\\\\n&= \\frac{1-(1-p)^x}{1-(1-p)}p \\\\\n&= 1 - (1-p)^x, \\quad x = 1, 2, \\dots .\n\\end{align*}\n\\]\nA fda \\(F_X(x)\\) √© plana entre os inteiros n√£o negativos, como no Exemplo 1.5.2. √â f√°cil mostrar que se \\(0 &lt; p &lt; 1\\), ent√£o \\(F_X(x)\\) satisfaz as condi√ß√µes do Teorema 1.5.3. Primeiro,\n\\[\n\\lim_{x \\to -\\infty} F_X(x) = 0\n\\]\numa vez que \\(F_X(x) = 0\\) para todo \\(x &lt; 0\\), e\n\\[\n\\lim_{x \\to \\infty} F_X(x) = \\lim_{x \\to \\infty} 1 - (1-p)^x = 1,\n\\]\nonde \\(x\\) passa apenas por valores inteiros quando este limite √© tomado. Para verificar a propriedade (b), simplesmente notamos que a soma em (1.5.3) cont√©m mais termos positivos conforme \\(x\\) aumenta. Finalmente, para verificar (c), note que, para qualquer \\(x\\), \\(F_X(x+\\epsilon) = F_X(x)\\) se \\(\\epsilon &gt; 0\\) √© suficientemente pequeno. Portanto,\n\\[\n\\lim_{\\epsilon \\downarrow 0} F_X(x+\\epsilon) = F_X(x),\n\\]\nent√£o \\(F_X(x)\\) √© cont√≠nua √† direita. \\(F_X(x)\\) √© a fda de uma distribui√ß√£o chamada distribui√ß√£o geom√©trica (ap√≥s a s√©rie) e √© retratada na Figura 1.5.2.\n\n\n\n\nFigura 1.5.2 - Cdf geom√©trica, p = .3\n\n\n\nExemplo 1.5.5 (Cdf cont√≠nua)\nUm exemplo de uma fda cont√≠nua √© a fun√ß√£o\n\\[\nF_X(x) = \\frac{1}{1+e^{-x}}, \\quad (1.5.5)\n\\]\nque satisfaz as condi√ß√µes do Teorema 1.5.3. Por exemplo,\n\\[\n\\lim_{x \\to -\\infty} F_X(x) = 0 \\quad \\text{visto que} \\quad \\lim_{x \\to -\\infty} e^{-x} = \\infty\n\\]\ne\n\\[\n\\lim_{x \\to \\infty} F_X(x) = 1 \\quad \\text{visto que} \\quad \\lim_{x \\to \\infty} e^{-x} = 0.\n\\]\nDiferenciando \\(F_X(x)\\) resulta\n\\[\n\\frac{d}{dx} F_X(x) = \\frac{e^{-x}}{(1+e^{-x})^2} &gt; 0,\n\\]\nmostrando que \\(F_X(x)\\) √© crescente. \\(F_X\\) n√£o √© apenas cont√≠nua √† direita, mas tamb√©m cont√≠nua. Esta √© um caso especial da distribui√ß√£o log√≠stica.\n\n\nExemplo 1.5.6 (Cdf com saltos)\nSe \\(F_X\\) n√£o √© uma fun√ß√£o cont√≠nua de \\(x\\), √© poss√≠vel que seja uma mistura de peda√ßos cont√≠nuos e saltos. Por exemplo, se modificarmos \\(F_X(x)\\) de (1.5.5) para ser, para algum \\(\\epsilon, 1 &gt; \\epsilon &gt; 0\\),\n\\[\nF_Y(y) = \\begin{cases}\n\\frac{1-\\epsilon}{1+e^{-y}} & \\text{se } y &lt; 0 \\\\\n\\epsilon + \\frac{(1-\\epsilon)}{1+e^{-y}} & \\text{se } y \\ge 0,\n\\end{cases} \\quad (1.5.6)\n\\]\nent√£o \\(F_Y(y)\\) √© a fda de uma vari√°vel aleat√≥ria \\(Y\\) (veja Exerc√≠cio 1.47). A fun√ß√£o \\(F_Y\\) tem um salto de altura \\(\\epsilon\\) em \\(y=0\\) e, de outra forma, √© cont√≠nua. Este modelo pode ser apropriado se estiv√©ssemos observando a leitura de um medidor, uma leitura que poderia (teoricamente) estar em qualquer lugar entre \\(-\\infty\\) e \\(\\infty\\). Este medidor particular, no entanto, √†s vezes trava em 0. Poder√≠amos ent√£o modelar nossas observa√ß√µes com \\(F_Y\\), onde \\(\\epsilon\\) √© a probabilidade de que o medidor trave.\n\nSe uma fda √© cont√≠nua ou tem saltos corresponde √† vari√°vel aleat√≥ria associada ser cont√≠nua ou n√£o. De fato, a associa√ß√£o √© tal que √© conveniente definir vari√°veis aleat√≥rias cont√≠nuas desta maneira.\n\nDefini√ß√£o 1.5.7\nUma vari√°vel aleat√≥ria \\(X\\) √© cont√≠nua se \\(F_X(x)\\) √© uma fun√ß√£o cont√≠nua de \\(x\\). Uma vari√°vel aleat√≥ria \\(X\\) √© discreta se \\(F_X(x)\\) √© uma fun√ß√£o escada de \\(x\\).\n\nFechamos esta se√ß√£o com um teorema declarando formalmente que \\(F_X\\) determina completamente a distribui√ß√£o de probabilidade de uma vari√°vel aleat√≥ria \\(X\\). Isso √© verdade se \\(P(X \\in A)\\) √© definida apenas para eventos \\(A\\) em \\(\\mathcal{B}^1\\), a menor sigma-√°lgebra contendo todos os intervalos de n√∫meros reais da forma \\((a, b), [a, b), (a, b]\\), e \\([a, b]\\). Se probabilidades s√£o definidas para uma classe maior de eventos, √© poss√≠vel que duas vari√°veis aleat√≥rias tenham a mesma distribui√ß√£o de probabilidade, mas n√£o a mesma probabilidade para todo evento (veja Chung 1974, p√°gina 27). Neste livro, como na maioria das aplica√ß√µes estat√≠sticas, estamos preocupados apenas com eventos que s√£o intervalos, uni√µes enumer√°veis ou interse√ß√µes de intervalos, etc. Ent√£o n√£o consideramos tais casos patol√≥gicos. Primeiro precisamos da no√ß√£o de duas vari√°veis aleat√≥rias sendo identicamente distribu√≠das.\n\nDefini√ß√£o 1.5.8\nAs vari√°veis aleat√≥rias \\(X\\) e \\(Y\\) s√£o identicamente distribu√≠das se, para todo conjunto \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\).\n\nNote que duas vari√°veis aleat√≥rias que s√£o identicamente distribu√≠das n√£o s√£o necessariamente iguais. Isto √©, a Defini√ß√£o 1.5.8 n√£o diz que \\(X=Y\\).\n\nExemplo 1.5.9 (Vari√°veis aleat√≥rias identicamente distribu√≠das)\nConsidere o experimento de lan√ßar uma moeda justa tr√™s vezes como no Exemplo 1.4.3. Defina as vari√°veis aleat√≥rias \\(X\\) e \\(Y\\) por\n\\[\nX = \\text{n√∫mero de caras observadas} \\quad \\text{e} \\quad Y = \\text{n√∫mero de coroas observadas}.\n\\]\nA distribui√ß√£o de \\(X\\) √© dada no Exemplo 1.4.3, e √© facilmente verificado que a distribui√ß√£o de \\(Y\\) √© exatamente a mesma. Isto √©, para cada \\(k = 0, 1, 2, 3\\), temos \\(P(X=k) = P(Y=k)\\). Ent√£o \\(X\\) e \\(Y\\) s√£o identicamente distribu√≠das. No entanto, para nenhum ponto amostral temos \\(X(s) = Y(s)\\).\n\n\nTeorema 1.5.10\nAs duas declara√ß√µes seguintes s√£o equivalentes:\n\na. As vari√°veis aleat√≥rias \\(X\\) e \\(Y\\) s√£o identicamente distribu√≠das.\nb. \\(F_X(x) = F_Y(x)\\) para todo \\(x\\).\n\n\n\nComprova√ß√£o. Para mostrar a equival√™ncia devemos mostrar que cada declara√ß√£o implica a outra. Primeiro mostramos que (a) \\(\\Rightarrow\\) (b). Como \\(X\\) e \\(Y\\) s√£o identicamente distribu√≠das, para qualquer conjunto \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\). Em particular, para cada \\(x\\), o conjunto \\((-\\infty, x]\\) est√° em \\(\\mathcal{B}^1\\), e\n\\[\nF_X(x) = P(X \\in (-\\infty, x]) = P(Y \\in (-\\infty, x]) = F_Y(x).\n\\]\nA implica√ß√£o inversa, que (b) \\(\\Rightarrow\\) (a), √© muito mais dif√≠cil de provar. O argumento acima mostrou que se as probabilidades \\(X\\) e \\(Y\\) concordaram em todos os conjuntos, ent√£o elas concordaram em intervalos. Agora devemos provar o oposto; isto √©, se as probabilidades \\(X\\) e \\(Y\\) concordam em todos os intervalos, ent√£o elas concordam em todos os conjuntos. Isso requer uso pesado de sigma-√°lgebras; n√£o entraremos nesses detalhes aqui. Basta dizer que √© necess√°rio provar apenas que as duas fun√ß√µes de probabilidade concordam em todos os intervalos (Chung 1974, Se√ß√£o 2.2). \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#fun√ß√µes-de-densidade-e-de-massa",
    "href": "cap-1.html#fun√ß√µes-de-densidade-e-de-massa",
    "title": "Teoria da Probabilidade",
    "section": "1.6 Fun√ß√µes de Densidade e de Massa",
    "text": "1.6 Fun√ß√µes de Densidade e de Massa\nAssociada a uma vari√°vel aleat√≥ria \\(X\\) e sua fda \\(F_X\\) existe outra fun√ß√£o, chamada de fun√ß√£o de densidade de probabilidade (fdp) ou fun√ß√£o de massa de probabilidade (fmp). Os termos fdp e fmp referem-se, respectivamente, aos casos cont√≠nuo e discreto. Tanto fdp quanto fmp dizem respeito a ‚Äúprobabilidades pontuais‚Äù de vari√°veis aleat√≥rias.\n\nDefini√ß√£o 1.6.1\nA fun√ß√£o de massa de probabilidade (fmp) de uma vari√°vel aleat√≥ria discreta \\(X\\) √© dada por \\[\nf_X(x) = P(X = x) \\quad \\text{para todo } x.\n\\]\n\n\nExemplo 1.6.2 (Probabilidades geom√©tricas)\nPara a distribui√ß√£o geom√©trica do Exemplo 1.5.4, temos a fmp \\[\nf_X(x) = P(X = x) = \\begin{cases} (1-p)^{x-1}p & \\text{para } x = 1, 2, \\dots \\\\ 0 & \\text{caso contr√°rio.} \\end{cases}\n\\] Lembre-se que \\(P(X = x)\\) ou, equivalentemente, \\(f_X(x)\\) √© o tamanho do salto na fda em \\(x\\). Podemos usar a fmp para calcular probabilidades. Como agora podemos medir a probabilidade de um √∫nico ponto, precisamos apenas somar todos os pontos no evento apropriado. Assim, para inteiros positivos \\(a\\) e \\(b\\), com \\(a \\le b\\), temos \\[\nP(a \\le X \\le b) = \\sum_{k=a}^b f_X(k) = \\sum_{k=a}^b (1-p)^{k-1}p.\n\\]\n\nComo um caso especial disso, obtemos \\[\nP(X \\le b) = \\sum_{k=1}^b f_X(k) = F_X(b). \\quad (1.6.1)\n\\]\nUma conven√ß√£o amplamente aceita, que adotaremos, √© usar uma letra mai√∫scula para a fda e a letra min√∫scula correspondente para a fmp ou fdp. Devemos ser um pouco mais cuidadosos em nossa defini√ß√£o de fdp e no caso cont√≠nuo. Se tentarmos ingenuamente calcular \\(P(X = x)\\) para uma vari√°vel aleat√≥ria cont√≠nua, obtemos o seguinte. Visto que \\(\\{X = x\\} \\subset \\{x - \\epsilon &lt; X \\le x\\}\\) para qualquer \\(\\epsilon &gt; 0\\), temos do Teorema 1.2.9(c) que \\[\nP(X = x) \\le P(x - \\epsilon &lt; X \\le x) = F_X(x) - F_X(x - \\epsilon)\n\\] para qualquer \\(\\epsilon &gt; 0\\). Portanto, \\[\n0 \\le P(X = x) \\le \\lim_{\\epsilon \\downarrow 0} [F_X(x) - F_X(x - \\epsilon)] = 0\n\\] pela continuidade de \\(F_X\\). No entanto, se entendermos o prop√≥sito da fdp, sua defini√ß√£o ficar√° clara. Do Exemplo 1.6.2, vemos que uma fmp nos d√° ‚Äúprobabilidades pontuais‚Äù. No caso discreto, podemos somar valores da fmp para obter a fda (como em (1.6.1)). O procedimento an√°logo no caso cont√≠nuo √© substituir integrais por somas, e obtemos \\[\nP(X \\le x) = F_X(x) = \\int_{-\\infty}^x f_X(t) \\, dt.\n\\] Usando o Teorema Fundamental do C√°lculo, se \\(f_X(x)\\) √© cont√≠nua, temos a rela√ß√£o adicional \\[\n\\frac{d}{dx} F_X(x) = f_X(x). \\quad (1.6.2)\n\\] Note que a analogia com o caso discreto √© quase exata. N√≥s ‚Äúsomamos‚Äù as ‚Äúprobabilidades pontuais‚Äù \\(f_X(x)\\) para obter probabilidades de intervalo.\n\nDefini√ß√£o 1.6.3\nA fun√ß√£o de densidade de probabilidade ou fdp, \\(f_X(x)\\), de uma vari√°vel aleat√≥ria cont√≠nua \\(X\\) √© a fun√ß√£o que satisfaz \\[\nF_X(x) = \\int_{-\\infty}^x f_X(t) \\, dt \\quad \\text{para todo } x. \\quad (1.6.3)\n\\]\n\nUma nota sobre nota√ß√£o: A express√£o ‚Äú\\(X\\) tem uma distribui√ß√£o dada por \\(F_X(x)\\)‚Äù √© abreviada simbolicamente por ‚Äú\\(X \\sim F_X(x)\\)‚Äù, onde lemos o s√≠mbolo ‚Äú\\(\\sim\\)‚Äù como ‚Äú√© distribu√≠do como‚Äù. Podemos similarmente escrever \\(X \\sim f_X(x)\\) ou, se \\(X\\) e \\(Y\\) t√™m a mesma distribui√ß√£o, \\(X \\sim Y\\). No caso cont√≠nuo, podemos ser um pouco desleixados sobre a especifica√ß√£o de probabilidades de intervalo. Visto que \\(P(X = x) = 0\\) se \\(X\\) √© uma vari√°vel aleat√≥ria cont√≠nua, \\[\nP(a &lt; X &lt; b) = P(a &lt; X \\le b) = P(a \\le X &lt; b) = P(a \\le X \\le b).\n\\]\n\n\n\nFigura 1.6.1 - √Årea sob a curva log√≠stica\n\n\nDeve ficar claro que a fdp (ou fmp) cont√©m a mesma informa√ß√£o que a fda. Sendo este o caso, podemos usar uma para resolver problemas e devemos tentar escolher a mais simples.\n\nExemplo 1.6.4 (Probabilidades log√≠sticas)\nPara a distribui√ß√£o log√≠stica do Exemplo 1.5.5, temos \\[\nF_X(x) = \\frac{1}{1+e^{-x}}\n\\] e, portanto, \\[\nf_X(x) = \\frac{d}{dx} F_X(x) = \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\] A √°rea sob a curva \\(f_X(x)\\) nos d√° probabilidades de intervalo (veja Figura 1.6.1): \\[\n\\begin{align*}\nP(a &lt; X &lt; b) &= F_X(b) - F_X(a) \\\\\n&= \\int_{-\\infty}^b f_X(x) \\, dx - \\int_{-\\infty}^a f_X(x) \\, dx \\\\\n&= \\int_{a}^b f_X(x) \\, dx.\n\\end{align*}\n\\]\n\nExistem realmente apenas dois requisitos para uma fdp (ou fmp), ambos consequ√™ncias imediatas da defini√ß√£o.\n\nTeorema 1.6.5\nUma fun√ß√£o \\(f_X(x)\\) √© uma fdp (ou fmp) de uma vari√°vel aleat√≥ria \\(X\\) se e somente se\n\na. \\(f_X(x) \\ge 0\\) para todo \\(x\\).\nb. \\(\\sum_x f_X(x) = 1\\) (fmp) ou \\(\\int_{-\\infty}^{\\infty} f_X(x) \\, dx = 1\\) (fdp).\n\n\n\nComprova√ß√£o. Se \\(f_X(x)\\) √© uma fdp (ou fmp), ent√£o as duas propriedades s√£o imediatas das defini√ß√µes. Em particular, para uma fdp, usando (1.6.3) e o Teorema 1.5.3, temos \\[\n1 = \\lim_{x \\to \\infty} F_X(x) = \\int_{-\\infty}^{\\infty} f_X(t) \\, dt.\n\\] A implica√ß√£o inversa √© igualmente f√°cil de provar. Uma vez que temos \\(f_X(x)\\), podemos definir \\(F_X(x)\\) e apelar para o Teorema 1.5.3. \\(\\square\\)\n\nDe um ponto de vista puramente matem√°tico, qualquer fun√ß√£o n√£o negativa com uma integral positiva finita (ou soma) pode ser transformada em uma fdp ou fmp. Por exemplo, se \\(h(x)\\) √© qualquer fun√ß√£o n√£o negativa que √© positiva em um conjunto \\(A\\), 0 em outro lugar, e \\[\n\\int_{\\{x \\in A\\}} h(x) \\, dx = K &lt; \\infty\n\\] para alguma constante \\(K &gt; 0\\), ent√£o a fun√ß√£o \\(f_X(x) = h(x)/K\\) √© uma fdp de uma vari√°vel aleat√≥ria \\(X\\) assumindo valores em \\(A\\). Na verdade, a rela√ß√£o (1.6.3) nem sempre √© v√°lida porque \\(F_X(x)\\) pode ser cont√≠nua mas n√£o diferenci√°vel. De fato, existem vari√°veis aleat√≥rias cont√≠nuas para as quais a integral n√£o existe para nenhuma \\(f_X(x)\\). Estes casos s√£o bastante patol√≥gicos e vamos ignor√°-los. Assim, neste texto, vamos assumir que (1.6.3) √© v√°lida para qualquer vari√°vel aleat√≥ria cont√≠nua. Em textos mais avan√ßados (por exemplo, Billingsley 1995, Se√ß√£o 31) uma vari√°vel aleat√≥ria √© chamada absolutamente cont√≠nua se (1.6.3) √© v√°lida.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#exerc√≠cios",
    "href": "cap-1.html#exerc√≠cios",
    "title": "Teoria da Probabilidade",
    "section": "1.7 Exerc√≠cios",
    "text": "1.7 Exerc√≠cios\n1.1 Para cada um dos seguintes experimentos, descreva o espa√ßo amostral. (a) Lan√ßar uma moeda quatro vezes. (b) Contar o n√∫mero de folhas danificadas por insetos em uma planta. (c) Medir a vida √∫til (em horas) de uma marca particular de l√¢mpada. (d) Registrar os pesos de ratos de 10 dias de idade. (e) Observar a propor√ß√£o de defeituosos em um carregamento de componentes eletr√¥nicos.\n1.2 Verifique as seguintes identidades. (a) \\(A \\setminus B = A \\setminus (A \\cap B) = A \\cap B^c\\) (b) \\(B = (B \\cap A) \\cup (B \\cap A^c)\\) (c) \\(B \\setminus A = B \\cap A^c\\) (d) \\(A \\cup B = A \\cup (B \\cap A^c)\\)\n1.3 Termine a prova do Teorema 1.1.4. Para quaisquer eventos \\(A, B\\) e \\(C\\) definidos em um espa√ßo amostral \\(S\\), mostre que (a) \\(A \\cup B = B \\cup A\\) e \\(A \\cap B = B \\cap A\\). (comutatividade) (b) \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\). (associatividade) (c) \\((A \\cup B)^c = A^c \\cap B^c\\) e \\((A \\cap B)^c = A^c \\cup B^c\\). (Leis de DeMorgan)\n1.4 Para eventos \\(A\\) e \\(B\\), encontre f√≥rmulas para as probabilidades dos seguintes eventos em termos das quantidades \\(P(A), P(B)\\) e \\(P(A \\cap B)\\). (a) ou \\(A\\) ou \\(B\\) ou ambos (b) ou \\(A\\) ou \\(B\\), mas n√£o ambos (c) pelo menos um de \\(A\\) ou \\(B\\) (d) no m√°ximo um de \\(A\\) ou \\(B\\)\n1.5 Aproximadamente um ter√ßo de todos os g√™meos humanos s√£o id√™nticos (um ovo) e dois ter√ßos s√£o fraternos (dois ovos). G√™meos id√™nticos s√£o necessariamente do mesmo sexo, com masculino e feminino sendo igualmente prov√°veis. Entre g√™meos fraternos, aproximadamente um quarto s√£o ambos do sexo feminino, um quarto s√£o ambos do sexo masculino e metade s√£o um macho e uma f√™mea. Finalmente, entre todos os nascimentos nos EUA, aproximadamente 1 em 90 √© um nascimento de g√™meos. Defina os seguintes eventos: \\[\n\\begin{align*}\nA &= \\{\\text{um nascimento nos EUA resulta em g√™meas do sexo feminino}\\} \\\\\nB &= \\{\\text{um nascimento nos EUA resulta em g√™meos id√™nticos}\\} \\\\\nC &= \\{\\text{um nascimento nos EUA resulta em g√™meos}\\}\n\\end{align*}\n\\] (a) Declare, em palavras, o evento \\(A \\cap B \\cap C\\). (b) Encontre \\(P(A \\cap B \\cap C)\\).\n1.6 Duas moedas, uma com \\(P(\\text{cara}) = u\\) e uma com \\(P(\\text{cara}) = w\\), devem ser lan√ßadas juntas independentemente. Defina \\[\n\\begin{align*}\np_0 &= P(0 \\text{ caras ocorrem}), \\\\\np_1 &= P(1 \\text{ cara ocorre}), \\\\\np_2 &= P(2 \\text{ caras ocorrem}).\n\\end{align*}\n\\] Podem \\(u\\) e \\(w\\) serem escolhidos de tal forma que \\(p_0 = p_1 = p_2\\)? Prove sua resposta.\n1.7 Refira-se ao jogo de dardos do Exemplo 1.2.7. Suponha que n√£o assumimos que a probabilidade de atingir o alvo de dardos √© 1, mas sim que √© proporcional √† √°rea do alvo. Assuma que o alvo de dardos √© montado em uma parede que √© atingida com probabilidade 1, e a parede tem √°rea \\(A\\). (a) Usando o fato de que a probabilidade de atingir uma regi√£o √© proporcional √† √°rea, construa uma fun√ß√£o de probabilidade para \\(P(\\text{marcar } i \\text{ pontos}), i = 0, \\dots, 5\\). (Sem pontos s√£o marcados se o alvo de dardos n√£o for atingido.) (b) Mostre que a distribui√ß√£o de probabilidade condicional \\(P(\\text{marcar } i \\text{ pontos}|\\text{alvo √© atingido})\\) √© exatamente a distribui√ß√£o de probabilidade do Exemplo 1.2.7.\n1.8 Novamente refira-se ao jogo de dardos explicado no Exemplo 1.2.7. (a) Derive a f√≥rmula geral para a probabilidade de marcar \\(i\\) pontos. (b) Mostre que \\(P(\\text{marcar } i \\text{ pontos})\\) √© uma fun√ß√£o decrescente de \\(i\\), isto √©, conforme os pontos aumentam, a probabilidade de marcar os pontos diminui. (c) Mostre que \\(P(\\text{marcar } i \\text{ pontos})\\) √© uma fun√ß√£o de probabilidade de acordo com os Axiomas de Kolmogorov.\n1.9 Prove a vers√£o geral das Leis de DeMorgan. Seja \\(\\{A_{\\alpha} : \\alpha \\in \\Gamma\\}\\) uma cole√ß√£o (possivelmente n√£o enumer√°vel) de conjuntos. Prove que (a) \\((\\cup_{\\alpha} A_{\\alpha})^c = \\cap_{\\alpha} A_{\\alpha}^c\\). (b) \\((\\cap_{\\alpha} A_{\\alpha})^c = \\cup_{\\alpha} A_{\\alpha}^c\\).\n1.10 Formule e prove uma vers√£o das Leis de DeMorgan que se aplica a uma cole√ß√£o finita de conjuntos \\(A_1, \\dots, A_n\\).\n1.11 Seja \\(S\\) um espa√ßo amostral. (a) Mostre que a cole√ß√£o \\(\\mathcal{B} = \\{\\emptyset, S\\}\\) √© uma sigma-√°lgebra. (b) Seja \\(\\mathcal{B} = \\{\\text{todos os subconjuntos de } S, \\text{ incluindo } S \\text{ ele mesmo}\\}\\). Mostre que \\(\\mathcal{B}\\) √© uma sigma-√°lgebra. (c) Mostre que a interse√ß√£o de duas sigma-√°lgebras √© uma sigma-√°lgebra.\n1.12 Foi observado na Se√ß√£o 1.2.1 que estat√≠sticos que seguem a escola de deFinetti n√£o aceitam o Axioma da Aditividade Enumer√°vel, aderindo em vez disso ao Axioma da Aditividade Finita. (a) Mostre que o Axioma da Aditividade Enumer√°vel implica Aditividade Finita. (b) Mostre que, por si s√≥, o Axioma da Aditividade Finita n√£o implica Aditividade Enumer√°vel. Para ajudar, suponha que complementamos com o seguinte. Seja \\(A_1 \\supset A_2 \\supset \\dots \\supset A_n \\supset \\dots\\) uma sequ√™ncia infinita de conjuntos aninhados cujo limite √© o conjunto vazio, o que denotamos por \\(A_n \\downarrow \\emptyset\\). Considere o seguinte: Axioma da Continuidade: Se \\(A_n \\downarrow \\emptyset\\), ent√£o \\(P(A_n) \\to 0\\). Prove que o Axioma da Continuidade e o Axioma da Aditividade Finita implicam Aditividade Enumer√°vel.\n1.13 Se \\(P(A) = \\frac{1}{3}\\) e \\(P(B^c) = \\frac{1}{4}\\), podem \\(A\\) e \\(B\\) ser disjuntos? Explique.\n1.14 Suponha que um espa√ßo amostral \\(S\\) tenha \\(n\\) elementos. Prove que o n√∫mero de subconjuntos que podem ser formados a partir dos elementos de \\(S\\) √© \\(2^n\\).\n1.15 Termine a prova do Teorema 1.2.14. Use o resultado estabelecido para \\(k=2\\) como a base de um argumento de indu√ß√£o.\n1.16 Quantos conjuntos diferentes de iniciais podem ser formados se cada pessoa tiver um sobrenome e (a) exatamente dois nomes pr√≥prios? (b) ou um ou dois nomes pr√≥prios? (Respostas: (a) \\(26^3\\) (b) \\(26^3 + 26^2\\) (c) \\(26^4 + 26^3 + 26^2\\))\n1.17 No jogo de domin√≥, cada pe√ßa √© marcada com dois n√∫meros. As pe√ßas s√£o sim√©tricas de modo que o par num√©rico n√£o √© ordenado (assim, por exemplo, \\((2, 6) = (6, 2)\\)). Quantas pe√ßas diferentes podem ser formadas usando os n√∫meros \\(1, 2, \\dots, n\\)? (Answer: \\(n(n + 1)/2\\))\n1.18 Se \\(n\\) bolas s√£o colocadas aleatoriamente em \\(n\\) c√©lulas, encontre a probabilidade de que exatamente uma c√©lula permane√ßa vazia. (Answer: \\(\\binom{n}{2} n!/n^n\\))\n1.19 Se uma fun√ß√£o multivariada tem derivadas parciais cont√≠nuas, a ordem na qual as derivadas s√£o calculadas n√£o importa. Assim, por exemplo, a fun√ß√£o \\(f(x, y)\\) de duas vari√°veis tem parciais terceiras iguais \\[\n\\frac{\\partial^3}{\\partial x^2 \\partial y} f(x, y) = \\frac{\\partial^3}{\\partial y \\partial x^2} f(x, y).\n\\] (a) Quantas quartas derivadas parciais tem uma fun√ß√£o de tr√™s vari√°veis? (b) Prove que uma fun√ß√£o de \\(n\\) vari√°veis tem \\(\\binom{n+r-1}{r}\\) \\(r\\)-√©simas derivadas parciais.\n1.20 Meu telefone toca 12 vezes por semana, as chamadas sendo distribu√≠das aleatoriamente entre os 7 dias. Qual √© a probabilidade de que eu receba pelo menos uma chamada a cada dia? (Resposta: .2285)\n1.21 Um arm√°rio cont√©m \\(n\\) pares de sapatos. Se \\(2r\\) sapatos s√£o escolhidos ao acaso (\\(2r &lt; n\\)), qual √© a probabilidade de que n√£o haja nenhum par correspondente na amostra? (Resposta: \\(\\binom{n}{2r} 2^{2r} / \\binom{2n}{2r}\\))\n1.22 (a) Em um sorteio de loteria contendo os 366 dias do ano (incluindo 29 de fevereiro), qual √© a probabilidade de que os primeiros 180 dias sorteados (sem reposi√ß√£o) sejam distribu√≠dos uniformemente entre os 12 meses? (b) Qual √© a probabilidade de que os primeiros 30 dias sorteados n√£o contenham nenhum de setembro? (Respostas: (a) \\(.167 \\times 10^{-8}\\) (b) \\(\\binom{336}{30} / \\binom{366}{30}\\))\n1.23 Duas pessoas lan√ßam cada uma uma moeda honesta \\(n\\) vezes. Encontre a probabilidade de que eles obtenham o mesmo n√∫mero de caras. (Resposta: \\(\\binom{2n}{n} (\\frac{1}{4})^n\\))\n1.24 Dois jogadores, A e B, alternadamente e independentemente lan√ßam uma moeda e o primeiro jogador a obter uma cara ganha. Assuma que o jogador A lan√ßa primeiro. (a) Se a moeda √© honesta, qual √© a probabilidade de que A ven√ßa? (b) Suponha que \\(P(\\text{cara}) = p\\), n√£o necessariamente \\(\\frac{1}{2}\\). Qual √© a probabilidade de que A ven√ßa? (c) Mostre que para todo \\(p, 0 &lt; p &lt; 1, P(\\text{A vence}) &gt; \\frac{1}{2}\\). (Dica: Tente escrever \\(P(\\text{A vence})\\) em termos dos eventos \\(E_1, E_2, \\dots\\), onde \\(E_i = \\{\\text{primeira cara aparece no i-√©simo lan√ßamento}\\}\\).) (Respostas: (a) 2/3 (b) \\(\\frac{p}{1-(1-p)^2}\\))\n1.25 Os Smith t√™m dois filhos. Pelo menos um deles √© menino. Qual √© a probabilidade de que ambos os filhos sejam meninos? (Veja Gardner 1961 para uma discuss√£o completa deste problema.)\n1.26 Um dado honesto √© lan√ßado at√© que um 6 apare√ßa. Qual √© a probabilidade de que ele deva ser lan√ßado mais de cinco vezes?\n1.27 Verifique as seguintes identidades para \\(n \\ge 2\\). (a) \\(\\sum_{k=0}^n (-1)^k \\binom{n}{k} = 0\\) (b) \\(\\sum_{k=1}^n k \\binom{n}{k} = n 2^{n-1}\\) (c) \\(\\sum_{k=1}^n (-1)^{k+1} k \\binom{n}{k} = 0\\)\n1.28 Uma maneira de aproximar fatoriais grandes √© atrav√©s do uso da F√≥rmula de Stirling: \\[\nn! \\approx \\sqrt{2\\pi n} n^n e^{-n},\n\\] uma deriva√ß√£o completa da qual √© dif√≠cil. Em vez disso, prove o fato mais f√°cil, \\[\n\\lim_{n \\to \\infty} \\frac{n!}{n^{n+(1/2)} e^{-n}} = \\text{uma constante}.\n\\] (Dica: Feller 1968 procede usando a monotonicidade do logaritmo para estabelecer que \\[\n\\int_{k-1}^k \\log x \\, dx &lt; \\log k &lt; \\int_k^{k+1} \\log x \\, dx, \\quad k = 1, \\dots, n,\n\\] e consequentemente \\[\n\\int_0^n \\log x \\, dx &lt; \\log n! &lt; \\int_1^{n+1} \\log x \\, dx.\n\\] Agora compare \\(\\log n!\\) com a m√©dia das duas integrais. Veja Exerc√≠cio 5.35 para outra deriva√ß√£o.)\n1.29 (a) Para a situa√ß√£o do Exemplo 1.2.20, enumere as amostras ordenadas que comp√µem as amostras n√£o ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (b) Enumere as amostras ordenadas que comp√µem as amostras n√£o ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (Nota: Parece haver um erro de digita√ß√£o no livro original repetindo a pergunta, mas a segunda parte geralmente se refere a calcular as probabilidades associadas ou comparar os tamanhos).\n1.29 (Corre√ß√£o baseada no contexto do Exemplo 1.2.20) (a) Para a situa√ß√£o do Exemplo 1.2.20, enumere as amostras ordenadas que comp√µem as amostras n√£o ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (c) Suponha que tiv√©ssemos uma cole√ß√£o de seis n√∫meros, \\(\\{1, 2, 7, 8, 14, 20\\}\\). Qual √© a probabilidade de sortear, com reposi√ß√£o, a amostra n√£o ordenada \\(\\{2, 7, 7, 8, 14, 14\\}\\)? (d) Verifique que uma amostra n√£o ordenada de tamanho \\(k\\), de \\(m\\) n√∫meros diferentes repetidos \\(k_1, k_2, \\dots, k_m\\) vezes, tem \\(\\frac{k!}{k_1! k_2! \\dots k_m!}\\) componentes ordenados, onde \\(k_1 + k_2 + \\dots + k_m = k\\). (e) Use o resultado da parte anterior para estabelecer a identidade \\[\n\\sum_{k_1, k_2, \\dots, k_m : k_1 + k_2 + \\dots + k_m = k} \\frac{k!}{k_1! k_2! \\dots k_m!} = \\binom{k+m-1}{k}.\n\\]\n1.30 Para a cole√ß√£o de seis n√∫meros, \\(\\{1, 2, 7, 8, 14, 20\\}\\), desenhe um histograma da distribui√ß√£o de todas as m√©dias amostrais poss√≠veis calculadas a partir de amostras sorteadas com reposi√ß√£o.\n1.31 Para a situa√ß√£o do Exemplo 1.2.20, a m√©dia do conjunto original de n√∫meros \\(\\{2, 4, 9, 12\\}\\) √© \\(\\frac{27}{4}\\), que tem a maior probabilidade. (a) Prove que, em geral, se amostramos com reposi√ß√£o do conjunto \\(\\{x_1, x_2, \\dots, x_n\\}\\), o resultado com m√©dia \\((x_1 + x_2 + \\dots + x_n)/n\\) √© o mais prov√°vel, tendo probabilidade \\(n!/n^n\\). (b) Use a F√≥rmula de Stirling (Exerc√≠cio 1.28) para mostrar que \\(n!/n^n \\approx \\sqrt{2\\pi n} / e^n\\) (Hall 1992, Ap√™ndice I). (c) Mostre que a probabilidade de que um \\(x_i\\) particular esteja faltando em um resultado √© \\((1 - \\frac{1}{n})^n \\to e^{-1}\\) quando \\(n \\to \\infty\\).\n1.32 Um empregador est√° prestes a contratar um novo empregado de um grupo de \\(N\\) candidatos, cujo potencial futuro pode ser classificado em uma escala de 1 a \\(N\\). O empregador procede de acordo com as seguintes regras: (a) Cada candidato √© visto em sucess√£o (em ordem aleat√≥ria) e uma decis√£o √© tomada se contrata ou n√£o o candidato. (b) Tendo rejeitado \\(m-1\\) candidatos (\\(m &gt; 1\\)), o empregador pode contratar o \\(m\\)-√©simo candidato apenas se o \\(m\\)-√©simo candidato for melhor do que os \\(m-1\\) anteriores. Suponha que um candidato √© contratado na \\(i\\)-√©sima tentativa. Qual √© a probabilidade de que o melhor candidato tenha sido contratado?\n1.33 Suponha que 5% dos homens e 0,25% das mulheres s√£o dalt√¥nicos. Uma pessoa √© escolhida aleatoriamente e essa pessoa √© dalt√¥nica. Qual √© a probabilidade de que a pessoa seja do sexo masculino? (Assuma que homens e mulheres est√£o em igual n√∫mero.)\n1.34 Duas ninhadas de uma esp√©cie particular de roedor nasceram, uma com dois filhotes de p√™lo castanho e um de p√™lo cinza (ninhada 1), e a outra com tr√™s de p√™lo castanho e dois de p√™lo cinza (ninhada 2). Selecionamos uma ninhada aleatoriamente e depois selecionamos uma prole aleatoriamente da ninhada selecionada. (a) Qual √© a probabilidade de que o animal escolhido tenha p√™lo castanho? (b) Dado que uma prole de p√™lo castanho foi selecionada, qual √© a probabilidade de que a amostragem tenha sido da ninhada 1?\n1.35 Prove que se \\(P(\\cdot)\\) √© uma fun√ß√£o de probabilidade leg√≠tima e \\(B\\) √© um conjunto com \\(P(B) &gt; 0\\), ent√£o \\(P(\\cdot|B)\\) tamb√©m satisfaz os Axiomas de Kolmogorov.\n1.36 Se a probabilidade de atingir um alvo √© \\(\\frac{1}{5}\\), e dez tiros s√£o disparados independentemente, qual √© a probabilidade de o alvo ser atingido pelo menos duas vezes? Qual √© a probabilidade condicional de que o alvo seja atingido pelo menos duas vezes, dado que √© atingido pelo menos uma vez?\n1.37 Aqui olhamos para algumas varia√ß√µes do Exemplo 1.3.4. (a) No c√°lculo do diretor no Exemplo 1.3.4 foi assumido que se A fosse perdoado, ent√£o com igual probabilidade o diretor diria a A que B ou C morreria. No entanto, isso n√£o precisa ser o caso. O diretor pode atribuir probabilidades \\(\\gamma\\) e \\(1-\\gamma\\) a esses eventos, como mostrado aqui:\n\n\n\nPrisioneiro perdoado\nDiretor diz a A\n\n\n\n\n\nA\nB morre\ncom probabilidade \\(\\gamma\\)\n\n\nA\nC morre\ncom probabilidade \\(1-\\gamma\\)\n\n\nB\nC morre\n\n\n\nC\nB morre\n\n\n\n\nCalcule \\(P(A|\\mathcal{W})\\) como uma fun√ß√£o de \\(\\gamma\\). Para quais valores de \\(\\gamma\\) √© \\(P(A|\\mathcal{W})\\) menor que, igual a, ou maior que \\(\\frac{1}{3}\\)? (b) Suponha novamente que \\(\\gamma = \\frac{1}{2}\\), como no texto. Depois que o diretor diz a A que B vai morrer, A pensa um pouco e percebe que seu c√°lculo original era falso. No entanto, A ent√£o tem uma ideia brilhante. A pede ao diretor se ele pode trocar de destino com C. O diretor, pensando que nenhuma informa√ß√£o foi passada, concorda. Prove que o racioc√≠nio de A agora est√° correto e que sua probabilidade de sobreviv√™ncia saltou para \\(\\frac{2}{3}\\)! Um problema semelhante, mas um pouco mais complicado, o ‚Äúproblema de Monty Hall‚Äù, √© discutido por Selvin (1975). O problema nesta guisa ganhou uma quantidade razo√°vel de notoriedade quando apareceu em uma revista de domingo (vos Savant 1990) juntamente com uma resposta correta, mas com explica√ß√£o question√°vel. O debate que se seguiu foi at√© relatado na primeira p√°gina do Sunday New York Times (Tierney 1991). Uma an√°lise completa e um tanto divertida √© dada por Morgan et al.¬†(1991) (veja tamb√©m a resposta de vos Savant 1991). Chun (1999) praticamente esgota o problema com uma an√°lise muito completa.\n1.38 Prove cada uma das seguintes afirma√ß√µes. (Assuma que qualquer evento condicionante tem probabilidade positiva.) (a) Se \\(P(B) = 1\\), ent√£o \\(P(A|B) = P(A)\\) para qualquer \\(A\\). (b) Se \\(A \\subset B\\), ent√£o \\(P(B|A) = 1\\) e \\(P(A|B) = P(A)/P(B)\\). (c) Se \\(A\\) e \\(B\\) s√£o mutuamente exclusivos, ent√£o \\[\nP(A|A \\cup B) = \\frac{P(A)}{P(A) + P(B)}.\n\\] (d) \\(P(A \\cap B \\cap C) = P(A|B \\cap C)P(B|C)P(C)\\).\n1.39 Um par de eventos \\(A\\) e \\(B\\) n√£o pode ser simultaneamente mutuamente exclusivo e independente. Prove que se \\(P(A) &gt; 0\\) e \\(P(B) &gt; 0\\), ent√£o: (a) Se \\(A\\) e \\(B\\) s√£o mutuamente exclusivos, eles n√£o podem ser independentes. (b) Se \\(A\\) e \\(B\\) s√£o independentes, eles n√£o podem ser mutuamente exclusivos.\n1.40 Termine a prova do Teorema 1.3.9 provando as partes (b) e (c).\n1.41 Como no Exemplo 1.3.6, considere sinais de tel√©grafo ‚Äúponto‚Äù e ‚Äútra√ßo‚Äù enviados na propor√ß√£o 3:4, onde transmiss√µes err√°ticas fazem com que um ponto se torne um tra√ßo com probabilidade \\(\\frac{1}{4}\\) e um tra√ßo se torne um ponto com probabilidade \\(\\frac{1}{3}\\). (a) Se um tra√ßo √© recebido, qual √© a probabilidade de que um tra√ßo tenha sido enviado? (b) Assumindo independ√™ncia entre sinais, se a mensagem ponto-ponto foi recebida, qual √© a distribui√ß√£o de probabilidade das quatro mensagens poss√≠veis que poderiam ter sido enviadas?\n1.42 A identidade de inclus√£o-exclus√£o da Miscel√¢nea 1.8.1 recebe seu nome do fato de que √© provada pelo m√©todo de inclus√£o e exclus√£o (Feller 1968, Se√ß√£o IV.1). Aqui vamos entrar nos detalhes. A probabilidade \\(P(\\cup_{i=1}^n A_i)\\) √© a soma das probabilidades de todos os pontos amostrais que est√£o contidos em pelo menos um dos \\(A_i\\)s. O m√©todo de inclus√£o e exclus√£o √© uma receita para contar esses pontos. (a) Seja \\(E_k\\) o conjunto de todos os pontos amostrais que est√£o contidos em exatamente \\(k\\) dos eventos \\(A_1, A_2, \\dots, A_n\\). Mostre que \\(P(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n P(E_i)\\). (b) Se \\(E_1\\) n√£o √© vazio, mostre que \\(P(E_1) = \\sum_{i=1}^n P(A_i)\\). (c) Sem perda de generalidade, assuma que \\(E_k\\) est√° contido em \\(A_1, A_2, \\dots, A_k\\). Mostre que \\(P(E_k)\\) aparece \\(k\\) vezes na soma \\(P_1\\), \\(\\binom{k}{2}\\) vezes na soma \\(P_2\\), \\(\\binom{k}{3}\\) vezes na soma \\(P_3\\), etc. (d) Mostre que \\[\nk - \\binom{k}{2} + \\binom{k}{3} - \\dots \\pm \\binom{k}{k} = 1.\n\\] (Veja Exerc√≠cio 1.27.) (e) Mostre que as partes (a) ‚Äì (c) implicam \\(\\sum_{i=1}^n P(E_i) = P_1 - P_2 = \\dots \\pm P_n\\), estabelecendo a identidade de inclus√£o-exclus√£o.\n1.43 Para a identidade de inclus√£o-exclus√£o da Miscel√¢nea 1.8.1: (a) Derive a Desigualdade de Boole e a Desigualdade de Bonferroni a partir da identidade de inclus√£o-exclus√£o. (b) Mostre que os \\(P_i\\) satisfazem \\(P_i \\ge P_j\\) se \\(i \\ge j\\) e que a sequ√™ncia de limites na Miscel√¢nea 1.8.1 melhora √† medida que o n√∫mero de termos aumenta. (c) Tipicamente, conforme o n√∫mero de termos no limite aumenta, o limite se torna mais √∫til. No entanto, Schwager (1984) adverte que existem alguns casos onde n√£o h√° muita melhora, em particular se os \\(A_i\\)s s√£o altamente correlacionados. Examine o que acontece com a sequ√™ncia de limites no caso extremo quando \\(A_i = A\\) para todo \\(i\\). (Veja Worsley 1982 e a correspond√™ncia de Worsley 1985 e Schwager 1985.)\n1.44 Testes padronizados fornecem uma aplica√ß√£o interessante da teoria da probabilidade. Suponha primeiro que um teste consiste em 20 quest√µes de m√∫ltipla escolha, cada uma com 4 respostas poss√≠veis. Se o aluno chuta em cada quest√£o, ent√£o a realiza√ß√£o do exame pode ser modelada como uma sequ√™ncia de 20 eventos independentes. Encontre a probabilidade de que o aluno acerte pelo menos 10 quest√µes, dado que ele est√° chutando.\n1.45 Mostre que a fun√ß√£o de probabilidade induzida definida em (1.4.1) define uma fun√ß√£o de probabilidade leg√≠tima que satisfaz os Axiomas de Kolmogorov.\n1.46 Sete bolas s√£o distribu√≠das aleatoriamente em sete c√©lulas. Seja \\(X_i = \\text{o n√∫mero de c√©lulas contendo exatamente } i \\text{ bolas}\\). Qual √© a distribui√ß√£o de probabilidade de \\(X_3\\)? (Isto √©, encontre \\(P(X_3 = x)\\) para cada \\(x\\) poss√≠vel.)\n1.47 Prove que as seguintes fun√ß√µes s√£o cdfs. (a) \\(\\frac{1}{2} + \\frac{1}{\\pi} \\tan^{-1}(x), x \\in (-\\infty, \\infty)\\) (b) \\((1 + e^{-x})^{-1}, x \\in (-\\infty, \\infty)\\) (c) \\(e^{-e^{-x}}, x \\in (-\\infty, \\infty)\\) (d) \\(1 - e^{-x}, x \\in (0, \\infty)\\) (e) a fun√ß√£o definida em (1.5.6)\n1.48 Prove a parte de necessidade do Teorema 1.5.3.\n1.49 Uma cdf \\(F_X\\) √© estocasticamente maior que uma cdf \\(F_Y\\) se \\(F_X(t) \\le F_Y(t)\\) para todo \\(t\\) e \\(F_X(t) &lt; F_Y(t)\\) para algum \\(t\\). Prove que se \\(X \\sim F_X\\) e \\(Y \\sim F_Y\\), ent√£o \\[\nP(X &gt; t) \\ge P(Y &gt; t) \\quad \\text{para todo } t\n\\] e \\[\nP(X &gt; t) &gt; P(Y &gt; t) \\quad \\text{para algum } t,\n\\] isto √©, \\(X\\) tende a ser maior que \\(Y\\).\n1.50 Verifique a f√≥rmula (1.5.4), a f√≥rmula para a soma parcial da s√©rie geom√©trica.\n1.51 Uma loja de eletrodom√©sticos recebe um carregamento de 30 fornos de microondas, 5 dos quais s√£o (desconhecidos pelo gerente) defeituosos. O gerente da loja seleciona 4 fornos aleatoriamente, sem reposi√ß√£o, para testar a fim de ver se eles s√£o defeituosos. Seja \\(X = \\text{n√∫mero de defeituosos encontrados}\\). Calcule a fmp e a cdf de \\(X\\) e plote a cdf.\n1.52 Seja \\(X\\) uma vari√°vel aleat√≥ria cont√≠nua com pdf \\(f(x)\\) e cdf \\(F(x)\\). Para um n√∫mero fixo \\(x_0\\), defina a fun√ß√£o \\[\ng(x) = \\begin{cases} f(x)/[1 - F(x_0)] & x \\ge x_0 \\\\ 0 & x &lt; x_0. \\end{cases}\n\\] Prove que \\(g(x)\\) √© uma pdf. (Assuma que \\(F(x_0) &lt; 1\\).)\n1.53 Um certo rio inunda todos os anos. Suponha que a marca de √°gua baixa √© definida em 1 e a marca de √°gua alta \\(Y\\) tem fun√ß√£o de distribui√ß√£o \\[\nF_Y(y) = P(Y \\le y) = 1 - \\frac{1}{y^2}, \\quad 1 \\le y &lt; \\infty.\n\\] (a) Verifique que \\(F_Y(y)\\) √© uma cdf. (b) Encontre \\(f_Y(y)\\), a pdf de \\(Y\\). (c) Se a marca de √°gua baixa √© redefinida em 0 e usamos uma unidade de medida que √© \\(\\frac{1}{10}\\) daquela dada anteriormente, a marca de √°gua alta se torna \\(Z = 10(Y - 1)\\). Encontre \\(F_Z(z)\\).\n1.54 Para cada uma das seguintes, determine o valor de \\(c\\) que faz de \\(f(x)\\) uma pdf. (a) \\(f(x) = c \\sin x, 0 &lt; x &lt; \\pi/2\\) (b) \\(f(x) = c e^{-|x|}, -\\infty &lt; x &lt; \\infty\\)\n1.55 Um dispositivo eletr√¥nico tem tempo de vida denotado por \\(T\\). O dispositivo tem valor \\(V = 5\\) se ele falhar antes do tempo \\(t = 3\\); caso contr√°rio, ele tem valor \\(V = 2T\\). Encontre a cdf de \\(V\\), se \\(T\\) tem pdf \\[\nf_T(t) = \\frac{1}{1.5} e^{-t/(1.5)}, \\quad t &gt; 0.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#assuntos-diversos",
    "href": "cap-1.html#assuntos-diversos",
    "title": "Teoria da Probabilidade",
    "section": "1.8 Assuntos Diversos",
    "text": "1.8 Assuntos Diversos\n\n1.8.1 Bonferroni e Al√©m\nO limite de Bonferroni de (1.2.10), ou Desigualdade de Boole (Teorema 1.2.11), fornece limites simples para a probabilidade de uma interse√ß√£o ou uni√£o. Esses limites podem ser tornados cada vez mais precisos com a seguinte expans√£o.\nPara conjuntos \\(A_1, A_2, \\dots, A_n\\), criamos um novo conjunto de interse√ß√µes aninhadas como segue. Seja \\[\nP_1 = \\sum_{i=1}^n P(A_i)\n\\] \\[\nP_2 = \\sum_{1 \\le i &lt; j \\le n} P(A_i \\cap A_j)\n\\] \\[\nP_3 = \\sum_{1 \\le i &lt; j &lt; k \\le n} P(A_i \\cap A_j \\cap A_k)\n\\] \\[\n\\vdots\n\\] \\[\nP_n = P(A_1 \\cap A_2 \\cap \\dots \\cap A_n).\n\\]\nEnt√£o a identidade de inclus√£o-exclus√£o diz que \\[\nP(A_1 \\cup A_2 \\cup \\dots \\cup A_n) = P_1 - P_2 + P_3 - P_4 + \\dots \\pm P_n.\n\\] Al√©m disso, os \\(P_i\\) s√£o ordenados de tal forma que \\(P_i \\ge P_j\\) se \\(i \\le j\\), e temos a sequ√™ncia de limites superiores e inferiores \\[\n\\begin{align*}\nP_1 \\ge P(\\cup_{i=1}^n A_i) &\\ge P_1 - P_2 \\\\\nP_1 - P_2 + P_3 \\ge P(\\cup_{i=1}^n A_i) &\\ge P_1 - P_2 + P_3 - P_4 \\\\\n\\vdots\n\\end{align*}\n\\]\nVeja Exerc√≠cios 1.42 e 1.43 para detalhes. Esses limites tornam-se cada vez mais apertados √† medida que o n√∫mero de termos aumenta, e eles fornecem um refinamento dos limites originais de Bonferroni. Aplica√ß√µes desses limites incluem a aproxima√ß√£o de probabilidades de sequ√™ncias (runs) (Karlin e Ost 1988) e procedimentos de compara√ß√µes m√∫ltiplas (Naiman e Wynn 1992).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-2.html",
    "href": "cap-2.html",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "",
    "text": "2.1 Distribui√ß√µes de Fun√ß√µes de uma Vari√°vel Aleat√≥ria\nFrequentemente, se somos capazes de modelar um fen√¥meno em termos de uma vari√°vel aleat√≥ria \\(X\\) com fda \\(F_X(x)\\), tamb√©m estaremos interessados no comportamento de fun√ß√µes de \\(X\\). Neste cap√≠tulo, estudamos t√©cnicas que nos permitem obter informa√ß√µes sobre fun√ß√µes de \\(X\\) que podem ser de interesse, informa√ß√µes que podem variar desde muito completas (as distribui√ß√µes dessas fun√ß√µes) at√© mais vagas (o comportamento m√©dio).\nSe \\(X\\) √© uma vari√°vel aleat√≥ria com fda \\(F_X(x)\\), ent√£o qualquer fun√ß√£o de \\(X\\), digamos \\(g(X)\\), tamb√©m √© uma vari√°vel aleat√≥ria. Frequentemente, \\(g(X)\\) √© de interesse por si s√≥ e escrevemos \\(Y = g(X)\\) para denotar a nova vari√°vel aleat√≥ria \\(g(X)\\). Como \\(Y\\) √© uma fun√ß√£o de \\(X\\), podemos descrever o comportamento probabil√≠stico de \\(Y\\) em termos do comportamento de \\(X\\). Isto √©, para qualquer conjunto \\(A\\),\n\\[\nP(Y \\in A) = P(g(X) \\in A),\n\\]\nmostrando que a distribui√ß√£o de \\(Y\\) depende das fun√ß√µes \\(F_X\\) e \\(g\\). Dependendo da escolha de \\(g\\), √†s vezes √© poss√≠vel obter uma express√£o trat√°vel para essa probabilidade.\nFormalmente, se escrevermos \\(y = g(x)\\), a fun√ß√£o \\(g(x)\\) define um mapeamento do espa√ßo amostral original de \\(X\\), \\(\\mathcal{X}\\), para um novo espa√ßo amostral, \\(\\mathcal{Y}\\), o espa√ßo amostral da vari√°vel aleat√≥ria \\(Y\\). Isto √©,\n\\[\ng(x): \\mathcal{X} \\to \\mathcal{Y}.\n\\]\nAssociamos a \\(g\\) um mapeamento inverso, denotado por \\(g^{-1}\\), que √© um mapeamento de subconjuntos de \\(\\mathcal{Y}\\) para subconjuntos de \\(\\mathcal{X}\\), e √© definido por\n\\[\ng^{-1}(A) = \\{x \\in \\mathcal{X} : g(x) \\in A\\}.\n\\tag{3.1}\\]\nNote que o mapeamento \\(g^{-1}\\) leva conjuntos em conjuntos, ou seja, \\(g^{-1}(A)\\) √© o conjunto de pontos em \\(\\mathcal{X}\\) que \\(g(x)\\) leva para o conjunto \\(A\\). √â poss√≠vel que \\(A\\) seja um conjunto de um √∫nico ponto, digamos \\(A = \\{y\\}\\). Ent√£o\n\\[\ng^{-1}(\\{y\\}) = \\{x \\in \\mathcal{X} : g(x) = y\\}.\n\\]\nNeste caso, frequentemente escrevemos \\(g^{-1}(y)\\) em vez de \\(g^{-1}(\\{y\\})\\). A quantidade \\(g^{-1}(y)\\) ainda pode ser um conjunto, no entanto, se houver mais de um \\(x\\) para o qual \\(g(x) = y\\). Se houver apenas um \\(x\\) para o qual \\(g(x) = y\\), ent√£o \\(g^{-1}(y)\\) √© o conjunto de ponto \\(\\{x\\}\\), e escreveremos \\(g^{-1}(y) = x\\). Se a vari√°vel aleat√≥ria \\(Y\\) for agora definida por \\(Y = g(X)\\), podemos escrever para qualquer conjunto \\(A \\subset \\mathcal{Y}\\),\n\\[\n\\begin{aligned}\nP(Y \\in A) &= P(g(X) \\in A) \\\\\n&= P(\\{x \\in \\mathcal{X} : g(x) \\in A\\}) \\\\\n&= P(X \\in g^{-1}(A)).\n\\end{aligned}\n\\tag{3.2}\\]\nIsto define a distribui√ß√£o de probabilidade de \\(Y\\). √â imediato mostrar que esta distribui√ß√£o de probabilidade satisfaz os Axiomas de Kolmogorov.\nSe \\(X\\) √© uma vari√°vel aleat√≥ria discreta, ent√£o \\(\\mathcal{X}\\) √© enumer√°vel. O espa√ßo amostral para \\(Y = g(X)\\) √© \\(\\mathcal{Y} = \\{y : y = g(x), x \\in \\mathcal{X}\\}\\), que tamb√©m √© um conjunto enumer√°vel. Assim, \\(Y\\) tamb√©m √© uma vari√°vel aleat√≥ria discreta. Usando Equa√ß√£o¬†3.2, a fmp para \\(Y\\) √©\n\\[\nf_Y(y) = P(Y = y) = \\sum_{x \\in g^{-1}(y)} P(X = x) = \\sum_{x \\in g^{-1}(y)} f_X(x), \\text{ para } y \\in \\mathcal{Y},\n\\]\ne \\(f_Y(y) = 0\\) para \\(y \\notin \\mathcal{Y}\\). Neste caso, encontrar a fmp de \\(Y\\) envolve simplesmente identificar \\(g^{-1}(y)\\), para cada \\(y \\in \\mathcal{Y}\\), e somar as probabilidades apropriadas.\nSe \\(X\\) e \\(Y\\) s√£o vari√°veis aleat√≥rias cont√≠nuas, ent√£o em alguns casos √© poss√≠vel encontrar f√≥rmulas simples para a fda e fdp de \\(Y\\) em termos da fda e fdp de \\(X\\) e da fun√ß√£o \\(g\\). No restante desta se√ß√£o, consideramos alguns desses casos.\nA fda de \\(Y = g(X)\\) √©\n\\[\n\\begin{aligned}\nF_Y(y) &= P(Y \\leq y) \\\\\n&= P(g(X) \\leq y) \\\\\n&= P(\\{x \\in \\mathcal{X} : g(x) \\leq y\\}) \\\\\n&= \\int_{\\{x \\in \\mathcal{X} : g(x) \\leq y\\}} f_X(x) dx.\n\\end{aligned}\n\\tag{3.4}\\]\n√Äs vezes, pode haver dificuldade em identificar \\(\\{x \\in \\mathcal{X} : g(x) \\leq y\\}\\) e realizar a integra√ß√£o de \\(f_X(x)\\) sobre esta regi√£o, como mostra o pr√≥ximo exemplo.\nAo realizar transforma√ß√µes, √© importante manter o controle sobre os espa√ßos amostrais das vari√°veis aleat√≥rias; caso contr√°rio, muita confus√£o pode surgir. Ao fazer uma transforma√ß√£o de \\(X\\) para \\(Y = g(X)\\), √© mais conveniente usar\n\\[\n\\mathcal{X} = \\{x : f_X(x) &gt; 0\\} \\quad \\text{e} \\quad \\mathcal{Y} = \\{y : y = g(x) \\text{ para algum } x \\in \\mathcal{X}\\}.\n\\tag{3.7}\\]\nA fdp da vari√°vel aleat√≥ria \\(X\\) √© positiva apenas no conjunto \\(\\mathcal{X}\\) e √© zero em outros lugares. Tal conjunto √© chamado de conjunto suporte de uma distribui√ß√£o ou, mais informalmente, o suporte de uma distribui√ß√£o. Esta terminologia tamb√©m pode ser aplicada a uma fmp ou, em geral, a qualquer fun√ß√£o n√£o negativa.\n√â mais f√°cil lidar com fun√ß√µes \\(g(x)\\) que s√£o monot√¥nicas, isto √©, aquelas que satisfazem ou\n\\[\nu &gt; v \\implies g(u) &gt; g(v) \\quad \\text{(crescente)} \\quad \\text{ou} \\quad u &lt; v \\implies g(u) &gt; g(v) \\quad \\text{(decrescente)}.\n\\]\nSe a transforma√ß√£o \\(x \\to g(x)\\) √© monot√¥nica, ent√£o ela √© um-para-um (injetora) e sobre \\(\\mathcal{X} \\to \\mathcal{Y}\\) (sobrejetora). Isto √©, cada \\(x\\) vai para apenas um \\(y\\) e cada \\(y\\) vem de no m√°ximo um \\(x\\) (um-para-um). Al√©m disso, para \\(\\mathcal{Y}\\) definido como em Equa√ß√£o¬†3.7, para cada \\(y \\in \\mathcal{Y}\\) existe um \\(x \\in \\mathcal{X}\\) tal que \\(g(x) = y\\) (sobre). Assim, a transforma√ß√£o \\(g\\) associa exclusivamente \\(xs\\) e \\(ys\\). Se \\(g\\) for monot√¥nica, ent√£o \\(g^{-1}\\) ter√° um √∫nico valor, isto √©, \\(g^{-1}(y) = x\\) se, e somente se, \\(y = g(x)\\). Se \\(g\\) for crescente, isso implica que\n\\[\n\\{x \\in \\mathcal{X} : g(x) \\leq y\\} = \\{x \\in \\mathcal{X} : g^{-1}(g(x)) \\leq g^{-1}(y)\\} = \\{x \\in \\mathcal{X} : x \\leq g^{-1}(y)\\}.\n\\tag{3.8}\\]\nSe \\(g\\) for decrescente, isso implica que\n\\[\n\\{x \\in \\mathcal{X} : g(x) \\leq y\\} = \\{x \\in \\mathcal{X} : g^{-1}(g(x)) \\geq g^{-1}(y)\\} = \\{x \\in \\mathcal{X} : x \\geq g^{-1}(y)\\}.\n\\tag{3.9}\\]\n(Um gr√°fico ilustrar√° por que a desigualdade se inverte no caso decrescente.) Se \\(g(x)\\) for uma fun√ß√£o crescente, ent√£o usando Equa√ß√£o¬†3.4, podemos escrever\n\\[\nF_Y(y) = \\int_{\\{x \\in \\mathcal{X} : x \\leq g^{-1}(y)\\}} f_X(x) dx = \\int_{-\\infty}^{g^{-1}(y)} f_X(x) dx = F_X(g^{-1}(y)).\n\\]\nSe \\(g(x)\\) for decrescente, temos\n\\[\nF_Y(y) = \\int_{g^{-1}(y)}^{\\infty} f_X(x) dx = 1 - F_X(g^{-1}(y)).\n\\]\nA continuidade de \\(X\\) √© usada para obter a segunda igualdade. Resumimos esses resultados no seguinte teorema.\nSe a fdp de \\(Y\\) for cont√≠nua, ela pode ser obtida diferenciando a fda. O resultado da express√£o √© dado no seguinte teorema.\nEm muitas aplica√ß√µes, a fun√ß√£o \\(g\\) pode n√£o ser nem crescente nem decrescente, portanto os resultados acima n√£o se aplicar√£o. No entanto, √© frequente o caso em que \\(g\\) ser√° monot√¥nica em certos intervalos, e isso nos permite obter uma express√£o para \\(Y = g(X)\\).\nNote que a fdp de \\(Y\\) em Equa√ß√£o¬†3.11 √© expressa como a soma de duas partes, partes que representam os intervalos onde \\(g(x) = x^2\\) √© monot√¥nica. Em geral, este ser√° o caso. ||\nO ponto importante no Teorema 2.1.8 √© que \\(\\mathcal{X}\\) pode ser dividido em conjuntos \\(A_1, \\dots, A_k\\) tais que \\(g(x)\\) √© monot√¥nica em cada \\(A_i\\). Podemos ignorar o ‚Äúconjunto excepcional‚Äù \\(A_0\\) j√° que \\(P(X \\in A_0) = 0\\).\nEncerramos esta se√ß√£o com uma transforma√ß√£o especial e muito √∫til.\nAntes de provarmos este teorema, faremos uma breve digress√£o para analisar \\(F_X^{-1}\\), o inverso da fda \\(F_X\\), em mais detalhes. Se \\(F_X\\) for estritamente crescente, ent√£o \\(F_X^{-1}\\) √© bem definida por\n\\[\nF_X^{-1}(y) = x \\iff F_X(x) = y.\n\\tag{3.12}\\]\nNo entanto, se \\(F_X\\) for constante em algum intervalo, ent√£o \\(F_X^{-1}\\) n√£o √© bem definida por Equa√ß√£o¬†3.12, como ilustra a Figura¬†3.2. Esse problema √© evitado definindo \\(F_X^{-1}(y)\\) para \\(0 &lt; y &lt; 1\\) por\n\\[\nF_X^{-1}(y) = \\inf\\{x : F_X(x) \\geq y\\}.\n\\tag{3.13}\\]\nNos pontos extremos, temos \\(P(Y \\leq y) = 1\\) para \\(y \\geq 1\\) e \\(P(Y \\leq y) = 0\\) para \\(y \\leq 0\\), mostrando que \\(Y\\) possui uma distribui√ß√£o uniforme.\nO racioc√≠nio por tr√°s da igualdade\n\\[P(F_X^{-1}(F_X(X)) \\leq F_X^{-1}(y)) = P(X \\leq F_X^{-1}(y))\\]\n√© um tanto sutil e merece aten√ß√£o adicional. Se \\(F_X\\) for estritamente crescente, ent√£o √© verdade que \\(F_X^{-1}(F_X(x)) = x\\) (consulte a Figura¬†3.2(a)). No entanto, se \\(F_X\\) for constante (plana), pode ser que \\(F_X^{-1}(F_X(x)) \\neq x\\). Suponha que \\(F_X\\) seja como na Figura¬†3.2(b) e considere \\(x \\in [x_1, x_2]\\). Ent√£o \\(F_X^{-1}(F_X(x)) = x_1\\) para qualquer \\(x\\) neste intervalo. Mesmo neste caso, a igualdade de probabilidade se mant√©m, visto que \\(P(X \\leq x) = P(X \\leq x_1)\\) para qualquer \\(x \\in [x_1, x_2]\\). A fun√ß√£o de distribui√ß√£o acumulada (cdf) plana denota uma regi√£o de probabilidade zero (\\(P(x_1 &lt; X \\leq x) = F_X(x) - F_X(x_1) = 0\\)).\nUma aplica√ß√£o do Teorema 2.1.10 est√° na gera√ß√£o de amostras aleat√≥rias de uma distribui√ß√£o espec√≠fica. Se for necess√°rio gerar uma observa√ß√£o \\(X\\) de uma popula√ß√£o com cdf \\(F_X\\), precisamos apenas gerar um n√∫mero aleat√≥rio uniforme \\(U\\), entre 0 e 1, e resolver para \\(x\\) na equa√ß√£o \\(F_X(x) = u\\). (Para muitas distribui√ß√µes, existem outros m√©todos de gera√ß√£o de observa√ß√µes que consomem menos tempo computacional, mas este m√©todo ainda √© √∫til devido √† sua aplicabilidade geral.)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#distribui√ß√µes-de-fun√ß√µes-de-uma-vari√°vel-aleat√≥ria",
    "href": "cap-2.html#distribui√ß√µes-de-fun√ß√µes-de-uma-vari√°vel-aleat√≥ria",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "",
    "text": "Exemplo 2.1.1 (Transforma√ß√£o binomial)\nUma vari√°vel aleat√≥ria discreta \\(X\\) tem uma distribui√ß√£o binomial se sua fmp for da forma\n\\[\nf_X(x) = P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n,\n\\tag{3.3}\\]\nonde \\(n\\) √© um inteiro positivo e \\(0 \\leq p \\leq 1\\). Valores como \\(n\\) e \\(p\\) que podem ser ajustados para diferentes valores, produzindo diferentes distribui√ß√µes de probabilidade, s√£o chamados de par√¢metros. Considere a vari√°vel aleat√≥ria \\(Y = g(X)\\), onde \\(g(x) = n - x\\). Isto √©, \\(Y = n - X\\). Aqui \\(\\mathcal{X} = \\{0, 1, \\dots, n\\}\\) e \\(\\mathcal{Y} = \\{y : y = g(x), x \\in \\mathcal{X}\\} = \\{0, 1, \\dots, n\\}\\). Para qualquer \\(y \\in \\mathcal{Y}\\), \\(n - x = g(x) = y\\) se, e somente se, \\(x = n - y\\). Assim, \\(g^{-1}(y)\\) √© o ponto √∫nico \\(x = n - y\\), e\n\\[\n\\begin{aligned}\nf_Y(y) &= \\sum_{x \\in g^{-1}(y)} f_X(x) \\\\\n&= f_X(n-y) \\\\\n&= \\binom{n}{n-y} p^{n-y} (1-p)^{n-(n-y)} \\\\\n&= \\binom{n}{y} (1-p)^y p^{n-y}.\n\\end{aligned}\n\\]\n(A Defini√ß√£o 1.2.17 implica que \\(\\binom{n}{y} = \\binom{n}{n-y}\\)). Assim, vemos que \\(Y\\) tamb√©m tem uma distribui√ß√£o binomial, mas com par√¢metros \\(n\\) e \\(1-p\\). ||\n\n\n\n\n\n\nExemplo 2.1.2 (Transforma√ß√£o uniforme)\nSuponha que \\(X\\) tenha uma distribui√ß√£o uniforme no intervalo \\((0, 2\\pi)\\), isto √©,\n\\[\nf_X(x) =\n\\begin{cases}\n1/(2\\pi) & 0 &lt; x &lt; 2\\pi \\\\\n0 & \\text{caso contr√°rio}.\n\\end{cases}\n\\]\nConsidere \\(Y = \\sin^2(X)\\). Ent√£o (veja a Figura¬†3.1)\n\\[\nP(Y \\leq y) = P(X \\leq x_1) + P(x_2 \\leq X \\leq x_3) + P(X \\geq x_4).\n\\tag{3.5}\\]\n\n\n\n\n\n\nFigura¬†3.1: Figura 2.1.1 - Gr√°fico da transforma√ß√£o \\(y = \\sin^2(x)\\) do Exemplo 2.1.2\n\n\n\nPela simetria da fun√ß√£o \\(\\sin^2(x)\\), e pelo fato de \\(X\\) ter uma distribui√ß√£o uniforme, temos\n\\[\nP(X \\leq x_1) = P(X \\geq x_4) \\quad \\text{e} \\quad P(x_2 \\leq X \\leq x_3) = 2P(x_2 \\leq X \\leq \\pi),\n\\]\nent√£o\n\\[\nP(Y \\leq y) = 2P(X \\leq x_1) + 2P(x_2 \\leq X \\leq \\pi)\n\\tag{3.6}\\]\nonde \\(x_1\\) e \\(x_2\\) s√£o as duas solu√ß√µes para\n\\[\n\\sin^2(x) = y, \\quad 0 &lt; x &lt; \\pi.\n\\]\nAssim, embora este exemplo tenha tratado de uma situa√ß√£o aparentemente simples, a express√£o resultante para a fda de \\(Y\\) n√£o foi simples. ||\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeorema 2.1.3\nSeja \\(X\\) com fda \\(F_X(x)\\), seja \\(Y = g(X)\\), e sejam \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) definidos como em Equa√ß√£o¬†3.7.\n\nSe \\(g\\) √© uma fun√ß√£o crescente em \\(\\mathcal{X}\\), \\(F_Y(y) = F_X(g^{-1}(y))\\) para \\(y \\in \\mathcal{Y}\\).\nSe \\(g\\) √© uma fun√ß√£o decrescente em \\(\\mathcal{X}\\) e \\(X\\) √© uma vari√°vel aleat√≥ria cont√≠nua, \\(F_Y(y) = 1 - F_X(g^{-1}(y))\\) para \\(y \\in \\mathcal{Y}\\).\n\n\n\nExemplo 2.1.4 (Rela√ß√£o uniforme-exponencial‚ÄîI)\nSuponha que \\(X \\sim f_X(x) = 1\\) se \\(0 &lt; x &lt; 1\\) e \\(0\\) caso contr√°rio, a distribui√ß√£o uniforme(0,1). √â imediato verificar que \\(F_X(x) = x, 0 &lt; x &lt; 1\\). Fazemos agora a transforma√ß√£o \\(Y = g(X) = -\\log X\\). Como\n\\[\n\\frac{d}{dx}g(x) = \\frac{d}{dx}(-\\log x) = -\\frac{1}{x} &lt; 0, \\quad \\text{para } 0 &lt; x &lt; 1,\n\\]\n\\(g(x)\\) √© uma fun√ß√£o decrescente. Conforme \\(X\\) varia entre 0 e 1, \\(-\\log x\\) varia entre 0 e \\(\\infty\\), isto √©, \\(\\mathcal{Y} = (0, \\infty)\\). Para \\(y &gt; 0\\), \\(y = -\\log x\\) implica \\(x = e^{-y}\\), logo \\(g^{-1}(y) = e^{-y}\\). Portanto, para \\(y &gt; 0\\),\n\\[\nF_Y(y) = 1 - F_X(g^{-1}(y)) = 1 - F_X(e^{-y}) = 1 - e^{-y}. \\quad (F_X(x) = x)\n\\]\nNaturalmente, \\(F_Y(y) = 0\\) para \\(y \\leq 0\\). Note que foi necess√°rio apenas verificar que \\(g(x) = -\\log x\\) √© monot√¥nica em (0,1), o suporte de \\(X\\). ||\n\n\n\nTeorema 2.1.5\nSeja \\(X\\) com fdp \\(f_X(x)\\) e seja \\(Y = g(X)\\), onde \\(g\\) √© uma fun√ß√£o monot√¥nica. Sejam \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) definidos por Equa√ß√£o¬†3.7. Suponha que \\(f_X(x)\\) seja cont√≠nua em \\(\\mathcal{X}\\) e que \\(g^{-1}(y)\\) tenha uma derivada cont√≠nua em \\(\\mathcal{Y}\\). Ent√£o a fdp de \\(Y\\) √© dada por\n\\[\nf_Y(y) =\n\\begin{cases}\nf_X(g^{-1}(y)) \\left| \\frac{d}{dy} g^{-1}(y) \\right| & y \\in \\mathcal{Y} \\\\\n0 & \\text{caso contr√°rio}.\n\\end{cases}\n\\tag{3.10}\\]\n\n\nComprova√ß√£o. Pelo Teorema 2.1.3 temos, pela regra da cadeia,\n\\[\nf_Y(y) = \\frac{d}{dy} F_Y(y) =\n\\begin{cases}\nf_X(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y) & \\text{se } g \\text{ √© crescente}, \\\\\n-f_X(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y) & \\text{se } g \\text{ √© decrescente},\n\\end{cases}\n\\]\nque pode ser expresso concisamente como Equa√ß√£o¬†3.10. \\(\\square\\)\n\n\nExemplo 2.1.6 (fdp gama invertida)\nSeja \\(f_X(x)\\) a fdp gama \\[\nf(x) = \\frac{1}{(n-1)!\\beta^n} x^{n-1} e^{-x/\\beta}, \\quad 0 &lt; x &lt; \\infty,\n\\]\nonde \\(\\beta\\) √© uma constante positiva e \\(n\\) √© um inteiro positivo. Suponha que queiramos encontrar a fdp de \\(g(X) = 1/X\\). Note que aqui os conjuntos suporte \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) s√£o ambos o intervalo \\((0, \\infty)\\). Se fizermos \\(y = g(x)\\), ent√£o \\(g^{-1}(y) = 1/y\\) e \\(\\frac{d}{dy} g^{-1}(y) = -1/y^2\\). Aplicando o teorema acima, para \\(y \\in (0, \\infty)\\),\n\\[\n\\begin{aligned}\nf_Y(y) &= f_X(g^{-1}(y)) \\left| \\frac{d}{dy} g^{-1}(y) \\right| \\\\\n&= \\frac{1}{(n-1)!\\beta^n} \\left(\\frac{1}{y}\\right)^{n-1} e^{-1/(\\beta y)} \\frac{1}{y^2} \\\\\n&= \\frac{1}{(n-1)!\\beta^n} \\left(\\frac{1}{y}\\right)^{n+1} e^{-1/(\\beta y)},\n\\end{aligned}\n\\]\num caso especial de uma fdp conhecida como a fdp gama invertida. ||\n\n\n\nExemplo 2.1.7 (Transforma√ß√£o quadr√°tica)\nSuponha que \\(X\\) seja uma vari√°vel aleat√≥ria cont√≠nua. Para \\(y &gt; 0\\), a fda de \\(Y = X^2\\) √©\n\\[\nF_Y(y) = P(Y \\leq y) = P(X^2 \\leq y) = P(-\\sqrt{y} \\leq X \\leq \\sqrt{y}).\n\\]\nComo \\(x\\) √© cont√≠nuo, podemos descartar a igualdade do endpoint esquerdo e obter\n\\[\nF_Y(y) = P(-\\sqrt{y} &lt; X \\leq \\sqrt{y}) = P(X \\leq \\sqrt{y}) - P(X \\leq -\\sqrt{y}) = F_X(\\sqrt{y}) - F_X(-\\sqrt{y}).\n\\]\nA fdp de \\(Y\\) agora pode ser obtida da fda por diferencia√ß√£o:\n\\[\n\\begin{aligned}\nf_Y(y) &= \\frac{d}{dy} F_Y(y) \\\\\n&= \\frac{d}{dy} [F_X(\\sqrt{y}) - F_X(-\\sqrt{y})] \\\\\n&= \\frac{1}{2\\sqrt{y}} f_X(\\sqrt{y}) + \\frac{1}{2\\sqrt{y}} f_X(-\\sqrt{y}),\n\\end{aligned}\n\\]\nonde usamos a regra da cadeia para diferenciar \\(F_X(\\sqrt{y})\\) e \\(F_X(-\\sqrt{y})\\). Portanto, a fdp √©\n\\[\nf_Y(y) = \\frac{1}{2\\sqrt{y}} (f_X(\\sqrt{y}) + f_X(-\\sqrt{y})).\n\\tag{3.11}\\]\n\n\n\nTeorema 2.1.8\nSeja \\(X\\) com fdp \\(f_X(x)\\), seja \\(Y = g(X)\\), e defina o espa√ßo amostral \\(\\mathcal{X}\\) como em Equa√ß√£o¬†3.7. Suponha que exista uma parti√ß√£o, \\(A_0, A_1, \\dots, A_k\\), de \\(\\mathcal{X}\\) tal que \\(P(X \\in A_0) = 0\\) e \\(f_X(x)\\) seja cont√≠nua em cada \\(A_i\\). Al√©m disso, suponha que existam fun√ß√µes \\(g_1(x), \\dots, g_k(x)\\), definidas em \\(A_1, \\dots, A_k\\), respectivamente, satisfazendo:\n\n\\(g(x) = g_i(x)\\), para \\(x \\in A_i\\),\n\\(g_i(x)\\) √© monot√¥nica em \\(A_i\\),\no conjunto \\(\\mathcal{Y} = \\{y : y = g_i(x) \\text{ para algum } x \\in A_i\\}\\) √© o mesmo para cada \\(i = 1, \\dots, k\\), e\n\\(g_i^{-1}(y)\\) tem uma derivada cont√≠nua em \\(\\mathcal{Y}\\), para cada \\(i = 1, \\dots, k\\).\n\nEnt√£o \\[\nf_Y(y) =\n\\begin{cases}\n\\sum_{i=1}^{k} f_X(g_i^{-1}(y)) \\left| \\frac{d}{dy} g_i^{-1}(y) \\right| & y \\in \\mathcal{Y} \\\\\n0 & \\text{caso contr√°rio}.\n\\end{cases}\n\\]\n\n\n\nExemplo 2.1.9 (Rela√ß√£o Normal-qui quadrado)\nSeja \\(X\\) com distribui√ß√£o normal padr√£o,\n\\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\]\nConsidere \\(Y = X^2\\). A fun√ß√£o \\(g(x) = x^2\\) √© monot√¥nica em \\((-\\infty, 0)\\) e em \\((0, \\infty)\\). O conjunto \\(\\mathcal{Y} = (0, \\infty)\\). Aplicando o Teorema 2.1.8, tomamos\n\\[\n\\begin{aligned}\nA_0 &= \\{0\\}; \\\\\nA_1 &= (-\\infty, 0), \\quad g_1(x) = x^2, \\quad g_1^{-1}(y) = -\\sqrt{y}; \\\\\nA_2 &= (0, \\infty), \\quad g_2(x) = x^2, \\quad g_2^{-1}(y) = \\sqrt{y}.\n\\end{aligned}\n\\]\nA fdp de \\(Y\\) √©\n\\[\n\\begin{aligned}\nf_Y(y) &= \\frac{1}{\\sqrt{2\\pi}} e^{-(-\\sqrt{y})^2/2} \\left| -\\frac{1}{2\\sqrt{y}} \\right| + \\frac{1}{\\sqrt{2\\pi}} e^{-(\\sqrt{y})^2/2} \\left| \\frac{1}{2\\sqrt{y}} \\right| \\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sqrt{y}} e^{-y/2}, \\quad 0 &lt; y &lt; \\infty.\n\\end{aligned}\n\\]\nA fdp de \\(Y\\) √© uma que encontraremos frequentemente, a de uma vari√°vel aleat√≥ria qui-quadrado com 1 grau de liberdade. ||\n\n\n\nTeorema 2.1.10 (Transforma√ß√£o integral de probabilidade)\nSeja \\(X\\) com fda cont√≠nua \\(F_X(x)\\) e defina a vari√°vel aleat√≥ria \\(Y\\) como \\(Y = F_X(X)\\). Ent√£o \\(Y\\) √© uniformemente distribu√≠da em \\((0, 1)\\), isto √©, \\(P(Y \\leq y) = y, 0 &lt; y &lt; 1\\).\n\n\n\n\n\n\n\n\n\n\n\nFigura¬†3.2: Figura 2.1.2 - (a) \\(F(x)\\) estritamente crescente; (b) \\(F(x)\\) n√£o decrescente\n\n\n\n\nComprova√ß√£o. Para \\(Y = F_X(X)\\) temos, para \\(0 &lt; y &lt; 1\\),\n\\[\n\\begin{aligned}\nP(Y \\leq y) &= P(F_X(X) \\leq y) \\\\\n&= P(F_X^{-1}[F_X(X)] \\leq F_X^{-1}(y)) && (F_X^{-1} \\text{ √© crescente}) \\\\\n&= P(X \\leq F_X^{-1}(y)) && (\\text{veja o texto abaixo}) \\\\\n&= F_X(F_X^{-1}(y)) && (\\text{defini√ß√£o de } F_X) \\\\\n&= y. && (\\text{continuidade de } F_X)\n\\end{aligned}\n\\]\nNos pontos extremos temos \\(P(Y \\leq y) = 1\\) para \\(y \\geq 1\\) e \\(P(Y \\leq y) = 0\\) para \\(y \\leq 0\\), mostrando que \\(Y\\) tem uma distribui√ß√£o uniforme. \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#valores-esperados",
    "href": "cap-2.html#valores-esperados",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "2.2 Valores Esperados",
    "text": "2.2 Valores Esperados\nO valor esperado, ou esperan√ßa, de uma vari√°vel aleat√≥ria √© meramente seu valor m√©dio, onde falamos de valor ‚Äúm√©dio‚Äù como aquele que √© ponderado de acordo com a distribui√ß√£o de probabilidade. O valor esperado de uma distribui√ß√£o pode ser pensado como uma medida de centro, pois pensamos em m√©dias como sendo valores centrais. Ao ponderar os valores da vari√°vel aleat√≥ria de acordo com a distribui√ß√£o de probabilidade, esperamos obter um n√∫mero que resuma um valor t√≠pico ou esperado de uma observa√ß√£o da vari√°vel aleat√≥ria.\n\nDefini√ß√£o 2.2.1\nO valor esperado ou m√©dia de uma vari√°vel aleat√≥ria \\(g(X)\\), denotado por \\(Eg(X)\\), √©\n\\[\nEg(X) =\n\\begin{cases}\n\\int_{-\\infty}^{\\infty} g(x) f_X(x) dx & \\text{se } X \\text{ √© cont√≠nua} \\\\\n\\sum_{x \\in \\mathcal{X}} g(x) f_X(x) = \\sum_{x \\in \\mathcal{X}} g(x) P(X = x) & \\text{se } X \\text{ √© discreta},\n\\end{cases}\n\\]\ndesde que a integral ou a soma exista. Se \\(E|g(X)| = \\infty\\), dizemos que \\(Eg(X)\\) n√£o existe. (Ross (1988) refere-se a isso como a ‚Äúlei do estat√≠stico inconsciente‚Äù. N√£o achamos isso divertido.)\n\n\nExemplo 2.2.2 (M√©dia exponencial)\nSuponha que \\(X\\) tenha uma distribui√ß√£o exponencial(\\(\\lambda\\)), ou seja, ela tem fdp dada por\n\\[\nf_X(x) = \\frac{1}{\\lambda} e^{-x/\\lambda}, \\quad 0 \\leq x &lt; \\infty, \\quad \\lambda &gt; 0.\n\\]\nEnt√£o \\(EX\\) √© dado por\n\\[\n\\begin{aligned}\nEX &= \\int_{0}^{\\infty} \\frac{1}{\\lambda} x e^{-x/\\lambda} dx \\\\\n&= -xe^{-x/\\lambda} \\Big|_0^\\infty + \\int_{0}^{\\infty} e^{-x/\\lambda} dx && \\text{(integra√ß√£o por partes)} \\\\\n&= \\int_{0}^{\\infty} e^{-x/\\lambda} dx = \\lambda.\n\\end{aligned}\n\\] ||\n\n\nExemplo 2.2.3 (M√©dia binomial)\nSe \\(X\\) tem uma distribui√ß√£o binomial, sua fmp √© dada por\n\\[\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n\n\\]\nonde \\(n\\) √© um inteiro positivo, \\(0 \\leq p \\leq 1\\), e para cada par fixo \\(n\\) e \\(p\\) a fmp soma 1. O valor esperado de uma vari√°vel aleat√≥ria binomial √© dado por\n\\[\nEX = \\sum_{x=0}^{n} x \\binom{n}{x} p^x (1-p)^{n-x} = \\sum_{x=1}^{n} x \\binom{n}{x} p^x (1-p)^{n-x}\n\\]\n(o termo \\(x = 0\\) √© 0). Usando a identidade \\(x \\binom{n}{x} = n \\binom{n-1}{x-1}\\), temos\n\\[\n\\begin{aligned}\nEX &= \\sum_{x=1}^{n} n \\binom{n-1}{x-1} p^x (1-p)^{n-x} \\\\\n&= \\sum_{y=0}^{n-1} n \\binom{n-1}{y} p^{y+1} (1-p)^{n-(y+1)} && \\text{(substitua } y = x-1\\text{)} \\\\\n&= np \\sum_{y=0}^{n-1} \\binom{n-1}{y} p^y (1-p)^{n-1-y} \\\\\n&= np,\n\\end{aligned}\n\\]\nvisto que a √∫ltima soma deve ser 1, sendo a soma de todos os valores poss√≠veis de uma fmp binomial(\\(n-1, p\\)). ||\n\n\nExemplo 2.2.4 (M√©dia de Cauchy)\nUm exemplo cl√°ssico de uma vari√°vel aleat√≥ria cujo valor esperado n√£o existe √© a vari√°vel aleat√≥ria de Cauchy, ou seja, aquela com fdp\n\\[\nf_X(x) = \\frac{1}{\\pi} \\frac{1}{1+x^2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\]\n√â imediato verificar que \\(\\int_{-\\infty}^{\\infty} f_X(x) dx = 1\\), mas \\(E|X| = \\infty\\). Escreva\n\\[\nE|X| = \\int_{-\\infty}^{\\infty} \\frac{|x|}{\\pi} \\frac{1}{1+x^2} dx = \\frac{2}{\\pi} \\int_{0}^{\\infty} \\frac{x}{1+x^2} dx.\n\\]\nPara qualquer n√∫mero positivo \\(M\\),\n\\[\n\\int_{0}^{M} \\frac{x}{1+x^2} dx = \\frac{\\log(1+x^2)}{2} \\Big|_0^M = \\frac{\\log(1+M^2)}{2}.\n\\]\nAssim,\n\\[\nE|X| = \\lim_{M \\to \\infty} \\frac{2}{\\pi} \\int_{0}^{M} \\frac{x}{1+x^2} dx = \\frac{1}{\\pi} \\lim_{M \\to \\infty} \\log(1+M^2) = \\infty\n\\]\ne \\(EX\\) n√£o existe. ||\n\nO processo de tomar expectativas √© uma opera√ß√£o linear, o que significa que a expectativa de uma fun√ß√£o linear de \\(X\\) pode ser facilmente avaliada notando que para quaisquer constantes \\(a\\) e \\(b\\),\n\\[\nE(aX + b) = aEX + b.\n\\tag{3.14}\\]\nPor exemplo, se \\(X\\) √© binomial(\\(n, p\\)), ent√£o \\(EX = np\\), logo\n\\[\nE(X - np) = EX - np = np - np = 0.\n\\]\nO operador esperan√ßa, de fato, possui muitas propriedades que podem ajudar a facilitar o esfor√ßo de c√°lculo. A maioria dessas propriedades decorre das propriedades da integral ou da soma e est√° resumida no teorema a seguir.\n\nTeorema 2.2.5\nSeja \\(X\\) uma vari√°vel aleat√≥ria e sejam \\(a, b\\) e \\(c\\) constantes. Ent√£o, para quaisquer fun√ß√µes \\(g_1(x)\\) e \\(g_2(x)\\) cujas expectativas existam,\n\n\\(E(ag_1(X) + bg_2(X) + c) = aEg_1(X) + bEg_2(X) + c\\).\nSe \\(g_1(x) \\geq 0\\) para todo \\(x\\), ent√£o \\(Eg_1(X) \\geq 0\\).\nSe \\(g_1(x) \\geq g_2(x)\\) para todo \\(x\\), ent√£o \\(Eg_1(X) \\geq Eg_2(X)\\).\nSe \\(a \\leq g_1(x) \\leq b\\) para todo \\(x\\), ent√£o \\(a \\leq Eg_1(X) \\leq b\\).\n\n\n\nComprova√ß√£o. Forneceremos detalhes apenas para o caso cont√≠nuo, sendo o caso discreto similar. Por defini√ß√£o,\n\\[\n\\begin{aligned}\nE(ag_1(X) + bg_2(X) + c) &= \\int_{-\\infty}^{\\infty} (ag_1(x) + bg_2(x) + c)f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} ag_1(x)f_X(x) dx + \\int_{-\\infty}^{\\infty} bg_2(x)f_X(x) dx + \\int_{-\\infty}^{\\infty} c f_X(x) dx\n\\end{aligned}\n\\]\npela aditividade da integral. Como \\(a, b\\) e \\(c\\) s√£o constantes, eles saem de suas respectivas integrais e temos\n\\[\n\\begin{aligned}\nE(ag_1(X) + bg_2(X) + c) &= a \\int_{-\\infty}^{\\infty} g_1(x)f_X(x) dx + b \\int_{-\\infty}^{\\infty} g_2(x)f_X(x) dx + c \\int_{-\\infty}^{\\infty} f_X(x) dx \\\\\n&= aEg_1(X) + bEg_2(x) + c,\n\\end{aligned}\n\\]\nestabelecendo (a). As outras tr√™s propriedades s√£o provadas de maneira semelhante. \\(\\square\\)\n\n\nExemplo 2.2.6 (Minimizando a dist√¢ncia)\nO valor esperado de uma vari√°vel aleat√≥ria tem outra propriedade, que podemos pensar como relacionada √† interpreta√ß√£o de \\(EX\\) como um bom palpite para um valor de \\(X\\).\nSuponha que me√ßamos a dist√¢ncia entre uma vari√°vel aleat√≥ria \\(X\\) e uma constante \\(b\\) por \\((X - b)^2\\). Quanto mais pr√≥ximo \\(b\\) estiver de \\(X\\), menor ser√° essa quantidade. Podemos agora determinar o valor de \\(b\\) que minimiza \\(E(X - b)^2\\) e, portanto, nos fornecer√° um bom preditor de \\(X\\). (Note que n√£o adianta procurar um valor de \\(b\\) que minimize \\((X - b)^2\\), pois a resposta dependeria de \\(X\\), tornando-o um preditor in√∫til de \\(X\\).)\nPoder√≠amos prosseguir com a minimiza√ß√£o de \\(E(X - b)^2\\) usando c√°lculo, mas h√° um m√©todo mais simples. (Veja o Exerc√≠cio 2.19 para uma prova baseada em c√°lculo.) Usando a cren√ßa de que h√° algo especial sobre \\(EX\\), escreva\n\\[\n\\begin{aligned}\nE(X - b)^2 &= E(X - EX + EX - b)^2 && \\text{(adicione } \\pm EX \\\\\n&= E((X - EX) + (EX - b))^2 && \\text{(agrupe os termos)} \\\\\n&= E(X - EX)^2 + (EX - b)^2 + 2E((X - EX)(EX - b)),\n\\end{aligned}\n\\]\nonde expandimos o quadrado. Agora, note que\n\\[\nE((X - EX)(EX - b)) = (EX - b)E(X - EX) = 0,\n\\]\nvisto que \\((EX - b)\\) √© constante e sai da expectativa, e \\(E(X - EX) = EX - EX = 0\\). Isso significa que\n\\[\nE(X - b)^2 = E(X - EX)^2 + (EX - b)^2.\n\\tag{3.15}\\]\nN√£o temos controle sobre o primeiro termo no lado direito de Equa√ß√£o¬†3.15 e o segundo termo, que √© sempre maior ou igual a 0, pode ser feito igual a 0 escolhendo \\(b = EX\\). Logo,\n\\[\n\\min_b E(X - b)^2 = E(X - EX)^2.\n\\tag{3.16}\\]\nVeja o Exerc√≠cio 2.18 para um resultado semelhante sobre a mediana. ||\n\nAo avaliar expectativas de fun√ß√µes n√£o lineares de \\(X\\), podemos proceder de uma de duas maneiras. Pela defini√ß√£o de \\(Eg(X)\\), poder√≠amos calcular diretamente\n\\[\nEg(X) = \\int_{-\\infty}^{\\infty} g(x)f_X(x) dx.\n\\tag{3.17}\\]\nMas tamb√©m poder√≠amos encontrar a fdp \\(f_Y(y)\\) de \\(Y = g(X)\\) e ter√≠amos\n\\[\nEg(X) = EY = \\int_{-\\infty}^{\\infty} y f_Y(y) dy.\n\\tag{3.18}\\]\n\nExemplo 2.2.7 (Rela√ß√£o uniforme-exponencial‚ÄîII)\nSeja \\(X\\) com uma distribui√ß√£o uniforme(0,1), ou seja, a fdp de \\(X\\) √© dada por\n\\[\nf_X(x) =\n\\begin{cases}\n1 & \\text{se } 0 \\leq x \\leq 1 \\\\\n0 & \\text{caso contr√°rio},\n\\end{cases}\n\\]\ne defina uma nova vari√°vel aleat√≥ria \\(g(X) = -\\log X\\). Ent√£o\n\\[\nEg(X) = E(-\\log X) = \\int_{0}^{1} -\\log x dx = x - x \\log x \\Big|_0^1 = 1.\n\\]\nMas tamb√©m vimos no Exemplo 2.1.4 que \\(Y = -\\log X\\) tem fda \\(1 - e^{-y}\\) e, portanto, fdp \\(f_Y(y) = \\frac{d}{dy}(1 - e^{-y}) = e^{-y}, 0 &lt; y &lt; \\infty\\), que √© um caso especial da fdp exponencial com \\(\\lambda = 1\\). Assim, pelo Exemplo 2.2.2, \\(EY = 1\\). ||",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#momentos-e-fun√ß√µes-geradoras-de-momentos",
    "href": "cap-2.html#momentos-e-fun√ß√µes-geradoras-de-momentos",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "2.3 Momentos e Fun√ß√µes Geradoras de Momentos",
    "text": "2.3 Momentos e Fun√ß√µes Geradoras de Momentos\nOs v√°rios momentos de uma distribui√ß√£o s√£o uma classe importante de expectativas.\n\nDefini√ß√£o 2.3.1\nPara cada inteiro \\(n\\), o \\(n\\)-√©simo momento de \\(X\\) (ou \\(F_X(x)\\)), \\(\\mu'_n\\), √©\n\\[\n\\mu'_n = EX^n.\n\\]\nO \\(n\\)-√©simo momento central de \\(X\\), \\(\\mu_n\\), √©\n\\[\n\\mu_n = E(X - \\mu)^n,\n\\]\nonde \\(\\mu = \\mu'_1 = EX\\).\n\nAl√©m da m√©dia, \\(EX\\), de uma vari√°vel aleat√≥ria, talvez o momento mais importante seja o segundo momento central, mais comumente conhecido como a vari√¢ncia.\n\nDefini√ß√£o 2.3.2\nA vari√¢ncia de uma vari√°vel aleat√≥ria \\(X\\) √© seu segundo momento central, \\(Var X = E(X - EX)^2\\). A raiz quadrada positiva de \\(Var X\\) √© o desvio padr√£o de \\(X\\).\n\nA vari√¢ncia fornece uma medida do grau de dispers√£o de uma distribui√ß√£o em torno de sua m√©dia. Vimos anteriormente no Exemplo 2.2.6 que a quantidade \\(E(X - b)^2\\) √© minimizada escolhendo \\(b = EX\\). Agora consideramos o tamanho absoluto desse m√≠nimo. A interpreta√ß√£o atribu√≠da √† vari√¢ncia √© que valores maiores significam que \\(X\\) √© mais vari√°vel. No extremo, se \\(Var X = E(X - EX)^2 = 0\\), ent√£o \\(X\\) √© igual a \\(EX\\) com probabilidade 1, e n√£o h√° varia√ß√£o em \\(X\\). O desvio padr√£o tem a mesma interpreta√ß√£o qualitativa: valores pequenos significam que √© muito prov√°vel que \\(X\\) esteja pr√≥ximo de \\(EX\\), e valores grandes significam que \\(X\\) √© muito vari√°vel. O desvio padr√£o √© mais f√°cil de interpretar no sentido de que a unidade de medida no desvio padr√£o √© a mesma da vari√°vel original \\(X\\). A unidade de medida na vari√¢ncia √© o quadrado da unidade original.\n\n\n\n\n\n\nFigura¬†3.3: Densidades exponenciais para \\(\\lambda = 1, \\frac{1}{3}, \\frac{1}{5}\\)\n\n\n\n\nExemplo 2.3.3 (Vari√¢ncia exponencial)\nSeja \\(X\\) com a distribui√ß√£o exponencial(\\(\\lambda\\)), definida no Exemplo 2.2.2. Calculamos \\(EX = \\lambda\\), e agora podemos calcular a vari√¢ncia por\n\\[\n\\begin{aligned}\nVar X = E(X - \\lambda)^2 &= \\int_{0}^{\\infty} (x - \\lambda)^2 \\frac{1}{\\lambda} e^{-x/\\lambda} dx \\\\\n&= \\int_{0}^{\\infty} (x^2 - 2x\\lambda + \\lambda^2) \\frac{1}{\\lambda} e^{-x/\\lambda} dx.\n\\end{aligned}\n\\]\nPara completar a integra√ß√£o, podemos integrar cada um dos termos separadamente, usando integra√ß√£o por partes nos termos que envolvem \\(x\\) e \\(x^2\\). Ao fazer isso, descobrimos que \\(Var X = \\lambda^2\\). ||\n\nVemos que a vari√¢ncia de uma distribui√ß√£o exponencial est√° diretamente relacionada ao par√¢metro \\(\\lambda\\). A Figura¬†3.3 mostra v√°rias distribui√ß√µes exponenciais correspondentes a diferentes valores de \\(\\lambda\\). Note como a distribui√ß√£o √© mais concentrada em torno de sua m√©dia para valores menores de \\(\\lambda\\). O comportamento da vari√¢ncia de uma exponencial, como fun√ß√£o de \\(\\lambda\\), √© um caso especial do comportamento da vari√¢ncia resumido no teorema a seguir.\n\nTeorema 2.3.4\nSe \\(X\\) √© uma vari√°vel aleat√≥ria com vari√¢ncia finita, ent√£o para quaisquer constantes \\(a\\) e \\(b\\),\n\\[\nVar(aX + b) = a^2 Var X.\n\\]\n\n\nComprova√ß√£o. Da defini√ß√£o, temos\n\\[\n\\begin{aligned}\nVar(aX + b) &= E((aX + b) - E(aX + b))^2 \\\\\n&= E(aX - aEX)^2 && (E(aX + b) = aEX + b) \\\\\n&= a^2 E(X - EX)^2 \\\\\n&= a^2 Var X.\n\\end{aligned}\n\\] \\(\\square\\)\n\n√Äs vezes √© mais f√°cil usar uma f√≥rmula alternativa para a vari√¢ncia, dada por\n\\[\nVar X = EX^2 - (EX)^2,\n\\tag{3.19}\\]\nque √© facilmente estabelecida notando que\n\\[\n\\begin{aligned}\nVar X &= E(X - EX)^2 = E[X^2 - 2XEX + (EX)^2] \\\\\n&= EX^2 - 2(EX)^2 + (EX)^2 \\\\\n&= EX^2 - (EX)^2,\n\\end{aligned}\n\\]\nonde usamos o fato de que \\(E(X EX) = (EX)(EX) = (EX)^2\\), visto que \\(EX\\) √© uma constante. Ilustramos agora alguns c√°lculos de momentos com uma distribui√ß√£o discreta.\n\nExemplo 2.3.5 (Vari√¢ncia binomial)\nSeja \\(X \\sim\\) binomial(\\(n, p\\)), ou seja,\n\\[\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n.\n\\]\nVimos anteriormente que \\(EX = np\\). Para calcular \\(Var X\\), primeiro calculamos \\(EX^2\\). Temos\n\\[\nEX^2 = \\sum_{x=0}^{n} x^2 \\binom{n}{x} p^x (1-p)^{n-x}.\n\\tag{3.20}\\]\nPara somar esta s√©rie, devemos primeiro manipular o coeficiente binomial de maneira semelhante √† usada para \\(EX\\) (Exemplo 2.2.3). Escrevemos\n\\[\nx^2 \\binom{n}{x} = x \\frac{n!}{(x-1)!(n-x)!} = xn \\binom{n-1}{x-1}.\n\\tag{3.21}\\]\nO termo no somat√≥rio em Equa√ß√£o¬†3.20 correspondente a \\(x = 0\\) √© zero e, usando Equa√ß√£o¬†3.21, temos\n\\[\n\\begin{aligned}\nEX^2 &= n \\sum_{x=1}^{n} x \\binom{n-1}{x-1} p^x (1-p)^{n-x} \\\\\n&= n \\sum_{y=0}^{n-1} (y+1) \\binom{n-1}{y} p^{y+1} (1-p)^{n-1-y} && \\text{(ajustando } y = x-1\\text{)} \\\\\n&= np \\sum_{y=0}^{n-1} y \\binom{n-1}{y} p^y (1-p)^{n-1-y} + np \\sum_{y=0}^{n-1} \\binom{n-1}{y} p^y (1-p)^{n-1-y}.\n\\end{aligned}\n\\]\nAgora √© f√°cil ver que a primeira soma √© igual a \\((n-1)p\\) (j√° que √© a m√©dia de uma binomial(\\(n-1, p\\))), enquanto a segunda soma √© igual a 1. Logo,\n\\[\nEX^2 = n(n-1)p^2 + np.\n\\tag{3.22}\\]\nUsando Equa√ß√£o¬†3.19, temos\n\\[\nVar X = n(n-1)p^2 + np - (np)^2 = -np^2 + np = np(1-p).\n\\] ||\n\nO c√°lculo de momentos de ordem superior prossegue de maneira an√°loga, mas geralmente as manipula√ß√µes matem√°ticas tornam-se bastante complexas. Em aplica√ß√µes, momentos de ordem 3 ou 4 s√£o √†s vezes de interesse, mas geralmente h√° pouca raz√£o estat√≠stica para examinar momentos superiores a estes.\nIntroduzimos agora uma nova fun√ß√£o que est√° associada a uma distribui√ß√£o de probabilidade, a fun√ß√£o geradora de momentos (fgm). Como o pr√≥prio nome sugere, a fgm pode ser usada para gerar momentos. Na pr√°tica, √© mais f√°cil em muitos casos calcular momentos diretamente do que usar a fgm. No entanto, o principal uso da fgm n√£o √© gerar momentos, mas ajudar a caracterizar uma distribui√ß√£o. Essa propriedade pode levar a resultados extremamente poderosos quando usada adequadamente.\n\nDefini√ß√£o 2.3.6\nSeja \\(X\\) uma vari√°vel aleat√≥ria com fda \\(F_X\\). A fun√ß√£o geradora de momentos (fgm) de \\(X\\) (ou \\(F_X\\)), denotada por \\(M_X(t)\\), √©\n\\[\nM_X(t) = Ee^{tX},\n\\]\ndesde que a esperan√ßa exista para \\(t\\) em alguma vizinhan√ßa de 0. Ou seja, existe um \\(h &gt; 0\\) tal que, para todo \\(t\\) em \\(-h &lt; t &lt; h\\), \\(Ee^{tX}\\) existe. Se a esperan√ßa n√£o existir em uma vizinhan√ßa de 0, dizemos que a fun√ß√£o geradora de momentos n√£o existe.\n\nMais explicitamente, podemos escrever a fgm de \\(X\\) como\n\\[\nM_X(t) = \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx \\quad \\text{se } X \\text{ √© cont√≠nua}.\n\\]\nou\n\\[\nM_X(t) = \\sum_{x} e^{tx} P(X = x) \\quad \\text{se } X \\text{ √© discreta}.\n\\]\n√â muito f√°cil ver como a fgm gera momentos. Resumimos o resultado no seguinte teorema.\n\nTeorema 2.3.7\nSe \\(X\\) tem fgm \\(M_X(t)\\), ent√£o\n\\[\nEX^n = M_X^{(n)}(0),\n\\]\nonde definimos \\[\nM_X^{(n)}(0) = \\frac{d^n}{dt^n} M_X(t) \\Big|_{t=0}.\n\\]\nOu seja, o \\(n\\)-√©simo momento √© igual √† \\(n\\)-√©sima derivada de \\(M_X(t)\\) avaliada em \\(t = 0\\).\n\n\nComprova√ß√£o. Assumindo que podemos diferenciar sob o sinal da integral (veja a pr√≥xima se√ß√£o), temos\n\\[\n\\begin{aligned}\n\\frac{d}{dt} M_X(t) &= \\frac{d}{dt} \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} \\left( \\frac{d}{dt} e^{tx} \\right) f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} (xe^{tx}) f_X(x) dx \\\\\n&= E X e^{tX}.\n\\end{aligned}\n\\]\nAssim, \\[\n\\frac{d}{dt} M_X(t) \\Big|_{t=0} = E X e^{tX} \\Big|_{t=0} = EX.\n\\]\nProcedendo de maneira an√°loga, podemos estabelecer que \\[\n\\frac{d^n}{dt^n} M_X(t) \\Big|_{t=0} = E X^n e^{tX} \\Big|_{t=0} = EX^n.\n\\] \\(\\square\\)\n\n\nExemplo 2.3.8 (fgm Gama)\nNo Exemplo 2.1.6 encontramos um caso especial da fdp gama\n\\[\nf(x) = \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} x^{\\alpha-1} e^{-x/\\beta}, \\quad 0 &lt; x &lt; \\infty, \\quad \\alpha &gt; 0, \\quad \\beta &gt; 0,\n\\]\nonde \\(\\Gamma(\\alpha)\\) denota a fun√ß√£o gama. A fgm √© dada por\n\\[\n\\begin{aligned}\nM_X(t) &= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} e^{tx} x^{\\alpha-1} e^{-x/\\beta} dx \\\\\n&= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} x^{\\alpha-1} e^{-(1/\\beta - t)x} dx \\\\\n&= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} x^{\\alpha-1} e^{-x/(\\frac{\\beta}{1-\\beta t})} dx.\n\\end{aligned}\n\\tag{3.23}\\]\nReconhecemos agora o integrando em Equa√ß√£o¬†3.23 como o n√∫cleo de outra fdp gama. (O n√∫cleo de uma fun√ß√£o √© a parte principal da fun√ß√£o, a parte que permanece quando as constantes s√£o desconsideradas.) Usando o fato de que, para quaisquer constantes positivas \\(a\\) e \\(b\\),\n\\[\nf(x) = \\frac{1}{\\Gamma(a)b^a} x^{a-1} e^{-x/b}\n\\]\n√© uma fdp, temos que\n\\[\n\\int_{0}^{\\infty} \\frac{1}{\\Gamma(a)b^a} x^{a-1} e^{-x/b} dx = 1\n\\]\ne, portanto, \\[\n\\int_{0}^{\\infty} x^{a-1} e^{-x/b} dx = \\Gamma(a)b^a.\n\\tag{3.24}\\]\nAplicando Equa√ß√£o¬†3.24 a Equa√ß√£o¬†3.23, temos\n\\[\nM_X(t) = \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\Gamma(\\alpha) \\left( \\frac{\\beta}{1-\\beta t} \\right)^\\alpha = \\left( \\frac{1}{1-\\beta t} \\right)^\\alpha \\quad \\text{se } t &lt; \\frac{1}{\\beta}.\n\\]\nSe \\(t \\geq 1/\\beta\\), ent√£o a quantidade \\((1/\\beta) - t\\), no integrando de Equa√ß√£o¬†3.23, √© n√£o positiva e a integral em Equa√ß√£o¬†3.24 √© infinita. Assim, a fgm da distribui√ß√£o gama existe apenas se \\(t &lt; 1/\\beta\\).\nA m√©dia da distribui√ß√£o gama √© dada por \\[\nEX = \\frac{d}{dt} M_X(t) \\Big|_{t=0} = \\frac{\\alpha\\beta}{(1-\\beta t)^{\\alpha+1}} \\Big|_{t=0} = \\alpha\\beta.\n\\]\nOutros momentos podem ser calculados de maneira semelhante. ||\n\n\nExemplo 2.3.9 (fgm Binomial)\nPara uma segunda ilustra√ß√£o do c√°lculo de uma fun√ß√£o geradora de momentos, consideramos uma distribui√ß√£o discreta, a distribui√ß√£o binomial. A fmp binomial(\\(n, p\\)) √© dada em Equa√ß√£o¬†3.3. Ent√£o\n\\[\nM_X(t) = \\sum_{x=0}^{n} e^{tx} \\binom{n}{x} p^x (1-p)^{n-x} = \\sum_{x=0}^{n} \\binom{n}{x} (pe^t)^x (1-p)^{n-x}.\n\\]\nA f√≥rmula binomial d√°\n\\[\n\\sum_{x=0}^{n} \\binom{n}{x} u^x v^{n-x} = (u+v)^n.\n\\tag{3.25}\\]\nLogo, fazendo \\(u = pe^t\\) e \\(v = 1-p\\), temos \\[\nM_X(t) = [pe^t + (1-p)]^n.\n\\] ||\n\nComo mencionado anteriormente, a utilidade principal da fun√ß√£o geradora de momentos n√£o est√° em sua capacidade de gerar momentos. Em vez disso, sua utilidade decorre do fato de que, em muitos casos, a fun√ß√£o geradora de momentos pode caracterizar uma distribui√ß√£o. Existem, no entanto, algumas dificuldades t√©cnicas associadas ao uso de momentos para caracterizar uma distribui√ß√£o, que investigaremos agora.\nSe a fgm existe, ela caracteriza um conjunto infinito de momentos. A quest√£o natural √© se a caracteriza√ß√£o do conjunto infinito de momentos determina exclusivamente uma fun√ß√£o de distribui√ß√£o. A resposta a essa pergunta, infelizmente, √© n√£o. Caracterizar o conjunto de momentos n√£o √© suficiente para determinar uma distribui√ß√£o de forma √∫nica porque pode haver duas vari√°veis aleat√≥rias distintas tendo os mesmos momentos.\n\nExemplo 2.3.10 (Momentos n√£o √∫nicos)\nConsidere as duas fdps dadas por\n\\[\nf_1(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}, \\quad 0 \\leq x &lt; \\infty,\n\\]\n\\[\nf_2(x) = f_1(x)[1 + \\sin(2\\pi \\log x)], \\quad 0 \\leq x &lt; \\infty.\n\\]\n(A fdp \\(f_1\\) √© um caso especial de uma fdp lognormal.) Pode-se mostrar que se \\(X_1 \\sim f_1(x)\\), ent√£o \\[\nEX_1^r = e^{r^2/2}, \\quad r = 0, 1, \\dots,\n\\]\nlogo \\(X_1\\) possui todos os seus momentos. Agora suponha que \\(X_2 \\sim f_2(x)\\). Temos \\[\nEX_2^r = \\int_{0}^{\\infty} x^r f_1(x)[1 + \\sin(2\\pi \\log x)] dx = EX_1^r + \\int_{0}^{\\infty} x^r f_1(x) \\sin(2\\pi \\log x) dx.\n\\]\nNo entanto, a transforma√ß√£o \\(y = \\log x - r\\) mostra que esta √∫ltima integral √© a de uma fun√ß√£o √≠mpar sobre \\((-\\infty, \\infty)\\) e, portanto, √© igual a 0 para \\(r = 0, 1, \\dots\\). Assim, embora \\(X_1\\) e \\(X_2\\) tenham fdps distintas, elas t√™m os mesmos momentos para todo \\(r\\). As duas fdps est√£o ilustradas na Figura¬†3.4. ||\n\n\n\n\n\n\nFigura¬†3.4: Duas fdps com os mesmos momentos: \\(f_1(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}\\) e \\(f_2(x) = f_1(x)[1+\\sin(2\\pi \\log x)]\\)\n\n\n\n\nO problema da n√£o unicidade dos momentos n√£o ocorre se as vari√°veis aleat√≥rias tiverem suporte limitado. Se esse for o caso, ent√£o a sequ√™ncia infinita de momentos determina unicamente a distribui√ß√£o. Al√©m disso, se a fgm existe em uma vizinhan√ßa de zero, ent√£o a distribui√ß√£o √© unicamente determinada, n√£o importa qual seja o seu suporte. Assim, a exist√™ncia de todos os momentos n√£o √© equivalente √† exist√™ncia da fun√ß√£o geradora de momentos. O teorema a seguir mostra como uma distribui√ß√£o pode ser caracterizada.\n\nTeorema 2.3.11\nSejam \\(F_X(x)\\) e \\(F_Y(y)\\) duas fdas cujos momentos todos existem.\n\nSe \\(X\\) e \\(Y\\) t√™m suporte limitado, ent√£o \\(F_X(u) = F_Y(u)\\) para todo \\(u\\) se, e somente se, \\(EX^r = EY^r\\) para todos os inteiros \\(r = 0, 1, 2, \\dots\\).\nSe as fun√ß√µes geradoras de momentos existem e \\(M_X(t) = M_Y(t)\\) para todo \\(t\\) em alguma vizinhan√ßa de 0, ent√£o \\(F_X(u) = F_Y(u)\\) para todo \\(u\\).\n\n\nNo pr√≥ximo teorema, que trata de uma sequ√™ncia de fgms que converge, n√£o tratamos o caso de suporte limitado separadamente. Note que a suposi√ß√£o de unicidade √© automaticamente satisfeita se a fgm limite existir em uma vizinhan√ßa de 0 (Assuntos Diversos 2.6.1).\n\nTeorema 2.3.12 (Converg√™ncia de fgms)\nSuponha que \\(\\{X_i, i = 1, 2, \\dots\\}\\) seja uma sequ√™ncia de vari√°veis aleat√≥rias, cada uma com fgm \\(M_{X_i}(t)\\). Al√©m disso, suponha que \\[\n\\lim_{i \\to \\infty} M_{X_i}(t) = M_X(t), \\quad \\text{para todo } t \\text{ em uma vizinhan√ßa de 0},\n\\]\ne \\(M_X(t)\\) seja uma fgm. Ent√£o existe uma √∫nica fda \\(F_X\\) cujos momentos s√£o determinados por \\(M_X(t)\\) e, para todo \\(x\\) onde \\(F_X(x)\\) √© cont√≠nua, temos \\[\n\\lim_{i \\to \\infty} F_{X_i}(x) = F_X(x).\n\\]\n\nOu seja, a converg√™ncia das fgms para uma fgm em \\(|t| &lt; h\\) implica a converg√™ncia das fdas.\nAs provas dos Teoremas 2.3.11 e 2.3.12 baseiam-se na teoria das transformadas de Laplace. A equa√ß√£o definidora para \\(M_X(t)\\), ou seja, \\[\nM_X(t) = \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx,\n\\tag{3.26}\\]\ndefine uma transformada de Laplace (\\(M_X(t)\\) √© a transformada de Laplace de \\(f_X(x)\\)). Um fato fundamental sobre as transformadas de Laplace √© a sua unicidade. Se Equa√ß√£o¬†3.26 for v√°lida para todo \\(t\\) tal que \\(|t| &lt; h\\), onde \\(h\\) √© algum n√∫mero positivo, ent√£o dada \\(M_X(t)\\) existe apenas uma fun√ß√£o \\(f_X(x)\\) que satisfaz Equa√ß√£o¬†3.26.\n\n\nExemplo 2.3.13 (Aproxima√ß√£o de Poisson)\nUma aproxima√ß√£o que geralmente √© ensinada em cursos elementares de estat√≠stica √© que as probabilidades binomiais (veja o Exemplo 2.3.5) podem ser aproximadas por probabilidades de Poisson, que s√£o geralmente mais f√°ceis de calcular. A distribui√ß√£o binomial √© caracterizada por duas quantidades, denotadas por \\(n\\) e \\(p\\). Ensina-se que a aproxima√ß√£o de Poisson √© v√°lida ‚Äúquando \\(n\\) √© grande e \\(np\\) √© pequeno‚Äù e regras pr√°ticas √†s vezes s√£o fornecidas.\nA fmp Poisson(\\(\\lambda\\)) √© dada por \\[\nP(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0, 1, 2, \\dots,\n\\]\nonde \\(\\lambda\\) √© uma constante positiva. A aproxima√ß√£o afirma que se \\(X \\sim\\) binomial(\\(n, p\\)) e \\(Y \\sim\\) Poisson(\\(\\lambda\\)), com \\(\\lambda = np\\), ent√£o \\[\nP(X = x) \\approx P(Y = x)\n\\tag{3.27}\\]\npara \\(n\\) grande e \\(np\\) pequeno. Mostramos agora que as fgms convergem, dando cr√©dito a essa aproxima√ß√£o. Lembre-se que \\(M_X(t) = [pe^t + (1-p)]^n\\). Para a distribui√ß√£o Poisson(\\(\\lambda\\)), podemos calcular \\(M_Y(t) = e^{\\lambda(e^t - 1)}\\), e se definirmos \\(p = \\lambda/n\\), ent√£o \\(M_X(t) \\to M_Y(t)\\) quando \\(n \\to \\infty\\). A validade da aproxima√ß√£o em Equa√ß√£o¬†3.27 seguir√° ent√£o do Teorema 2.3.12.\nPrimeiro devemos abrir um par√™ntese e mencionar um resultado de limite importante, um que tem ampla aplicabilidade em estat√≠stica.\n\n\nLema 2.3.14\nSeja \\(a_1, a_2, \\dots\\) uma sequ√™ncia de n√∫meros convergindo para \\(a\\), ou seja, \\(\\lim_{n \\to \\infty} a_n = a\\). Ent√£o \\[\n\\lim_{n \\to \\infty} \\left( 1 + \\frac{a_n}{n} \\right)^n = e^a.\n\\]\n\nRetornando ao exemplo, temos \\[\nM_X(t) = [pe^t + (1-p)]^n = \\left[ 1 + \\frac{1}{n}(e^t - 1)(np) \\right]^n = \\left[ 1 + \\frac{1}{n}(e^t - 1)\\lambda \\right]^n,\n\\]\nporque \\(\\lambda = np\\). Agora defina \\(a_n = a = (e^t - 1)\\lambda\\), e aplique o Lema 2.3.14 para obter \\[\n\\lim_{n \\to \\infty} M_X(t) = e^{\\lambda(e^t - 1)} = M_Y(t),\n\\]\na fun√ß√£o geradora de momentos da Poisson. A aproxima√ß√£o de Poisson pode ser bastante boa mesmo para valores moderados de \\(p\\) e \\(n\\). Na Figura¬†3.5 mostramos uma fun√ß√£o de massa de probabilidade binomial junto com sua aproxima√ß√£o de Poisson, com \\(\\lambda = np\\). A aproxima√ß√£o parece ser satisfat√≥ria.\n\n\n\n\n\n\nFigura¬†3.5: Figura 2.3.3 - Aproxima√ß√£o de Poisson (linha pontilhada) para a binomial (linha s√≥lida), n = 15, p = .3\n\n\n\n||\n\nEncerramos esta se√ß√£o com um resultado √∫til relativo √†s fgms.\n\nTeorema 2.3.15\nPara quaisquer constantes \\(a\\) e \\(b\\), a fgm da vari√°vel aleat√≥ria \\(aX + b\\) √© dada por \\[\nM_{aX+b}(t) = e^{bt} M_X(at).\n\\]\n\n\nComprova√ß√£o. Por defini√ß√£o, \\[\n\\begin{aligned}\nM_{aX+b}(t) &= E(e^{(aX+b)t}) \\\\\n&= E(e^{aXt} e^{bt}) && \\text{(propriedades de exponenciais)} \\\\\n&= e^{bt} E(e^{(at)X}) && (e^{bt} \\text{ √© constante}) \\\\\n&= e^{bt} M_X(at), && \\text{(defini√ß√£o de fgm)}\n\\end{aligned}\n\\] provando o teorema. \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#diferenciando-sob-o-sinal-de-integral",
    "href": "cap-2.html#diferenciando-sob-o-sinal-de-integral",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "2.4 Diferenciando sob o Sinal de Integral",
    "text": "2.4 Diferenciando sob o Sinal de Integral\nNa se√ß√£o anterior, encontramos uma inst√¢ncia em que desejamos permutar a ordem de integra√ß√£o e diferencia√ß√£o. Esta situa√ß√£o √© encontrada frequentemente em estat√≠stica te√≥rica. O prop√≥sito desta se√ß√£o √© caracterizar as condi√ß√µes sob as quais esta opera√ß√£o √© leg√≠tima. Tamb√©m discutiremos a permuta da ordem de diferencia√ß√£o e somat√≥rio.\nMuitas dessas condi√ß√µes podem ser estabelecidas usando teoremas padr√£o do c√°lculo e provas detalhadas podem ser encontradas na maioria dos livros de c√°lculo. Portanto, provas detalhadas n√£o ser√£o apresentadas aqui. Primeiro, queremos estabelecer o m√©todo de c√°lculo de\n\\[\n\\frac{d}{d\\theta} \\int_{a(\\theta)}^{b(\\theta)} f(x, \\theta) dx\n\\tag{3.28}\\]\nonde \\(-\\infty &lt; a(\\theta), b(\\theta) &lt; \\infty\\) para todo \\(\\theta\\). A regra para diferenciar Equa√ß√£o¬†3.28 √© chamada de Regra de Leibnitz e √© uma aplica√ß√£o do Teorema Fundamental do C√°lculo e da regra da cadeia.\n\nTeorema 2.4.1 (Regra de Leibnitz)\nSe \\(f(x, \\theta)\\), \\(a(\\theta)\\) e \\(b(\\theta)\\) s√£o diferenci√°veis em rela√ß√£o a \\(\\theta\\), ent√£o \\[\n\\frac{d}{d\\theta} \\int_{a(\\theta)}^{b(\\theta)} f(x, \\theta) dx = f(b(\\theta), \\theta) \\frac{d}{d\\theta} b(\\theta) - f(a(\\theta), \\theta) \\frac{d}{d\\theta} a(\\theta) + \\int_{a(\\theta)}^{b(\\theta)} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\]\n\nObserve que se \\(a(\\theta)\\) e \\(b(\\theta)\\) s√£o constantes, temos um caso especial da Regra de Leibnitz:\n\\[\n\\frac{d}{d\\theta} \\int_{a}^{b} f(x, \\theta) dx = \\int_{a}^{b} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\]\nAssim, em geral, se tivermos a integral de uma fun√ß√£o diferenci√°vel sobre um intervalo finito, a diferencia√ß√£o da integral n√£o representa problemas. Se o intervalo de integra√ß√£o for infinito, no entanto, podem surgir problemas. Note que a permuta de derivada e integral na equa√ß√£o acima iguala uma derivada parcial com uma derivada ordin√°ria. Formalmente, este deve ser o caso, pois o lado esquerdo √© uma fun√ß√£o apenas de \\(\\theta\\), enquanto o integrando no lado direito √© uma fun√ß√£o de ambos \\(\\theta\\) e \\(x\\).\nA quest√£o de saber se a permuta da ordem de diferencia√ß√£o e integra√ß√£o √© justificada √©, na verdade, uma quest√£o de saber se limites e integra√ß√£o podem ser permutados, j√° que uma derivada √© um tipo especial de limite. Lembre-se que se \\(f(x, \\theta)\\) √© diferenci√°vel, ent√£o\n\\[\n\\frac{\\partial}{\\partial \\theta} f(x, \\theta) = \\lim_{\\delta \\to 0} \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta},\n\\]\nent√£o temos\n\\[\n\\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx = \\int_{-\\infty}^{\\infty} \\lim_{\\delta \\to 0} \\left[ \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta} \\right] dx,\n\\]\nenquanto\n\\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx = \\lim_{\\delta \\to 0} \\int_{-\\infty}^{\\infty} \\left[ \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta} \\right] dx.\n\\]\nPortanto, se pudermos justificar a permuta da ordem de limites e integra√ß√£o, a diferencia√ß√£o sob o sinal da integral ser√° justificada. O tratamento deste problema em total generalidade exigir√°, infelizmente, o uso da teoria da medida, um t√≥pico que n√£o ser√° abordado neste livro. No entanto, as declara√ß√µes e conclus√µes de alguns resultados importantes podem ser dadas. Os seguintes teoremas s√£o todos corol√°rios do Teorema da Converg√™ncia Dominada de Lebesgue (veja, por exemplo, Rudin (1976)).\n\nTeorema 2.4.2\nSuponha que a fun√ß√£o \\(h(x, y)\\) seja cont√≠nua em \\(y_0\\) para cada \\(x\\), e exista uma fun√ß√£o \\(g(x)\\) satisfazendo i. \\(|h(x, y)| \\leq g(x)\\) para todos \\(x\\) e \\(y\\) ii. \\(\\int_{-\\infty}^{\\infty} g(x) dx &lt; \\infty\\). Ent√£o \\[\n\\lim_{y \\to y_0} \\int_{-\\infty}^{\\infty} h(x, y) dx = \\int_{-\\infty}^{\\infty} \\lim_{y \\to y_0} h(x, y) dx.\n\\]\n\nA condi√ß√£o chave neste teorema √© a exist√™ncia de uma fun√ß√£o dominante \\(g(x)\\), com uma integral finita, que garanta que as integrais n√£o se comportem muito mal. Podemos agora aplicar este teorema ao caso que estamos considerando, identificando \\(h(x, y)\\) com a diferen√ßa \\((f(x, \\theta + \\delta) - f(x, \\theta))/\\delta\\).\n\nTeorema 2.4.3\nSuponha que \\(f(x, \\theta)\\) seja diferenci√°vel em \\(\\theta = \\theta_0\\), isto √©, \\[\n\\lim_{\\delta \\to 0} \\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} = \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0}\n\\] exista para cada \\(x\\), e exista uma fun√ß√£o \\(g(x, \\theta_0)\\) e uma constante \\(\\delta_0 &gt; 0\\) tal que i. \\(\\left| \\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} \\right| \\leq g(x, \\theta_0)\\), para todos \\(x\\) e \\(|\\delta| \\leq \\delta_0\\), ii. \\(\\int_{-\\infty}^{\\infty} g(x, \\theta_0) dx &lt; \\infty\\). Ent√£o \\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx \\Big|_{\\theta = \\theta_0} = \\int_{-\\infty}^{\\infty} \\left[ \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0} \\right] dx.\n\\tag{3.29}\\]\n\nA condi√ß√£o (i) √© semelhante ao que √© conhecido como uma condi√ß√£o de Lipschitz, uma condi√ß√£o que imp√µe suavidade a uma fun√ß√£o. Aqui, a condi√ß√£o (i) est√° efetivamente limitando a variabilidade na primeira derivada; outras restri√ß√µes de suavidade podem limitar essa variabilidade por uma constante (em vez de uma fun√ß√£o \\(g\\)), ou colocar um limite na variabilidade da segunda derivada de \\(f\\).\nA conclus√£o do Teorema 2.4.3 √© um pouco pesada, mas √© importante perceber que, embora pare√ßamos estar tratando \\(\\theta\\) como uma vari√°vel, a declara√ß√£o do teorema √© para um valor de \\(\\theta\\). Isto √©, para cada valor \\(\\theta_0\\) para o qual \\(f(x, \\theta)\\) √© diferenci√°vel em \\(\\theta_0\\) e satisfaz as condi√ß√µes (i) e (ii), a ordem de integra√ß√£o e diferencia√ß√£o pode ser permutada. Frequentemente, a distin√ß√£o entre \\(\\theta\\) e \\(\\theta_0\\) n√£o √© enfatizada e Equa√ß√£o¬†3.29 √© escrita como\n\\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx = \\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\tag{3.30}\\]\nTipicamente, \\(f(x, \\theta)\\) √© diferenci√°vel em todos os \\(\\theta\\), n√£o apenas em um valor \\(\\theta_0\\). Neste caso, a condi√ß√£o (i) do Teorema 2.4.3 pode ser substitu√≠da por outra condi√ß√£o que muitas vezes se mostra mais f√°cil de verificar. Por uma aplica√ß√£o do teorema do valor m√©dio, segue que, para \\(x\\) e \\(\\theta_0\\) fixos, e \\(|\\delta| \\leq \\delta_0\\),\n\\[\n\\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} = \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0 + \\delta^*(x)}\n\\]\npara algum n√∫mero \\(\\delta^*(x), |\\delta^*(x)| \\leq \\delta_0\\). Portanto, a condi√ß√£o (i) ser√° satisfeita se encontrarmos uma \\(g(x, \\theta)\\) que satisfa√ßa a condi√ß√£o (ii) e\n\\[\n\\left| \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta'} \\right| \\leq g(x, \\theta) \\quad \\text{para todos } \\theta' \\text{ tais que } |\\theta' - \\theta| \\leq \\delta_0.\n\\tag{3.31}\\]\nNote que em Equa√ß√£o¬†3.31 \\(\\delta_0\\) √© implicitamente uma fun√ß√£o de \\(\\theta\\), como √© o caso no Teorema 2.4.3. Isto √© permitido, j√° que o teorema √© aplicado a cada valor de \\(\\theta\\) individualmente. De Equa√ß√£o¬†3.31 obtemos o seguinte corol√°rio.\n\nCorol√°rio 2.4.4\nSuponha que \\(f(x, \\theta)\\) seja diferenci√°vel em \\(\\theta\\) e exista uma fun√ß√£o \\(g(x, \\theta)\\) tal que Equa√ß√£o¬†3.31 seja satisfeita e \\(\\int_{-\\infty}^{\\infty} g(x, \\theta) dx &lt; \\infty\\). Ent√£o Equa√ß√£o¬†3.30 se mant√©m.\n\nObserve que tanto a condi√ß√£o (i) do Teorema 2.4.3 quanto Equa√ß√£o¬†3.31 imp√µem um requisito de uniformidade nas fun√ß√µes a serem limitadas; algum tipo de uniformidade √© geralmente necess√°rio antes que derivadas e integrais possam ser permutadas.\n\nExemplo 2.4.5 (Intercambiando integra√ß√£o e diferencia√ß√£o‚ÄîI)\nSeja \\(X\\) com a fdp exponencial(\\(\\lambda\\)) dada por \\(f(x) = (1/\\lambda)e^{-x/\\lambda}, 0 &lt; x &lt; \\infty\\), e suponha que queiramos calcular\n\\[\n\\frac{d}{d\\lambda} EX^n = \\frac{d}{d\\lambda} \\int_{0}^{\\infty} x^n \\left( \\frac{1}{\\lambda} \\right) e^{-x/\\lambda} dx,\n\\tag{3.32}\\]\npara um inteiro \\(n &gt; 0\\). Se pud√©ssemos mover a diferencia√ß√£o para dentro da integral, ter√≠amos\n\\[\n\\begin{aligned}\n\\frac{d}{d\\lambda} EX^n &= \\int_{0}^{\\infty} \\frac{\\partial}{\\partial \\lambda} x^n \\left( \\frac{1}{\\lambda} \\right) e^{-x/\\lambda} dx \\\\\n&= \\int_{0}^{\\infty} \\frac{x^n}{\\lambda^2} \\left( \\frac{x}{\\lambda} - 1 \\right) e^{-x/\\lambda} dx \\\\\n&= \\frac{1}{\\lambda^2} EX^{n+1} - \\frac{1}{\\lambda} EX^n.\n\\end{aligned}\n\\tag{3.33}\\]\nPara justificar a permuta de integra√ß√£o e diferencia√ß√£o, limitamos a derivada de \\(x^n(1/\\lambda)e^{-x/\\lambda}\\). Agora\n\\[\n\\left| \\frac{\\partial}{\\partial \\lambda} \\frac{x^n e^{-x/\\lambda}}{\\lambda} \\right| = \\frac{x^n e^{-x/\\lambda}}{\\lambda^2} \\left| \\frac{x}{\\lambda} - 1 \\right| \\leq \\frac{x^n e^{-x/\\lambda}}{\\lambda^2} \\left( \\frac{x}{\\lambda} + 1 \\right). \\quad (\\text{visto que } \\frac{x}{\\lambda} &gt; 0)\n\\]\nPara alguma constante \\(\\delta_0\\) satisfazendo \\(0 &lt; \\delta_0 &lt; \\lambda\\), tome\n\\[\ng(x, \\lambda) = \\frac{x^n e^{-x/(\\lambda + \\delta_0)}}{(\\lambda - \\delta_0)^2} \\left( \\frac{x}{\\lambda - \\delta_0} + 1 \\right).\n\\]\nTemos ent√£o\n\\[\n\\left| \\frac{\\partial}{\\partial \\lambda} \\left( \\frac{x^n e^{-x/\\lambda}}{\\lambda} \\right) \\Big|_{\\lambda = \\lambda'} \\right| \\leq g(x, \\lambda) \\quad \\text{para todos } \\lambda' \\text{ tais que } |\\lambda' - \\lambda| \\leq \\delta_0.\n\\]\nComo a distribui√ß√£o exponencial possui todos os seus momentos, \\(\\int_{-\\infty}^{\\infty} g(x, \\lambda) dx &lt; \\infty\\) contanto que \\(\\lambda - \\delta_0 &gt; 0\\), ent√£o a permuta de integra√ß√£o e diferencia√ß√£o √© justificada. ||\n\nA propriedade ilustrada para a distribui√ß√£o exponencial vale para uma grande classe de densidades, que ser√£o abordadas na Se√ß√£o 3.4. Observe que Equa√ß√£o¬†3.33 nos d√° uma rela√ß√£o de recorr√™ncia para os momentos da distribui√ß√£o exponencial,\n\\[\nEX^{n+1} = \\lambda EX^n + \\lambda^2 \\frac{d}{d\\lambda} EX^n,\n\\tag{3.34}\\]\ntornando o c√°lculo do \\((n+1)\\)-√©simo momento relativamente f√°cil. Este tipo de relacionamento existe para outras distribui√ß√µes. Em particular, se \\(X\\) tem uma distribui√ß√£o normal com m√©dia \\(\\mu\\) e vari√¢ncia 1, ent√£o ela tem fdp \\(f(x) = (1/\\sqrt{2\\pi})e^{-(x-\\mu)^2/2}\\), ent√£o\n\\[\nEX^{n+1} = \\mu EX^n + \\frac{d}{d\\mu} EX^n.\n\\]\nIlustramos mais uma permuta de diferencia√ß√£o e integra√ß√£o, uma envolvendo a fun√ß√£o geradora de momentos.\n\nExemplo 2.4.6 (Intercambiando integra√ß√£o e diferencia√ß√£o‚ÄîII)\nNovamente, seja \\(X\\) com uma distribui√ß√£o normal com m√©dia \\(\\mu\\) e vari√¢ncia 1, e considere a fgm de \\(X\\),\n\\[\nM_X(t) = Ee^{tX} = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{tx} e^{-(x-\\mu)^2/2} dx.\n\\]\nNa Se√ß√£o 2.3 foi afirmado que podemos calcular momentos por diferencia√ß√£o de \\(M_X(t)\\), e a diferencia√ß√£o sob o sinal da integral foi justificada:\n\\[\n\\frac{d}{dt} M_X(t) = \\frac{d}{dt} Ee^{tX} = E \\frac{\\partial}{\\partial t} e^{tX} = E(X e^{tX}).\n\\tag{3.35}\\]\nPodemos aplicar os resultados desta se√ß√£o para justificar as opera√ß√µes em Equa√ß√£o¬†3.35. Observe que ao aplicar o Teorema 2.4.3 ou o Corol√°rio 2.4.4 aqui, identificamos \\(t\\) com a vari√°vel \\(\\theta\\) no Teorema 2.4.3. O par√¢metro \\(\\mu\\) √© tratado como uma constante. Pelo Corol√°rio 2.4.4, devemos encontrar uma fun√ß√£o \\(g(x, t)\\), com integral finita, que satisfa√ßa\n\\[\n\\left| \\frac{\\partial}{\\partial t} e^{tx} e^{-(x-\\mu)^2/2} \\Big|_{t=t'} \\right| \\leq g(x, t) \\quad \\text{para todos } t' \\text{ tais que } |t' - t| \\leq \\delta_0.\n\\tag{3.36}\\]\nFazendo o √≥bvio, temos\n\\[\n\\left| \\frac{\\partial}{\\partial t} e^{tx} e^{-(x-\\mu)^2/2} \\right| = |x e^{tx} e^{-(x-\\mu)^2/2}| \\leq |x| e^{tx} e^{-(x-\\mu)^2/2}.\n\\]\n√â mais f√°cil definir nossa fun√ß√£o \\(g(x, t)\\) separadamente para \\(x \\geq 0\\) e \\(x &lt; 0\\). Tomamos\n\\[\ng(x, t) =\n\\begin{cases}\n|x| e^{(t-\\delta_0)x} e^{-(x-\\mu)^2/2} & \\text{se } x &lt; 0 \\\\\n|x| e^{(t+\\delta_0)x} e^{-(x-\\mu)^2/2} & \\text{se } x \\geq 0.\n\\end{cases}\n\\]\n√â claro que esta fun√ß√£o satisfaz Equa√ß√£o¬†3.36; resta verificar que sua integral √© finita. Para \\(x \\geq 0\\) temos\n\\[\ng(x, t) = x e^{-(x^2 - 2x(\\mu+t+\\delta_0) + \\mu^2)/2}.\n\\]\nAgora completamos o quadrado no expoente, ou seja, escrevemos\n\\[\n\\begin{aligned}\nx^2 - 2x(\\mu + t + \\delta_0) + \\mu^2 &= x^2 - 2x(\\mu + t + \\delta_0) + (\\mu + t + \\delta_0)^2 - (\\mu + t + \\delta_0)^2 + \\mu^2 \\\\\n&= (x - (\\mu + t + \\delta_0))^2 + \\mu^2 - (\\mu + t + \\delta_0)^2,\n\\end{aligned}\n\\]\ne assim, para \\(x \\geq 0\\),\n\\[\ng(x, t) = x e^{-[x - (\\mu + t + \\delta_0)]^2/2} e^{-[\\mu^2 - (\\mu + t + \\delta_0)^2]/2}.\n\\]\nComo o √∫ltimo fator exponencial nesta express√£o n√£o depende de \\(x\\), \\(\\int_{0}^{\\infty} g(x, t) dx\\) √© essencialmente o c√°lculo da m√©dia de uma distribui√ß√£o normal com m√©dia \\(\\mu + t + \\delta_0\\), exceto que a integra√ß√£o √© apenas sobre \\([0, \\infty)\\). No entanto, segue que a integral √© finita porque a distribui√ß√£o normal tem uma m√©dia finita (a ser mostrada no Cap√≠tulo 3). Um desenvolvimento semelhante para \\(x &lt; 0\\) mostra que \\(\\int_{-\\infty}^{0} g(x, t) dx &lt; \\infty\\). Portanto, encontramos uma fun√ß√£o integr√°vel satisfazendo Equa√ß√£o¬†3.36 e a opera√ß√£o em Equa√ß√£o¬†3.35 √© justificada. ||\n\nVoltamo-nos agora para a quest√£o de quando √© poss√≠vel permutar diferencia√ß√£o e somat√≥rio, uma opera√ß√£o que desempenha um papel importante em distribui√ß√µes discretas. √â claro que estamos preocupados apenas com somas infinitas, j√° que uma derivada sempre pode ser levada para dentro de uma soma finita.\n\nExemplo 2.4.7 (Intercambiando somat√≥rio e diferencia√ß√£o)\nSeja \\(X\\) uma vari√°vel aleat√≥ria discreta com a distribui√ß√£o geom√©trica\n\\[\nP(X = x) = \\theta(1-\\theta)^x, \\quad x = 0, 1, \\dots, \\quad 0 &lt; \\theta &lt; 1.\n\\]\nTemos que \\(\\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x = 1\\) e, desde que as opera√ß√µes sejam justificadas,\n\\[\n\\begin{aligned}\n\\frac{d}{d\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x &= \\sum_{x=0}^{\\infty} \\frac{d}{d\\theta} \\theta(1-\\theta)^x \\\\\n&= \\sum_{x=0}^{\\infty} [(1-\\theta)^x - \\theta x(1-\\theta)^{x-1}] \\\\\n&= \\frac{1}{\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x - \\frac{1}{1-\\theta} \\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x.\n\\end{aligned}\n\\]\nComo \\(\\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x = 1\\) para todo \\(0 &lt; \\theta &lt; 1\\), sua derivada √© zero. Ent√£o temos\n\\[\n\\frac{1}{\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x - \\frac{1}{1-\\theta} \\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x = 0.\n\\tag{3.37}\\]\nAgora a primeira soma em Equa√ß√£o¬†3.37 √© igual a 1 e a segunda soma √© \\(EX\\), logo Equa√ß√£o¬†3.37 torna-se\n\\[\n\\frac{1}{\\theta} - \\frac{1}{1-\\theta} EX = 0,\n\\]\nou\n\\[\nEX = \\frac{1-\\theta}{\\theta}.\n\\]\nN√≥s, em ess√™ncia, somamos a s√©rie \\(\\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x\\) por diferencia√ß√£o. ||\n\nA justificativa de levar a derivada para dentro do somat√≥rio √© mais direta do que o caso da integra√ß√£o. O teorema a seguir fornece os detalhes.\n\nTeorema 2.4.8\nSuponha que a s√©rie \\(\\sum_{x=0}^{\\infty} h(\\theta, x)\\) convirja para todos os \\(\\theta\\) em um intervalo \\((a, b)\\) de n√∫meros reais e i. \\(\\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) seja cont√≠nua em \\(\\theta\\) para cada \\(x\\), ii. \\(\\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) convirja uniformemente em cada subintervalo fechado e limitado de \\((a, b)\\). Ent√£o \\[\n\\frac{d}{d\\theta} \\sum_{x=0}^{\\infty} h(\\theta, x) = \\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x).\n\\tag{3.38}\\]\n\nA condi√ß√£o de converg√™ncia uniforme √© a chave a ser verificada para estabelecer que a diferencia√ß√£o pode ser levada para dentro do somat√≥rio. Lembre-se que uma s√©rie converge uniformemente se sua sequ√™ncia de somas parciais convergir uniformemente, um fato que usamos no exemplo a seguir.\n\nExemplo 2.4.9 (Continua√ß√£o do Exerc√≠cio 2.4.7)\nPara aplicar o Teorema 2.4.8 identificamos\n\\[\nh(\\theta, x) = \\theta(1-\\theta)^x,\n\\]\ne\n\\[\n\\frac{\\partial}{\\partial \\theta} h(\\theta, x) = (1-\\theta)^x - \\theta x(1-\\theta)^{x-1},\n\\]\ne verificamos que \\(\\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) converge uniformemente. Defina \\(S_n(\\theta)\\) por\n\\[\nS_n(\\theta) = \\sum_{x=0}^{n} [(1-\\theta)^x - \\theta x(1-\\theta)^{x-1}].\n\\]\nA converg√™ncia ser√° uniforme em \\([c, d] \\subset (0, 1)\\) se, dado \\(\\varepsilon &gt; 0\\), pudermos encontrar um \\(N\\) tal que\n\\[\nn &gt; N \\implies |S_n(\\theta) - S_{\\infty}(\\theta)| &lt; \\varepsilon \\quad \\text{para todos } \\theta \\in [c, d].\n\\]\nLembre-se da soma parcial da s√©rie geom√©trica (1.5.3). Se \\(y \\neq 1\\), ent√£o podemos escrever\n\\[\n\\sum_{k=0}^{n} y^k = \\frac{1 - y^{n+1}}{1 - y}.\n\\]\nAplicando isto, temos\n\\[\n\\sum_{x=0}^{n} (1-\\theta)^x = \\frac{1 - (1-\\theta)^{n+1}}{\\theta}\n\\]\n\\[\n\\sum_{x=0}^{n} \\theta x(1-\\theta)^{x-1} = \\theta \\sum_{x=0}^{n} - \\frac{\\partial}{\\partial \\theta} (1-\\theta)^x = -\\theta \\frac{d}{d\\theta} \\sum_{x=0}^{n} (1-\\theta)^x = -\\theta \\frac{d}{d\\theta} \\left[ \\frac{1 - (1-\\theta)^{n+1}}{\\theta} \\right].\n\\]\nAqui n√≥s (justificadamente) puxamos a derivada atrav√©s da soma finita. Calcular esta derivada resulta em\n\\[\n\\sum_{x=0}^{n} \\theta x(1-\\theta)^{x-1} = \\frac{(1 - (1-\\theta)^{n+1}) - (n+1)\\theta(1-\\theta)^n}{\\theta},\n\\]\ne, consequentemente,\n\\[\n\\begin{aligned}\nS_n(\\theta) &= \\frac{1 - (1-\\theta)^{n+1}}{\\theta} - \\frac{(1 - (1-\\theta)^{n+1}) - (n+1)\\theta(1-\\theta)^n}{\\theta} \\\\\n&= (n+1)(1-\\theta)^n.\n\\end{aligned}\n\\]\n√â claro que, para \\(0 &lt; \\theta &lt; 1\\), \\(S_{\\infty} = \\lim_{n \\to \\infty} S_n(\\theta) = 0\\). Como \\(S_n(\\theta)\\) √© cont√≠nua, a converg√™ncia √© uniforme em qualquer intervalo limitado e fechado. Portanto, a s√©rie de derivadas converge uniformemente e a permuta de diferencia√ß√£o e somat√≥rio √© justificada. ||\n\nEncerramos esta se√ß√£o com um teorema que √© semelhante ao Teorema 2.4.8, mas trata do caso de permutar a ordem de somat√≥rio e integra√ß√£o.\n\nTeorema 2.4.10\nSuponha que a s√©rie \\(\\sum_{x=0}^{\\infty} h(\\theta, x)\\) convirja uniformemente em \\([a, b]\\) e que, para cada \\(x\\), \\(h(\\theta, x)\\) seja uma fun√ß√£o cont√≠nua de \\(\\theta\\). Ent√£o \\[\n\\int_{a}^{b} \\sum_{x=0}^{\\infty} h(\\theta, x) d\\theta = \\sum_{x=0}^{\\infty} \\int_{a}^{b} h(\\theta, x) d\\theta.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#exerc√≠cios",
    "href": "cap-2.html#exerc√≠cios",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "2.5 Exerc√≠cios",
    "text": "2.5 Exerc√≠cios\n2.1 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\). Mostre que a fdp integra 1. (a) \\(Y = X^3\\) e \\(f_X(x) = 42x^5(1-x), 0 &lt; x &lt; 1\\). (b) \\(Y = 4X + 3\\) e \\(f_X(x) = 7e^{-7x}, 0 &lt; x &lt; \\infty\\). (c) \\(Y = X^2\\) e \\(f_X(x) = 30x^2(1-x)^2, 0 &lt; x &lt; 1\\). (Veja o Exemplo 12.6.2 no ap√™ndice de √Ålgebra Computacional.)\n2.2 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\). (a) \\(Y = X^2\\) e \\(f_X(x) = 1, 0 &lt; x &lt; 1\\). (b) \\(Y = -\\log X\\) e \\(X\\) tem fdp \\[\nf_X(x) = \\frac{(n+m+1)!}{n!m!} x^n (1-x)^m, \\quad 0 &lt; x &lt; 1, \\quad m, n \\text{ inteiros positivos}.\n\\] (c) \\(Y = e^X\\) e \\(X\\) tem fdp \\[\nf_X(x) = \\frac{1}{\\sigma^2} x e^{-(x/\\sigma)^2/2}, \\quad 0 &lt; x &lt; \\infty, \\quad \\sigma^2 \\text{ uma constante positiva}.\n\\]\n2.3 Suponha que \\(X\\) tenha a fmp geom√©trica, \\(f_X(x) = \\frac{1}{3} \\left(\\frac{2}{3}\\right)^x, x = 0, 1, 2, \\dots\\). Determine a distribui√ß√£o de probabilidade de \\(Y = X/(X+1)\\). Note que aqui tanto \\(X\\) quanto \\(Y\\) s√£o vari√°veis aleat√≥rias discretas. Para especificar a distribui√ß√£o de probabilidade de \\(Y\\), especifique sua fmp.\n2.4 Seja \\(\\lambda\\) uma constante positiva fixa, e defina a fun√ß√£o \\(f(x)\\) por \\(f(x) = \\frac{1}{2}\\lambda e^{-\\lambda x}\\) se \\(x \\geq 0\\) e \\(f(x) = \\frac{1}{2}\\lambda e^{\\lambda x}\\) se \\(x &lt; 0\\). (a) Verifique que \\(f(x)\\) √© uma fdp. (b) Se \\(X\\) √© uma vari√°vel aleat√≥ria com fdp dada por \\(f(x)\\), encontre \\(P(X &lt; t)\\) para todo \\(t\\). Avalie todas as integrais. (c) Encontre \\(P(|X| &lt; t)\\) para todo \\(t\\). Avalie todas as integrais.\n2.5 Use o Teorema 2.1.8 para encontrar a fdp de \\(Y\\) no Exemplo 2.1.2. Mostre que a mesma resposta √© obtida diferenciando a fda dada em (2.1.6).\n2.6 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\) e mostre que a fdp integra 1. (a) \\(f_X(x) = \\frac{1}{2} e^{-|x|}, -\\infty &lt; x &lt; \\infty; Y = |X|^3\\). (b) \\(f_X(x) = \\frac{3}{8}(x+1)^2, -1 &lt; x &lt; 1; Y = 1 - X^2\\). (c) \\(f_X(x) = \\frac{3}{8}(x+1)^2, -1 &lt; x &lt; 1; Y = 1 - X^2\\) se \\(X \\leq 0\\) e \\(Y = 1 - X\\) se \\(X &gt; 0\\).\n2.7 Seja \\(X\\) com fdp \\(f_X(x) = \\frac{2}{9}(x+1), -1 \\leq x \\leq 2\\). (a) Encontre a fdp de \\(Y = X^2\\). Note que o Teorema 2.1.8 n√£o √© diretamente aplic√°vel neste problema. (b) Mostre que o Teorema 2.1.8 permanece v√°lido se os conjuntos \\(A_0, A_1, \\dots, A_k\\) contiverem \\(\\mathcal{X}\\), e aplique a extens√£o para resolver a parte (a) usando \\(A_0 = \\emptyset, A_1 = (-2, 0)\\) e \\(A_2 = (0, 2)\\).\n2.8 Em cada um dos seguintes itens, mostre que a fun√ß√£o dada √© uma fda e encontre \\(F_X^{-1}(y)\\). (a) \\(F_X(x) = \\begin{cases} 0 & \\text{se } x &lt; 0 \\\\ 1 - e^{-x} & \\text{se } x \\geq 0. \\end{cases}\\) (b) \\(F_X(x) = \\begin{cases} e^x/2 & \\text{se } x &lt; 0 \\\\ 1/2 & \\text{se } 0 \\leq x &lt; 1 \\\\ 1 - (e^{1-x}/2) & \\text{se } 1 \\leq x. \\end{cases}\\) (c) \\(F_X(x) = \\begin{cases} e^x/4 & \\text{se } x &lt; 0 \\\\ 1 - (e^{-x}/4) & \\text{se } x \\geq 0. \\end{cases}\\) Note que, na parte (c), \\(F_X(x)\\) √© descont√≠nua, mas (2.1.13) ainda √© a defini√ß√£o apropriada de \\(F_X^{-1}(y)\\).\n2.9 Se a vari√°vel aleat√≥ria \\(X\\) tem fdp \\[\nf(x) = \\begin{cases} \\frac{x-1}{2} & 1 &lt; x &lt; 3 \\\\ 0 & \\text{caso contr√°rio}, \\end{cases}\n\\] encontre uma fun√ß√£o monot√¥nica \\(u(x)\\) tal que a vari√°vel aleat√≥ria \\(Y = u(X)\\) tenha uma distribui√ß√£o uniforme(0,1).\n2.10 No Teorema 2.1.10, a transforma√ß√£o integral de probabilidade foi provada, relacionando a fda uniforme a qualquer fda cont√≠nua. Neste exerc√≠cio, investigamos a rela√ß√£o entre vari√°veis aleat√≥rias discretas e vari√°veis aleat√≥rias uniformes. Seja \\(X\\) uma vari√°vel aleat√≥ria discreta com fda \\(F_X(x)\\) e defina a vari√°vel aleat√≥ria \\(Y\\) como \\(Y = F_X(X)\\). (a) Prove que \\(Y\\) √© estocasticamente maior que uma uniforme(0,1); isto √©, se \\(U \\sim \\text{uniforme}(0,1)\\), ent√£o \\[\nP(Y &gt; y) \\geq P(U &gt; y) = 1 - y, \\quad \\text{para todo } y, 0 &lt; y &lt; 1,\n\\] \\[\nP(Y &gt; y) &gt; P(U &gt; y) = 1 - y, \\quad \\text{para algum } y, 0 &lt; y &lt; 1.\n\\] (Lembre-se que estocasticamente maior foi definido no Exerc√≠cio 1.49.) (b) Equivalentemente, mostre que a fda de \\(Y\\) satisfaz \\(F_Y(y) \\leq y\\) para todo \\(0 &lt; y &lt; 1\\) e \\(F_Y(y) &lt; y\\) para algum \\(0 &lt; y &lt; 1\\). (Dica: Seja \\(x_0\\) um ponto de salto de \\(F_X\\), e defina \\(y_0 = F_X(x_0)\\). Mostre que \\(P(Y \\leq y_0) = y_0\\). Agora estabele√ßa a desigualdade considerando \\(y = y_0 + \\varepsilon\\). Imagens das fdas ajudar√£o.)\n2.11 Seja \\(X\\) com a fdp normal padr√£o, \\(f_X(x) = (1/\\sqrt{2\\pi})e^{-x^2/2}\\). (a) Encontre \\(EX^2\\) diretamente, e ent√£o usando a fdp de \\(Y = X^2\\) do Exemplo 2.1.7 e calculando \\(EY\\). (b) Encontre a fdp de \\(Y = |X|\\), e encontre sua m√©dia e vari√¢ncia.\n2.12 Um tri√¢ngulo ret√¢ngulo aleat√≥rio pode ser constru√≠do da seguinte maneira. Seja \\(X\\) um √¢ngulo aleat√≥rio cuja distribui√ß√£o √© uniforme em \\((0, \\pi/2)\\). Para cada \\(X\\), construa um tri√¢ngulo como ilustrado abaixo. Aqui, \\(Y = \\text{altura do tri√¢ngulo ret√¢ngulo}\\). Para uma constante fixa \\(d\\), encontre a distribui√ß√£o de \\(Y\\) e \\(EY\\).\n\n\n\n\n\n\nFigura¬†3.6: Figura 2.5.1 - Tri√¢ngulo ret√¢ngulo aleat√≥rio\n\n\n\n2.13 Considere uma sequ√™ncia de lan√ßamentos de moedas independentes, cada um com probabilidade \\(p\\) de ser Cara. Defina uma vari√°vel aleat√≥ria \\(X\\) como o comprimento da sequ√™ncia (de Caras ou Coras) iniciada pela primeira tentativa. (Por exemplo, \\(X = 3\\) se TTTC ou CCCK for observado.) Encontre a distribui√ß√£o de \\(X\\) e encontre \\(EX\\).\n2.14 (a) Seja \\(X\\) uma vari√°vel aleat√≥ria cont√≠nua e n√£o negativa [\\(f(x) = 0\\) para \\(x &lt; 0\\)]. Mostre que \\[\nEX = \\int_0^\\infty [1 - F_X(x)] dx,\n\\] onde \\(F_X(x)\\) √© a fda de \\(X\\). (b) Seja \\(X\\) uma vari√°vel aleat√≥ria discreta cujo intervalo s√£o os inteiros n√£o negativos. Mostre que \\[\nEX = \\sum_{k=0}^\\infty (1 - F_X(k)),\n\\] onde \\(F_X(k) = P(X \\leq k)\\). Compare isso com a parte (a).\n2.15 Betteley (1977) fornece uma lei de adi√ß√£o interessante para expectativas. Sejam \\(X\\) e \\(Y\\) duas vari√°veis aleat√≥rias quaisquer e defina \\[\nX \\land Y = \\min(X, Y) \\quad \\text{e} \\quad X \\lor Y = \\max(X, Y).\n\\] De forma an√°loga √† lei de probabilidade \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\), mostre que \\[\nE(X \\lor Y) = EX + EY - E(X \\land Y).\n\\] (Dica: Estabele√ßa que \\(X + Y = (X \\lor Y) + (X \\land Y)\\).)\n2.16 Use o resultado do Exerc√≠cio 2.14 para encontrar a dura√ß√£o m√©dia de certas chamadas telef√¥nicas, onde assumimos que a dura√ß√£o, \\(T\\), de uma chamada particular pode ser descrita probabilisticamente por \\(P(T &gt; t) = ae^{-\\lambda t} + (1-a)e^{-\\mu t}\\), onde \\(a, \\lambda\\) e \\(\\mu\\) s√£o constantes, \\(0 &lt; a &lt; 1, \\lambda &gt; 0, \\mu &gt; 0\\).\n2.17 Uma mediana de uma distribui√ß√£o √© um valor \\(m\\) tal que \\(P(X \\leq m) \\geq 1/2\\) e \\(P(X \\geq m) \\geq 1/2\\). (Se \\(X\\) √© cont√≠nua, \\(m\\) satisfaz \\(\\int_{-\\infty}^m f(x) dx = \\int_m^\\infty f(x) dx = 1/2\\).) Encontre a mediana das seguintes distribui√ß√µes. (a) \\(f(x) = 3x^2, 0 &lt; x &lt; 1\\) (b) \\(f(x) = \\frac{1}{\\pi(1+x^2)}, -\\infty &lt; x &lt; \\infty\\)\n2.18 Mostre que se \\(X\\) √© uma vari√°vel aleat√≥ria cont√≠nua, ent√£o \\[\n\\min_a E|X - a| = E|X - m|,\n\\] onde \\(m\\) √© a mediana de \\(X\\) (veja o Exerc√≠cio 2.17).\n2.19 Prove que \\[\n\\frac{d}{da} E(X - a)^2 = 0 \\iff EX = a,\n\\] diferenciando a integral. Verifique, usando c√°lculo, que \\(a = EX\\) √© de fato um m√≠nimo. Liste as suposi√ß√µes sobre \\(F_X\\) e \\(f_X\\) que s√£o necess√°rias.\n2.20 Um casal decide continuar a ter filhos at√© que uma filha nas√ßa. Qual √© o n√∫mero esperado de filhos deste casal? (Dica: Veja o Exemplo 1.5.4.)\n2.21 Prove a regra de ‚Äúduas vias‚Äù para expectativas, equa√ß√£o (2.2.5), que diz \\(Eg(X) = EY\\), onde \\(Y = g(X)\\). Assuma que \\(g(x)\\) √© uma fun√ß√£o monot√¥nica.\n2.22 Seja \\(X\\) com a fdp \\[\nf(x) = \\frac{4}{\\beta^3\\sqrt{\\pi}} x^2 e^{-x^2/\\beta^2}, \\quad 0 &lt; x &lt; \\infty, \\quad \\beta &gt; 0.\n\\] (a) Verifique que \\(f(x)\\) √© uma fdp. (b) Encontre \\(EX\\) e \\(Var X\\).\n2.23 Seja \\(X\\) com a fdp \\[\nf(x) = \\frac{1}{2}(1+x), \\quad -1 &lt; x &lt; 1.\n\\] (a) Encontre a fdp de \\(Y = X^2\\). (b) Encontre \\(EY\\) e \\(Var Y\\).\n2.24 Calcule \\(EX\\) e \\(Var X\\) para cada uma das seguintes distribui√ß√µes de probabilidade. (a) \\(f_X(x) = ax^{a-1}, 0 &lt; x &lt; 1, a &gt; 0\\) (b) \\(f_X(x) = 1/n, x = 1, 2, \\dots, n, n &gt; 0\\) um inteiro (c) \\(f_X(x) = \\frac{3}{2}(x-1)^2, 0 &lt; x &lt; 2\\)\n2.25 Suponha que a fdp \\(f_X(x)\\) de uma vari√°vel aleat√≥ria \\(X\\) seja uma fun√ß√£o par. (\\(f_X(x)\\) √© uma fun√ß√£o par se \\(f_X(x) = f_X(-x)\\) para todo \\(x\\).) Mostre que (a) \\(X\\) e \\(-X\\) s√£o identicamente distribu√≠das. (b) \\(M_X(t)\\) √© sim√©trica em torno de zero.\n2.26 Seja \\(f(x)\\) uma fdp e seja \\(a\\) um n√∫mero tal que, para todo \\(\\varepsilon &gt; 0, f(a+\\varepsilon) = f(a-\\varepsilon)\\). Tal fdp √© dita ser sim√©trica em torno do ponto a. (a) D√™ tr√™s exemplos de fdps sim√©tricas. (b) Mostre que se \\(X \\sim f(x)\\), sim√©trica, ent√£o a mediana de \\(X\\) (veja o Exerc√≠cio 2.17) √© o n√∫mero \\(a\\). (c) Mostre que se \\(X \\sim f(x)\\), sim√©trica, e \\(EX\\) existe, ent√£o \\(EX = a\\). (d) Mostre que \\(f(x) = e^{-x}, x \\geq 0\\), n√£o √© uma fdp sim√©trica. (e) Mostre que para a fdp na parte (d), a mediana √© menor que a m√©dia.\n2.27 Seja \\(f(x)\\) uma fdp e seja \\(a\\) um n√∫mero tal que, se \\(a \\geq x \\geq y\\) ent√£o \\(f(a) \\geq f(x) \\geq f(y)\\) e, se \\(a \\leq x \\leq y\\) ent√£o \\(f(a) \\geq f(x) \\geq f(y)\\). Tal fdp √© chamada de unimodal com um moda igual a \\(a\\). (a) D√™ um exemplo de uma fdp unimodal para a qual a moda √© √∫nica. (b) D√™ um exemplo de uma fdp unimodal para a qual a moda n√£o √© √∫nica. (c) Mostre que se \\(f(x)\\) √© tanto sim√©trica (veja o Exerc√≠cio 2.26) quanto unimodal, ent√£o o ponto de simetria √© uma moda. (d) Considere a fdp \\(f(x) = e^{-x}, x \\geq 0\\). Mostre que esta fdp √© unimodal. Qual √© sua moda?\n2.28 Seja \\(\\mu_n\\) o \\(n\\)-√©simo momento central de uma vari√°vel aleat√≥ria \\(X\\). Duas quantidades de interesse, al√©m da m√©dia e vari√¢ncia, s√£o \\[\n\\alpha_3 = \\frac{\\mu_3}{(\\mu_2)^{3/2}} \\quad \\text{e} \\quad \\alpha_4 = \\frac{\\mu_4}{\\mu_2^2}.\n\\] O valor \\(\\alpha_3\\) √© chamado de assimetria e \\(\\alpha_4\\) √© chamado de curtose. A assimetria mede a falta de simetria na fdp (veja o Exerc√≠cio 2.26). A curtose, embora mais dif√≠cil de interpretar, mede o pico ou achatamento da fdp. (a) Mostre que se uma fdp √© sim√©trica em torno de um ponto \\(a\\), ent√£o \\(\\alpha_3 = 0\\). (b) Calcule \\(\\alpha_3\\) para \\(f(x) = e^{-x}, x \\geq 0\\), uma fdp que √© assim√©trica √† direita. (c) Calcule \\(\\alpha_4\\) para cada uma das seguintes fdps e comente sobre o pico de cada uma. \\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty\n\\] \\[\nf(x) = \\frac{1}{2}, \\quad -1 &lt; x &lt; 1\n\\] \\[\nf(x) = \\frac{1}{2} e^{-|x|}, \\quad -\\infty &lt; x &lt; \\infty\n\\] Ruppert (1987) usa fun√ß√µes de influ√™ncia (Se√ß√£o 10.6.4) para explorar ainda mais o significado de curtose e Groeneveld (1991) as usa para explorar a assimetria; veja tamb√©m Balanda e MacGillivray (1988) para mais sobre a interpreta√ß√£o de \\(\\alpha_4\\).\n2.29 Ao calcular momentos de distribui√ß√µes discretas, muitas vezes √© mais f√°cil trabalhar com os momentos fatoriais (veja Assuntos Diversos 2.6.2). (a) Calcule o momento fatorial \\(E[X(X-1)]\\) para as distribui√ß√µes binomial e Poisson. (b) Use os resultados da parte (a) para calcular as vari√¢ncias da distribui√ß√£o binomial e Poisson. (c) Uma distribui√ß√£o discreta particularmente desagrad√°vel √© a beta-binomial, com fmp \\[\nP(Y = y) = \\binom{n}{y} \\frac{\\Gamma(y+a)\\Gamma(n-y+b)\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)\\Gamma(n+a+b)}, \\quad y = 0, 1, \\dots, n.\n\\] onde \\(n, a\\) e \\(b\\) s√£o inteiros positivos. Use momentos fatoriais para calcular a vari√¢ncia da beta binomial. (Veja o Exerc√≠cio 4.34 para outra abordagem deste c√°lculo.)\n2.30 Encontre a fun√ß√£o geradora de momentos correspondente a (a) \\(f(x) = \\frac{1}{c}, 0 &lt; x &lt; c\\) (b) \\(f(x) = \\frac{2x}{c^2}, 0 &lt; x &lt; c\\) (c) \\(f(x) = \\frac{1}{2\\beta} e^{-|x-\\alpha|/\\beta}, -\\infty &lt; x &lt; \\infty, -\\infty &lt; \\alpha &lt; \\infty, \\beta &gt; 0\\) (d) \\(P(X = x) = \\binom{r+x-1}{x} p^r(1-p)^x, x = 0, 1, \\dots, 0 &lt; p &lt; 1, r &gt; 0\\) um inteiro\n2.31 Existe uma distribui√ß√£o para a qual \\(M_X(t) = t/(1-t), |t| &lt; 1\\)? Se sim, encontre-a. Se n√£o, prove.\n2.32 Seja \\(M_X(t)\\) a fun√ß√£o geradora de momentos de \\(X\\), e defina \\(S(t) = \\log(M_X(t))\\). Mostre que \\[\n\\frac{d}{dt} S(t) \\Big|_{t=0} = EX \\quad \\text{e} \\quad \\frac{d^2}{dt^2} S(t) \\Big|_{t=0} = Var X.\n\\]\n2.33 Em cada um dos seguintes casos, verifique a express√£o dada para a fun√ß√£o geradora de momentos e, em cada caso, use a fgm para calcular \\(EX\\) e \\(Var X\\). (a) \\(P(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, M_X(t) = e^{\\lambda(e^t-1)}, x = 0, 1, \\dots; \\lambda &gt; 0\\) (b) \\(P(X = x) = p(1-p)^x, M_X(t) = \\frac{p}{1-(1-p)e^t}, x = 0, 1, \\dots; 0 &lt; p &lt; 1\\) (c) \\(f_X(x) = \\frac{e^{-(x-\\mu)^2/(2\\sigma^2)}}{\\sqrt{2\\pi}\\sigma}, M_X(t) = e^{\\mu t + \\sigma^2t^2/2}, -\\infty &lt; x &lt; \\infty; -\\infty &lt; \\mu &lt; \\infty, \\sigma &gt; 0\\)\n2.34 Uma distribui√ß√£o n√£o pode ser unicamente determinada por uma cole√ß√£o finita de momentos, como mostra este exemplo de Romano e Siegel (1986). Seja \\(X\\) com distribui√ß√£o normal, ou seja, \\(X\\) tem fdp \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\] Defina uma vari√°vel aleat√≥ria discreta \\(Y\\) por \\[\nP(Y = \\sqrt{3}) = P(Y = -\\sqrt{3}) = 1/6, \\quad P(Y = 0) = 2/3.\n\\] Mostre que \\[\nEX^r = EY^r \\quad \\text{para } r = 1, 2, 3, 4, 5.\n\\] (Romano e Siegel (1986) apontam que para qualquer \\(n\\) finito existe uma vari√°vel aleat√≥ria discreta, e portanto n√£o normal, cujos primeiros \\(n\\) momentos s√£o iguais aos de \\(X\\).)\n2.35 Preencha as lacunas no Exemplo 2.3.10. (a) Mostre que se \\(X_1 \\sim f_1(x)\\), ent√£o \\[\nEX_1^r = e^{r^2/2}, \\quad r = 0, 1, \\dots.\n\\] Logo \\(f_1(x)\\) possui todos os seus momentos, e todos os momentos s√£o finitos. (b) Agora mostre que \\[\n\\int_0^\\infty x^r f_1(x) \\sin(2\\pi \\log x) dx = 0,\n\\] para todos os inteiros positivos \\(r\\), logo \\(EX_1^r = EX_2^r\\) para todo \\(r\\). (Romano e Siegel (1986) discutem uma vers√£o extrema deste exemplo, onde uma classe inteira de fdps distintas tem os mesmos momentos. Al√©m disso, Berg (1988) mostrou que este comportamento de momentos pode surgir com transformadas mais simples da distribui√ß√£o normal, como \\(X^3\\).)\n2.36 A distribui√ß√£o lognormal, na qual o Exemplo 2.3.10 se baseia, tem uma propriedade interessante. Se tivermos a fdp \\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}, \\quad 0 \\leq x &lt; \\infty,\n\\] ent√£o o Exerc√≠cio 2.35 mostra que todos os momentos existem e s√£o finitos. No entanto, esta distribui√ß√£o n√£o possui uma fun√ß√£o geradora de momentos, isto √©, \\[\nM_X(t) = \\int_0^\\infty \\frac{e^{tx}}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2} dx\n\\] n√£o existe. Prove isso.\n2.37 Referindo-se √† situa√ß√£o descrita em Assuntos Diversos 2.6.3: (a) Trace as fdps \\(f_1\\) e \\(f_2\\) para ilustrar sua diferen√ßa. (b) Trace as fun√ß√µes geradoras de cumulantes \\(K_1\\) e \\(K_2\\) para ilustrar sua semelhan√ßa. (c) Calcule as fun√ß√µes geradoras de momentos das fdps \\(f_1\\) e \\(f_2\\). Elas s√£o semelhantes ou diferentes? (d) Como as fdps \\(f_1\\) e \\(f_2\\) se relacionam com as fdps descritas no Exemplo 2.3.10?\n2.38 Seja \\(X\\) com a distribui√ß√£o binomial negativa com fmp \\[\nf(x) = \\binom{r+x-1}{x} p^r(1-p)^x, \\quad x = 0, 1, 2, \\dots\n\\] onde \\(0 &lt; p &lt; 1\\) e \\(r &gt; 0\\) √© um inteiro. (a) Calcule a fgm de \\(X\\). (b) Defina uma nova vari√°vel aleat√≥ria por \\(Y = 2pX\\). Mostre que, conforme \\(p \\downarrow 0\\), a fgm de \\(Y\\) converge para a de uma vari√°vel aleat√≥ria qui-quadrado com \\(2r\\) graus de liberdade, mostrando que \\[\n\\lim_{p \\to 0} M_Y(t) = \\left( \\frac{1}{1-2t} \\right)^r, \\quad |t| &lt; 1/2.\n\\]\n2.39 Em cada um dos seguintes casos, calcule as derivadas indicadas, justificando todas as opera√ß√µes. (a) \\(\\frac{d}{dx} \\int_0^x e^{-\\lambda t} dt\\) (b) \\(\\frac{d}{d\\lambda} \\int_0^\\infty e^{-\\lambda t} dt\\) (c) \\(\\frac{d}{dt} \\int_t^1 \\frac{1}{x^2} dx\\) (d) \\(\\frac{d}{dt} \\int_1^\\infty \\frac{1}{(x-t)^2} dx\\)\n2.40 Prove \\[\n\\sum_{k=0}^x \\binom{n}{k} p^k(1-p)^{n-k} = (n-x) \\binom{n}{x} \\int_0^{1-p} t^{n-x-1}(1-t)^x dt.\n\\] (Dica: Integre por partes ou diferencie ambos os lados em rela√ß√£o a \\(p\\).)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-2.html#assuntos-diversos",
    "href": "cap-2.html#assuntos-diversos",
    "title": "Transforma√ß√µes e Esperan√ßas",
    "section": "2.6 Assuntos Diversos",
    "text": "2.6 Assuntos Diversos\n\n2.6.1 Unicidade de Sequ√™ncias de Momentos\nUma distribui√ß√£o n√£o √© necessariamente determinada por seus momentos. Mas se \\(\\sum_{r=1}^{\\infty} \\mu'_r t^r/r!\\) possui um raio de converg√™ncia positivo, onde \\(X \\sim F_X\\) e \\(EX^r = \\mu'_r\\), ent√£o a sequ√™ncia de momentos √© √∫nica e, portanto, a distribui√ß√£o √© unicamente determinada (Billingsley 1995, Se√ß√£o 30). A converg√™ncia desta soma tamb√©m implica que a fun√ß√£o geradora de momentos existe em um intervalo e, portanto, a fun√ß√£o geradora de momentos determina a distribui√ß√£o.\nUma condi√ß√£o suficiente para que a sequ√™ncia de momentos seja √∫nica √© a Condi√ß√£o de Carleman (Chung 1974). Se \\(X \\sim F_X\\) e denotamos \\(EX^r = \\mu'_r\\), ent√£o a sequ√™ncia de momentos √© √∫nica se\n\\[\n\\sum_{r=1}^{\\infty} \\frac{1}{(\\mu'_{2r})^{1/(2r)}} = +\\infty.\n\\tag{3.39}\\]\nEsta condi√ß√£o √©, em geral, dif√≠cil de verificar.\nFeller (1971) apresenta um desenvolvimento muito completo das transformadas de Laplace, das quais as fgms s√£o um caso especial. Em particular, Feller mostra (similarmente a Billingsley) que sempre que\n\\[\nM_X(t) = \\sum_{r=0}^{\\infty} \\frac{\\mu'_r t^r}{r!}\n\\]\nconverge em um intervalo \\(-t_0 \\leq t &lt; t_0, t_0 &gt; 0\\), a distribui√ß√£o \\(F_X\\) √© unicamente determinada. Assim, quando a fgm existe, a sequ√™ncia de momentos determina a distribui√ß√£o \\(F_X\\) univocamente.\nDeve estar claro que usar a fgm para determinar a distribui√ß√£o √© uma tarefa dif√≠cil. Um m√©todo melhor √© atrav√©s do uso de fun√ß√µes caracter√≠sticas, que s√£o explicadas abaixo. Embora as fun√ß√µes caracter√≠sticas simplifiquem a caracteriza√ß√£o de uma distribui√ß√£o, elas necessitam da compreens√£o de an√°lise complexa. Ganha-se por um lado e perde-se por outro.\n\n\n2.6.2 Outras Fun√ß√µes Geradoras\nAl√©m da fun√ß√£o geradora de momentos, h√° uma s√©rie de outras fun√ß√µes geradoras dispon√≠veis. Na maioria dos casos, a fun√ß√£o caracter√≠stica √© a mais √∫til destas. Exceto por circunst√¢ncias raras, as outras fun√ß√µes geradoras s√£o menos √∫teis, mas h√° situa√ß√µes em que elas podem facilitar os c√°lculos.\nFun√ß√£o geradora de cumulantes Para uma vari√°vel aleat√≥ria \\(X\\), a fun√ß√£o geradora de cumulantes √© a fun√ß√£o \\(\\log[M_X(t)]\\). Esta fun√ß√£o pode ser usada para gerar os cumulantes de \\(X\\), que s√£o definidos (de forma um tanto indireta) como os coeficientes na s√©rie de Taylor da fun√ß√£o geradora de cumulantes (veja o Exerc√≠cio 2.32).\nFun√ß√£o geradora de momentos fatoriais A fun√ß√£o geradora de momentos fatoriais de \\(X\\) √© definida como \\(Et^X\\), se a esperan√ßa existir. O nome adv√©m do fato de que esta fun√ß√£o satisfaz\n\\[\n\\frac{d^r}{dt^r} Et^X \\Big|_{t=1} = E\\{X(X-1)\\dots(X-r+1)\\},\n\\]\nonde o lado direito √© um momento fatorial. Se \\(X\\) √© uma vari√°vel aleat√≥ria discreta, ent√£o podemos escrever\n\\[\nEt^X = \\sum_{x} t^x P(X = x),\n\\]\ne a fun√ß√£o geradora de momentos fatoriais √© chamada de fun√ß√£o geradora de probabilidades, visto que os coeficientes da s√©rie de pot√™ncias fornecem as probabilidades. Isto √©, para obter a probabilidade de que \\(X = k\\), calcula-se\n\\[\n\\frac{1}{k!} \\frac{d^k}{dt^k} Et^X \\Big|_{t=0} = P(X = k).\n\\]\n\n\n2.6.3 A Fun√ß√£o Geradora de Momentos Caracteriza uma Distribui√ß√£o?\nEm um artigo com o t√≠tulo acima, McCullagh (1994) analisa um par de densidades semelhantes √†s do Exemplo 2.3.10, mas que possuem fgms:\n\\[\nf_1 = n(0,1) \\quad \\text{e} \\quad f_2 = f_1(x) \\left[ 1 + \\frac{1}{2} \\sin(2\\pi x) \\right]\n\\]\ncom fun√ß√µes geradoras de cumulantes\n\\[\nK_1(t) = t^2/2 \\quad \\text{e} \\quad K_2(t) = K_1(t) + \\log \\left[ 1 + \\frac{1}{2} e^{-2\\pi^2} \\sin(2\\pi t) \\right].\n\\]\nEle observa que, embora as densidades sejam visivelmente dessemelhantes, as cgfs s√£o virtualmente id√™nticas, com diferen√ßa m√°xima inferior a \\(1,34 \\times 10^{-9}\\) em todo o intervalo (menos que o tamanho de um pixel). Portanto, a resposta √† pergunta feita no t√≠tulo √© ‚Äúsim para fins matem√°ticos, mas um retumbante n√£o para fins num√©ricos‚Äù. Em contraste, Waller (1995) ilustra que, embora as fgms falhem em distinguir numericamente as distribui√ß√µes, as fun√ß√µes caracter√≠sticas fazem um excelente trabalho. (Waller et al.¬†(1995) e Luce√±o (1997) investigam mais a fundo a utilidade da fun√ß√£o caracter√≠stica na obten√ß√£o num√©rica das fdas.) Veja o Exerc√≠cio 2.37 para detalhes.\nFun√ß√£o caracter√≠stica Talvez a mais √∫til de todos esses tipos de fun√ß√µes seja a fun√ß√£o caracter√≠stica. A fun√ß√£o caracter√≠stica de \\(X\\) √© definida por\n\\[\n\\phi_X(t) = Ee^{itX},\n\\]\nonde \\(i\\) √© o n√∫mero complexo \\(\\sqrt{-1}\\), portanto a esperan√ßa acima requer integra√ß√£o complexa. A fun√ß√£o caracter√≠stica faz muito mais do que a fgm faz. Quando os momentos de \\(F_X\\) existem, \\(\\phi_X\\) pode ser usada para ger√°-los, de forma muito semelhante a uma fgm. A fun√ß√£o caracter√≠stica sempre existe e determina completamente a distribui√ß√£o. Isto √©, cada fda tem uma √∫nica fun√ß√£o caracter√≠stica. Assim, podemos enunciar um teorema como o Teorema 2.3.11, por exemplo, mas sem ressalvas.\n\n\nTeorema 2.6.1 (Converg√™ncia de Fun√ß√µes Caracter√≠sticas)\nSuponha que \\(X_k, k = 1, 2, \\dots\\), seja uma sequ√™ncia de vari√°veis aleat√≥rias, cada uma com fun√ß√£o caracter√≠stica \\(\\phi_{X_k}(t)\\). Al√©m disso, suponha que \\[\n\\lim_{k \\to \\infty} \\phi_{X_k}(t) = \\phi_X(t), \\quad \\text{para todo } t \\text{ em uma vizinhan√ßa de 0}\n\\] e \\(\\phi_X(t)\\) seja uma fun√ß√£o caracter√≠stica. Ent√£o, para todo \\(X\\) onde \\(F_X(x)\\) √© cont√≠nua, \\[\n\\lim_{k \\to \\infty} F_{X_k}(x) = F_X(x).\n\\]\n\nUm tratamento completo das fun√ß√µes geradoras √© dado por Feller (1968). Fun√ß√µes caracter√≠sticas podem ser encontradas em quase qualquer texto avan√ßado de probabilidade; veja Billingsley (1995) ou Resnick (1999).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Transforma√ß√µes e Esperan√ßas</span>"
    ]
  },
  {
    "objectID": "cap-3.html",
    "href": "cap-3.html",
    "title": "Fam√≠lias Comuns de Distribui√ß√µes",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Fam√≠lias Comuns de Distribui√ß√µes</span>"
    ]
  },
  {
    "objectID": "cap-3.html#conte√∫do-previsto",
    "href": "cap-3.html#conte√∫do-previsto",
    "title": "Fam√≠lias Comuns de Distribui√ß√µes",
    "section": "",
    "text": "Introdu√ß√£o\nDistribui√ß√µes Discretas\nDistribui√ß√µes Cont√≠nuas\nFam√≠lias Exponenciais\nFam√≠lias de Localiza√ß√£o e Escala\nDesigualdades e Identidades",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Fam√≠lias Comuns de Distribui√ß√µes</span>"
    ]
  },
  {
    "objectID": "cap-4.html",
    "href": "cap-4.html",
    "title": "M√∫ltiplas Vari√°veis Aleat√≥rias",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>M√∫ltiplas Vari√°veis Aleat√≥rias</span>"
    ]
  },
  {
    "objectID": "cap-4.html#conte√∫do-previsto",
    "href": "cap-4.html#conte√∫do-previsto",
    "title": "M√∫ltiplas Vari√°veis Aleat√≥rias",
    "section": "",
    "text": "Distribui√ß√µes Conjuntas e Marginais\nDistribui√ß√µes Condicionais e Independ√™ncia\nTransforma√ß√µes Bivariadas\nModelos Hier√°rquicos e Distribui√ß√µes de Mistura\nCovari√¢ncia e Correla√ß√£o\nDistribui√ß√µes Multivariadas\nDesigualdades",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>M√∫ltiplas Vari√°veis Aleat√≥rias</span>"
    ]
  },
  {
    "objectID": "cap-5.html",
    "href": "cap-5.html",
    "title": "Propriedades de uma Amostra Aleat√≥ria",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Propriedades de uma Amostra Aleat√≥ria</span>"
    ]
  },
  {
    "objectID": "cap-5.html#conte√∫do-previsto",
    "href": "cap-5.html#conte√∫do-previsto",
    "title": "Propriedades de uma Amostra Aleat√≥ria",
    "section": "",
    "text": "Conceitos B√°sicos de Amostras Aleat√≥rias\nSomas de Vari√°veis Aleat√≥rias de uma Amostra Aleat√≥ria\nAmostragem da Distribui√ß√£o Normal\nEstat√≠sticas de Ordem\nConceitos de Converg√™ncia\n\nConverg√™ncia em Probabilidade\nConverg√™ncia Quase Certa\nConverg√™ncia em Distribui√ß√£o\nO M√©todo Delta\n\nGerando uma Amostra Aleat√≥ria",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Propriedades de uma Amostra Aleat√≥ria</span>"
    ]
  },
  {
    "objectID": "cap-6.html",
    "href": "cap-6.html",
    "title": "Princ√≠pios de Redu√ß√£o de Dados",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Princ√≠pios de Redu√ß√£o de Dados</span>"
    ]
  },
  {
    "objectID": "cap-6.html#conte√∫do-previsto",
    "href": "cap-6.html#conte√∫do-previsto",
    "title": "Princ√≠pios de Redu√ß√£o de Dados",
    "section": "",
    "text": "O Princ√≠pio da Sufici√™ncia\n\nEstat√≠sticas Suficientes\nEstat√≠sticas Suficientes M√≠nimas\nEstat√≠sticas Ancilares\nEstat√≠sticas Suficientes, Completas e Ancilares\n\nO Princ√≠pio da Verossimilhan√ßa\n\nA Fun√ß√£o de Verossimilhan√ßa\nO Princ√≠pio da Verossimilhan√ßa Formal\n\nO Princ√≠pio da Equivari√¢ncia",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Princ√≠pios de Redu√ß√£o de Dados</span>"
    ]
  },
  {
    "objectID": "cap-7.html",
    "href": "cap-7.html",
    "title": "Estima√ß√£o Pontual",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Estima√ß√£o Pontual</span>"
    ]
  },
  {
    "objectID": "cap-7.html#conte√∫do-previsto",
    "href": "cap-7.html#conte√∫do-previsto",
    "title": "Estima√ß√£o Pontual",
    "section": "",
    "text": "M√©todos para Encontrar Estimadores\n\nM√©todo dos Momentos\nEstimadores de M√°xima Verossimilhan√ßa\nEstimadores de Bayes\nO Algoritmo EM\n\nM√©todos de Avalia√ß√£o de Estimadores\n\nErro Quadr√°tico M√©dio\nMelhores Estimadores N√£o Viesados\nSufici√™ncia e N√£o-viesamento\nOtimalidade da Fun√ß√£o de Perda",
    "crumbs": [
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Estima√ß√£o Pontual</span>"
    ]
  },
  {
    "objectID": "cap-8.html",
    "href": "cap-8.html",
    "title": "Teste de Hip√≥teses",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Teste de Hip√≥teses</span>"
    ]
  },
  {
    "objectID": "cap-8.html#conte√∫do-previsto",
    "href": "cap-8.html#conte√∫do-previsto",
    "title": "Teste de Hip√≥teses",
    "section": "",
    "text": "M√©todos para Encontrar Testes\n\nTestes de Raz√£o de Verossimilhan√ßa\nTestes Bayesianos\nTestes de Uni√£o-Interse√ß√£o e Interse√ß√£o-Uni√£o\n\nM√©todos de Avalia√ß√£o de Testes\n\nProbabilidades de Erro e Fun√ß√£o Poder\nTestes Mais Poderosos\nTamanhos de Testes de Uni√£o-Interse√ß√£o\nP-valores",
    "crumbs": [
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Teste de Hip√≥teses</span>"
    ]
  },
  {
    "objectID": "cap-9.html",
    "href": "cap-9.html",
    "title": "Estima√ß√£o por Intervalo",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Estima√ß√£o por Intervalo</span>"
    ]
  },
  {
    "objectID": "cap-9.html#conte√∫do-previsto",
    "href": "cap-9.html#conte√∫do-previsto",
    "title": "Estima√ß√£o por Intervalo",
    "section": "",
    "text": "M√©todos para Encontrar Estimadores de Intervalo\n\nInvertendo uma Estat√≠stica de Teste\nQuantidades Pivotais\nPivotando a FDA\nIntervalos Bayesianos\n\nM√©todos de Avalia√ß√£o de Estimadores de Intervalo\n\nTamanho e Probabilidade de Cobertura\nOtimalidade Relacionada a Testes\nOtimalidade Bayesiana\nOtimalidade da Fun√ß√£o de Perda",
    "crumbs": [
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Estima√ß√£o por Intervalo</span>"
    ]
  },
  {
    "objectID": "cap-10.html",
    "href": "cap-10.html",
    "title": "Avalia√ß√µes Assint√≥ticas",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Avalia√ß√µes Assint√≥ticas</span>"
    ]
  },
  {
    "objectID": "cap-10.html#conte√∫do-previsto",
    "href": "cap-10.html#conte√∫do-previsto",
    "title": "Avalia√ß√µes Assint√≥ticas",
    "section": "",
    "text": "Estima√ß√£o Pontual\n\nConsist√™ncia\nEfici√™ncia\nC√°lculos e Compara√ß√µes\nBootstrap\n\nRobustez\n\nA M√©dia e a Mediana\nM-Estimadores\n\nTeste de Hip√≥teses\n\nDistribui√ß√£o Assint√≥tica de TRVs\nOutros Testes com Grandes Amostras\n\nEstima√ß√£o por Intervalo\n\nIntervalos de Verossimilhan√ßa Aproximada\nOutros Intervalos Aproximados (e Robustos)",
    "crumbs": [
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Avalia√ß√µes Assint√≥ticas</span>"
    ]
  },
  {
    "objectID": "cap-11.html",
    "href": "cap-11.html",
    "title": "An√°lise de Vari√¢ncia e Regress√£o",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>An√°lise de Vari√¢ncia e Regress√£o</span>"
    ]
  },
  {
    "objectID": "cap-11.html#conte√∫do-previsto",
    "href": "cap-11.html#conte√∫do-previsto",
    "title": "An√°lise de Vari√¢ncia e Regress√£o",
    "section": "",
    "text": "An√°lise de Vari√¢ncia (ANOVA) de Um Fator\nRegress√£o Linear Simples",
    "crumbs": [
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>An√°lise de Vari√¢ncia e Regress√£o</span>"
    ]
  },
  {
    "objectID": "cap-12.html",
    "href": "cap-12.html",
    "title": "Modelos de Regress√£o",
    "section": "",
    "text": "Conte√∫do Previsto\nEste cap√≠tulo abordar√°:",
    "crumbs": [
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Modelos de Regress√£o</span>"
    ]
  },
  {
    "objectID": "cap-12.html#conte√∫do-previsto",
    "href": "cap-12.html#conte√∫do-previsto",
    "title": "Modelos de Regress√£o",
    "section": "",
    "text": "Introdu√ß√£o aos Modelos de Regress√£o\nEstima√ß√£o e Teste com Erros Normais\nEstima√ß√£o e Predi√ß√£o em um Dado \\(x = x_0\\)\nInfer√™ncia Simult√¢nea",
    "crumbs": [
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Modelos de Regress√£o</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-este-livro",
    "href": "index.html#sobre-este-livro",
    "title": "Infer√™ncia Estat√≠stica",
    "section": "",
    "text": "üìö Refer√™ncia Original\nCasella, G., & Berger, R. L. (2002). Statistical Inference (2nd ed.). Duxbury/Thomson Learning.\nISBN: 0-534-24312-6",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Infer√™ncia Estat√≠stica</span>"
    ]
  }
]