[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferência Estatística",
    "section": "",
    "text": "Sobre Este Livro\nEste projeto é uma tradução não oficial para o português brasileiro do clássico Statistical Inference, de George Casella e Roger L. Berger. Seu único objetivo é facilitar o acesso de estudantes de estatística de língua portuguesa. Para uso acadêmico e profissional, recomendamos fortemente a aquisição da obra original em inglês.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#segunda-edição",
    "href": "index.html#segunda-edição",
    "title": "Inferência Estatística",
    "section": "1.1 Segunda Edição",
    "text": "1.1 Segunda Edição\n\nGeorge Casella University of Florida\nRoger L. Berger North Carolina State University\n\n\nTradução para o Português Brasileiro",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-este-livro",
    "href": "index.html#sobre-este-livro",
    "title": "Inferência Estatística",
    "section": "1.2 Sobre Este Livro",
    "text": "1.2 Sobre Este Livro\nEste é um texto clássico e abrangente sobre inferência estatística, reconhecido mundialmente como uma das principais referências para estudantes de pós-graduação e pesquisadores em estatística. O livro oferece uma apresentação rigorosa e matematicamente elegante dos fundamentos da teoria estatística.\n\n\n\n\n\n\nNota sobre a Tradução\n\n\n\nEsta tradução para o português brasileiro foi elaborada com o objetivo de tornar este material fundamental mais acessível aos estudantes e pesquisadores lusófonos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-livro",
    "href": "index.html#estrutura-do-livro",
    "title": "Inferência Estatística",
    "section": "Estrutura do Livro",
    "text": "Estrutura do Livro\nO livro está organizado em 12 capítulos:\n\nCapítulo 1: Teoria da Probabilidade\nEstabelece os fundamentos matemáticos necessários para o restante do livro, incluindo:\n\nTeoria dos Conjuntos\nFundamentos da Teoria da Probabilidade\n\nFundações Axiomáticas\nO Cálculo de Probabilidades\nContagem\nEnumerando Resultados\n\nProbabilidade Condicional e Independência\nVariáveis Aleatórias\nFunções de Distribuição\nFunções de Densidade e de Massa\n\n\n\nCapítulo 2: Transformações e Esperanças\n\nDistribuições de Funções de uma Variável Aleatória\nValores Esperados (Esperança)\nMomentos e Funções Geradoras de Momentos\nDiferenciação sob o Sinal de Integral\n\n\n\nCapítulo 3: Famílias Comuns de Distribuições\n\nIntrodução\nDistribuições Discretas\nDistribuições Contínuas\nFamílias Exponenciais\nFamílias de Localização e Escala\nDesigualdades e Identidades\n\n\n\nCapítulo 4: Múltiplas Variáveis Aleatórias\n\nDistribuições Conjuntas e Marginais\nDistribuições Condicionais e Independência\nTransformações Bivariadas\nModelos Hierárquicos e Distribuições de Mistura\nCovariância e Correlação\nDistribuições Multivariadas\nDesigualdades\n\n\n\nCapítulo 5: Propriedades de uma Amostra Aleatória\n\nConceitos Básicos de Amostras Aleatórias\nSomas de Variáveis Aleatórias de uma Amostra Aleatória\nAmostragem da Distribuição Normal\nEstatísticas de Ordem\nConceitos de Convergência\n\nConvergência em Probabilidade\nConvergência Quase Certa\nConvergência em Distribuição\nO Método Delta\n\nGerando uma Amostra Aleatória\n\n\n\nCapítulo 6: Princípios de Redução de Dados\n\nO Princípio da Suficiência\n\nEstatísticas Suficientes\nEstatísticas Suficientes Mínimas\nEstatísticas Ancilares\nEstatísticas Suficientes, Completas e Ancilares\n\nO Princípio da Verossimilhança\n\nA Função de Verossimilhança\nO Princípio da Verossimilhança Formal\n\nO Princípio da Equivariância\n\n\n\nCapítulo 7: Estimação Pontual\n\nMétodos para Encontrar Estimadores\n\nMétodo dos Momentos\nEstimadores de Máxima Verossimilhança\nEstimadores de Bayes\nO Algoritmo EM\n\nMétodos de Avaliação de Estimadores\n\nErro Quadrático Médio\nMelhores Estimadores Não Viesados\nSuficiência e Não-viesamento\nOtimalidade da Função de Perda\n\n\n\n\nCapítulo 8: Teste de Hipóteses\n\nMétodos para Encontrar Testes\n\nTestes de Razão de Verossimilhança\nTestes Bayesianos\nTestes de União-Interseção e Interseção-União\n\nMétodos de Avaliação de Testes\n\nProbabilidades de Erro e Função Poder\nTestes Mais Poderosos\nTamanhos de Testes de União-Interseção\nP-valores\n\n\n\n\nCapítulo 9: Estimação por Intervalo\n\nMétodos para Encontrar Estimadores de Intervalo\n\nInvertendo uma Estatística de Teste\nQuantidades Pivotais\nPivotando a FDA\nIntervalos Bayesianos\n\nMétodos de Avaliação de Estimadores de Intervalo\n\nTamanho e Probabilidade de Cobertura\nOtimalidade Relacionada a Testes\nOtimalidade Bayesiana\nOtimalidade da Função de Perda\n\n\n\n\nCapítulo 10: Avaliações Assintóticas\n\nEstimação Pontual\n\nConsistência\nEficiência\nCálculos e Comparações\nBootstrap\n\nRobustez\n\nA Média e a Mediana\nM-Estimadores\n\nTeste de Hipóteses\n\nDistribuição Assintótica de TRVs\nOutros Testes com Grandes Amostras\n\nEstimação por Intervalo\n\nIntervalos de Verossimilhança Aproximada\nOutros Intervalos Aproximados (e Robustos)\n\n\n\n\nCapítulo 11: Análise de Variância e Regressão\n\nAnálise de Variância (ANOVA) de Um Fator\nRegressão Linear Simples\n\n\n\nCapítulo 12: Modelos de Regressão\n\nIntrodução aos Modelos de Regressão\nEstimação e Teste com Erros Normais\nEstimação e Predição em um Dado \\(x = x_0\\)\nInferência Simultânea",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Inferência Estatística",
    "section": "1.4 Pré-requisitos",
    "text": "1.4 Pré-requisitos\nPara um aproveitamento pleno deste material, recomenda-se conhecimento prévio de:\n\nCálculo: Diferenciação, integração, séries e limites\nÁlgebra Linear: Matrizes, determinantes e autovalores\nTeoria dos Conjuntos: Noções básicas de conjuntos e operações",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#como-usar-este-material",
    "href": "index.html#como-usar-este-material",
    "title": "Inferência Estatística",
    "section": "1.5 Como Usar Este Material",
    "text": "1.5 Como Usar Este Material\n\nEstudantesProfessoresPesquisadores\n\n\nEste livro é ideal para cursos de pós-graduação em estatística. Cada capítulo contém:\n\nDesenvolvimento teórico rigoroso\nExemplos detalhados\nExercícios com diferentes níveis de dificuldade\nTópicos avançados em seções especiais\n\n\n\nO material pode ser adaptado para diferentes cursos:\n\nProbabilidade I: Capítulos 1-4\nInferência Estatística: Capítulos 5-10\nTeoria Estatística Completa: Todos os capítulos\n\n\n\nAlém de ser uma referência fundamental, o livro inclui:\n\nDiscussões sobre fronteiras da pesquisa\nReferências bibliográficas extensas\nConexões entre diferentes áreas da estatística",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#referência-bibliográfica",
    "href": "index.html#referência-bibliográfica",
    "title": "Inferência Estatística",
    "section": "1.6 Referência Bibliográfica",
    "text": "1.6 Referência Bibliográfica\n\nCasella, G., & Berger, R. L. (2002). Statistical Inference (2nd ed.). Duxbury/Thomson Learning.\nISBN: 0-534-24312-6\n\n\n\n“A estatística é a gramática da ciência.” — Karl Pearson",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "cap-1.html",
    "href": "cap-1.html",
    "title": "Teoria da Probabilidade",
    "section": "",
    "text": "1.1 Teoria dos Conjuntos\nO tema da teoria da probabilidade é a fundação sobre a qual toda a estatística é construída, fornecendo um meio para modelar populações, experimentos ou quase qualquer outra coisa que possa ser considerada um fenômeno aleatório. Por meio desses modelos, os estatísticos são capazes de tirar inferências sobre populações, inferências baseadas no exame de apenas uma parte do todo.\nA teoria da probabilidade tem uma história longa e rica, que remonta pelo menos ao século XVII, quando, a pedido de seu amigo, o Chevalier de Méré, Pascal e Fermat desenvolveram uma formulação matemática para as probabilidades em jogos de azar.\nO objetivo deste capítulo não é fornecer uma introdução exaustiva à teoria da probabilidade; tal tentativa seria imprudente em um espaço tão curto. Em vez disso, tentamos delinear algumas das ideias básicas da teoria da probabilidade que são fundamentais para o estudo da estatística.\nAssim como a estatística se baseia na fundação da teoria da probabilidade, a teoria da probabilidade, por sua vez, se baseia na teoria dos conjuntos, que é onde começamos.\nUm dos principais objetivos de um estatístico é tirar conclusões sobre uma população de objetos realizando um experimento. O primeiro passo nesse esforço é identificar os possíveis resultados ou, na terminologia estatística, o espaço amostral.\nSe o experimento consiste em lançar uma moeda, o espaço amostral contém dois resultados, cara e coroa; portanto,\n\\[\nS = \\{H, T\\}.\n\\]\nSe, por outro lado, o experimento consiste em observar as notas do SAT reportadas de alunos selecionados aleatoriamente em uma certa universidade, o espaço amostral seria o conjunto de inteiros positivos entre 200 e 800 que são múltiplos de dez — isto é, \\(S = \\{200, 210, 220, \\dots, 780, 790, 800\\}\\). Finalmente, considere um experimento onde a observação é o tempo de reação a um determinado estímulo. Aqui, o espaço amostral consistiria em todos os números positivos, isto é, \\(S = (0, \\infty)\\).\nPodemos classificar os espaços amostrais em dois tipos, de acordo com o número de elementos que eles contêm. Espaços amostrais podem ser enumeráveis ou não enumeráveis; se os elementos de um espaço amostral podem ser colocados em correspondência biunívoca (1 para 1) com um subconjunto dos inteiros, o espaço amostral é enumerável. É claro que, se o espaço amostral contém apenas um número finito de elementos, ele é enumerável. Assim, os espaços amostrais do lançamento da moeda e das notas do SAT são ambos enumeráveis (de fato, finitos), enquanto o espaço amostral do tempo de reação é não enumerável, uma vez que os números reais positivos não podem ser colocados em correspondência biunívoca com os inteiros. Se, no entanto, medíssemos o tempo de reação arredondando para o segundo mais próximo, então o espaço amostral seria (em segundos) \\(S = \\{0, 1, 2, 3, \\dots\\}\\), que é então enumerável.\nEssa distinção entre espaços amostrais enumeráveis e não enumeráveis é importante apenas na medida em que dita a maneira pela qual as probabilidades podem ser atribuídas. Na maior parte das vezes, isso não causa problemas, embora o tratamento matemático das situações seja diferente. Em um nível filosófico, poderia ser argumentado que só podem existir espaços amostrais enumeráveis, uma vez que as medições não podem ser feitas com precisão infinita. (Um espaço amostral consistindo, digamos, de todos os números de dez dígitos é um espaço amostral enumerável.) Embora na prática isso seja verdade, métodos probabilísticos e estatísticos associados a espaços amostrais não enumeráveis são, em geral, menos trabalhosos do que aqueles para espaços amostrais enumeráveis e fornecem uma aproximação próxima da situação verdadeira (enumerável).\nUma vez definido o espaço amostral, estamos em posição de considerar coleções de possíveis resultados de um experimento.\nSeja \\(A\\) um evento, um subconjunto de \\(S\\). Dizemos que o evento \\(A\\) ocorre se o resultado do experimento estiver no conjunto \\(A\\). Ao falar de probabilidades, geralmente falamos da probabilidade de um evento, em vez de um conjunto. Mas podemos usar os termos de forma intercambiável.\nPrimeiro, precisamos definir formalmente as duas relações a seguir, que nos permitem ordenar e igualar conjuntos:\n\\[\n\\begin{align*}\nA \\subset B &\\iff x \\in A \\Rightarrow x \\in B; &(\\text{continência}) \\\\\nA = B &\\iff A \\subset B \\text{ e } B \\subset A. &(\\text{igualdade})\n\\end{align*}\n\\]\nDados dois eventos (ou conjuntos) \\(A\\) e \\(B\\), temos as seguintes operações elementares de conjuntos:\nUnião: A união de \\(A\\) e \\(B\\), escrita \\(A \\cup B\\), é o conjunto de elementos que pertencem a \\(A\\) ou a \\(B\\) ou a ambos:\n\\[\nA \\cup B = \\{x : x \\in A \\text{ ou } x \\in B\\}.\n\\]\nInterseção: A interseção de \\(A\\) e \\(B\\), escrita \\(A \\cap B\\), é o conjunto de elementos que pertencem a ambos \\(A\\) e \\(B\\):\n\\[\nA \\cap B = \\{x : x \\in A \\text{ e } x \\in B\\}.\n\\]\nComplementar: O complementar de \\(A\\), escrito \\(A^c\\), é o conjunto de todos os elementos que não estão em \\(A\\):\n\\[\nA^c = \\{x : x \\notin A\\}.\n\\]\nAs operações elementares de conjuntos podem ser combinadas, de certa forma semelhante à maneira como a adição e a multiplicação podem ser combinadas. Desde que tenhamos cuidado, podemos tratar conjuntos como se fossem números. Podemos agora enunciar as seguintes propriedades úteis das operações de conjuntos.\nAs operações de união e interseção podem ser estendidas para coleções infinitas de conjuntos também. Se \\(A_1, A_2, A_3, \\dots\\) é uma coleção de conjuntos, todos definidos em um espaço amostral \\(S\\), então\n\\[\n\\bigcup_{i=1}^{\\infty} A_i = \\{x \\in S : x \\in A_i \\text{ para algum } i\\},\n\\] \\[\n\\bigcap_{i=1}^{\\infty} A_i = \\{x \\in S : x \\in A_i \\text{ para todo } i\\}.\n\\]\nPor exemplo, seja \\(S = (0, 1]\\) e defina \\(A_i = [(1/i), 1]\\). Então\n\\[\n\\begin{align*}\n\\bigcup_{i=1}^{\\infty} A_i &= \\bigcup_{i=1}^{\\infty} [(1/i), 1] &&= \\{x \\in (0, 1] : x \\in [(1/i), 1] \\text{ para algum } i\\} \\\\\n& &&= \\{x \\in (0, 1]\\} &&= (0, 1]; \\\\\n\\bigcap_{i=1}^{\\infty} A_i &= \\bigcap_{i=1}^{\\infty} [(1/i), 1] &&= \\{x \\in (0, 1] : x \\in [(1/i), 1] \\text{ para todo } i\\} \\\\\n& &&= \\{x \\in (0, 1] : x \\in [1, 1]\\} &&= \\{1\\}. \\quad \\text{(o ponto 1)}\n\\end{align*}\n\\]\nTambém é possível definir uniões e interseções sobre coleções não enumeráveis de conjuntos. Se \\(\\Gamma\\) é um conjunto de índices (um conjunto de elementos a serem usados como índices), então\n\\[\n\\bigcup_{\\alpha \\in \\Gamma} A_{\\alpha} = \\{x \\in S : x \\in A_{\\alpha} \\text{ para algum } \\alpha\\},\n\\] \\[\n\\bigcap_{\\alpha \\in \\Gamma} A_{\\alpha} = \\{x \\in S : x \\in A_{\\alpha} \\text{ para todo } \\alpha\\}.\n\\]\nSe, por exemplo, tomarmos \\(\\Gamma = \\{\\text{todos os números reais positivos}\\}\\) e \\(A_{\\alpha} = (0, \\alpha]\\), então \\(\\cup_{\\alpha \\in \\Gamma} A_{\\alpha} = (0, \\infty)\\) é uma união não enumerável. Embora uniões e interseções não enumeráveis não desempenhem um papel importante na estatística, elas às vezes fornecem um mecanismo útil para obter uma resposta (veja a Seção 8.2.3).\nFinalmente, discutimos a ideia de uma partição do espaço amostral.\nConjuntos disjuntos são conjuntos sem pontos em comum. Se desenharmos um diagrama de Venn para dois conjuntos disjuntos, os conjuntos não se sobrepõem. A coleção\n\\[\nA_i = [i, i+1), \\quad i = 0, 1, 2, \\dots,\n\\]\nconsiste em conjuntos disjuntos dois a dois. Note ainda que \\(\\cup_{i=0}^{\\infty} A_i = [0, \\infty)\\).\nOs conjuntos \\(A_i = [i, i+1)\\) formam uma partição de \\([0, \\infty)\\). Em geral, partições são muito úteis, permitindo-nos dividir o espaço amostral em pedaços pequenos e não sobrepostos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#teoria-dos-conjuntos",
    "href": "cap-1.html#teoria-dos-conjuntos",
    "title": "Teoria da Probabilidade",
    "section": "",
    "text": "Definição 1.1.1 - Espaço Amostral\nO conjunto, \\(S\\), de todos os resultados possíveis de um experimento particular é chamado de espaço amostral do experimento.\n\n\n\n\n\n\n\n\nDefinição 1.1.2 - Evento\nUm evento é qualquer coleção de possíveis resultados de um experimento, isto é, qualquer subconjunto de \\(S\\) (incluindo o próprio \\(S\\)).\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo 1.1.3 (Operações com eventos)\nConsidere o experimento de selecionar uma carta aleatoriamente de um baralho padrão e anotar seu naipe: paus (C), ouros (D), copas (H) ou espadas (S). O espaço amostral é\n\\[\nS = \\{C, D, H, S\\},\n\\]\ne alguns eventos possíveis são\n\\[\nA = \\{C, D\\} \\quad \\text{e} \\quad B = \\{D, H, S\\}.\n\\]\nA partir desses eventos, podemos formar\n\\[\nA \\cup B = \\{C, D, H, S\\}, \\quad A \\cap B = \\{D\\}, \\quad \\text{e} \\quad A^c = \\{H, S\\}.\n\\]\nAlém disso, note que \\(A \\cup B = S\\) (o evento \\(S\\)) e \\((A \\cup B)^c = \\emptyset\\), onde \\(\\emptyset\\) denota o conjunto vazio (o conjunto que não consiste em nenhum elemento).\n\n\n\nTeorema 1.1.4\nPara quaisquer três eventos, \\(A, B\\) e \\(C\\), definidos em um espaço amostral \\(S\\),\n\na. Comutatividade \\[\n\\begin{align*}\nA \\cup B &= B \\cup A, \\\\\nA \\cap B &= B \\cap A;\n\\end{align*}\n\\]\nb. Associatividade \\[\n\\begin{align*}\nA \\cup (B \\cup C) &= (A \\cup B) \\cup C, \\\\\nA \\cap (B \\cap C) &= (A \\cap B) \\cap C;\n\\end{align*}\n\\]\nc. Leis Distributivas \\[\n\\begin{align*}\nA \\cap (B \\cup C) &= (A \\cap B) \\cup (A \\cap C), \\\\\nA \\cup (B \\cap C) &= (A \\cup B) \\cap (A \\cup C);\n\\end{align*}\n\\]\nd. Leis de DeMorgan \\[\n\\begin{align*}\n(A \\cup B)^c &= A^c \\cap B^c, \\\\\n(A \\cap B)^c &= A^c \\cup B^c.\n\\end{align*}\n\\]\n\n\n\nComprovação. A prova de grande parte deste teorema é deixada como Exercício 1.3. Além disso, os Exercícios 1.9 e 1.10 generalizam o teorema. Para ilustrar a técnica, no entanto, provaremos a Lei Distributiva:\n\\[\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C).\n\\]\n(Você pode estar familiarizado com o uso de diagramas de Venn para “provar” teoremas na teoria dos conjuntos. Advertimos que, embora os diagramas de Venn sejam às vezes úteis para visualizar uma situação, eles não constituem uma prova formal.) Para provar que dois conjuntos são iguais, deve-se demonstrar que cada conjunto contém o outro. Formalmente, então,\n\\[\n\\begin{align*}\nA \\cap (B \\cup C) &= \\{x \\in S : x \\in A \\text{ e } x \\in (B \\cup C)\\}; \\\\\n(A \\cap B) \\cup (A \\cap C) &= \\{x \\in S : x \\in (A \\cap B) \\text{ ou } x \\in (A \\cap C)\\}.\n\\end{align*}\n\\]\nPrimeiro mostramos que \\(A \\cap (B \\cup C) \\subset (A \\cap B) \\cup (A \\cap C)\\). Seja \\(x \\in (A \\cap (B \\cup C))\\). Pela definição de interseção, deve ser que \\(x \\in A\\) e \\(x \\in (B \\cup C)\\), isto é, \\(x \\in B\\) ou \\(x \\in C\\). Como \\(x\\) também deve estar em \\(A\\), temos que \\(x \\in (A \\cap B)\\) ou \\(x \\in (A \\cap C)\\); portanto,\n\\[\nx \\in ((A \\cap B) \\cup (A \\cap C)),\n\\]\ne a continência está estabelecida. Agora assuma \\(x \\in ((A \\cap B) \\cup (A \\cap C))\\). Isso implica que \\(x \\in (A \\cap B)\\) ou \\(x \\in (A \\cap C)\\). Se \\(x \\in (A \\cap B)\\), então \\(x\\) está em ambos \\(A\\) e \\(B\\). Visto que \\(x \\in B, x \\in (B \\cup C)\\) e assim \\(x \\in (A \\cap (B \\cup C))\\). Se, por outro lado, \\(x \\in (A \\cap C)\\), o argumento é similar, e novamente concluímos que \\(x \\in (A \\cap (B \\cup C))\\). Assim, estabelecemos \\((A \\cap B) \\cup (A \\cap C) \\subset A \\cap (B \\cup C)\\), mostrando a continência na outra direção e, portanto, provando a Lei Distributiva. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\nDefinição 1.1.5 - Disjuntos\nDois eventos \\(A\\) e \\(B\\) são disjuntos (ou mutuamente exclusivos) se \\(A \\cap B = \\emptyset\\). Os eventos \\(A_1, A_2, \\dots\\) são disjuntos dois a dois (ou mutuamente exclusivos) se \\(A_i \\cap A_j = \\emptyset\\) para todo \\(i \\ne j\\).\n\n\n\n\n\nDefinição 1.1.6 - Partição\nSe \\(A_1, A_2, \\dots\\) são disjuntos dois a dois e \\(\\cup_{i=1}^{\\infty} A_i = S\\), então a coleção \\(A_1, A_2, \\dots\\) forma uma partição de \\(S\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#fundamentos-da-probabilidade",
    "href": "cap-1.html#fundamentos-da-probabilidade",
    "title": "Teoria da Probabilidade",
    "section": "1.2 Fundamentos da Probabilidade",
    "text": "1.2 Fundamentos da Probabilidade\nQuando um experimento é realizado, a realização do experimento é um resultado no espaço amostral. Se o experimento é realizado um número de vezes, diferentes resultados podem ocorrer a cada vez ou alguns resultados podem se repetir. Essa “frequência de ocorrência” de um resultado pode ser pensada como uma probabilidade. Resultados mais prováveis ocorrem com mais frequência. Se os resultados de um experimento podem ser descritos probabilisticamente, estamos a caminho de analisar o experimento estatisticamente.\nNesta seção, descrevemos alguns dos fundamentos da teoria da probabilidade. Não definimos probabilidades em termos de frequências, mas, em vez disso, adotamos a abordagem axiomática matematicamente mais simples. Como será visto, a abordagem axiomática não se preocupa com as interpretações das probabilidades, mas preocupa-se apenas que as probabilidades sejam definidas por uma função que satisfaça os axiomas. Interpretações das probabilidades são outra questão. A “frequência de ocorrência” de um evento é um exemplo de uma interpretação particular de probabilidade. Outra interpretação possível é subjetiva, onde, em vez de pensar em probabilidade como frequência, podemos pensar nela como uma crença na chance de um evento ocorrer.\n\n1.2.1 Fundações Axiomáticas\nPara cada evento \\(A\\) no espaço amostral \\(S\\), queremos associar a \\(A\\) um número entre zero e um que será chamado de probabilidade de \\(A\\), denotado por \\(P(A)\\). Pareceria natural definir o domínio de \\(P\\) (o conjunto onde os argumentos da função \\(P(\\cdot)\\) são definidos) como todos os subconjuntos de \\(S\\); isto é, para cada \\(A \\subset S\\) definimos \\(P(A)\\) como a probabilidade de que \\(A\\) ocorra. Infelizmente, as coisas não são tão simples. Existem algumas dificuldades técnicas a serem superadas. Não nos deteremos nessas tecnicalidades; embora sejam importantes, geralmente são de maior interesse para probabilistas do que para estatísticos. No entanto, uma compreensão firme de estatística requer pelo menos uma familiaridade passageira com o seguinte.\n\n\nDefinição 1.2.1 - Sigma-álgebra\nUma coleção de subconjuntos de \\(S\\) é chamada de sigma-álgebra (ou corpo de Borel), denotada por \\(\\mathcal{B}\\), se satisfaz as três propriedades a seguir: a. \\(\\emptyset \\in \\mathcal{B}\\) (o conjunto vazio é um elemento de \\(\\mathcal{B}\\)). b. Se \\(A \\in \\mathcal{B}\\), então \\(A^c \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) é fechada sob complementação). c. Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\), então \\(\\cup_{i=1}^{\\infty} A_i \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) é fechada sob uniões enumeráveis).\n\nO conjunto vazio \\(\\emptyset\\) é um subconjunto de qualquer conjunto. Assim, \\(\\emptyset \\subset S\\). A propriedade (a) afirma que este subconjunto está sempre em uma sigma-álgebra. Uma vez que \\(S = \\emptyset^c\\), as propriedades (a) e (b) implicam que \\(S\\) está sempre em \\(\\mathcal{B}\\) também. Além disso, das Leis de DeMorgan, segue-se que \\(\\mathcal{B}\\) é fechada sob interseções enumeráveis. Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\), então \\(A_1^c, A_2^c, \\dots \\in \\mathcal{B}\\) pela propriedade (b), e portanto \\(\\cup_{i=1}^{\\infty} A_i^c \\in \\mathcal{B}\\). No entanto, usando a Lei de DeMorgan (como no Exercício 1.9), temos\n\\[\n\\left( \\bigcup_{i=1}^{\\infty} A_i^c \\right)^c = \\bigcap_{i=1}^{\\infty} A_i.\n\\]\nAssim, novamente pela propriedade (b), \\(\\cap_{i=1}^{\\infty} A_i \\in \\mathcal{B}\\). Associadas ao espaço amostral \\(S\\), podemos ter muitas sigma-álgebras diferentes. Por exemplo, a coleção dos dois conjuntos \\(\\{\\emptyset, S\\}\\) é uma sigma-álgebra, geralmente chamada de sigma-álgebra trivial. A única sigma-álgebra com a qual nos preocuparemos é a menor que contém todos os conjuntos abertos em um dado espaço amostral \\(S\\).\n\nExemplo 1.2.2 (Sigma-álgebra—I)\nSe \\(S\\) é finito ou enumerável, essas tecnicalidades realmente não surgem, pois definimos para um dado espaço amostral \\(S\\),\n\\[\n\\mathcal{B} = \\{\\text{todos os subconjuntos de } S, \\text{ incluindo } S \\text{ ele mesmo}\\}.\n\\]\nSe \\(S\\) tem \\(n\\) elementos, existem \\(2^n\\) conjuntos em \\(\\mathcal{B}\\) (veja Exercício 1.14). Por exemplo, se \\(S = \\{1, 2, 3\\}\\), então \\(\\mathcal{B}\\) é a seguinte coleção de \\(2^3 = 8\\) conjuntos:\n\\[\n\\begin{matrix}\n\\{1\\} & \\{1, 2\\} & \\{1, 2, 3\\} \\\\\n\\{2\\} & \\{1, 3\\} & \\emptyset \\\\\n\\{3\\} & \\{2, 3\\} &\n\\end{matrix}\n\\]\n\nEm geral, se \\(S\\) é não enumerável, não é uma tarefa fácil descrever \\(\\mathcal{B}\\). No entanto, \\(\\mathcal{B}\\) é escolhida para conter qualquer conjunto de interesse.\n\nExemplo 1.2.3 (Sigma-álgebra—II)\nSeja \\(S = (-\\infty, \\infty)\\), a reta real. Então \\(\\mathcal{B}\\) é escolhida para conter todos os conjuntos da forma\n\\[\n[a, b], \\quad (a, b], \\quad (a, b), \\quad \\text{e} \\quad [a, b)\n\\]\npara todos os números reais \\(a\\) e \\(b\\). Além disso, pelas propriedades de \\(\\mathcal{B}\\), segue-se que \\(\\mathcal{B}\\) contém todos os conjuntos que podem ser formados tomando uniões (possivelmente infinitas enumeráveis) e interseções de conjuntos das variedades acima.\n\nEstamos agora em posição de definir uma função de probabilidade.\n\nDefinição 1.2.4 - Função de Probabilidade\nDado um espaço amostral \\(S\\) e uma sigma-álgebra associada \\(\\mathcal{B}\\), uma função de probabilidade é uma função \\(P\\) com domínio \\(\\mathcal{B}\\) que satisfaz 1. \\(P(A) \\ge 0\\) para todo \\(A \\in \\mathcal{B}\\). 2. \\(P(S) = 1\\). 3. Se \\(A_1, A_2, \\dots \\in \\mathcal{B}\\) são disjuntos dois a dois, então \\(P(\\cup_{i=1}^{\\infty} A_i) = \\sum_{i=1}^{\\infty} P(A_i)\\).\n\nAs três propriedades dadas na Definição 1.2.4 são geralmente referidas como os Axiomas da Probabilidade (ou os Axiomas de Kolmogorov, em homenagem a A. Kolmogorov, um dos pais da teoria da probabilidade). Qualquer função \\(P\\) que satisfaça os Axiomas de Probabilidade é chamada de função de probabilidade. A definição axiomática não tenta dizer qual função particular \\(P\\) escolher; ela apenas requer que \\(P\\) satisfaça os axiomas. Para qualquer espaço amostral, muitas funções de probabilidade diferentes podem ser definidas. Qual delas reflete o que é provável de ser observado em um experimento particular ainda precisa ser discutido.\n\nExemplo 1.2.5 (Definindo probabilidades—I)\nConsidere o experimento simples de lançar uma moeda justa, então \\(S = \\{H, T\\}\\). Por uma moeda “justa”, queremos dizer uma moeda balanceada que tem igual probabilidade de cair com a face para cima ou para baixo, e, portanto, a função de probabilidade razoável é aquela que atribui probabilidades iguais a cara e coroa, isto é,\n\\[\nP(\\{H\\}) = P(\\{T\\}).\n\\]\nNote que (1.2.2) não decorre dos Axiomas de Probabilidade, mas é de fora dos axiomas. Usamos uma interpretação de simetria da probabilidade (ou apenas intuição) para impor o requisito de que cara e coroa sejam igualmente prováveis. Como \\(S = \\{H\\} \\cup \\{T\\}\\), temos, pelo Axioma 1, \\(P(\\{H\\} \\cup \\{T\\}) = 1\\). Além disso, \\(\\{H\\}\\) e \\(\\{T\\}\\) são disjuntos, então \\(P(\\{H\\} \\cup \\{T\\}) = P(\\{H\\}) + P(\\{T\\})\\) e\n\\[\nP(\\{H\\}) + P(\\{T\\}) = 1.\n\\]\nResolvendo simultaneamente (1.2.2) e (1.2.3), temos \\(P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}\\). Como (1.2.2) é baseado em nosso conhecimento do experimento particular, e não nos axiomas, quaisquer valores não negativos para \\(P(\\{H\\})\\) e \\(P(\\{T\\})\\) que satisfaçam (1.2.3) definem uma função de probabilidade legítima. Por exemplo, poderíamos escolher \\(P(\\{H\\}) = \\frac{1}{9}\\) e \\(P(\\{T\\}) = \\frac{8}{9}\\).\n\nPrecisamos de métodos gerais para definir funções de probabilidade que saibamos que sempre satisfarão os Axiomas de Kolmogorov. Não queremos ter que verificar os Axiomas para cada nova função de probabilidade, como fizemos no Exemplo 1.2.5. O seguinte fornece um método comum de definir uma função de probabilidade legítima.\n\nTeorema 1.2.6\nSeja \\(S = \\{s_1, \\dots, s_n\\}\\) um conjunto finito. Seja \\(\\mathcal{B}\\) qualquer sigma-álgebra de subconjuntos de \\(S\\). Sejam \\(p_1, \\dots, p_n\\) números não negativos que somam 1. Para qualquer \\(A \\in \\mathcal{B}\\), defina \\(P(A)\\) por\n\\[\nP(A) = \\sum_{\\{i : s_i \\in A\\}} p_i.\n\\]\n(A soma sobre um conjunto vazio é definida como 0.) Então \\(P\\) é uma função de probabilidade em \\(\\mathcal{B}\\). Isso permanece verdadeiro se \\(S = \\{s_1, s_2, \\dots\\}\\) é um conjunto enumerável.\n\n\nComprovação. Daremos a prova para \\(S\\) finito. Para qualquer \\(A \\in \\mathcal{B}, P(A) = \\sum_{\\{i : s_i \\in A\\}} p_i \\ge 0\\), porque todo \\(p_i \\ge 0\\). Assim, o Axioma 1 é verdadeiro. Agora,\n\\[\nP(S) = \\sum_{\\{i : s_i \\in S\\}} p_i = \\sum_{i=1}^n p_i = 1.\n\\]\nAssim, o Axioma 2 é verdadeiro. Sejam \\(A_1, \\dots, A_k\\) eventos disjuntos dois a dois. (\\(\\mathcal{B}\\) contém apenas um número finito de conjuntos, então precisamos considerar apenas uniões disjuntas finitas.) Então,\n\\[\nP\\left( \\bigcup_{i=1}^k A_i \\right) = \\sum_{\\{j : s_j \\in \\cup_{i=1}^k A_i\\}} p_j = \\sum_{i=1}^k \\sum_{\\{j : s_j \\in A_i\\}} p_j = \\sum_{i=1}^k P(A_i).\n\\]\nA primeira e a terceira igualdades são verdadeiras pela definição de \\(P(A)\\). A disjunção dos \\(A_i\\)s garante que a segunda igualdade é verdadeira, porque os mesmos \\(p_j\\)s aparecem exatamente uma vez em cada lado da igualdade. Assim, o Axioma 3 é verdadeiro e os Axiomas de Kolmogorov são satisfeitos. \\(\\square\\)\n\nA realidade física do experimento pode ditar a atribuição de probabilidade, como o próximo exemplo ilustra.\n\nExemplo 1.2.7 (Definindo probabilidades—II)\nO jogo de dardos é jogado lançando um dardo em um alvo e recebendo uma pontuação correspondente ao número atribuído à região em que o dardo cai. Para um jogador novato, parece razoável assumir que a probabilidade de o dardo atingir uma região específica é proporcional à área da região. Assim, uma região maior tem uma probabilidade maior de ser atingida. Referindo-se à Figura 1.2.1, vemos que o alvo de dardos tem raio \\(r\\) e a distância entre os anéis é \\(r/5\\). Se fizermos a suposição de que o alvo é sempre atingido (veja o Exercício 1.7 para uma variação sobre isso), então temos\n\\[\nP(\\text{marcar } i \\text{ pontos}) = \\frac{\\text{Área da região } i}{\\text{Área do alvo de dardos}}.\n\\]\n\n\n\nFigura 1.2.1 - Alvo de dardos para o Exemplo 1.2.7\n\n\nPor exemplo,\n\\[\nP(\\text{marcar } 1 \\text{ ponto}) = \\frac{\\pi r^2 - \\pi(4r/5)^2}{\\pi r^2} = 1 - \\left( \\frac{4}{5} \\right)^2.\n\\]\nÉ fácil derivar a fórmula geral, e descobrimos que\n\\[\nP(\\text{marcar } i \\text{ pontos}) = \\frac{(6-i)^2 - (5-i)^2}{5^2}, \\quad i = 1, \\dots, 5,\n\\]\nindependente de \\(\\pi\\) e \\(r\\). A soma das áreas das regiões disjuntas é igual à área do alvo de dardos. Assim, as probabilidades que foram atribuídas aos cinco resultados somam 1, e, pelo Teorema 1.2.6, esta é uma função de probabilidade (veja Exercício 1.8).\n\nAntes de deixarmos o desenvolvimento axiomático da probabilidade, há mais um ponto a considerar. O Axioma 3 da Definição 1.2.4, que é comumente conhecido como o Axioma da Aditividade Enumerável, não é universalmente aceito entre os estatísticos. De fato, pode-se argumentar que os axiomas devem ser simples, autoevidentes. Comparando o Axioma 3 com os outros axiomas, que são simples e autoevidentes, isso pode nos levar a duvidar se é razoável assumir a verdade do Axioma 3.\nO Axioma da Aditividade Enumerável é rejeitado por uma escola de estatísticos liderada por deFinetti (1972), que opta por substituir este axioma pelo Axioma da Aditividade Finita.\nAxioma da Aditividade Finita: Se \\(A \\in \\mathcal{B}\\) e \\(B \\in \\mathcal{B}\\) são disjuntos, então\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nEmbora este axioma possa não ser inteiramente autoevidente, é certamente mais simples do que o Axioma da Aditividade Enumerável (e é implicado por ele – veja Exercício 1.12).\nAssumir apenas a aditividade finita, embora talvez mais plausível, pode levar a complicações inesperadas na teoria estatística – complicações que, a este nível, não necessariamente aumentam a compreensão do assunto. Portanto, prosseguimos sob a suposição de que o Axioma da Aditividade Enumerável é válido.\n\n1.2.2 O Cálculo de Probabilidades\nA partir dos Axiomas da Probabilidade, podemos construir muitas propriedades da função de probabilidade, propriedades que são bastante úteis no cálculo de probabilidades mais complicadas. Algumas dessas manipulações serão discutidas em detalhes nesta seção; outras serão deixadas como exercícios.\nComeçamos com algumas propriedades (bastante autoevidentes) da função de probabilidade quando aplicadas a um único evento.\n\n\nTeorema 1.2.8\nSe P é uma função de probabilidade e A é qualquer conjunto em \\(\\mathcal{B}\\), então\n\na. \\(P(\\emptyset) = 0\\), onde \\(\\emptyset\\) é o conjunto vazio;\nb. \\(P(A) \\le 1\\);\nc. \\(P(A^c) = 1 - P(A)\\).\n\n\n\nComprovação. É mais fácil provar (c) primeiro. Os conjuntos \\(A\\) e \\(A^c\\) formam uma partição do espaço amostral, isto é, \\(S = A \\cup A^c\\). Portanto,\n\\[\nP(A \\cup A^c) = P(S) = 1\n\\]\npelo segundo axioma. Além disso, \\(A\\) e \\(A^c\\) são disjuntos, então pelo terceiro axioma,\n\\[\nP(A \\cup A^c) = P(A) + P(A^c).\n\\]\nCombinando (1.2.4) e (1.2.5) obtemos (c). Como \\(P(A^c) \\ge 0\\), (b) é imediatamente implicado por (c). Para provar (a), usamos um argumento semelhante em \\(S = S \\cup \\emptyset\\). (Lembre-se que tanto \\(S\\) quanto \\(\\emptyset\\) estão sempre em \\(\\mathcal{B}\\).) Como \\(S\\) e \\(\\emptyset\\) são disjuntos, temos\n\\[\n1 = P(S) = P(S \\cup \\emptyset) = P(S) + P(\\emptyset),\n\\]\ne assim \\(P(\\emptyset) = 0\\). \\(\\square\\)\n\nO Teorema 1.2.8 contém propriedades que são tão básicas que também têm o sabor de axiomas, embora tenhamos provado formalmente usando apenas os Axiomas de Kolmogorov originais. O próximo teorema, que é semelhante em espírito ao Teorema 1.2.8, contém afirmações que não são tão autoevidentes.\n\nTeorema 1.2.9\nSe P é uma função de probabilidade e A e B são quaisquer conjuntos em \\(\\mathcal{B}\\), então\n\na. \\(P(B \\cap A^c) = P(B) - P(A \\cap B)\\);\nb. \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\);\nc. Se \\(A \\subset B\\), então \\(P(A) \\le P(B)\\).\n\n\n\nComprovação. Para estabelecer (a), note que para quaisquer conjuntos \\(A\\) e \\(B\\) temos\n\\[\nB = \\{B \\cap A\\} \\cup \\{B \\cap A^c\\},\n\\]\ne portanto\n\\[\nP(B) = P(\\{B \\cap A\\} \\cup \\{B \\cap A^c\\}) = P(B \\cap A) + P(B \\cap A^c),\n\\]\nonde a última igualdade em (1.2.6) decorre do fato de que \\(B \\cap A\\) e \\(B \\cap A^c\\) são disjuntos. Reorganizando (1.2.6) obtemos (a). Para estabelecer (b), usamos a identidade\n\\[\nA \\cup B = A \\cup \\{B \\cap A^c\\}.\n\\]\nUm diagrama de Venn mostrará por que (1.2.7) é válida, embora uma prova formal não seja difícil (veja Exercício 1.2). Usando (1.2.7) e o fato de que \\(A\\) e \\(B \\cap A^c\\) são disjuntos (visto que \\(A\\) e \\(A^c\\) o são), temos\n\\[\nP(A \\cup B) = P(A) + P(B \\cap A^c) = P(A) + P(B) - P(A \\cap B)\n\\]\na partir de (a). Se \\(A \\subset B\\), então \\(A \\cap B = A\\). Portanto, usando (a), temos\n\\[\n0 \\le P(B \\cap A^c) = P(B) - P(A),\n\\]\nestabelecendo (c). \\(\\square\\)\n\nA fórmula (b) do Teorema 1.2.9 fornece uma desigualdade útil para a probabilidade de uma interseção. Como \\(P(A \\cup B) \\le 1\\), temos de (1.2.8), após algum rearranjo,\n\\[\nP(A \\cap B) \\ge P(A) + P(B) - 1.\n\\]\nEsta desigualdade é um caso especial do que é conhecido como Desigualdade de Bonferroni (Miller 1981 é uma boa referência). A Desigualdade de Bonferroni nos permite limitar a probabilidade de um evento simultâneo (a interseção) em termos das probabilidades dos eventos individuais.\n\nExemplo 1.2.10 (Desigualdade de Bonferroni)\nA Desigualdade de Bonferroni é particularmente útil quando é difícil (ou até impossível) calcular a probabilidade da interseção, mas se deseja alguma ideia do tamanho dessa probabilidade. Suponha que \\(A\\) e \\(B\\) sejam dois eventos e cada um tenha probabilidade 0,95. Então a probabilidade de que ambos ocorram é limitada inferiormente por\n\\[\nP(A \\cap B) \\ge P(A) + P(B) - 1 = 0,95 + 0,95 - 1 = 0,90.\n\\]\nNote que, a menos que as probabilidades dos eventos individuais sejam suficientemente grandes, o limite de Bonferroni é um número negativo inútil (embora correto!).\n\nEncerramos esta seção com um teorema que fornece alguns resultados úteis para lidar com uma coleção de conjuntos.\n\nTeorema 1.2.11\nSe P é uma função de probabilidade, então\n\na. \\(P(A) = \\sum_{i=1}^{\\infty} P(A \\cap C_i)\\) para qualquer partição \\(C_1, C_2, \\dots\\);\nb. \\(P(\\cup_{i=1}^{\\infty} A_i) \\le \\sum_{i=1}^{\\infty} P(A_i)\\) para quaisquer conjuntos \\(A_1, A_2, \\dots\\). (Desigualdade de Boole)\n\n\n\nComprovação. Visto que \\(C_1, C_2, \\dots\\) formam uma partição, temos que \\(C_i \\cap C_j = \\emptyset\\) para todo \\(i \\ne j\\), e \\(S = \\cup_{i=1}^{\\infty} C_i\\). Portanto,\n\\[\nA = A \\cap S = A \\cap \\left( \\bigcup_{i=1}^{\\infty} C_i \\right) = \\bigcup_{i=1}^{\\infty} (A \\cap C_i),\n\\]\nonde a última igualdade segue da Lei Distributiva (Teorema 1.1.4). Nós, portanto, temos\n\\[\nP(A) = P\\left( \\bigcup_{i=1}^{\\infty} (A \\cap C_i) \\right).\n\\]\nAgora, como os \\(C_i\\) são disjuntos, os conjuntos \\(A \\cap C_i\\) também são disjuntos, e das propriedades de uma função de probabilidade temos\n\\[\nP\\left( \\bigcup_{i=1}^{\\infty} (A \\cap C_i) \\right) = \\sum_{i=1}^{\\infty} P(A \\cap C_i),\n\\]\nestabelecendo (a). Para estabelecer (b), primeiro construímos uma coleção disjunta \\(A_1^*, A_2^*, \\dots\\), com a propriedade de que \\(\\cup_{i=1}^{\\infty} A_i^* = \\cup_{i=1}^{\\infty} A_i\\). Definimos \\(A_i^*\\) por\n\\[\nA_1^* = A_1, \\quad A_i^* = A_i \\setminus \\left( \\bigcup_{j=1}^{i-1} A_j \\right), \\quad i = 2, 3, \\dots,\n\\]\nonde a notação \\(A \\setminus B\\) denota a parte de \\(A\\) que não intersecta com \\(B\\). Em símbolos mais familiares, \\(A \\setminus B = A \\cap B^c\\). Deve ser fácil ver que \\(\\cup_{i=1}^{\\infty} A_i^* = \\cup_{i=1}^{\\infty} A_i\\), e portanto temos\n\\[\nP\\left( \\bigcup_{i=1}^{\\infty} A_i \\right) = P\\left( \\bigcup_{i=1}^{\\infty} A_i^* \\right) = \\sum_{i=1}^{\\infty} P(A_i^*),\n\\]\nonde a última igualdade segue uma vez que os \\(A_i^*\\) são disjuntos. Para ver isso, escrevemos\n\\[\n\\begin{align*}\nA_i^* \\cap A_k^* &= \\left\\{ A_i \\cap \\left( \\bigcup_{j=1}^{i-1} A_j \\right)^c \\right\\} \\cap \\left\\{ A_k \\cap \\left( \\bigcup_{j=1}^{k-1} A_j \\right)^c \\right\\} \\quad (\\text{definição de } A_i^*) \\\\\n&= \\left\\{ A_i \\cap \\left( \\bigcap_{j=1}^{i-1} A_j^c \\right) \\right\\} \\cap \\left\\{ A_k \\cap \\left( \\bigcap_{j=1}^{k-1} A_j^c \\right) \\right\\} \\quad (\\text{Leis de DeMorgan})\n\\end{align*}\n\\]\nAgora, se \\(i &gt; k\\), a primeira interseção acima estará contida no conjunto \\(A_k^c\\), que terá uma interseção vazia com \\(A_k\\). Se \\(k &gt; i\\), o argumento é semelhante. Além disso, por construção \\(A_i^* \\subset A_i\\), então \\(P(A_i^*) \\le P(A_i)\\) e temos\n\\[\n\\sum_{i=1}^{\\infty} P(A_i^*) \\le \\sum_{i=1}^{\\infty} P(A_i),\n\\]\nestabelecendo (b). \\(\\square\\)\n\nExiste uma similaridade entre a Desigualdade de Boole e a Desigualdade de Bonferroni. De fato, elas são essencialmente a mesma coisa. Se aplicarmos a Desigualdade de Boole a \\(A^c\\), temos\n\\[\nP\\left( \\bigcup_{i=1}^n A_i^c \\right) \\le \\sum_{i=1}^n P(A_i^c),\n\\]\ne usando os fatos de que \\(\\cup A_i^c = (\\cap A_i)^c\\) e \\(P(A_i^c) = 1 - P(A_i)\\), obtemos\n\\[\n1 - P\\left( \\bigcap_{i=1}^n A_i \\right) \\le n - \\sum_{i=1}^n P(A_i).\n\\]\nIsso se torna, ao reorganizar os termos,\n\\[\nP\\left( \\bigcap_{i=1}^n A_i \\right) \\ge \\sum_{i=1}^n P(A_i) - (n-1),\n\\]\nque é uma versão mais geral da Desigualdade de Bonferroni de (1.2.9).\n\n1.2.3 Contagem\nO processo elementar de contagem pode se tornar bastante sofisticado quando colocado nas mãos de um estatístico. Na maioria das vezes, métodos de contagem são usados para construir atribuições de probabilidade em espaços amostrais finitos, embora possam ser usados para responder a outras perguntas também.\n\n\nExemplo 1.2.12 (Loteria-I)\nPor vários anos, a loteria do estado de Nova York operou de acordo com o seguinte esquema. A partir dos números \\(1, 2, \\dots, 44\\), uma pessoa pode escolher quaisquer seis para seu bilhete. O número vencedor é então decidido selecionando aleatoriamente seis números dentre os quarenta e quatro. Para calcular a probabilidade de ganhar, devemos primeiro contar quantos grupos diferentes de seis números podem ser escolhidos a partir dos quarenta e quatro.\n\n\nExemplo 1.2.13 (Torneio)\nEm um torneio de eliminação simples, como o torneio de tênis U.S. Open, os jogadores avançam apenas se vencerem (ao contrário de torneios de eliminação dupla ou todos contra todos). Se tivermos 16 participantes, podemos estar interessados no número de caminhos que um jogador em particular pode tomar para a vitória, onde um caminho é considerado uma sequência de oponentes.\n\nProblemas de contagem, em geral, parecem complicados, e muitas vezes devemos fazer nossa contagem sujeita a muitas restrições. A maneira de resolver tais problemas é dividi-los em uma série de tarefas simples que são fáceis de contar, e empregar regras conhecidas de combinação de tarefas. O teorema a seguir é um primeiro passo em tal processo e às vezes é conhecido como o Teorema Fundamental da Contagem.\n\nTeorema 1.2.14\nSe um trabalho consiste em \\(k\\) tarefas separadas, a i-ésima das quais pode ser feita de \\(n_i\\) maneiras, \\(i = 1, \\dots, k\\), então o trabalho inteiro pode ser feito de \\(n_1 \\times n_2 \\times \\dots \\times n_k\\) maneiras.\n\n\nComprovação. Basta provar o teorema para \\(k=2\\) (veja Exercício 1.15). A prova é apenas uma questão de contagem cuidadosa. A primeira tarefa pode ser feita de \\(n_1\\) maneiras, e para cada uma dessas maneiras temos \\(n_2\\) escolhas para a segunda tarefa. Assim, podemos fazer o trabalho em\n\\[\n\\underbrace{(1 \\times n_2) + (1 \\times n_2) + \\dots + (1 \\times n_2)}_{n_1 \\text{ termos}} = n_1 \\times n_2\n\\]\nmaneiras, estabelecendo o teorema para \\(k=2\\). \\(\\square\\)\n\n\nExemplo 1.2.15 (Loteria—II)\nEmbora o Teorema Fundamental da Contagem seja um lugar razoável para começar, em aplicações geralmente há mais aspectos de um problema a considerar. Por exemplo, na loteria do estado de Nova York, o primeiro número pode ser escolhido de 44 maneiras e o segundo número de 43 maneiras, totalizando \\(44 \\times 43 = 1.892\\) maneiras de escolher os dois primeiros números. No entanto, se uma pessoa tem permissão para escolher o mesmo número duas vezes, então os dois primeiros números podem ser escolhidos de \\(44 \\times 44 = 1.936\\) maneiras.\n\nA distinção feita no Exemplo 1.2.15 é entre contar com reposição e contar sem reposição. Há um segundo elemento crucial em qualquer problema de contagem: se a ordem das tarefas é importante. Para ilustrar com o exemplo da loteria, suponha que os números vencedores sejam selecionados na ordem 12, 37, 35, 9, 13, 22. Uma pessoa que selecionou 9, 12, 13, 22, 35, 37 se qualifica como vencedora? Em outras palavras, a ordem na qual a tarefa é realizada realmente importa? Levando todas essas considerações em conta, podemos construir uma tabela \\(2 \\times 2\\) de possibilidades:\n\nPossivel Método de Contar\n\n\n\nSem reposição\nCom reposição\n\n\n\n\nOrdenado\n\n\n\n\nNão ordenado\n\n\n\n\n\nAntes de começarmos a contar, a seguinte definição nos dá uma notação extremamente útil.\n\nDefinição 1.2.16\nPara um inteiro positivo \\(n\\), \\(n!\\) (lê-se \\(n\\) fatorial) é o produto de todos os inteiros positivos menores ou iguais a \\(n\\). Isto é, \\[\nn! = n \\times (n-1) \\times (n-2) \\times \\dots \\times 3 \\times 2 \\times 1.\n\\] Além disso, definimos \\(0! = 1\\).\n\nVamos agora considerar todos os possíveis bilhetes de loteria sob cada um desses quatro casos.\n\nOrdenado, sem reposição: Pelo Teorema Fundamental da Contagem, o primeiro número pode ser selecionado de 44 maneiras, o segundo de 43 maneiras, etc. Portanto, existem \\[\n44 \\times 43 \\times 42 \\times 41 \\times 40 \\times 39 = \\frac{44!}{38!} = 5.082.517.440\n\\] bilhetes possíveis.\nOrdenado, com reposição: Como cada número pode agora ser selecionado de 44 maneiras (porque o número escolhido é reposto), existem \\[\n44 \\times 44 \\times 44 \\times 44 \\times 44 \\times 44 = 44^6 = 7.256.313.856\n\\] bilhetes possíveis.\nNão ordenado, sem reposição: Sabemos o número de bilhetes possíveis quando a ordem deve ser considerada, então o que devemos fazer é dividir as ordenações redundantes. Novamente pelo Teorema Fundamental, seis números podem ser organizados de \\(6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1\\) maneiras, então o número total de bilhetes não ordenados é\n\n\\[\n\\frac{44 \\times 43 \\times 42 \\times 41 \\times 40 \\times 39}{6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1} = \\frac{44!}{6! 38!} = 7.059.052.\n\\] Esta forma de contar desempenha um papel central em grande parte da estatística — tanto, de fato, que ganhou sua própria notação.\n\nDefinição 1.2.17\nPara inteiros não negativos \\(n\\) e \\(r\\), onde \\(n \\ge r\\), definimos o símbolo \\(\\binom{n}{r}\\), lido \\(n\\) escolhe \\(r\\), como \\[\n\\binom{n}{r} = \\frac{n!}{r!(n-r)!}.\n\\]\n\nEm nosso exemplo da loteria, o número de bilhetes possíveis (não ordenados, sem reposição) é \\(\\binom{44}{6}\\). Esses números também são referidos como coeficientes binomiais, por razões que ficarão claras no Capítulo 3.\n\nNão ordenado, com reposição: Este é o caso mais difícil de contar. Você pode primeiro supor que a resposta é \\(44^6 / (6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1)\\), mas isso não está correto (é muito pequeno). Para contar neste caso, é mais fácil pensar em colocar 6 marcadores nos 44 números. De fato, podemos pensar nos 44 números definindo compartimentos nos quais podemos colocar os seis marcadores, M, como mostrado nesta figura.\n\n\n\n\nFigura representando marcadores (M) em compartimentos numerados\n\n\nO número de bilhetes possíveis é então igual ao número de maneiras que podemos colocar os 6 marcadores nos 44 compartimentos. Mas isso pode ser ainda mais reduzido observando que tudo o que precisamos acompanhar é o arranjo dos marcadores e das paredes dos compartimentos. Note ainda que as duas paredes mais externas não desempenham nenhum papel. Assim, temos que contar todos os arranjos de 43 paredes (44 compartimentos geram 45 paredes, mas desconsideramos as duas paredes das extremidades) e 6 marcadores. Temos \\(43 + 6 = 49\\) objetos, que podem ser arranjados de \\(49!\\) maneiras. No entanto, para eliminar as ordenações redundantes, devemos dividir tanto por \\(6!\\) quanto por \\(43!\\), de modo que o número total de arranjos é\n\\[\n\\frac{49!}{6! 43!} = 13.983.816.\n\\]\nEmbora todas as derivações precedentes tenham sido feitas em termos de um exemplo, deve ser fácil ver que elas valem em geral. Por completude, podemos resumir essas situações na Tabela 1.2.1.\nTabela 1.2.1. Número de arranjos possíveis de tamanho \\(r\\) a partir de \\(n\\) objetos\n\n\n\n\nSem reposição\nCom reposição\n\n\n\n\nOrdenado\n\\(\\frac{n!}{(n-r)!}\\)\n\\(n^r\\)\n\n\nNão ordenado\n\\(\\binom{n}{r}\\)\n\\(\\binom{n+r-1}{r}\\)\n\n\n\n\n1.2.4 Enumerando Resultados\nAs técnicas de contagem da seção anterior são úteis quando o espaço amostral \\(S\\) é um conjunto finito e todos os resultados em \\(S\\) são igualmente prováveis. Então, probabilidades de eventos podem ser calculadas simplesmente contando o número de resultados no evento. Para ver isso, suponha que \\(S = \\{s_1, \\dots, s_N\\}\\) é um espaço amostral finito. Dizer que todos os resultados são igualmente prováveis significa que \\(P(\\{s_i\\}) = 1/N\\) para cada resultado \\(s_i\\). Então, usando o Axioma 3 da Definição 1.2.4, temos, para qualquer evento \\(A\\),\n\\[\nP(A) = \\sum_{s_i \\in A} P(\\{s_i\\}) = \\sum_{s_i \\in A} \\frac{1}{N} = \\frac{ \\text{ Número de elementos em } A}{ \\text{ Número de elementos em } S}.\n\\]\nPara grandes espaços amostrais, as técnicas de contagem podem ser usadas para calcular tanto o numerador quanto o denominador desta expressão.\n\n\nExemplo 1.2.18 (Pôquer)\nConsidere escolher uma mão de pôquer de cinco cartas de um baralho padrão de 52 cartas de baralho. Obviamente, estamos amostrando sem reposição do baralho. Mas para especificar os resultados possíveis (mãos possíveis), devemos decidir se pensamos na mão sendo dada sequencialmente (ordenada) ou toda de uma vez (não ordenada). Se desejamos calcular probabilidades para eventos que dependem da ordem, como a probabilidade de um ás nas duas primeiras cartas, então devemos usar os resultados ordenados. Mas se nossos eventos não dependem da ordem, podemos usar os resultados não ordenados. Para este exemplo, usaremos os resultados não ordenados, então o espaço amostral consiste em todas as mãos de cinco cartas que podem ser escolhidas do baralho de 52 cartas. Existem \\(\\binom{52}{5} = 2.598.960\\) mãos possíveis. Se o baralho for bem embaralhado e as cartas forem dadas aleatoriamente, é razoável atribuir probabilidade \\(1/2.598.960\\) a cada mão possível. Calculamos agora algumas probabilidades contando resultados em eventos. Qual é a probabilidade de ter quatro ases? Quantas mãos diferentes existem com quatro ases? Se especificarmos que quatro das cartas são ases, então há 48 maneiras diferentes de especificar a quinta carta. Assim,\n\\[\nP(\\text{quatro ases}) = \\frac{48}{2.598.960},\n\\]\nmenos de 1 chance em 50.000. Apenas uma contagem ligeiramente mais complicada, usando o Teorema 1.2.14, nos permite calcular a probabilidade de ter uma quadra (quatro cartas do mesmo valor). Existem 13 maneiras de especificar qual denominação haverá quatro. Depois de especificarmos esses quatro, existem 48 maneiras de especificar a quinta. Assim, o número total de mãos com uma quadra é \\((13)(48)\\) e\n\\[\nP(\\text{quadra}) = \\frac{(13)(48)}{2.598.960} = \\frac{624}{2.598.960}.\n\\]\nPara calcular a probabilidade de exatamente um par (não dois pares, não trinca, etc.) combinamos algumas das técnicas de contagem. O número de mãos com exatamente um par é\n\\[\n13 \\binom{4}{2} \\binom{12}{3} 4^3 = 1.098.240.\n\\]\nA expressão (1.2.11) vem do Teorema 1.2.14 porque:\n\n\\(13\\) é o número de maneiras de especificar a denominação para o par,\n\\(\\binom{4}{2}\\) é o número de maneiras de especificar as duas cartas daquela denominação,\n\\(\\binom{12}{3}\\) é o número de maneiras de especificar as outras três denominações,\n\\(4^3\\) é o número de maneiras de especificar as outras três cartas dessas denominações.\n\nAssim,\n\\[\nP(\\text{exatamente um par}) = \\frac{1.098.240}{2.598.960}.\n\\]\n\nAo amostrar sem reposição, como no Exemplo 1.2.18, se queremos calcular a probabilidade de um evento que não depende da ordem, podemos usar tanto o espaço amostral ordenado quanto o não ordenado. Cada resultado no espaço amostral não ordenado corresponde a \\(r!\\) resultados no espaço amostral ordenado. Assim, ao contar resultados no espaço amostral ordenado, usamos um fator de \\(r!\\) tanto no numerador quanto no denominador que cancelará para dar a mesma probabilidade como se contássemos no espaço amostral não ordenado. A situação é diferente se amostramos com reposição. Cada resultado no espaço amostral não ordenado corresponde a alguns resultados no espaço amostral ordenado, mas o número de resultados difere.\n\nExemplo 1.2.19 (Amostragem com reposição)\nConsidere amostrar \\(r=2\\) itens de \\(n=3\\) itens, com reposição. Os resultados nos espaços amostrais ordenados e não ordenados são estes:\n\n\n\n\n\n\n\n\n\n\n\n\nNão ordenado\n\\(\\{1,1\\}\\)\n\\(\\{2,2\\}\\)\n\\(\\{3,3\\}\\)\n\\(\\{1,2\\}\\)\n\\(\\{1,3\\}\\)\n\\(\\{2,3\\}\\)\n\n\nOrdenado\n\\((1,1)\\)\n\\((2,2)\\)\n\\((3,3)\\)\n\\((1,2), (2,1)\\)\n\\((1,3), (3,1)\\)\n\\((2,3), (3,2)\\)\n\n\nProbabilidade\n\\(1/9\\)\n\\(1/9\\)\n\\(1/9\\)\n\\(2/9\\)\n\\(2/9\\)\n\\(2/9\\)\n\n\n\nAs probabilidades vêm da consideração dos nove resultados no espaço amostral ordenado como sendo igualmente prováveis. Isto corresponde à interpretação comum de “amostragem com reposição”; a saber, um dos três itens é escolhido, cada um com probabilidade 1/3; o item é anotado e reposto; os itens são misturados e novamente um dos três itens é escolhido, cada um com probabilidade 1/3. Vê-se que os seis resultados no espaço amostral não ordenado não são igualmente prováveis sob este tipo de amostragem. A fórmula para o número de resultados no espaço amostral não ordenado é útil para enumerar os resultados, mas os resultados ordenados devem ser usados para calcular probabilidades corretamente.\n\nAlguns autores argumentam que é apropriado atribuir probabilidades iguais aos resultados não ordenados quando “distribuindo aleatoriamente \\(r\\) bolas indistinguíveis em \\(n\\) urnas distinguíveis”. Isto é, uma urna é escolhida aleatoriamente e uma bola colocada nela, e isso é repetido \\(r\\) vezes. A ordem em que as bolas são colocadas não é registrada, então, no final, um resultado como \\(\\{1,3\\}\\) significa uma bola na urna 1 e uma bola na urna 3. Mas aqui está o problema com essa interpretação. Suponha que duas pessoas observem este processo, e o Observador 1 registra a ordem em que as bolas são colocadas, mas o Observador 2 não. O Observador 1 atribuirá probabilidade \\(2/9\\) ao evento \\(\\{1,3\\}\\). O Observador 2, que está observando exatamente o mesmo processo, também deve atribuir probabilidade \\(2/9\\) a este evento. Mas se os seis resultados não ordenados são escritos em pedaços de papel idênticos e um é escolhido aleatoriamente para determinar a colocação das bolas, então os resultados não ordenados têm, cada um, probabilidade \\(1/6\\). Então o Observador 2 atribuirá probabilidade \\(1/6\\) ao evento \\(\\{1,3\\}\\). A confusão surge porque a frase “com reposição” tipicamente será interpretada com o tipo sequencial de amostragem que descrevemos acima, levando a atribuir uma probabilidade \\(2/9\\) ao evento \\(\\{1,3\\}\\). Esta é a maneira correta de proceder, pois as probabilidades devem ser determinadas pelo mecanismo de amostragem, não se as bolas são distinguíveis ou indistinguíveis.\n\nExemplo 1.2.20 (Calculando uma média)\nComo uma ilustração da abordagem distinguível/indistinguível, suponha que vamos calcular todas as médias possíveis de quatro números selecionados de\n\\[\n2, 4, 9, 12\n\\]\nonde sorteamos os números com reposição. Por exemplo, possíveis sorteios são \\(\\{2, 4, 4, 9\\}\\) com média 4,75 e \\(\\{4, 4, 9, 9\\}\\) com média 6,5. Se estamos interessados apenas na média dos números amostrados, a ordenação não é importante e, assim, o número total de amostras distintas é obtido contando de acordo com amostragem não ordenada, com reposição. O número total de amostras distintas é \\(\\binom{4+4-1}{4}\\). Mas agora, para calcular a distribuição de probabilidade das médias amostrais, devemos contar as diferentes maneiras que uma média particular pode ocorrer. O valor 4,75 pode ocorrer apenas se a amostra contiver um 2, dois 4s e um 9. O número de amostras possíveis que têm esta configuração é dado na seguinte tabela:\n\n\n\nFigura 1.2.2 - Histograma das médias de amostras com reposição dos quatro números {2, 4, 4, 9}\n\n\n\n\n\n\n\n\n\nNão ordenado\nOrdenado\n\n\n\n\n\\(\\{2, 4, 4, 9\\}\\)\n\\((2, 4, 4, 9), (2, 4, 9, 4), (2, 9, 4, 4), (4, 2, 4, 9),\\)  \\((4, 2, 9, 4), (4, 4, 2, 9), (4, 4, 9, 2), (4, 9, 2, 4),\\)  \\((4, 9, 4, 2), (9, 2, 4, 4), (9, 4, 2, 4), (9, 4, 4, 2)\\)\n\n\n\nO número total de amostras ordenadas é \\(n^n = 4^4 = 256\\), então a probabilidade de sortear a amostra não ordenada \\(\\{2, 4, 4, 9\\}\\) é 12/256. Compare isso com a probabilidade que teríamos obtido se considerássemos as amostras não ordenadas como igualmente prováveis — teríamos atribuído probabilidade \\(1/\\binom{n+n-1}{n} = 1/\\binom{7}{4} = 1/35\\) a \\(\\{2, 4, 4, 9\\}\\) e a qualquer outra amostra não ordenada. Para contar o número de amostras ordenadas que resultariam em \\(\\{2, 4, 4, 9\\}\\), argumentamos da seguinte forma. Precisamos enumerar as ordens possíveis dos quatro números \\(\\{2, 4, 4, 9\\}\\), então estamos essencialmente usando o método de contagem 1 da Seção 1.2.3. Podemos ordenar a amostra de \\(4 \\times 3 \\times 2 \\times 1 = 24\\) maneiras. Mas há um pouco de contagem dupla aqui, já que não podemos distinguir os dois 4s. Por exemplo, as 24 maneiras contariam \\(\\{9, 4, 2, 4\\}\\) duas vezes (o que estaria OK se os 4s fossem diferentes). Para corrigir isso, dividimos por \\(2!\\) (existem \\(2!\\) maneiras de organizar os dois 4s) e obtemos \\(24/2 = 12\\) amostras ordenadas. Em geral, se existem \\(k\\) lugares e temos \\(m\\) números diferentes repetidos \\(k_1, k_2, \\dots, k_m\\) vezes, então o número de amostras ordenadas é \\[\n\\frac{k!}{k_1! k_2! \\dots k_m!}.\n\\] Este tipo de contagem está relacionado à distribuição multinomial, que veremos na Seção 4.6. A Figura 1.2.2 é um histograma da distribuição de probabilidade das médias amostrais, refletindo a contagem multinomial das amostras. Há também mais um refinamento que é refletido na Figura 1.2.2. É possível que duas amostras não ordenadas diferentes resultem na mesma média. Por exemplo, as amostras não ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\) ambas resultam em uma média de 8. A primeira amostra tem probabilidade 6/256 e a segunda tem probabilidade 12/256, dando ao valor 8 uma probabilidade de \\(18/256 = .07\\). Veja o Exemplo A.0.1 no Apêndice A para detalhes sobre a construção de tal histograma. O cálculo que fizemos neste exemplo é uma versão elementar de uma técnica estatística muito importante conhecida como bootstrap (Efron e Tibshirani 1993). Voltaremos ao bootstrap na Seção 10.1.4.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#probabilidade-condicional-e-independência",
    "href": "cap-1.html#probabilidade-condicional-e-independência",
    "title": "Teoria da Probabilidade",
    "section": "1.3 Probabilidade Condicional e Independência",
    "text": "1.3 Probabilidade Condicional e Independência\nTodas as probabilidades com as quais lidamos até agora foram probabilidades incondicionais. Um espaço amostral foi definido e todas as probabilidades foram calculadas com respeito a esse espaço amostral. Em muitos casos, no entanto, estamos em uma posição de atualizar o espaço amostral com base em novas informações. Nesses casos, queremos ser capazes de atualizar os cálculos de probabilidade para calcular probabilidades condicionais.\n\nExemplo 1.3.1 (Quatro ases)\nQuatro cartas são distribuídas do topo de um baralho bem embaralhado. Qual é a probabilidade de que sejam os quatro ases? Podemos calcular essa probabilidade pelos métodos da seção anterior. O número de grupos distintos de quatro cartas é \\[\n\\binom{52}{4} = 270.725.\n\\] Apenas um desses grupos consiste nos quatro ases e cada grupo é igualmente provável, então a probabilidade de serem distribuídos os quatro ases é \\(1/270.725\\). Também podemos calcular essa probabilidade por um argumento de “atualização”, como segue. A probabilidade de que a primeira carta seja um ás é \\(4/52\\). Dado que a primeira carta é um ás, a probabilidade de que a segunda carta seja um ás é \\(3/51\\) (há 3 ases e 51 cartas restantes). Continuando com esse argumento, obtemos a probabilidade desejada como \\[\n\\frac{4}{52} \\times \\frac{3}{51} \\times \\frac{2}{50} \\times \\frac{1}{49} = \\frac{1}{270.725}.\n\\]\n\nEm nosso segundo método de resolver o problema, atualizamos o espaço amostral após cada distribuição de uma carta; calculamos probabilidades condicionais.\n\nDefinição 1.3.2\nSe \\(A\\) e \\(B\\) são eventos em \\(S\\), e \\(P(B) &gt; 0\\), então a probabilidade condicional de \\(A\\) dado \\(B\\), escrita \\(P(A|B)\\), é \\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}.\n\\]\n\nNote que o que acontece no cálculo da probabilidade condicional é que \\(B\\) se torna o espaço amostral: \\(P(B|B) = 1\\). A intuição é que nosso espaço amostral original, \\(S\\), foi atualizado para \\(B\\). Todas as outras ocorrências são então calibradas com respeito à sua relação com \\(B\\). Em particular, note o que acontece com probabilidades condicionais de conjuntos disjuntos. Suponha que \\(A\\) e \\(B\\) sejam disjuntos, então \\(P(A \\cap B) = 0\\). Segue então que \\(P(A|B) = P(B|A) = 0\\).\n\nExemplo 1.3.3 (Continuação do Exemplo 1.3.1)\nEmbora a probabilidade de obter todos os quatro ases seja bem pequena, vejamos como as probabilidades condicionais mudam dado que alguns ases já foram retirados. Quatro cartas serão novamente distribuídas de um baralho bem embaralhado, e agora calculamos \\[\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}), \\quad i = 1, 2, 3.\n\\] O evento \\(\\{4 \\text{ ases em 4 cartas}\\}\\) é um subconjunto do evento \\(\\{i \\text{ ases em } i \\text{ cartas}\\}\\). Assim, da definição de probabilidade condicional, (1.3.1), sabemos que \\[\n\\begin{align*}\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}) &= \\frac{P(\\{4 \\text{ ases em 4 cartas}\\} \\cap \\{i \\text{ ases em } i \\text{ cartas}\\})}{P(i \\text{ ases em } i \\text{ cartas})} \\\\\n&= \\frac{P(4 \\text{ ases em 4 cartas})}{P(i \\text{ ases em } i \\text{ cartas})}.\n\\end{align*}\n\\] O numerador já foi calculado, e o denominador pode ser calculado com um argumento semelhante. O número de grupos distintos de \\(i\\) cartas é \\(\\binom{52}{i}\\), e \\[\nP(i \\text{ ases em } i \\text{ cartas}) = \\frac{\\binom{4}{i}}{\\binom{52}{i}}.\n\\] Portanto, a probabilidade condicional é dada por \\[\nP(\\text{4 ases em 4 cartas} | i \\text{ ases em } i \\text{ cartas}) = \\frac{\\frac{\\binom{4}{4}}{\\binom{52}{4}}}{\\frac{\\binom{4}{i}}{\\binom{52}{i}}} = \\frac{(4-i)! 48!}{(52-i)!} = \\frac{1}{\\binom{52-i}{4-i}}.\n\\] Para \\(i = 1, 2\\) e \\(3\\), as probabilidades condicionais são \\(.00005, .00082\\) e \\(.02041\\), respectivamente.\n\nPara qualquer \\(B\\) para o qual \\(P(B) &gt; 0\\), é simples verificar que a função de probabilidade \\(P(\\cdot|B)\\) satisfaz os Axiomas de Kolmogorov (veja Exercício 1.35). Você pode suspeitar que exigir \\(P(B) &gt; 0\\) é redundante. Quem iria querer condicionar em um evento de probabilidade 0? Curiosamente, às vezes essa é uma maneira particularmente útil de pensar nas coisas. No entanto, adiaremos essas considerações até o Capítulo 4. Probabilidades condicionais podem ser entidades particularmente escorregadias e, às vezes, requerem reflexão cuidadosa. Considere o seguinte conto frequentemente narrado.\n\nExemplo 1.3.4 (Três prisioneiros)\nTrês prisioneiros, A, B e C, estão no corredor da morte. O governador decide perdoar um dos três e escolhe aleatoriamente o prisioneiro a ser perdoado. Ele informa o diretor da prisão de sua escolha, mas solicita que o nome seja mantido em segredo por alguns dias. No dia seguinte, A tenta fazer com que o diretor lhe diga quem foi perdoado. O diretor se recusa. A então pergunta qual de B ou C será executado. O diretor pensa por um momento, depois diz a A que B será executado. Raciocínio do diretor: Cada prisioneiro tem uma chance de \\(\\frac{1}{3}\\) de ser perdoado. Claramente, ou B ou C deve ser executado, então não dei a A nenhuma informação sobre se A será perdoado. Raciocínio de A: Dado que B será executado, então ou A ou C será perdoado. Minha chance de ser perdoado aumentou para \\(\\frac{1}{2}\\). Deve ficar claro que o raciocínio do diretor está correto, mas vejamos o porquê. Sejam \\(A, B\\) e \\(C\\) os eventos de que A, B ou C é perdoado, respectivamente. Sabemos que \\(P(A) = P(B) = P(C) = \\frac{1}{3}\\). Seja \\(\\mathcal{W}\\) o evento de que o diretor diz que B morrerá. Usando (1.3.1), A pode atualizar sua probabilidade de ser perdoado para \\[\nP(A|\\mathcal{W}) = \\frac{P(A \\cap \\mathcal{W})}{P(\\mathcal{W})}.\n\\] O que está acontecendo pode ser resumido nesta tabela:\n\n\n\nPrisioneiro perdoado\nDiretor diz a A\n\n\n\n\n\nA\nB morre\ncada um com igual\n\n\nA\nC morre\nprobabilidade\n\n\nB\nC morre\n\n\n\nC\nB morre\n\n\n\n\nUsando esta tabela, podemos calcular \\[\n\\begin{align*}\nP(\\mathcal{W}) &= P(\\text{diretor diz B morre}) \\\\\n&= P(\\text{diretor diz B morre e A perdoado}) \\\\\n&\\quad + P(\\text{diretor diz B morre e C perdoado}) \\\\\n&\\quad + P(\\text{diretor diz B morre e B perdoado}) \\\\\n&= \\frac{1}{6} + \\frac{1}{3} + 0 = \\frac{1}{2}.\n\\end{align*}\n\\] Assim, usando o raciocínio do diretor, temos \\[\nP(A|\\mathcal{W}) = \\frac{P(A \\cap \\mathcal{W})}{P(\\mathcal{W})} = \\frac{P(\\text{diretor diz B morre e A perdoado})}{P(\\text{diretor diz B morre})} = \\frac{1/6}{1/2} = \\frac{1}{3}.\n\\] No entanto, um A interpreta falsamente o evento \\(\\mathcal{W}\\) como igual ao evento \\(B^c\\) e calcula \\[\nP(A|B^c) = \\frac{P(A \\cap B^c)}{P(B^c)} = \\frac{1/3}{2/3} = \\frac{1}{2}.\n\\] Vemos que probabilidades condicionais podem ser bastante escorregadias e exigem interpretação cuidadosa. Para algumas outras variações deste problema, veja o Exercício 1.37.\n\nReexpressando (1.3.1) dá uma forma útil para calcular probabilidades de interseção, \\[\nP(A \\cap B) = P(A|B)P(B), \\quad (1.3.3)\n\\] que é essencialmente a fórmula que foi usada no Exemplo 1.3.1. Podemos tirar proveito da simetria de (1.3.3) e também escrever \\[\nP(A \\cap B) = P(B|A)P(A). \\quad (1.3.4)\n\\] Quando confrontados com cálculos aparentemente difíceis, podemos dividir nossos cálculos de acordo com (1.3.3) ou (1.3.4), o que for mais fácil. Além disso, podemos igualar os lados direitos dessas equações para obter (após rearranjo) \\[\nP(A|B) = P(B|A)\\frac{P(A)}{P(B)}, \\quad (1.3.5)\n\\] que nos dá uma fórmula para “inverter” probabilidades condicionais. A Equação (1.3.5) é frequentemente chamada de Regra de Bayes por seu descobridor, Sir Thomas Bayes (embora veja Stigler 1983). A Regra de Bayes tem uma forma mais geral do que (1.3.5), uma que se aplica a partições de um espaço amostral. Tomamos, portanto, o seguinte como a definição da Regra de Bayes.\n\nTeorema 1.3.5 (Regra de Bayes)\nSeja \\(A_1, A_2, \\dots\\) uma partição do espaço amostral, e seja \\(B\\) qualquer conjunto. Então, para cada \\(i = 1, 2, \\dots\\), \\[\nP(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{j=1}^{\\infty} P(B|A_j)P(A_j)}.\n\\]\n\n\nExemplo 1.3.6 (Codificação)\nQuando mensagens codificadas são enviadas, às vezes ocorrem erros na transmissão. Em particular, o código Morse usa “pontos” e “traços”, que são conhecidos por ocorrer na proporção de 3:4. Isso significa que para qualquer símbolo dado, \\[\nP(\\text{ponto enviado}) = \\frac{3}{7} \\quad \\text{e} \\quad P(\\text{traço enviado}) = \\frac{4}{7}.\n\\] Suponha que há interferência na linha de transmissão e, com probabilidade \\(\\frac{1}{8}\\), um ponto é erroneamente recebido como um traço, e vice-versa. Se recebermos um ponto, podemos ter certeza de que um ponto foi enviado? Usando a Regra de Bayes, podemos escrever \\[\nP(\\text{ponto enviado} | \\text{ponto recebido}) = P(\\text{ponto recebido} | \\text{ponto enviado}) \\frac{P(\\text{ponto enviado})}{P(\\text{ponto recebido})}.\n\\] Agora, a partir da informação dada, sabemos que \\(P(\\text{ponto enviado}) = \\frac{3}{7}\\) e \\(P(\\text{ponto recebido} | \\text{ponto enviado}) = \\frac{7}{8}\\). Além disso, também podemos escrever \\[\n\\begin{align*}\nP(\\text{ponto recebido}) &= P(\\text{ponto recebido} \\cap \\text{ponto enviado}) + P(\\text{ponto recebido} \\cap \\text{traço enviado}) \\\\\n&= P(\\text{ponto recebido} | \\text{ponto enviado})P(\\text{ponto enviado}) \\\\\n&\\quad + P(\\text{ponto recebido} | \\text{traço enviado})P(\\text{traço enviado}) \\\\\n&= \\frac{7}{8} \\times \\frac{3}{7} + \\frac{1}{8} \\times \\frac{4}{7} = \\frac{25}{56}.\n\\end{align*}\n\\] Combinando esses resultados, temos que a probabilidade de receber corretamente um ponto é \\[\nP(\\text{ponto enviado} | \\text{ponto recebido}) = \\frac{(7/8) \\times (3/7)}{25/56} = \\frac{21}{25}.\n\\]\n\nEm alguns casos, pode acontecer que a ocorrência de um evento particular, \\(B\\), não tenha efeito sobre a probabilidade de outro evento, \\(A\\). Simbolicamente, estamos dizendo que \\[\nP(A|B) = P(A). \\quad (1.3.6)\n\\] Se isso vale, então pela Regra de Bayes (1.3.5) e usando (1.3.6) temos \\[\nP(B|A) = P(A|B)\\frac{P(B)}{P(A)} = P(A)\\frac{P(B)}{P(A)} = P(B), \\quad (1.3.7)\n\\] então a ocorrência de \\(A\\) não tem efeito sobre \\(B\\). Além disso, como \\(P(B|A)P(A) = P(A \\cap B)\\), segue-se que \\[\nP(A \\cap B) = P(A)P(B),\n\\] o que tomamos como a definição de independência estatística.\n\nDefinição 1.3.7\nDois eventos, \\(A\\) e \\(B\\), são estatisticamente independentes se \\[\nP(A \\cap B) = P(A)P(B). \\quad (1.3.8)\n\\]\n\nNote que a independência poderia ter sido equivalentemente definida por (1.3.6) ou (1.3.7) (desde que \\(P(A) &gt; 0\\) ou \\(P(B) &gt; 0\\)). A vantagem de (1.3.8) é que ela trata os eventos simetricamente e será mais fácil de generalizar para mais de dois eventos. Muitos jogos de azar fornecem modelos de eventos independentes. Os giros de uma roleta e os lançamentos de um par de dados são ambas séries de eventos independentes.\n\nExemplo 1.3.8 (Chevalier de Méré)\nO jogador introduzido no início do capítulo, o Chevalier de Méré, estava particularmente interessado no evento de que ele poderia lançar pelo menos um 6 em 4 lançamentos de um dado. Nós temos \\[\n\\begin{align*}\nP(\\text{pelo menos um 6 em 4 lançamentos}) &= 1 - P(\\text{nenhum seis em 4 lançamentos}) \\\\\n&= 1 - \\prod_{i=1}^4 P(\\text{nenhum seis no lançamento } i),\n\\end{align*}\n\\] onde a última igualdade decorre da independência dos lançamentos. Em qualquer lançamento, a probabilidade de não rolar um seis é \\(\\frac{5}{6}\\), então \\[\nP(\\text{pelo menos um 6 em 4 lançamentos}) = 1 - \\left( \\frac{5}{6} \\right)^4 = .518.\n\\]\n\nA independência de \\(A\\) e \\(B\\) implica independência dos complementos também. De fato, temos o seguinte teorema.\n\nTeorema 1.3.9\nSe A e B são eventos independentes, então os seguintes pares também são independentes: * a. \\(A\\) e \\(B^c\\), * b. \\(A^c\\) e \\(B\\), * c. \\(A^c\\) e \\(B^c\\).\n\n\nComprovação. Provaremos apenas (a), deixando o restante como Exercício 1.40. Para provar (a) devemos mostrar que \\(P(A \\cap B^c) = P(A)P(B^c)\\). Do Teorema 1.2.9a temos \\[\n\\begin{align*}\nP(A \\cap B^c) &= P(A) - P(A \\cap B) \\\\\n&= P(A) - P(A)P(B) \\quad (A \\text{ e } B \\text{ são independentes}) \\\\\n&= P(A)(1 - P(B)) \\\\\n&= P(A)P(B^c). \\quad \\square\n\\end{align*}\n\\]\n\nA independência de mais de dois eventos pode ser definida de maneira semelhante a (1.3.8), mas devemos ter cuidado. Por exemplo, podemos pensar que poderíamos dizer \\(A, B\\) e \\(C\\) são independentes se \\(P(A \\cap B \\cap C) = P(A)P(B)P(C)\\). No entanto, esta não é a condição correta.\n\nExemplo 1.3.10 (Lançando dois dados)\nSeja um experimento consistindo em lançar dois dados. Para este experimento, o espaço amostral é \\[\nS = \\{(1,1), (1,2), \\dots, (1,6), (2,1), \\dots, (2,6), \\dots, (6,1), \\dots, (6,6)\\};\n\\] isto é, \\(S\\) consiste nos 36 pares ordenados formados a partir dos números 1 a 6. Defina os seguintes eventos: * \\(A = \\{\\text{duplas aparecem}\\} = \\{(1,1), (2,2), (3,3), (4,4), (5,5), (6,6)\\}\\), * \\(B = \\{\\text{a soma está entre 7 e 10}\\}\\), * \\(C = \\{\\text{a soma é 2 ou 7 ou 8}\\}\\).\nAs probabilidades podem ser calculadas contando entre os 36 resultados possíveis. Nós temos \\[\nP(A) = \\frac{1}{6}, \\quad P(B) = \\frac{1}{2}, \\quad \\text{e} \\quad P(C) = \\frac{1}{3}.\n\\] Além disso, \\[\n\\begin{align*}\nP(A \\cap B \\cap C) &= P(\\text{a soma é 8, composta de duplos 4s}) \\\\\n&= \\frac{1}{36} \\\\\n&= \\frac{1}{6} \\times \\frac{1}{2} \\times \\frac{1}{3} \\\\\n&= P(A)P(B)P(C).\n\\end{align*}\n\\] No entanto, \\[\nP(B \\cap C) = P(\\text{soma igual a 7 ou 8}) = \\frac{11}{36} \\ne P(B)P(C).\n\\] Similarmente, pode ser mostrado que \\(P(A \\cap B) \\ne P(A)P(B)\\); portanto, o requisito \\(P(A \\cap B \\cap C) = P(A)P(B)P(C)\\) não é uma condição forte o suficiente para garantir independência dois a dois.\n\nUma segunda tentativa de uma definição geral de independência, à luz do exemplo anterior, pode ser definir \\(A, B\\) e \\(C\\) como independentes se todos os pares forem independentes. Infelizmente, esta condição também falha.\n\nExemplo 1.3.11 (Letras)\nSeja o espaço amostral \\(S\\) consistindo nas \\(3!\\) permutações das letras a, b e c junto com as três triplas de cada letra. Assim, \\[\nS = \\begin{Bmatrix} \\text{aaa} & \\text{bbb} & \\text{ccc} \\\\ \\text{abc} & \\text{bca} & \\text{cba} \\\\ \\text{acb} & \\text{bac} & \\text{cab} \\end{Bmatrix}.\n\\] Além disso, seja cada elemento de \\(S\\) ter probabilidade \\(\\frac{1}{9}\\). Defina \\[\nA_i = \\{\\text{o } i\\text{-ésimo lugar na tripla é ocupado por a}\\}.\n\\] É então fácil contar que \\[\nP(A_i) = \\frac{1}{3}, \\quad i = 1, 2, 3,\n\\] e \\[\nP(A_1 \\cap A_2) = P(A_1 \\cap A_3) = P(A_2 \\cap A_3) = \\frac{1}{9},\n\\] então os \\(A_i\\)s são independentes dois a dois. Mas \\[\nP(A_1 \\cap A_2 \\cap A_3) = \\frac{1}{9} \\ne P(A_1)P(A_2)P(A_3),\n\\] então os \\(A_i\\)s não satisfazem o requisito de probabilidade.\n\nOs dois exemplos anteriores mostram que a independência simultânea (ou mútua) de uma coleção de eventos requer uma definição extremamente forte. A seguinte definição funciona.\n\nDefinição 1.3.12\nUma coleção de eventos \\(A_1, \\dots, A_n\\) são mutuamente independentes se para qualquer subcoleção \\(A_{i_1}, \\dots, A_{i_k}\\), temos \\[\nP\\left( \\bigcap_{j=1}^k A_{i_j} \\right) = \\prod_{j=1}^k P(A_{i_j}).\n\\]\n\n\nExemplo 1.3.13 (Três lançamentos de moeda—I)\nConsidere o experimento de lançar uma moeda três vezes. Um ponto amostral para este experimento deve indicar o resultado de cada lançamento. Por exemplo, HHT poderia indicar que duas caras e depois uma coroa foram observadas. O espaço amostral para este experimento tem oito pontos, a saber,\n\\[\n\\{\\text{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT}\\}.\n\\]\nSeja \\(H_i, i = 1, 2, 3\\), o evento de que o \\(i\\)-ésimo lançamento é uma cara. Por exemplo,\n\\[\nH_1 = \\{\\text{HHH, HHT, HTH, HTT}\\}.\n\\]\nSe atribuirmos probabilidade \\(\\frac{1}{8}\\) a cada ponto amostral, então, usando enumerações como (1.3.9), vemos que \\(P(H_1) = P(H_2) = P(H_3) = \\frac{1}{2}\\). Isso diz que a moeda é justa e tem igual probabilidade de dar cara ou coroa em cada lançamento. Sob este modelo de probabilidade, os eventos \\(H_1, H_2\\) e \\(H_3\\) também são mutuamente independentes. Para verificar isso, notamos que\n\\[\nP(H_1 \\cap H_2 \\cap H_3) = P(\\{\\text{HHH}\\}) = \\frac{1}{8} = \\frac{1}{2} \\cdot \\frac{1}{2} \\cdot \\frac{1}{2} = P(H_1)P(H_2)P(H_3).\n\\]\nPara verificar a condição na Definição 1.3.12, devemos também verificar cada par. Por exemplo,\n\\[\nP(H_1 \\cap H_2) = P(\\{\\text{HHH, HHT}\\}) = \\frac{2}{8} = \\frac{1}{2} \\cdot \\frac{1}{2} = P(H_1)P(H_2).\n\\]\nA igualdade também é verdadeira para os outros dois pares. Assim, \\(H_1, H_2\\) e \\(H_3\\) são mutuamente independentes. Ou seja, a ocorrência de uma cara em qualquer lançamento não tem efeito em nenhum dos outros lançamentos. Pode ser verificado que a atribuição de probabilidade \\(\\frac{1}{8}\\) para cada ponto amostral é o único modelo de probabilidade que tem \\(P(H_1) = P(H_2) = P(H_3) = \\frac{1}{2}\\) e \\(H_1, H_2\\) e \\(H_3\\) mutuamente independentes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#variáveis-aleatórias",
    "href": "cap-1.html#variáveis-aleatórias",
    "title": "Teoria da Probabilidade",
    "section": "1.4 Variáveis Aleatórias",
    "text": "1.4 Variáveis Aleatórias\nEm muitos experimentos, é mais fácil lidar com uma variável resumo do que com a estrutura de probabilidade original. Por exemplo, em uma pesquisa de opinião, podemos decidir perguntar a 50 pessoas se elas concordam ou discordam de uma certa questão. Se registrarmos um “1” para concordo e “0” para discordo, o espaço amostral para este experimento tem \\(2^{50}\\) elementos, cada um uma string ordenada de 1s e 0s de comprimento 50. Devemos ser capazes de reduzir isso a um tamanho razoável! Pode ser que a única quantidade de interesse seja o número de pessoas que concordam (equivalentemente, discordam) de 50, e, se definirmos uma variável \\(X\\) = número de 1s registrados em 50, capturamos a essência do problema. Note que o espaço amostral para \\(X\\) é o conjunto de inteiros \\(\\{0, 1, 2, \\dots, 50\\}\\) e é muito mais fácil de lidar do que o espaço amostral original. Ao definir a quantidade \\(X\\), definimos um mapeamento (uma função) do espaço amostral original para um novo espaço amostral, geralmente um conjunto de números reais. Em geral, temos a seguinte definição.\n\nDefinição 1.4.1 - Variável Aleatória\nUma variável aleatória é uma função de um espaço amostral \\(S\\) para os números reais.\n\n\nExemplo 1.4.2 (Variáveis aleatórias)\nEm alguns experimentos, variáveis aleatórias são usadas implicitamente; alguns exemplos são:\nExemplos de variáveis aleatórias\n\n\n\n\n\n\n\nExperimento\nVariável aleatória\n\n\n\n\nLançar dois dados\n\\(X =\\) soma dos números\n\n\nLançar uma moeda 25 vezes\n\\(X =\\) número de caras em 25 lançamentos\n\n\nAplicar diferentes quantidades de fertilizante em plantas de milho\n\\(X =\\) produtividade/acre\n\n\n\nAo definir uma variável aleatória, também definimos um novo espaço amostral (a imagem da variável aleatória). Devemos verificar formalmente se nossa função de probabilidade, definida no espaço amostral original, pode ser usada para a variável aleatória. Suponha que temos um espaço amostral \\[\nS = \\{s_1, \\dots, s_n\\}\n\\] com uma função de probabilidade \\(P\\) e definimos uma variável aleatória \\(X\\) com imagem \\(\\mathcal{X} = \\{x_1, \\dots, x_m\\}\\). Definimos uma função de probabilidade \\(P_X\\) em \\(\\mathcal{X}\\) da seguinte maneira. Observaremos \\(X = x_i\\) se e somente se o resultado do experimento aleatório for um \\(s_j \\in S\\) tal que \\(X(s_j) = x_i\\). Assim, \\[\nP_X(X = x_i) = P(\\{s_j \\in S : X(s_j) = x_i\\}). \\quad (1.4.1)\n\\] Note que o lado esquerdo de (1.4.1), a função \\(P_X\\), é uma probabilidade induzida em \\(\\mathcal{X}\\), definida em termos da função original \\(P\\). A Equação (1.4.1) define formalmente uma função de probabilidade, \\(P_X\\), para a variável aleatória \\(X\\). É claro que temos que verificar se \\(P_X\\) satisfaz os Axiomas de Kolmogorov, mas essa é uma tarefa muito difícil (veja o Exercício 1.45). Devido à equivalência em (1.4.1), simplesmente escreveremos \\(P(X = x_i)\\) em vez de \\(P_X(X = x_i)\\). Uma nota sobre notação: Variáveis aleatórias sempre serão denotadas com letras maiúsculas e os valores realizados da variável (ou sua imagem) serão denotados pelas letras minúsculas correspondentes. Assim, a variável aleatória \\(X\\) pode assumir o valor \\(x\\).\n\n\nExemplo 1.4.3 (Três lançamentos de moeda—II)\nConsidere novamente o experimento de lançar uma moeda honesta três vezes do Exemplo 1.3.13. Defina a variável aleatória \\(X\\) como o número de caras obtidas nos três lançamentos. Uma enumeração completa do valor de \\(X\\) para cada ponto no espaço amostral é\n\n\n\n\\(s\\)\nHHH\nHHT\nHTH\nTHH\nTTH\nTHT\nHTT\nTTT\n\n\n\n\n\\(X(s)\\)\n3\n2\n2\n2\n1\n1\n1\n0\n\n\n\nA imagem da variável aleatória \\(X\\) é \\(\\mathcal{X} = \\{0, 1, 2, 3\\}\\). Assumindo que todos os oito pontos em \\(S\\) têm probabilidade \\(\\frac{1}{8}\\), simplesmente contando na exibição acima vemos que a função de probabilidade induzida em \\(\\mathcal{X}\\) é dada por\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\n\n\n\n\n\\(P_X(X=x)\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{3}{8}\\)\n\\(\\frac{3}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\nPor exemplo, \\(P_X(X=1) = P(\\{\\text{HTT, THT, TTH}\\}) = \\frac{3}{8}\\).\n\n\nExemplo 1.4.4 (Distribuição de uma variável aleatória)\nPode ser possível determinar \\(P_X\\) mesmo se uma listagem completa, como no Exemplo 1.4.3, não for possível. Seja \\(S\\) as \\(2^{50}\\) strings de 50 zeros e uns, \\(X =\\) número de 1s, e \\(\\mathcal{X} = \\{0, 1, 2, \\dots, 50\\}\\), como mencionado no início desta seção. Suponha que cada uma das \\(2^{50}\\) strings seja igualmente provável. A probabilidade de que \\(X = 27\\) pode ser obtida contando todas as strings com 27 uns no espaço amostral original. Como cada string é igualmente provável, segue-se que \\[\nP_X(X = 27) = \\frac{\\# \\text{ strings com 27 1s}}{\\# \\text{ strings}} = \\frac{\\binom{50}{27}}{2^{50}}.\n\\] Em geral, para qualquer \\(i \\in \\mathcal{X}\\), \\[\nP_X(X = i) = \\frac{\\binom{50}{i}}{2^{50}}.\n\\]\n\nAs ilustrações anteriores tinham tanto um \\(S\\) finito quanto um \\(\\mathcal{X}\\) finito, e a definição de \\(P_X\\) foi direta. Tal também é o caso se \\(\\mathcal{X}\\) é enumerável. Se \\(\\mathcal{X}\\) é não enumerável, definimos a função de probabilidade induzida, \\(P_X\\), de uma maneira semelhante a (1.4.1). Para qualquer conjunto \\(A \\subset \\mathcal{X}\\), \\[\nP_X(X \\in A) = P(\\{s \\in S : X(s) \\in A\\}). \\quad (1.4.2)\n\\] Isso define uma função de probabilidade legítima para a qual os Axiomas de Kolmogorov podem ser verificados. (Para ser preciso, usamos (1.4.2) para definir probabilidades apenas para uma certa sigma-álgebra de subconjuntos de \\(\\mathcal{X}\\). Mas não nos preocuparemos com essas tecnicalidades.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#funções-de-distribuição",
    "href": "cap-1.html#funções-de-distribuição",
    "title": "Teoria da Probabilidade",
    "section": "1.5 Funções de Distribuição",
    "text": "1.5 Funções de Distribuição\nA cada variável aleatória \\(X\\), associamos uma função chamada função de distribuição acumulada de \\(X\\).\n\nDefinição 1.5.1\nA função de distribuição acumulada ou fda (cdf - cumulative distribution function em inglês) de uma variável aleatória \\(X\\), denotada por \\(F_X(x)\\), é definida por \\[\nF_X(x) = P_X(X \\le x), \\quad \\text{para todo } x.\n\\]\n\n\nExemplo 1.5.2 (Lançando três moedas)\nConsidere o experimento de lançar três moedas justas, e seja \\(X =\\) número de caras observadas. A fda de \\(X\\) é\n\\[\nF_X(x) = \\begin{cases}\n0 & \\text{se } -\\infty &lt; x &lt; 0 \\\\\n\\frac{1}{8} & \\text{se } 0 \\le x &lt; 1 \\\\\n\\frac{1}{2} & \\text{se } 1 \\le x &lt; 2 \\\\\n\\frac{7}{8} & \\text{se } 2 \\le x &lt; 3 \\\\\n1 & \\text{se } 3 \\le x &lt; \\infty.\n\\end{cases} \\quad (1.5.1)\n\\]\nA função escada \\(F_X(x)\\) é grafada na Figura 1.5.1. Há vários pontos a notar na Figura 1.5.1. \\(F_X\\) é definida para todos os valores de \\(x\\), não apenas aqueles em \\(\\mathcal{X} = \\{0, 1, 2, 3\\}\\). Assim, por exemplo,\n\\[\nF_X(2.5) = P(X \\le 2.5) = P(X = 0, 1, \\text{ou } 2) = \\frac{7}{8}.\n\\]\nNote que \\(F_X\\) tem saltos nos valores de \\(x_i \\in \\mathcal{X}\\) e o tamanho do salto em \\(x_i\\) é igual a \\(P(X = x_i)\\). Além disso, \\(F_X(x) = 0\\) para \\(x &lt; 0\\) uma vez que \\(X\\) não pode ser negativo, e \\(F_X(x) = 1\\) para \\(x \\ge 3\\) uma vez que \\(x\\) é certo ser menor ou igual a tal valor.\n\n\n\nFigura 1.5.1 - Cdf do Exemplo 1.5.2\n\n\nComo é aparente na Figura 1.5.1, \\(F_X\\) pode ser descontínua, com saltos em certos valores de \\(x\\). A propósito, na maneira como \\(F_X\\) é definida, no entanto, nos pontos de salto \\(F_X\\) assume o valor no topo do salto. (Note as diferentes desigualdades em (1.5.1).) Isso é conhecido como continuidade à direita — a função é contínua quando um ponto é abordado pela direita. A propriedade de continuidade à direita é uma consequência da definição da fda. Em contraste, se tivéssemos definido \\(F_X(x) = P_X(X &lt; x)\\) (note a desigualdade estrita), \\(F_X\\) seria então contínua à esquerda. O tamanho do salto em qualquer ponto \\(x\\) é igual a \\(P(X = x)\\). Toda fda satisfaz certas propriedades, algumas das quais são óbvias quando pensamos na definição de \\(F_X(x)\\) em termos de probabilidades.\n\n\nTeorema 1.5.3\nA função \\(F(x)\\) é uma fda se e somente se as três condições seguintes forem satisfeitas: * a. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) e \\(\\lim_{x \\to \\infty} F(x) = 1\\). * b. \\(F(x)\\) é uma função não decrescente de \\(x\\). * c. \\(F(x)\\) é contínua à direita; isto é, para todo número \\(x_0\\), \\(\\lim_{x \\downarrow x_0} F(x) = F(x_0)\\).\n\n\nComprovação. Esboço da prova: Para provar a necessidade, as três propriedades podem ser verificadas escrevendo \\(F\\) em termos da função de probabilidade (veja Exercício 1.48). Para provar a suficiência, ou seja, que se uma função \\(F\\) satisfaz as três condições do teorema então existe alguma variável aleatória, é muito mais difícil. Deve ser estabelecido que existe um espaço amostral \\(S\\), uma função de probabilidade \\(P\\) em \\(S\\), e uma variável aleatória \\(X\\) definida em \\(S\\) tal que \\(F\\) é a fda de \\(X\\). \\(\\square\\)\n\n\nExemplo 1.5.4 (Lançando até obter uma cara)\nSuponha que fazemos um experimento que consiste em lançar uma moeda até que uma cara apareça. Seja \\(p =\\) probabilidade de uma cara em qualquer lançamento dado, e defina uma variável aleatória \\(X =\\) número de lançamentos necessários para obter uma cara. Então, para qualquer \\(x = 1, 2, \\dots\\),\n\\[\nP(X = x) = (1-p)^{x-1}p, \\quad (1.5.2)\n\\]\numa vez que devemos obter \\(x-1\\) coroas seguidas por uma cara para que o evento ocorra e todas as tentativas são independentes. A partir de (1.5.2) calculamos, para qualquer inteiro positivo \\(x\\),\n\\[\nP(X \\le x) = \\sum_{i=1}^x P(X=i) = \\sum_{i=1}^x (1-p)^{i-1}p. \\quad (1.5.3)\n\\]\nA soma parcial da série geométrica é\n\\[\n\\sum_{k=1}^n t^{k-1} = \\frac{1-t^n}{1-t}, \\quad t \\ne 1, \\quad (1.5.4)\n\\]\num fato que pode ser estabelecido por indução (veja Exercício 1.50). Aplicando (1.5.4) à nossa probabilidade, descobrimos que a fda da variável aleatória \\(X\\) é\n\\[\n\\begin{align*}\nF_X(x) &= P(X \\le x) \\\\\n&= \\frac{1-(1-p)^x}{1-(1-p)}p \\\\\n&= 1 - (1-p)^x, \\quad x = 1, 2, \\dots .\n\\end{align*}\n\\]\nA fda \\(F_X(x)\\) é plana entre os inteiros não negativos, como no Exemplo 1.5.2. É fácil mostrar que se \\(0 &lt; p &lt; 1\\), então \\(F_X(x)\\) satisfaz as condições do Teorema 1.5.3. Primeiro,\n\\[\n\\lim_{x \\to -\\infty} F_X(x) = 0\n\\]\numa vez que \\(F_X(x) = 0\\) para todo \\(x &lt; 0\\), e\n\\[\n\\lim_{x \\to \\infty} F_X(x) = \\lim_{x \\to \\infty} 1 - (1-p)^x = 1,\n\\]\nonde \\(x\\) passa apenas por valores inteiros quando este limite é tomado. Para verificar a propriedade (b), simplesmente notamos que a soma em (1.5.3) contém mais termos positivos conforme \\(x\\) aumenta. Finalmente, para verificar (c), note que, para qualquer \\(x\\), \\(F_X(x+\\epsilon) = F_X(x)\\) se \\(\\epsilon &gt; 0\\) é suficientemente pequeno. Portanto,\n\\[\n\\lim_{\\epsilon \\downarrow 0} F_X(x+\\epsilon) = F_X(x),\n\\]\nentão \\(F_X(x)\\) é contínua à direita. \\(F_X(x)\\) é a fda de uma distribuição chamada distribuição geométrica (após a série) e é retratada na Figura 1.5.2.\n\n\n\n\nFigura 1.5.2 - Cdf geométrica, p = .3\n\n\n\nExemplo 1.5.5 (Cdf contínua)\nUm exemplo de uma fda contínua é a função\n\\[\nF_X(x) = \\frac{1}{1+e^{-x}}, \\quad (1.5.5)\n\\]\nque satisfaz as condições do Teorema 1.5.3. Por exemplo,\n\\[\n\\lim_{x \\to -\\infty} F_X(x) = 0 \\quad \\text{visto que} \\quad \\lim_{x \\to -\\infty} e^{-x} = \\infty\n\\]\ne\n\\[\n\\lim_{x \\to \\infty} F_X(x) = 1 \\quad \\text{visto que} \\quad \\lim_{x \\to \\infty} e^{-x} = 0.\n\\]\nDiferenciando \\(F_X(x)\\) resulta\n\\[\n\\frac{d}{dx} F_X(x) = \\frac{e^{-x}}{(1+e^{-x})^2} &gt; 0,\n\\]\nmostrando que \\(F_X(x)\\) é crescente. \\(F_X\\) não é apenas contínua à direita, mas também contínua. Esta é um caso especial da distribuição logística.\n\n\nExemplo 1.5.6 (Cdf com saltos)\nSe \\(F_X\\) não é uma função contínua de \\(x\\), é possível que seja uma mistura de pedaços contínuos e saltos. Por exemplo, se modificarmos \\(F_X(x)\\) de (1.5.5) para ser, para algum \\(\\epsilon, 1 &gt; \\epsilon &gt; 0\\),\n\\[\nF_Y(y) = \\begin{cases}\n\\frac{1-\\epsilon}{1+e^{-y}} & \\text{se } y &lt; 0 \\\\\n\\epsilon + \\frac{(1-\\epsilon)}{1+e^{-y}} & \\text{se } y \\ge 0,\n\\end{cases} \\quad (1.5.6)\n\\]\nentão \\(F_Y(y)\\) é a fda de uma variável aleatória \\(Y\\) (veja Exercício 1.47). A função \\(F_Y\\) tem um salto de altura \\(\\epsilon\\) em \\(y=0\\) e, de outra forma, é contínua. Este modelo pode ser apropriado se estivéssemos observando a leitura de um medidor, uma leitura que poderia (teoricamente) estar em qualquer lugar entre \\(-\\infty\\) e \\(\\infty\\). Este medidor particular, no entanto, às vezes trava em 0. Poderíamos então modelar nossas observações com \\(F_Y\\), onde \\(\\epsilon\\) é a probabilidade de que o medidor trave.\n\nSe uma fda é contínua ou tem saltos corresponde à variável aleatória associada ser contínua ou não. De fato, a associação é tal que é conveniente definir variáveis aleatórias contínuas desta maneira.\n\nDefinição 1.5.7\nUma variável aleatória \\(X\\) é contínua se \\(F_X(x)\\) é uma função contínua de \\(x\\). Uma variável aleatória \\(X\\) é discreta se \\(F_X(x)\\) é uma função escada de \\(x\\).\n\nFechamos esta seção com um teorema declarando formalmente que \\(F_X\\) determina completamente a distribuição de probabilidade de uma variável aleatória \\(X\\). Isso é verdade se \\(P(X \\in A)\\) é definida apenas para eventos \\(A\\) em \\(\\mathcal{B}^1\\), a menor sigma-álgebra contendo todos os intervalos de números reais da forma \\((a, b), [a, b), (a, b]\\), e \\([a, b]\\). Se probabilidades são definidas para uma classe maior de eventos, é possível que duas variáveis aleatórias tenham a mesma distribuição de probabilidade, mas não a mesma probabilidade para todo evento (veja Chung 1974, página 27). Neste livro, como na maioria das aplicações estatísticas, estamos preocupados apenas com eventos que são intervalos, uniões enumeráveis ou interseções de intervalos, etc. Então não consideramos tais casos patológicos. Primeiro precisamos da noção de duas variáveis aleatórias sendo identicamente distribuídas.\n\nDefinição 1.5.8\nAs variáveis aleatórias \\(X\\) e \\(Y\\) são identicamente distribuídas se, para todo conjunto \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\).\n\nNote que duas variáveis aleatórias que são identicamente distribuídas não são necessariamente iguais. Isto é, a Definição 1.5.8 não diz que \\(X=Y\\).\n\nExemplo 1.5.9 (Variáveis aleatórias identicamente distribuídas)\nConsidere o experimento de lançar uma moeda justa três vezes como no Exemplo 1.4.3. Defina as variáveis aleatórias \\(X\\) e \\(Y\\) por\n\\[\nX = \\text{número de caras observadas} \\quad \\text{e} \\quad Y = \\text{número de coroas observadas}.\n\\]\nA distribuição de \\(X\\) é dada no Exemplo 1.4.3, e é facilmente verificado que a distribuição de \\(Y\\) é exatamente a mesma. Isto é, para cada \\(k = 0, 1, 2, 3\\), temos \\(P(X=k) = P(Y=k)\\). Então \\(X\\) e \\(Y\\) são identicamente distribuídas. No entanto, para nenhum ponto amostral temos \\(X(s) = Y(s)\\).\n\n\nTeorema 1.5.10\nAs duas declarações seguintes são equivalentes:\n\na. As variáveis aleatórias \\(X\\) e \\(Y\\) são identicamente distribuídas.\nb. \\(F_X(x) = F_Y(x)\\) para todo \\(x\\).\n\n\n\nComprovação. Para mostrar a equivalência devemos mostrar que cada declaração implica a outra. Primeiro mostramos que (a) \\(\\Rightarrow\\) (b). Como \\(X\\) e \\(Y\\) são identicamente distribuídas, para qualquer conjunto \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\). Em particular, para cada \\(x\\), o conjunto \\((-\\infty, x]\\) está em \\(\\mathcal{B}^1\\), e\n\\[\nF_X(x) = P(X \\in (-\\infty, x]) = P(Y \\in (-\\infty, x]) = F_Y(x).\n\\]\nA implicação inversa, que (b) \\(\\Rightarrow\\) (a), é muito mais difícil de provar. O argumento acima mostrou que se as probabilidades \\(X\\) e \\(Y\\) concordaram em todos os conjuntos, então elas concordaram em intervalos. Agora devemos provar o oposto; isto é, se as probabilidades \\(X\\) e \\(Y\\) concordam em todos os intervalos, então elas concordam em todos os conjuntos. Isso requer uso pesado de sigma-álgebras; não entraremos nesses detalhes aqui. Basta dizer que é necessário provar apenas que as duas funções de probabilidade concordam em todos os intervalos (Chung 1974, Seção 2.2). \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#funções-de-densidade-e-de-massa",
    "href": "cap-1.html#funções-de-densidade-e-de-massa",
    "title": "Teoria da Probabilidade",
    "section": "1.6 Funções de Densidade e de Massa",
    "text": "1.6 Funções de Densidade e de Massa\nAssociada a uma variável aleatória \\(X\\) e sua fda \\(F_X\\) existe outra função, chamada de função de densidade de probabilidade (fdp) ou função de massa de probabilidade (fmp). Os termos fdp e fmp referem-se, respectivamente, aos casos contínuo e discreto. Tanto fdp quanto fmp dizem respeito a “probabilidades pontuais” de variáveis aleatórias.\n\nDefinição 1.6.1\nA função de massa de probabilidade (fmp) de uma variável aleatória discreta \\(X\\) é dada por \\[\nf_X(x) = P(X = x) \\quad \\text{para todo } x.\n\\]\n\n\nExemplo 1.6.2 (Probabilidades geométricas)\nPara a distribuição geométrica do Exemplo 1.5.4, temos a fmp \\[\nf_X(x) = P(X = x) = \\begin{cases} (1-p)^{x-1}p & \\text{para } x = 1, 2, \\dots \\\\ 0 & \\text{caso contrário.} \\end{cases}\n\\] Lembre-se que \\(P(X = x)\\) ou, equivalentemente, \\(f_X(x)\\) é o tamanho do salto na fda em \\(x\\). Podemos usar a fmp para calcular probabilidades. Como agora podemos medir a probabilidade de um único ponto, precisamos apenas somar todos os pontos no evento apropriado. Assim, para inteiros positivos \\(a\\) e \\(b\\), com \\(a \\le b\\), temos \\[\nP(a \\le X \\le b) = \\sum_{k=a}^b f_X(k) = \\sum_{k=a}^b (1-p)^{k-1}p.\n\\]\n\nComo um caso especial disso, obtemos \\[\nP(X \\le b) = \\sum_{k=1}^b f_X(k) = F_X(b). \\quad (1.6.1)\n\\]\nUma convenção amplamente aceita, que adotaremos, é usar uma letra maiúscula para a fda e a letra minúscula correspondente para a fmp ou fdp. Devemos ser um pouco mais cuidadosos em nossa definição de fdp e no caso contínuo. Se tentarmos ingenuamente calcular \\(P(X = x)\\) para uma variável aleatória contínua, obtemos o seguinte. Visto que \\(\\{X = x\\} \\subset \\{x - \\epsilon &lt; X \\le x\\}\\) para qualquer \\(\\epsilon &gt; 0\\), temos do Teorema 1.2.9(c) que \\[\nP(X = x) \\le P(x - \\epsilon &lt; X \\le x) = F_X(x) - F_X(x - \\epsilon)\n\\] para qualquer \\(\\epsilon &gt; 0\\). Portanto, \\[\n0 \\le P(X = x) \\le \\lim_{\\epsilon \\downarrow 0} [F_X(x) - F_X(x - \\epsilon)] = 0\n\\] pela continuidade de \\(F_X\\). No entanto, se entendermos o propósito da fdp, sua definição ficará clara. Do Exemplo 1.6.2, vemos que uma fmp nos dá “probabilidades pontuais”. No caso discreto, podemos somar valores da fmp para obter a fda (como em (1.6.1)). O procedimento análogo no caso contínuo é substituir integrais por somas, e obtemos \\[\nP(X \\le x) = F_X(x) = \\int_{-\\infty}^x f_X(t) \\, dt.\n\\] Usando o Teorema Fundamental do Cálculo, se \\(f_X(x)\\) é contínua, temos a relação adicional \\[\n\\frac{d}{dx} F_X(x) = f_X(x). \\quad (1.6.2)\n\\] Note que a analogia com o caso discreto é quase exata. Nós “somamos” as “probabilidades pontuais” \\(f_X(x)\\) para obter probabilidades de intervalo.\n\nDefinição 1.6.3\nA função de densidade de probabilidade ou fdp, \\(f_X(x)\\), de uma variável aleatória contínua \\(X\\) é a função que satisfaz \\[\nF_X(x) = \\int_{-\\infty}^x f_X(t) \\, dt \\quad \\text{para todo } x. \\quad (1.6.3)\n\\]\n\nUma nota sobre notação: A expressão “\\(X\\) tem uma distribuição dada por \\(F_X(x)\\)” é abreviada simbolicamente por “\\(X \\sim F_X(x)\\)”, onde lemos o símbolo “\\(\\sim\\)” como “é distribuído como”. Podemos similarmente escrever \\(X \\sim f_X(x)\\) ou, se \\(X\\) e \\(Y\\) têm a mesma distribuição, \\(X \\sim Y\\). No caso contínuo, podemos ser um pouco desleixados sobre a especificação de probabilidades de intervalo. Visto que \\(P(X = x) = 0\\) se \\(X\\) é uma variável aleatória contínua, \\[\nP(a &lt; X &lt; b) = P(a &lt; X \\le b) = P(a \\le X &lt; b) = P(a \\le X \\le b).\n\\]\n\n\n\nFigura 1.6.1 - Área sob a curva logística\n\n\nDeve ficar claro que a fdp (ou fmp) contém a mesma informação que a fda. Sendo este o caso, podemos usar uma para resolver problemas e devemos tentar escolher a mais simples.\n\nExemplo 1.6.4 (Probabilidades logísticas)\nPara a distribuição logística do Exemplo 1.5.5, temos \\[\nF_X(x) = \\frac{1}{1+e^{-x}}\n\\] e, portanto, \\[\nf_X(x) = \\frac{d}{dx} F_X(x) = \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\] A área sob a curva \\(f_X(x)\\) nos dá probabilidades de intervalo (veja Figura 1.6.1): \\[\n\\begin{align*}\nP(a &lt; X &lt; b) &= F_X(b) - F_X(a) \\\\\n&= \\int_{-\\infty}^b f_X(x) \\, dx - \\int_{-\\infty}^a f_X(x) \\, dx \\\\\n&= \\int_{a}^b f_X(x) \\, dx.\n\\end{align*}\n\\]\n\nExistem realmente apenas dois requisitos para uma fdp (ou fmp), ambos consequências imediatas da definição.\n\nTeorema 1.6.5\nUma função \\(f_X(x)\\) é uma fdp (ou fmp) de uma variável aleatória \\(X\\) se e somente se\n\na. \\(f_X(x) \\ge 0\\) para todo \\(x\\).\nb. \\(\\sum_x f_X(x) = 1\\) (fmp) ou \\(\\int_{-\\infty}^{\\infty} f_X(x) \\, dx = 1\\) (fdp).\n\n\n\nComprovação. Se \\(f_X(x)\\) é uma fdp (ou fmp), então as duas propriedades são imediatas das definições. Em particular, para uma fdp, usando (1.6.3) e o Teorema 1.5.3, temos \\[\n1 = \\lim_{x \\to \\infty} F_X(x) = \\int_{-\\infty}^{\\infty} f_X(t) \\, dt.\n\\] A implicação inversa é igualmente fácil de provar. Uma vez que temos \\(f_X(x)\\), podemos definir \\(F_X(x)\\) e apelar para o Teorema 1.5.3. \\(\\square\\)\n\nDe um ponto de vista puramente matemático, qualquer função não negativa com uma integral positiva finita (ou soma) pode ser transformada em uma fdp ou fmp. Por exemplo, se \\(h(x)\\) é qualquer função não negativa que é positiva em um conjunto \\(A\\), 0 em outro lugar, e \\[\n\\int_{\\{x \\in A\\}} h(x) \\, dx = K &lt; \\infty\n\\] para alguma constante \\(K &gt; 0\\), então a função \\(f_X(x) = h(x)/K\\) é uma fdp de uma variável aleatória \\(X\\) assumindo valores em \\(A\\). Na verdade, a relação (1.6.3) nem sempre é válida porque \\(F_X(x)\\) pode ser contínua mas não diferenciável. De fato, existem variáveis aleatórias contínuas para as quais a integral não existe para nenhuma \\(f_X(x)\\). Estes casos são bastante patológicos e vamos ignorá-los. Assim, neste texto, vamos assumir que (1.6.3) é válida para qualquer variável aleatória contínua. Em textos mais avançados (por exemplo, Billingsley 1995, Seção 31) uma variável aleatória é chamada absolutamente contínua se (1.6.3) é válida.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#exercícios",
    "href": "cap-1.html#exercícios",
    "title": "Teoria da Probabilidade",
    "section": "1.7 Exercícios",
    "text": "1.7 Exercícios\n1.1 Para cada um dos seguintes experimentos, descreva o espaço amostral. (a) Lançar uma moeda quatro vezes. (b) Contar o número de folhas danificadas por insetos em uma planta. (c) Medir a vida útil (em horas) de uma marca particular de lâmpada. (d) Registrar os pesos de ratos de 10 dias de idade. (e) Observar a proporção de defeituosos em um carregamento de componentes eletrônicos.\n1.2 Verifique as seguintes identidades. (a) \\(A \\setminus B = A \\setminus (A \\cap B) = A \\cap B^c\\) (b) \\(B = (B \\cap A) \\cup (B \\cap A^c)\\) (c) \\(B \\setminus A = B \\cap A^c\\) (d) \\(A \\cup B = A \\cup (B \\cap A^c)\\)\n1.3 Termine a prova do Teorema 1.1.4. Para quaisquer eventos \\(A, B\\) e \\(C\\) definidos em um espaço amostral \\(S\\), mostre que (a) \\(A \\cup B = B \\cup A\\) e \\(A \\cap B = B \\cap A\\). (comutatividade) (b) \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\). (associatividade) (c) \\((A \\cup B)^c = A^c \\cap B^c\\) e \\((A \\cap B)^c = A^c \\cup B^c\\). (Leis de DeMorgan)\n1.4 Para eventos \\(A\\) e \\(B\\), encontre fórmulas para as probabilidades dos seguintes eventos em termos das quantidades \\(P(A), P(B)\\) e \\(P(A \\cap B)\\). (a) ou \\(A\\) ou \\(B\\) ou ambos (b) ou \\(A\\) ou \\(B\\), mas não ambos (c) pelo menos um de \\(A\\) ou \\(B\\) (d) no máximo um de \\(A\\) ou \\(B\\)\n1.5 Aproximadamente um terço de todos os gêmeos humanos são idênticos (um ovo) e dois terços são fraternos (dois ovos). Gêmeos idênticos são necessariamente do mesmo sexo, com masculino e feminino sendo igualmente prováveis. Entre gêmeos fraternos, aproximadamente um quarto são ambos do sexo feminino, um quarto são ambos do sexo masculino e metade são um macho e uma fêmea. Finalmente, entre todos os nascimentos nos EUA, aproximadamente 1 em 90 é um nascimento de gêmeos. Defina os seguintes eventos: \\[\n\\begin{align*}\nA &= \\{\\text{um nascimento nos EUA resulta em gêmeas do sexo feminino}\\} \\\\\nB &= \\{\\text{um nascimento nos EUA resulta em gêmeos idênticos}\\} \\\\\nC &= \\{\\text{um nascimento nos EUA resulta em gêmeos}\\}\n\\end{align*}\n\\] (a) Declare, em palavras, o evento \\(A \\cap B \\cap C\\). (b) Encontre \\(P(A \\cap B \\cap C)\\).\n1.6 Duas moedas, uma com \\(P(\\text{cara}) = u\\) e uma com \\(P(\\text{cara}) = w\\), devem ser lançadas juntas independentemente. Defina \\[\n\\begin{align*}\np_0 &= P(0 \\text{ caras ocorrem}), \\\\\np_1 &= P(1 \\text{ cara ocorre}), \\\\\np_2 &= P(2 \\text{ caras ocorrem}).\n\\end{align*}\n\\] Podem \\(u\\) e \\(w\\) serem escolhidos de tal forma que \\(p_0 = p_1 = p_2\\)? Prove sua resposta.\n1.7 Refira-se ao jogo de dardos do Exemplo 1.2.7. Suponha que não assumimos que a probabilidade de atingir o alvo de dardos é 1, mas sim que é proporcional à área do alvo. Assuma que o alvo de dardos é montado em uma parede que é atingida com probabilidade 1, e a parede tem área \\(A\\). (a) Usando o fato de que a probabilidade de atingir uma região é proporcional à área, construa uma função de probabilidade para \\(P(\\text{marcar } i \\text{ pontos}), i = 0, \\dots, 5\\). (Sem pontos são marcados se o alvo de dardos não for atingido.) (b) Mostre que a distribuição de probabilidade condicional \\(P(\\text{marcar } i \\text{ pontos}|\\text{alvo é atingido})\\) é exatamente a distribuição de probabilidade do Exemplo 1.2.7.\n1.8 Novamente refira-se ao jogo de dardos explicado no Exemplo 1.2.7. (a) Derive a fórmula geral para a probabilidade de marcar \\(i\\) pontos. (b) Mostre que \\(P(\\text{marcar } i \\text{ pontos})\\) é uma função decrescente de \\(i\\), isto é, conforme os pontos aumentam, a probabilidade de marcar os pontos diminui. (c) Mostre que \\(P(\\text{marcar } i \\text{ pontos})\\) é uma função de probabilidade de acordo com os Axiomas de Kolmogorov.\n1.9 Prove a versão geral das Leis de DeMorgan. Seja \\(\\{A_{\\alpha} : \\alpha \\in \\Gamma\\}\\) uma coleção (possivelmente não enumerável) de conjuntos. Prove que (a) \\((\\cup_{\\alpha} A_{\\alpha})^c = \\cap_{\\alpha} A_{\\alpha}^c\\). (b) \\((\\cap_{\\alpha} A_{\\alpha})^c = \\cup_{\\alpha} A_{\\alpha}^c\\).\n1.10 Formule e prove uma versão das Leis de DeMorgan que se aplica a uma coleção finita de conjuntos \\(A_1, \\dots, A_n\\).\n1.11 Seja \\(S\\) um espaço amostral. (a) Mostre que a coleção \\(\\mathcal{B} = \\{\\emptyset, S\\}\\) é uma sigma-álgebra. (b) Seja \\(\\mathcal{B} = \\{\\text{todos os subconjuntos de } S, \\text{ incluindo } S \\text{ ele mesmo}\\}\\). Mostre que \\(\\mathcal{B}\\) é uma sigma-álgebra. (c) Mostre que a interseção de duas sigma-álgebras é uma sigma-álgebra.\n1.12 Foi observado na Seção 1.2.1 que estatísticos que seguem a escola de deFinetti não aceitam o Axioma da Aditividade Enumerável, aderindo em vez disso ao Axioma da Aditividade Finita. (a) Mostre que o Axioma da Aditividade Enumerável implica Aditividade Finita. (b) Mostre que, por si só, o Axioma da Aditividade Finita não implica Aditividade Enumerável. Para ajudar, suponha que complementamos com o seguinte. Seja \\(A_1 \\supset A_2 \\supset \\dots \\supset A_n \\supset \\dots\\) uma sequência infinita de conjuntos aninhados cujo limite é o conjunto vazio, o que denotamos por \\(A_n \\downarrow \\emptyset\\). Considere o seguinte: Axioma da Continuidade: Se \\(A_n \\downarrow \\emptyset\\), então \\(P(A_n) \\to 0\\). Prove que o Axioma da Continuidade e o Axioma da Aditividade Finita implicam Aditividade Enumerável.\n1.13 Se \\(P(A) = \\frac{1}{3}\\) e \\(P(B^c) = \\frac{1}{4}\\), podem \\(A\\) e \\(B\\) ser disjuntos? Explique.\n1.14 Suponha que um espaço amostral \\(S\\) tenha \\(n\\) elementos. Prove que o número de subconjuntos que podem ser formados a partir dos elementos de \\(S\\) é \\(2^n\\).\n1.15 Termine a prova do Teorema 1.2.14. Use o resultado estabelecido para \\(k=2\\) como a base de um argumento de indução.\n1.16 Quantos conjuntos diferentes de iniciais podem ser formados se cada pessoa tiver um sobrenome e (a) exatamente dois nomes próprios? (b) ou um ou dois nomes próprios? (Respostas: (a) \\(26^3\\) (b) \\(26^3 + 26^2\\) (c) \\(26^4 + 26^3 + 26^2\\))\n1.17 No jogo de dominó, cada peça é marcada com dois números. As peças são simétricas de modo que o par numérico não é ordenado (assim, por exemplo, \\((2, 6) = (6, 2)\\)). Quantas peças diferentes podem ser formadas usando os números \\(1, 2, \\dots, n\\)? (Answer: \\(n(n + 1)/2\\))\n1.18 Se \\(n\\) bolas são colocadas aleatoriamente em \\(n\\) células, encontre a probabilidade de que exatamente uma célula permaneça vazia. (Answer: \\(\\binom{n}{2} n!/n^n\\))\n1.19 Se uma função multivariada tem derivadas parciais contínuas, a ordem na qual as derivadas são calculadas não importa. Assim, por exemplo, a função \\(f(x, y)\\) de duas variáveis tem parciais terceiras iguais \\[\n\\frac{\\partial^3}{\\partial x^2 \\partial y} f(x, y) = \\frac{\\partial^3}{\\partial y \\partial x^2} f(x, y).\n\\] (a) Quantas quartas derivadas parciais tem uma função de três variáveis? (b) Prove que uma função de \\(n\\) variáveis tem \\(\\binom{n+r-1}{r}\\) \\(r\\)-ésimas derivadas parciais.\n1.20 Meu telefone toca 12 vezes por semana, as chamadas sendo distribuídas aleatoriamente entre os 7 dias. Qual é a probabilidade de que eu receba pelo menos uma chamada a cada dia? (Resposta: .2285)\n1.21 Um armário contém \\(n\\) pares de sapatos. Se \\(2r\\) sapatos são escolhidos ao acaso (\\(2r &lt; n\\)), qual é a probabilidade de que não haja nenhum par correspondente na amostra? (Resposta: \\(\\binom{n}{2r} 2^{2r} / \\binom{2n}{2r}\\))\n1.22 (a) Em um sorteio de loteria contendo os 366 dias do ano (incluindo 29 de fevereiro), qual é a probabilidade de que os primeiros 180 dias sorteados (sem reposição) sejam distribuídos uniformemente entre os 12 meses? (b) Qual é a probabilidade de que os primeiros 30 dias sorteados não contenham nenhum de setembro? (Respostas: (a) \\(.167 \\times 10^{-8}\\) (b) \\(\\binom{336}{30} / \\binom{366}{30}\\))\n1.23 Duas pessoas lançam cada uma uma moeda honesta \\(n\\) vezes. Encontre a probabilidade de que eles obtenham o mesmo número de caras. (Resposta: \\(\\binom{2n}{n} (\\frac{1}{4})^n\\))\n1.24 Dois jogadores, A e B, alternadamente e independentemente lançam uma moeda e o primeiro jogador a obter uma cara ganha. Assuma que o jogador A lança primeiro. (a) Se a moeda é honesta, qual é a probabilidade de que A vença? (b) Suponha que \\(P(\\text{cara}) = p\\), não necessariamente \\(\\frac{1}{2}\\). Qual é a probabilidade de que A vença? (c) Mostre que para todo \\(p, 0 &lt; p &lt; 1, P(\\text{A vence}) &gt; \\frac{1}{2}\\). (Dica: Tente escrever \\(P(\\text{A vence})\\) em termos dos eventos \\(E_1, E_2, \\dots\\), onde \\(E_i = \\{\\text{primeira cara aparece no i-ésimo lançamento}\\}\\).) (Respostas: (a) 2/3 (b) \\(\\frac{p}{1-(1-p)^2}\\))\n1.25 Os Smith têm dois filhos. Pelo menos um deles é menino. Qual é a probabilidade de que ambos os filhos sejam meninos? (Veja Gardner 1961 para uma discussão completa deste problema.)\n1.26 Um dado honesto é lançado até que um 6 apareça. Qual é a probabilidade de que ele deva ser lançado mais de cinco vezes?\n1.27 Verifique as seguintes identidades para \\(n \\ge 2\\). (a) \\(\\sum_{k=0}^n (-1)^k \\binom{n}{k} = 0\\) (b) \\(\\sum_{k=1}^n k \\binom{n}{k} = n 2^{n-1}\\) (c) \\(\\sum_{k=1}^n (-1)^{k+1} k \\binom{n}{k} = 0\\)\n1.28 Uma maneira de aproximar fatoriais grandes é através do uso da Fórmula de Stirling: \\[\nn! \\approx \\sqrt{2\\pi n} n^n e^{-n},\n\\] uma derivação completa da qual é difícil. Em vez disso, prove o fato mais fácil, \\[\n\\lim_{n \\to \\infty} \\frac{n!}{n^{n+(1/2)} e^{-n}} = \\text{uma constante}.\n\\] (Dica: Feller 1968 procede usando a monotonicidade do logaritmo para estabelecer que \\[\n\\int_{k-1}^k \\log x \\, dx &lt; \\log k &lt; \\int_k^{k+1} \\log x \\, dx, \\quad k = 1, \\dots, n,\n\\] e consequentemente \\[\n\\int_0^n \\log x \\, dx &lt; \\log n! &lt; \\int_1^{n+1} \\log x \\, dx.\n\\] Agora compare \\(\\log n!\\) com a média das duas integrais. Veja Exercício 5.35 para outra derivação.)\n1.29 (a) Para a situação do Exemplo 1.2.20, enumere as amostras ordenadas que compõem as amostras não ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (b) Enumere as amostras ordenadas que compõem as amostras não ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (Nota: Parece haver um erro de digitação no livro original repetindo a pergunta, mas a segunda parte geralmente se refere a calcular as probabilidades associadas ou comparar os tamanhos).\n1.29 (Correção baseada no contexto do Exemplo 1.2.20) (a) Para a situação do Exemplo 1.2.20, enumere as amostras ordenadas que compõem as amostras não ordenadas \\(\\{4, 4, 12, 12\\}\\) e \\(\\{2, 9, 9, 12\\}\\). (c) Suponha que tivéssemos uma coleção de seis números, \\(\\{1, 2, 7, 8, 14, 20\\}\\). Qual é a probabilidade de sortear, com reposição, a amostra não ordenada \\(\\{2, 7, 7, 8, 14, 14\\}\\)? (d) Verifique que uma amostra não ordenada de tamanho \\(k\\), de \\(m\\) números diferentes repetidos \\(k_1, k_2, \\dots, k_m\\) vezes, tem \\(\\frac{k!}{k_1! k_2! \\dots k_m!}\\) componentes ordenados, onde \\(k_1 + k_2 + \\dots + k_m = k\\). (e) Use o resultado da parte anterior para estabelecer a identidade \\[\n\\sum_{k_1, k_2, \\dots, k_m : k_1 + k_2 + \\dots + k_m = k} \\frac{k!}{k_1! k_2! \\dots k_m!} = \\binom{k+m-1}{k}.\n\\]\n1.30 Para a coleção de seis números, \\(\\{1, 2, 7, 8, 14, 20\\}\\), desenhe um histograma da distribuição de todas as médias amostrais possíveis calculadas a partir de amostras sorteadas com reposição.\n1.31 Para a situação do Exemplo 1.2.20, a média do conjunto original de números \\(\\{2, 4, 9, 12\\}\\) é \\(\\frac{27}{4}\\), que tem a maior probabilidade. (a) Prove que, em geral, se amostramos com reposição do conjunto \\(\\{x_1, x_2, \\dots, x_n\\}\\), o resultado com média \\((x_1 + x_2 + \\dots + x_n)/n\\) é o mais provável, tendo probabilidade \\(n!/n^n\\). (b) Use a Fórmula de Stirling (Exercício 1.28) para mostrar que \\(n!/n^n \\approx \\sqrt{2\\pi n} / e^n\\) (Hall 1992, Apêndice I). (c) Mostre que a probabilidade de que um \\(x_i\\) particular esteja faltando em um resultado é \\((1 - \\frac{1}{n})^n \\to e^{-1}\\) quando \\(n \\to \\infty\\).\n1.32 Um empregador está prestes a contratar um novo empregado de um grupo de \\(N\\) candidatos, cujo potencial futuro pode ser classificado em uma escala de 1 a \\(N\\). O empregador procede de acordo com as seguintes regras: (a) Cada candidato é visto em sucessão (em ordem aleatória) e uma decisão é tomada se contrata ou não o candidato. (b) Tendo rejeitado \\(m-1\\) candidatos (\\(m &gt; 1\\)), o empregador pode contratar o \\(m\\)-ésimo candidato apenas se o \\(m\\)-ésimo candidato for melhor do que os \\(m-1\\) anteriores. Suponha que um candidato é contratado na \\(i\\)-ésima tentativa. Qual é a probabilidade de que o melhor candidato tenha sido contratado?\n1.33 Suponha que 5% dos homens e 0,25% das mulheres são daltônicos. Uma pessoa é escolhida aleatoriamente e essa pessoa é daltônica. Qual é a probabilidade de que a pessoa seja do sexo masculino? (Assuma que homens e mulheres estão em igual número.)\n1.34 Duas ninhadas de uma espécie particular de roedor nasceram, uma com dois filhotes de pêlo castanho e um de pêlo cinza (ninhada 1), e a outra com três de pêlo castanho e dois de pêlo cinza (ninhada 2). Selecionamos uma ninhada aleatoriamente e depois selecionamos uma prole aleatoriamente da ninhada selecionada. (a) Qual é a probabilidade de que o animal escolhido tenha pêlo castanho? (b) Dado que uma prole de pêlo castanho foi selecionada, qual é a probabilidade de que a amostragem tenha sido da ninhada 1?\n1.35 Prove que se \\(P(\\cdot)\\) é uma função de probabilidade legítima e \\(B\\) é um conjunto com \\(P(B) &gt; 0\\), então \\(P(\\cdot|B)\\) também satisfaz os Axiomas de Kolmogorov.\n1.36 Se a probabilidade de atingir um alvo é \\(\\frac{1}{5}\\), e dez tiros são disparados independentemente, qual é a probabilidade de o alvo ser atingido pelo menos duas vezes? Qual é a probabilidade condicional de que o alvo seja atingido pelo menos duas vezes, dado que é atingido pelo menos uma vez?\n1.37 Aqui olhamos para algumas variações do Exemplo 1.3.4. (a) No cálculo do diretor no Exemplo 1.3.4 foi assumido que se A fosse perdoado, então com igual probabilidade o diretor diria a A que B ou C morreria. No entanto, isso não precisa ser o caso. O diretor pode atribuir probabilidades \\(\\gamma\\) e \\(1-\\gamma\\) a esses eventos, como mostrado aqui:\n\n\n\nPrisioneiro perdoado\nDiretor diz a A\n\n\n\n\n\nA\nB morre\ncom probabilidade \\(\\gamma\\)\n\n\nA\nC morre\ncom probabilidade \\(1-\\gamma\\)\n\n\nB\nC morre\n\n\n\nC\nB morre\n\n\n\n\nCalcule \\(P(A|\\mathcal{W})\\) como uma função de \\(\\gamma\\). Para quais valores de \\(\\gamma\\) é \\(P(A|\\mathcal{W})\\) menor que, igual a, ou maior que \\(\\frac{1}{3}\\)? (b) Suponha novamente que \\(\\gamma = \\frac{1}{2}\\), como no texto. Depois que o diretor diz a A que B vai morrer, A pensa um pouco e percebe que seu cálculo original era falso. No entanto, A então tem uma ideia brilhante. A pede ao diretor se ele pode trocar de destino com C. O diretor, pensando que nenhuma informação foi passada, concorda. Prove que o raciocínio de A agora está correto e que sua probabilidade de sobrevivência saltou para \\(\\frac{2}{3}\\)! Um problema semelhante, mas um pouco mais complicado, o “problema de Monty Hall”, é discutido por Selvin (1975). O problema nesta guisa ganhou uma quantidade razoável de notoriedade quando apareceu em uma revista de domingo (vos Savant 1990) juntamente com uma resposta correta, mas com explicação questionável. O debate que se seguiu foi até relatado na primeira página do Sunday New York Times (Tierney 1991). Uma análise completa e um tanto divertida é dada por Morgan et al. (1991) (veja também a resposta de vos Savant 1991). Chun (1999) praticamente esgota o problema com uma análise muito completa.\n1.38 Prove cada uma das seguintes afirmações. (Assuma que qualquer evento condicionante tem probabilidade positiva.) (a) Se \\(P(B) = 1\\), então \\(P(A|B) = P(A)\\) para qualquer \\(A\\). (b) Se \\(A \\subset B\\), então \\(P(B|A) = 1\\) e \\(P(A|B) = P(A)/P(B)\\). (c) Se \\(A\\) e \\(B\\) são mutuamente exclusivos, então \\[\nP(A|A \\cup B) = \\frac{P(A)}{P(A) + P(B)}.\n\\] (d) \\(P(A \\cap B \\cap C) = P(A|B \\cap C)P(B|C)P(C)\\).\n1.39 Um par de eventos \\(A\\) e \\(B\\) não pode ser simultaneamente mutuamente exclusivo e independente. Prove que se \\(P(A) &gt; 0\\) e \\(P(B) &gt; 0\\), então: (a) Se \\(A\\) e \\(B\\) são mutuamente exclusivos, eles não podem ser independentes. (b) Se \\(A\\) e \\(B\\) são independentes, eles não podem ser mutuamente exclusivos.\n1.40 Termine a prova do Teorema 1.3.9 provando as partes (b) e (c).\n1.41 Como no Exemplo 1.3.6, considere sinais de telégrafo “ponto” e “traço” enviados na proporção 3:4, onde transmissões erráticas fazem com que um ponto se torne um traço com probabilidade \\(\\frac{1}{4}\\) e um traço se torne um ponto com probabilidade \\(\\frac{1}{3}\\). (a) Se um traço é recebido, qual é a probabilidade de que um traço tenha sido enviado? (b) Assumindo independência entre sinais, se a mensagem ponto-ponto foi recebida, qual é a distribuição de probabilidade das quatro mensagens possíveis que poderiam ter sido enviadas?\n1.42 A identidade de inclusão-exclusão da Miscelânea 1.8.1 recebe seu nome do fato de que é provada pelo método de inclusão e exclusão (Feller 1968, Seção IV.1). Aqui vamos entrar nos detalhes. A probabilidade \\(P(\\cup_{i=1}^n A_i)\\) é a soma das probabilidades de todos os pontos amostrais que estão contidos em pelo menos um dos \\(A_i\\)s. O método de inclusão e exclusão é uma receita para contar esses pontos. (a) Seja \\(E_k\\) o conjunto de todos os pontos amostrais que estão contidos em exatamente \\(k\\) dos eventos \\(A_1, A_2, \\dots, A_n\\). Mostre que \\(P(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n P(E_i)\\). (b) Se \\(E_1\\) não é vazio, mostre que \\(P(E_1) = \\sum_{i=1}^n P(A_i)\\). (c) Sem perda de generalidade, assuma que \\(E_k\\) está contido em \\(A_1, A_2, \\dots, A_k\\). Mostre que \\(P(E_k)\\) aparece \\(k\\) vezes na soma \\(P_1\\), \\(\\binom{k}{2}\\) vezes na soma \\(P_2\\), \\(\\binom{k}{3}\\) vezes na soma \\(P_3\\), etc. (d) Mostre que \\[\nk - \\binom{k}{2} + \\binom{k}{3} - \\dots \\pm \\binom{k}{k} = 1.\n\\] (Veja Exercício 1.27.) (e) Mostre que as partes (a) – (c) implicam \\(\\sum_{i=1}^n P(E_i) = P_1 - P_2 = \\dots \\pm P_n\\), estabelecendo a identidade de inclusão-exclusão.\n1.43 Para a identidade de inclusão-exclusão da Miscelânea 1.8.1: (a) Derive a Desigualdade de Boole e a Desigualdade de Bonferroni a partir da identidade de inclusão-exclusão. (b) Mostre que os \\(P_i\\) satisfazem \\(P_i \\ge P_j\\) se \\(i \\ge j\\) e que a sequência de limites na Miscelânea 1.8.1 melhora à medida que o número de termos aumenta. (c) Tipicamente, conforme o número de termos no limite aumenta, o limite se torna mais útil. No entanto, Schwager (1984) adverte que existem alguns casos onde não há muita melhora, em particular se os \\(A_i\\)s são altamente correlacionados. Examine o que acontece com a sequência de limites no caso extremo quando \\(A_i = A\\) para todo \\(i\\). (Veja Worsley 1982 e a correspondência de Worsley 1985 e Schwager 1985.)\n1.44 Testes padronizados fornecem uma aplicação interessante da teoria da probabilidade. Suponha primeiro que um teste consiste em 20 questões de múltipla escolha, cada uma com 4 respostas possíveis. Se o aluno chuta em cada questão, então a realização do exame pode ser modelada como uma sequência de 20 eventos independentes. Encontre a probabilidade de que o aluno acerte pelo menos 10 questões, dado que ele está chutando.\n1.45 Mostre que a função de probabilidade induzida definida em (1.4.1) define uma função de probabilidade legítima que satisfaz os Axiomas de Kolmogorov.\n1.46 Sete bolas são distribuídas aleatoriamente em sete células. Seja \\(X_i = \\text{o número de células contendo exatamente } i \\text{ bolas}\\). Qual é a distribuição de probabilidade de \\(X_3\\)? (Isto é, encontre \\(P(X_3 = x)\\) para cada \\(x\\) possível.)\n1.47 Prove que as seguintes funções são cdfs. (a) \\(\\frac{1}{2} + \\frac{1}{\\pi} \\tan^{-1}(x), x \\in (-\\infty, \\infty)\\) (b) \\((1 + e^{-x})^{-1}, x \\in (-\\infty, \\infty)\\) (c) \\(e^{-e^{-x}}, x \\in (-\\infty, \\infty)\\) (d) \\(1 - e^{-x}, x \\in (0, \\infty)\\) (e) a função definida em (1.5.6)\n1.48 Prove a parte de necessidade do Teorema 1.5.3.\n1.49 Uma cdf \\(F_X\\) é estocasticamente maior que uma cdf \\(F_Y\\) se \\(F_X(t) \\le F_Y(t)\\) para todo \\(t\\) e \\(F_X(t) &lt; F_Y(t)\\) para algum \\(t\\). Prove que se \\(X \\sim F_X\\) e \\(Y \\sim F_Y\\), então \\[\nP(X &gt; t) \\ge P(Y &gt; t) \\quad \\text{para todo } t\n\\] e \\[\nP(X &gt; t) &gt; P(Y &gt; t) \\quad \\text{para algum } t,\n\\] isto é, \\(X\\) tende a ser maior que \\(Y\\).\n1.50 Verifique a fórmula (1.5.4), a fórmula para a soma parcial da série geométrica.\n1.51 Uma loja de eletrodomésticos recebe um carregamento de 30 fornos de microondas, 5 dos quais são (desconhecidos pelo gerente) defeituosos. O gerente da loja seleciona 4 fornos aleatoriamente, sem reposição, para testar a fim de ver se eles são defeituosos. Seja \\(X = \\text{número de defeituosos encontrados}\\). Calcule a fmp e a cdf de \\(X\\) e plote a cdf.\n1.52 Seja \\(X\\) uma variável aleatória contínua com pdf \\(f(x)\\) e cdf \\(F(x)\\). Para um número fixo \\(x_0\\), defina a função \\[\ng(x) = \\begin{cases} f(x)/[1 - F(x_0)] & x \\ge x_0 \\\\ 0 & x &lt; x_0. \\end{cases}\n\\] Prove que \\(g(x)\\) é uma pdf. (Assuma que \\(F(x_0) &lt; 1\\).)\n1.53 Um certo rio inunda todos os anos. Suponha que a marca de água baixa é definida em 1 e a marca de água alta \\(Y\\) tem função de distribuição \\[\nF_Y(y) = P(Y \\le y) = 1 - \\frac{1}{y^2}, \\quad 1 \\le y &lt; \\infty.\n\\] (a) Verifique que \\(F_Y(y)\\) é uma cdf. (b) Encontre \\(f_Y(y)\\), a pdf de \\(Y\\). (c) Se a marca de água baixa é redefinida em 0 e usamos uma unidade de medida que é \\(\\frac{1}{10}\\) daquela dada anteriormente, a marca de água alta se torna \\(Z = 10(Y - 1)\\). Encontre \\(F_Z(z)\\).\n1.54 Para cada uma das seguintes, determine o valor de \\(c\\) que faz de \\(f(x)\\) uma pdf. (a) \\(f(x) = c \\sin x, 0 &lt; x &lt; \\pi/2\\) (b) \\(f(x) = c e^{-|x|}, -\\infty &lt; x &lt; \\infty\\)\n1.55 Um dispositivo eletrônico tem tempo de vida denotado por \\(T\\). O dispositivo tem valor \\(V = 5\\) se ele falhar antes do tempo \\(t = 3\\); caso contrário, ele tem valor \\(V = 2T\\). Encontre a cdf de \\(V\\), se \\(T\\) tem pdf \\[\nf_T(t) = \\frac{1}{1.5} e^{-t/(1.5)}, \\quad t &gt; 0.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "cap-1.html#assuntos-diversos",
    "href": "cap-1.html#assuntos-diversos",
    "title": "Teoria da Probabilidade",
    "section": "1.8 Assuntos Diversos",
    "text": "1.8 Assuntos Diversos\n\n1.8.1 Bonferroni e Além\nO limite de Bonferroni de (1.2.10), ou Desigualdade de Boole (Teorema 1.2.11), fornece limites simples para a probabilidade de uma interseção ou união. Esses limites podem ser tornados cada vez mais precisos com a seguinte expansão.\nPara conjuntos \\(A_1, A_2, \\dots, A_n\\), criamos um novo conjunto de interseções aninhadas como segue. Seja \\[\nP_1 = \\sum_{i=1}^n P(A_i)\n\\] \\[\nP_2 = \\sum_{1 \\le i &lt; j \\le n} P(A_i \\cap A_j)\n\\] \\[\nP_3 = \\sum_{1 \\le i &lt; j &lt; k \\le n} P(A_i \\cap A_j \\cap A_k)\n\\] \\[\n\\vdots\n\\] \\[\nP_n = P(A_1 \\cap A_2 \\cap \\dots \\cap A_n).\n\\]\nEntão a identidade de inclusão-exclusão diz que \\[\nP(A_1 \\cup A_2 \\cup \\dots \\cup A_n) = P_1 - P_2 + P_3 - P_4 + \\dots \\pm P_n.\n\\] Além disso, os \\(P_i\\) são ordenados de tal forma que \\(P_i \\ge P_j\\) se \\(i \\le j\\), e temos a sequência de limites superiores e inferiores \\[\n\\begin{align*}\nP_1 \\ge P(\\cup_{i=1}^n A_i) &\\ge P_1 - P_2 \\\\\nP_1 - P_2 + P_3 \\ge P(\\cup_{i=1}^n A_i) &\\ge P_1 - P_2 + P_3 - P_4 \\\\\n\\vdots\n\\end{align*}\n\\]\nVeja Exercícios 1.42 e 1.43 para detalhes. Esses limites tornam-se cada vez mais apertados à medida que o número de termos aumenta, e eles fornecem um refinamento dos limites originais de Bonferroni. Aplicações desses limites incluem a aproximação de probabilidades de sequências (runs) (Karlin e Ost 1988) e procedimentos de comparações múltiplas (Naiman e Wynn 1992).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoria da Probabilidade</span>"
    ]
  },
  {
    "objectID": "index.html#aviso-legal",
    "href": "index.html#aviso-legal",
    "title": "Inferência Estatística",
    "section": "Aviso Legal",
    "text": "Aviso Legal\n\n⚠️ Nota Importante\nEsta tradução não é licenciada e não tem fins lucrativos. Seu único objetivo é facilitar o acesso de estudantes de estatística de língua portuguesa a um conteúdo sólido e fundamental em inferência estatística.\nPara uso acadêmico e profissional, recomendamos fortemente a aquisição da obra original em inglês.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-os-autores",
    "href": "index.html#sobre-os-autores",
    "title": "Inferência Estatística",
    "section": "Sobre os Autores",
    "text": "Sobre os Autores\nGeorge Casella (1951–2012) foi um estatístico americano e professor da Universidade da Flórida. Reconhecido por suas contribuições em inferência estatística, estatística bayesiana e métodos de Monte Carlo, foi eleito Fellow da American Statistical Association e do Institute of Mathematical Statistics.\nRoger L. Berger é professor emérito da Universidade Estadual da Carolina do Norte. Suas áreas de pesquisa incluem inferência estatística, bioestatística e educação estatística.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "index.html#como-navegar",
    "href": "index.html#como-navegar",
    "title": "Inferência Estatística",
    "section": "Como Navegar",
    "text": "Como Navegar\nUtilize o menu lateral para acessar os capítulos disponíveis. Esta tradução está em andamento, e novos capítulos serão adicionados progressivamente.\n\n📚 Referência Original\nCasella, G., & Berger, R. L. (2002). Statistical Inference (2nd ed.). Duxbury/Thomson Learning.\nISBN: 0-534-24312-6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferência Estatística</span>"
    ]
  },
  {
    "objectID": "cap-2.html",
    "href": "cap-2.html",
    "title": "Transformações e Esperanças",
    "section": "",
    "text": "2.1 Distribuições de Funções de uma Variável Aleatória\nFrequentemente, se somos capazes de modelar um fenômeno em termos de uma variável aleatória \\(X\\) com fda \\(F_X(x)\\), também estaremos interessados no comportamento de funções de \\(X\\). Neste capítulo, estudamos técnicas que nos permitem obter informações sobre funções de \\(X\\) que podem ser de interesse, informações que podem variar desde muito completas (as distribuições dessas funções) até mais vagas (o comportamento médio).\nSe \\(X\\) é uma variável aleatória com fda \\(F_X(x)\\), então qualquer função de \\(X\\), digamos \\(g(X)\\), também é uma variável aleatória. Frequentemente, \\(g(X)\\) é de interesse por si só e escrevemos \\(Y = g(X)\\) para denotar a nova variável aleatória \\(g(X)\\). Como \\(Y\\) é uma função de \\(X\\), podemos descrever o comportamento probabilístico de \\(Y\\) em termos do comportamento de \\(X\\). Isto é, para qualquer conjunto \\(A\\),\n\\[\nP(Y \\in A) = P(g(X) \\in A),\n\\]\nmostrando que a distribuição de \\(Y\\) depende das funções \\(F_X\\) e \\(g\\). Dependendo da escolha de \\(g\\), às vezes é possível obter uma expressão tratável para essa probabilidade.\nFormalmente, se escrevermos \\(y = g(x)\\), a função \\(g(x)\\) define um mapeamento do espaço amostral original de \\(X\\), \\(\\mathcal{X}\\), para um novo espaço amostral, \\(\\mathcal{Y}\\), o espaço amostral da variável aleatória \\(Y\\). Isto é,\n\\[\ng(x): \\mathcal{X} \\to \\mathcal{Y}.\n\\]\nAssociamos a \\(g\\) um mapeamento inverso, denotado por \\(g^{-1}\\), que é um mapeamento de subconjuntos de \\(\\mathcal{Y}\\) para subconjuntos de \\(\\mathcal{X}\\), e é definido por\n\\[\ng^{-1}(A) = \\{x \\in \\mathcal{X} : g(x) \\in A\\}.\n\\tag{3.1}\\]\nNote que o mapeamento \\(g^{-1}\\) leva conjuntos em conjuntos, ou seja, \\(g^{-1}(A)\\) é o conjunto de pontos em \\(\\mathcal{X}\\) que \\(g(x)\\) leva para o conjunto \\(A\\). É possível que \\(A\\) seja um conjunto de um único ponto, digamos \\(A = \\{y\\}\\). Então\n\\[\ng^{-1}(\\{y\\}) = \\{x \\in \\mathcal{X} : g(x) = y\\}.\n\\]\nNeste caso, frequentemente escrevemos \\(g^{-1}(y)\\) em vez de \\(g^{-1}(\\{y\\})\\). A quantidade \\(g^{-1}(y)\\) ainda pode ser um conjunto, no entanto, se houver mais de um \\(x\\) para o qual \\(g(x) = y\\). Se houver apenas um \\(x\\) para o qual \\(g(x) = y\\), então \\(g^{-1}(y)\\) é o conjunto de ponto \\(\\{x\\}\\), e escreveremos \\(g^{-1}(y) = x\\). Se a variável aleatória \\(Y\\) for agora definida por \\(Y = g(X)\\), podemos escrever para qualquer conjunto \\(A \\subset \\mathcal{Y}\\),\n\\[\n\\begin{aligned}\nP(Y \\in A) &= P(g(X) \\in A) \\\\\n&= P(\\{x \\in \\mathcal{X} : g(x) \\in A\\}) \\\\\n&= P(X \\in g^{-1}(A)).\n\\end{aligned}\n\\tag{3.2}\\]\nIsto define a distribuição de probabilidade de \\(Y\\). É imediato mostrar que esta distribuição de probabilidade satisfaz os Axiomas de Kolmogorov.\nSe \\(X\\) é uma variável aleatória discreta, então \\(\\mathcal{X}\\) é enumerável. O espaço amostral para \\(Y = g(X)\\) é \\(\\mathcal{Y} = \\{y : y = g(x), x \\in \\mathcal{X}\\}\\), que também é um conjunto enumerável. Assim, \\(Y\\) também é uma variável aleatória discreta. Usando Equação 3.2, a fmp para \\(Y\\) é\n\\[\nf_Y(y) = P(Y = y) = \\sum_{x \\in g^{-1}(y)} P(X = x) = \\sum_{x \\in g^{-1}(y)} f_X(x), \\text{ para } y \\in \\mathcal{Y},\n\\]\ne \\(f_Y(y) = 0\\) para \\(y \\notin \\mathcal{Y}\\). Neste caso, encontrar a fmp de \\(Y\\) envolve simplesmente identificar \\(g^{-1}(y)\\), para cada \\(y \\in \\mathcal{Y}\\), e somar as probabilidades apropriadas.\nSe \\(X\\) e \\(Y\\) são variáveis aleatórias contínuas, então em alguns casos é possível encontrar fórmulas simples para a fda e fdp de \\(Y\\) em termos da fda e fdp de \\(X\\) e da função \\(g\\). No restante desta seção, consideramos alguns desses casos.\nA fda de \\(Y = g(X)\\) é\n\\[\n\\begin{aligned}\nF_Y(y) &= P(Y \\leq y) \\\\\n&= P(g(X) \\leq y) \\\\\n&= P(\\{x \\in \\mathcal{X} : g(x) \\leq y\\}) \\\\\n&= \\int_{\\{x \\in \\mathcal{X} : g(x) \\leq y\\}} f_X(x) dx.\n\\end{aligned}\n\\tag{3.4}\\]\nÀs vezes, pode haver dificuldade em identificar \\(\\{x \\in \\mathcal{X} : g(x) \\leq y\\}\\) e realizar a integração de \\(f_X(x)\\) sobre esta região, como mostra o próximo exemplo.\nAo realizar transformações, é importante manter o controle sobre os espaços amostrais das variáveis aleatórias; caso contrário, muita confusão pode surgir. Ao fazer uma transformação de \\(X\\) para \\(Y = g(X)\\), é mais conveniente usar\n\\[\n\\mathcal{X} = \\{x : f_X(x) &gt; 0\\} \\quad \\text{e} \\quad \\mathcal{Y} = \\{y : y = g(x) \\text{ para algum } x \\in \\mathcal{X}\\}.\n\\tag{3.7}\\]\nA fdp da variável aleatória \\(X\\) é positiva apenas no conjunto \\(\\mathcal{X}\\) e é zero em outros lugares. Tal conjunto é chamado de conjunto suporte de uma distribuição ou, mais informalmente, o suporte de uma distribuição. Esta terminologia também pode ser aplicada a uma fmp ou, em geral, a qualquer função não negativa.\nÉ mais fácil lidar com funções \\(g(x)\\) que são monotônicas, isto é, aquelas que satisfazem ou\n\\[\nu &gt; v \\implies g(u) &gt; g(v) \\quad \\text{(crescente)} \\quad \\text{ou} \\quad u &lt; v \\implies g(u) &gt; g(v) \\quad \\text{(decrescente)}.\n\\]\nSe a transformação \\(x \\to g(x)\\) é monotônica, então ela é um-para-um (injetora) e sobre \\(\\mathcal{X} \\to \\mathcal{Y}\\) (sobrejetora). Isto é, cada \\(x\\) vai para apenas um \\(y\\) e cada \\(y\\) vem de no máximo um \\(x\\) (um-para-um). Além disso, para \\(\\mathcal{Y}\\) definido como em Equação 3.7, para cada \\(y \\in \\mathcal{Y}\\) existe um \\(x \\in \\mathcal{X}\\) tal que \\(g(x) = y\\) (sobre). Assim, a transformação \\(g\\) associa exclusivamente \\(xs\\) e \\(ys\\). Se \\(g\\) for monotônica, então \\(g^{-1}\\) terá um único valor, isto é, \\(g^{-1}(y) = x\\) se, e somente se, \\(y = g(x)\\). Se \\(g\\) for crescente, isso implica que\n\\[\n\\{x \\in \\mathcal{X} : g(x) \\leq y\\} = \\{x \\in \\mathcal{X} : g^{-1}(g(x)) \\leq g^{-1}(y)\\} = \\{x \\in \\mathcal{X} : x \\leq g^{-1}(y)\\}.\n\\tag{3.8}\\]\nSe \\(g\\) for decrescente, isso implica que\n\\[\n\\{x \\in \\mathcal{X} : g(x) \\leq y\\} = \\{x \\in \\mathcal{X} : g^{-1}(g(x)) \\geq g^{-1}(y)\\} = \\{x \\in \\mathcal{X} : x \\geq g^{-1}(y)\\}.\n\\tag{3.9}\\]\n(Um gráfico ilustrará por que a desigualdade se inverte no caso decrescente.) Se \\(g(x)\\) for uma função crescente, então usando Equação 3.4, podemos escrever\n\\[\nF_Y(y) = \\int_{\\{x \\in \\mathcal{X} : x \\leq g^{-1}(y)\\}} f_X(x) dx = \\int_{-\\infty}^{g^{-1}(y)} f_X(x) dx = F_X(g^{-1}(y)).\n\\]\nSe \\(g(x)\\) for decrescente, temos\n\\[\nF_Y(y) = \\int_{g^{-1}(y)}^{\\infty} f_X(x) dx = 1 - F_X(g^{-1}(y)).\n\\]\nA continuidade de \\(X\\) é usada para obter a segunda igualdade. Resumimos esses resultados no seguinte teorema.\nSe a fdp de \\(Y\\) for contínua, ela pode ser obtida diferenciando a fda. O resultado da expressão é dado no seguinte teorema.\nEm muitas aplicações, a função \\(g\\) pode não ser nem crescente nem decrescente, portanto os resultados acima não se aplicarão. No entanto, é frequente o caso em que \\(g\\) será monotônica em certos intervalos, e isso nos permite obter uma expressão para \\(Y = g(X)\\).\nNote que a fdp de \\(Y\\) em Equação 3.11 é expressa como a soma de duas partes, partes que representam os intervalos onde \\(g(x) = x^2\\) é monotônica. Em geral, este será o caso. ||\nO ponto importante no Teorema 2.1.8 é que \\(\\mathcal{X}\\) pode ser dividido em conjuntos \\(A_1, \\dots, A_k\\) tais que \\(g(x)\\) é monotônica em cada \\(A_i\\). Podemos ignorar o “conjunto excepcional” \\(A_0\\) já que \\(P(X \\in A_0) = 0\\).\nEncerramos esta seção com uma transformação especial e muito útil.\nAntes de provarmos este teorema, faremos uma breve digressão para analisar \\(F_X^{-1}\\), o inverso da fda \\(F_X\\), em mais detalhes. Se \\(F_X\\) for estritamente crescente, então \\(F_X^{-1}\\) é bem definida por\n\\[\nF_X^{-1}(y) = x \\iff F_X(x) = y.\n\\tag{3.12}\\]\nNo entanto, se \\(F_X\\) for constante em algum intervalo, então \\(F_X^{-1}\\) não é bem definida por Equação 3.12, como ilustra a Figura 3.2. Esse problema é evitado definindo \\(F_X^{-1}(y)\\) para \\(0 &lt; y &lt; 1\\) por\n\\[\nF_X^{-1}(y) = \\inf\\{x : F_X(x) \\geq y\\}.\n\\tag{3.13}\\]\nNos pontos extremos, temos \\(P(Y \\leq y) = 1\\) para \\(y \\geq 1\\) e \\(P(Y \\leq y) = 0\\) para \\(y \\leq 0\\), mostrando que \\(Y\\) possui uma distribuição uniforme.\nO raciocínio por trás da igualdade\n\\[P(F_X^{-1}(F_X(X)) \\leq F_X^{-1}(y)) = P(X \\leq F_X^{-1}(y))\\]\né um tanto sutil e merece atenção adicional. Se \\(F_X\\) for estritamente crescente, então é verdade que \\(F_X^{-1}(F_X(x)) = x\\) (consulte a Figura 3.2(a)). No entanto, se \\(F_X\\) for constante (plana), pode ser que \\(F_X^{-1}(F_X(x)) \\neq x\\). Suponha que \\(F_X\\) seja como na Figura 3.2(b) e considere \\(x \\in [x_1, x_2]\\). Então \\(F_X^{-1}(F_X(x)) = x_1\\) para qualquer \\(x\\) neste intervalo. Mesmo neste caso, a igualdade de probabilidade se mantém, visto que \\(P(X \\leq x) = P(X \\leq x_1)\\) para qualquer \\(x \\in [x_1, x_2]\\). A função de distribuição acumulada (cdf) plana denota uma região de probabilidade zero (\\(P(x_1 &lt; X \\leq x) = F_X(x) - F_X(x_1) = 0\\)).\nUma aplicação do Teorema 2.1.10 está na geração de amostras aleatórias de uma distribuição específica. Se for necessário gerar uma observação \\(X\\) de uma população com cdf \\(F_X\\), precisamos apenas gerar um número aleatório uniforme \\(U\\), entre 0 e 1, e resolver para \\(x\\) na equação \\(F_X(x) = u\\). (Para muitas distribuições, existem outros métodos de geração de observações que consomem menos tempo computacional, mas este método ainda é útil devido à sua aplicabilidade geral.)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#conteúdo-previsto",
    "href": "cap-2.html#conteúdo-previsto",
    "title": "Transformações e Esperanças",
    "section": "",
    "text": "Distribuições de Funções de uma Variável Aleatória\nValores Esperados (Esperança)\nMomentos e Funções Geradoras de Momentos\nDiferenciação sob o Sinal de Integral",
    "crumbs": [
      "Parte II: Transformações e Distribuições",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-3.html",
    "href": "cap-3.html",
    "title": "Famílias Comuns de Distribuições",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Famílias Comuns de Distribuições</span>"
    ]
  },
  {
    "objectID": "cap-3.html#conteúdo-previsto",
    "href": "cap-3.html#conteúdo-previsto",
    "title": "Famílias Comuns de Distribuições",
    "section": "",
    "text": "Introdução\nDistribuições Discretas\nDistribuições Contínuas\nFamílias Exponenciais\nFamílias de Localização e Escala\nDesigualdades e Identidades",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Famílias Comuns de Distribuições</span>"
    ]
  },
  {
    "objectID": "cap-4.html",
    "href": "cap-4.html",
    "title": "Múltiplas Variáveis Aleatórias",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte II: Transformações e Distribuições",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Múltiplas Variáveis Aleatórias</span>"
    ]
  },
  {
    "objectID": "cap-4.html#conteúdo-previsto",
    "href": "cap-4.html#conteúdo-previsto",
    "title": "Múltiplas Variáveis Aleatórias",
    "section": "",
    "text": "Distribuições Conjuntas e Marginais\nDistribuições Condicionais e Independência\nTransformações Bivariadas\nModelos Hierárquicos e Distribuições de Mistura\nCovariância e Correlação\nDistribuições Multivariadas\nDesigualdades",
    "crumbs": [
      "Parte II: Transformações e Distribuições",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Múltiplas Variáveis Aleatórias</span>"
    ]
  },
  {
    "objectID": "cap-5.html",
    "href": "cap-5.html",
    "title": "Propriedades de uma Amostra Aleatória",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte III: Amostras e Redução de Dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Propriedades de uma Amostra Aleatória</span>"
    ]
  },
  {
    "objectID": "cap-5.html#conteúdo-previsto",
    "href": "cap-5.html#conteúdo-previsto",
    "title": "Propriedades de uma Amostra Aleatória",
    "section": "",
    "text": "Conceitos Básicos de Amostras Aleatórias\nSomas de Variáveis Aleatórias de uma Amostra Aleatória\nAmostragem da Distribuição Normal\nEstatísticas de Ordem\nConceitos de Convergência\n\nConvergência em Probabilidade\nConvergência Quase Certa\nConvergência em Distribuição\nO Método Delta\n\nGerando uma Amostra Aleatória",
    "crumbs": [
      "Parte III: Amostras e Redução de Dados",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Propriedades de uma Amostra Aleatória</span>"
    ]
  },
  {
    "objectID": "cap-6.html",
    "href": "cap-6.html",
    "title": "Princípios de Redução de Dados",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte III: Amostras e Redução de Dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Princípios de Redução de Dados</span>"
    ]
  },
  {
    "objectID": "cap-6.html#conteúdo-previsto",
    "href": "cap-6.html#conteúdo-previsto",
    "title": "Princípios de Redução de Dados",
    "section": "",
    "text": "O Princípio da Suficiência\n\nEstatísticas Suficientes\nEstatísticas Suficientes Mínimas\nEstatísticas Ancilares\nEstatísticas Suficientes, Completas e Ancilares\n\nO Princípio da Verossimilhança\n\nA Função de Verossimilhança\nO Princípio da Verossimilhança Formal\n\nO Princípio da Equivariância",
    "crumbs": [
      "Parte III: Amostras e Redução de Dados",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Princípios de Redução de Dados</span>"
    ]
  },
  {
    "objectID": "cap-7.html",
    "href": "cap-7.html",
    "title": "Estimação Pontual",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estimação Pontual</span>"
    ]
  },
  {
    "objectID": "cap-7.html#conteúdo-previsto",
    "href": "cap-7.html#conteúdo-previsto",
    "title": "Estimação Pontual",
    "section": "",
    "text": "Métodos para Encontrar Estimadores\n\nMétodo dos Momentos\nEstimadores de Máxima Verossimilhança\nEstimadores de Bayes\nO Algoritmo EM\n\nMétodos de Avaliação de Estimadores\n\nErro Quadrático Médio\nMelhores Estimadores Não Viesados\nSuficiência e Não-viesamento\nOtimalidade da Função de Perda",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estimação Pontual</span>"
    ]
  },
  {
    "objectID": "cap-8.html",
    "href": "cap-8.html",
    "title": "Teste de Hipóteses",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teste de Hipóteses</span>"
    ]
  },
  {
    "objectID": "cap-8.html#conteúdo-previsto",
    "href": "cap-8.html#conteúdo-previsto",
    "title": "Teste de Hipóteses",
    "section": "",
    "text": "Métodos para Encontrar Testes\n\nTestes de Razão de Verossimilhança\nTestes Bayesianos\nTestes de União-Interseção e Interseção-União\n\nMétodos de Avaliação de Testes\n\nProbabilidades de Erro e Função Poder\nTestes Mais Poderosos\nTamanhos de Testes de União-Interseção\nP-valores",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teste de Hipóteses</span>"
    ]
  },
  {
    "objectID": "cap-9.html",
    "href": "cap-9.html",
    "title": "Estimação por Intervalo",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Estimação por Intervalo</span>"
    ]
  },
  {
    "objectID": "cap-9.html#conteúdo-previsto",
    "href": "cap-9.html#conteúdo-previsto",
    "title": "Estimação por Intervalo",
    "section": "",
    "text": "Métodos para Encontrar Estimadores de Intervalo\n\nInvertendo uma Estatística de Teste\nQuantidades Pivotais\nPivotando a FDA\nIntervalos Bayesianos\n\nMétodos de Avaliação de Estimadores de Intervalo\n\nTamanho e Probabilidade de Cobertura\nOtimalidade Relacionada a Testes\nOtimalidade Bayesiana\nOtimalidade da Função de Perda",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Estimação por Intervalo</span>"
    ]
  },
  {
    "objectID": "cap-10.html",
    "href": "cap-10.html",
    "title": "Avaliações Assintóticas",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Avaliações Assintóticas</span>"
    ]
  },
  {
    "objectID": "cap-10.html#conteúdo-previsto",
    "href": "cap-10.html#conteúdo-previsto",
    "title": "Avaliações Assintóticas",
    "section": "",
    "text": "Estimação Pontual\n\nConsistência\nEficiência\nCálculos e Comparações\nBootstrap\n\nRobustez\n\nA Média e a Mediana\nM-Estimadores\n\nTeste de Hipóteses\n\nDistribuição Assintótica de TRVs\nOutros Testes com Grandes Amostras\n\nEstimação por Intervalo\n\nIntervalos de Verossimilhança Aproximada\nOutros Intervalos Aproximados (e Robustos)",
    "crumbs": [
      "Parte IV: Inferência",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Avaliações Assintóticas</span>"
    ]
  },
  {
    "objectID": "cap-11.html",
    "href": "cap-11.html",
    "title": "Análise de Variância e Regressão",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte V: Modelos Lineares",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Análise de Variância e Regressão</span>"
    ]
  },
  {
    "objectID": "cap-11.html#conteúdo-previsto",
    "href": "cap-11.html#conteúdo-previsto",
    "title": "Análise de Variância e Regressão",
    "section": "",
    "text": "Análise de Variância (ANOVA) de Um Fator\nRegressão Linear Simples",
    "crumbs": [
      "Parte V: Modelos Lineares",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Análise de Variância e Regressão</span>"
    ]
  },
  {
    "objectID": "cap-12.html",
    "href": "cap-12.html",
    "title": "Modelos de Regressão",
    "section": "",
    "text": "Conteúdo Previsto\nEste capítulo abordará:",
    "crumbs": [
      "Parte V: Modelos Lineares",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Modelos de Regressão</span>"
    ]
  },
  {
    "objectID": "cap-12.html#conteúdo-previsto",
    "href": "cap-12.html#conteúdo-previsto",
    "title": "Modelos de Regressão",
    "section": "",
    "text": "Introdução aos Modelos de Regressão\nEstimação e Teste com Erros Normais\nEstimação e Predição em um Dado \\(x = x_0\\)\nInferência Simultânea",
    "crumbs": [
      "Parte V: Modelos Lineares",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Modelos de Regressão</span>"
    ]
  },
  {
    "objectID": "cap-2.html#distribuições-de-funções-de-uma-variável-aleatória",
    "href": "cap-2.html#distribuições-de-funções-de-uma-variável-aleatória",
    "title": "Transformações e Esperanças",
    "section": "",
    "text": "Exemplo 2.1.1 (Transformação binomial)\nUma variável aleatória discreta \\(X\\) tem uma distribuição binomial se sua fmp for da forma\n\\[\nf_X(x) = P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n,\n\\tag{3.3}\\]\nonde \\(n\\) é um inteiro positivo e \\(0 \\leq p \\leq 1\\). Valores como \\(n\\) e \\(p\\) que podem ser ajustados para diferentes valores, produzindo diferentes distribuições de probabilidade, são chamados de parâmetros. Considere a variável aleatória \\(Y = g(X)\\), onde \\(g(x) = n - x\\). Isto é, \\(Y = n - X\\). Aqui \\(\\mathcal{X} = \\{0, 1, \\dots, n\\}\\) e \\(\\mathcal{Y} = \\{y : y = g(x), x \\in \\mathcal{X}\\} = \\{0, 1, \\dots, n\\}\\). Para qualquer \\(y \\in \\mathcal{Y}\\), \\(n - x = g(x) = y\\) se, e somente se, \\(x = n - y\\). Assim, \\(g^{-1}(y)\\) é o ponto único \\(x = n - y\\), e\n\\[\n\\begin{aligned}\nf_Y(y) &= \\sum_{x \\in g^{-1}(y)} f_X(x) \\\\\n&= f_X(n-y) \\\\\n&= \\binom{n}{n-y} p^{n-y} (1-p)^{n-(n-y)} \\\\\n&= \\binom{n}{y} (1-p)^y p^{n-y}.\n\\end{aligned}\n\\]\n(A Definição 1.2.17 implica que \\(\\binom{n}{y} = \\binom{n}{n-y}\\)). Assim, vemos que \\(Y\\) também tem uma distribuição binomial, mas com parâmetros \\(n\\) e \\(1-p\\). ||\n\n\n\n\n\n\nExemplo 2.1.2 (Transformação uniforme)\nSuponha que \\(X\\) tenha uma distribuição uniforme no intervalo \\((0, 2\\pi)\\), isto é,\n\\[\nf_X(x) =\n\\begin{cases}\n1/(2\\pi) & 0 &lt; x &lt; 2\\pi \\\\\n0 & \\text{caso contrário}.\n\\end{cases}\n\\]\nConsidere \\(Y = \\sin^2(X)\\). Então (veja a Figura 3.1)\n\\[\nP(Y \\leq y) = P(X \\leq x_1) + P(x_2 \\leq X \\leq x_3) + P(X \\geq x_4).\n\\tag{3.5}\\]\n\n\n\n\n\n\nFigura 3.1: Figura 2.1.1 - Gráfico da transformação \\(y = \\sin^2(x)\\) do Exemplo 2.1.2\n\n\n\nPela simetria da função \\(\\sin^2(x)\\), e pelo fato de \\(X\\) ter uma distribuição uniforme, temos\n\\[\nP(X \\leq x_1) = P(X \\geq x_4) \\quad \\text{e} \\quad P(x_2 \\leq X \\leq x_3) = 2P(x_2 \\leq X \\leq \\pi),\n\\]\nentão\n\\[\nP(Y \\leq y) = 2P(X \\leq x_1) + 2P(x_2 \\leq X \\leq \\pi)\n\\tag{3.6}\\]\nonde \\(x_1\\) e \\(x_2\\) são as duas soluções para\n\\[\n\\sin^2(x) = y, \\quad 0 &lt; x &lt; \\pi.\n\\]\nAssim, embora este exemplo tenha tratado de uma situação aparentemente simples, a expressão resultante para a fda de \\(Y\\) não foi simples. ||\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeorema 2.1.3\nSeja \\(X\\) com fda \\(F_X(x)\\), seja \\(Y = g(X)\\), e sejam \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) definidos como em Equação 3.7.\n\nSe \\(g\\) é uma função crescente em \\(\\mathcal{X}\\), \\(F_Y(y) = F_X(g^{-1}(y))\\) para \\(y \\in \\mathcal{Y}\\).\nSe \\(g\\) é uma função decrescente em \\(\\mathcal{X}\\) e \\(X\\) é uma variável aleatória contínua, \\(F_Y(y) = 1 - F_X(g^{-1}(y))\\) para \\(y \\in \\mathcal{Y}\\).\n\n\n\nExemplo 2.1.4 (Relação uniforme-exponencial—I)\nSuponha que \\(X \\sim f_X(x) = 1\\) se \\(0 &lt; x &lt; 1\\) e \\(0\\) caso contrário, a distribuição uniforme(0,1). É imediato verificar que \\(F_X(x) = x, 0 &lt; x &lt; 1\\). Fazemos agora a transformação \\(Y = g(X) = -\\log X\\). Como\n\\[\n\\frac{d}{dx}g(x) = \\frac{d}{dx}(-\\log x) = -\\frac{1}{x} &lt; 0, \\quad \\text{para } 0 &lt; x &lt; 1,\n\\]\n\\(g(x)\\) é uma função decrescente. Conforme \\(X\\) varia entre 0 e 1, \\(-\\log x\\) varia entre 0 e \\(\\infty\\), isto é, \\(\\mathcal{Y} = (0, \\infty)\\). Para \\(y &gt; 0\\), \\(y = -\\log x\\) implica \\(x = e^{-y}\\), logo \\(g^{-1}(y) = e^{-y}\\). Portanto, para \\(y &gt; 0\\),\n\\[\nF_Y(y) = 1 - F_X(g^{-1}(y)) = 1 - F_X(e^{-y}) = 1 - e^{-y}. \\quad (F_X(x) = x)\n\\]\nNaturalmente, \\(F_Y(y) = 0\\) para \\(y \\leq 0\\). Note que foi necessário apenas verificar que \\(g(x) = -\\log x\\) é monotônica em (0,1), o suporte de \\(X\\). ||\n\n\n\nTeorema 2.1.5\nSeja \\(X\\) com fdp \\(f_X(x)\\) e seja \\(Y = g(X)\\), onde \\(g\\) é uma função monotônica. Sejam \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) definidos por Equação 3.7. Suponha que \\(f_X(x)\\) seja contínua em \\(\\mathcal{X}\\) e que \\(g^{-1}(y)\\) tenha uma derivada contínua em \\(\\mathcal{Y}\\). Então a fdp de \\(Y\\) é dada por\n\\[\nf_Y(y) =\n\\begin{cases}\nf_X(g^{-1}(y)) \\left| \\frac{d}{dy} g^{-1}(y) \\right| & y \\in \\mathcal{Y} \\\\\n0 & \\text{caso contrário}.\n\\end{cases}\n\\tag{3.10}\\]\n\n\nComprovação. Pelo Teorema 2.1.3 temos, pela regra da cadeia,\n\\[\nf_Y(y) = \\frac{d}{dy} F_Y(y) =\n\\begin{cases}\nf_X(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y) & \\text{se } g \\text{ é crescente}, \\\\\n-f_X(g^{-1}(y)) \\frac{d}{dy} g^{-1}(y) & \\text{se } g \\text{ é decrescente},\n\\end{cases}\n\\]\nque pode ser expresso concisamente como Equação 3.10. \\(\\square\\)\n\n\nExemplo 2.1.6 (fdp gama invertida)\nSeja \\(f_X(x)\\) a fdp gama \\[\nf(x) = \\frac{1}{(n-1)!\\beta^n} x^{n-1} e^{-x/\\beta}, \\quad 0 &lt; x &lt; \\infty,\n\\]\nonde \\(\\beta\\) é uma constante positiva e \\(n\\) é um inteiro positivo. Suponha que queiramos encontrar a fdp de \\(g(X) = 1/X\\). Note que aqui os conjuntos suporte \\(\\mathcal{X}\\) e \\(\\mathcal{Y}\\) são ambos o intervalo \\((0, \\infty)\\). Se fizermos \\(y = g(x)\\), então \\(g^{-1}(y) = 1/y\\) e \\(\\frac{d}{dy} g^{-1}(y) = -1/y^2\\). Aplicando o teorema acima, para \\(y \\in (0, \\infty)\\),\n\\[\n\\begin{aligned}\nf_Y(y) &= f_X(g^{-1}(y)) \\left| \\frac{d}{dy} g^{-1}(y) \\right| \\\\\n&= \\frac{1}{(n-1)!\\beta^n} \\left(\\frac{1}{y}\\right)^{n-1} e^{-1/(\\beta y)} \\frac{1}{y^2} \\\\\n&= \\frac{1}{(n-1)!\\beta^n} \\left(\\frac{1}{y}\\right)^{n+1} e^{-1/(\\beta y)},\n\\end{aligned}\n\\]\num caso especial de uma fdp conhecida como a fdp gama invertida. ||\n\n\n\nExemplo 2.1.7 (Transformação quadrática)\nSuponha que \\(X\\) seja uma variável aleatória contínua. Para \\(y &gt; 0\\), a fda de \\(Y = X^2\\) é\n\\[\nF_Y(y) = P(Y \\leq y) = P(X^2 \\leq y) = P(-\\sqrt{y} \\leq X \\leq \\sqrt{y}).\n\\]\nComo \\(x\\) é contínuo, podemos descartar a igualdade do endpoint esquerdo e obter\n\\[\nF_Y(y) = P(-\\sqrt{y} &lt; X \\leq \\sqrt{y}) = P(X \\leq \\sqrt{y}) - P(X \\leq -\\sqrt{y}) = F_X(\\sqrt{y}) - F_X(-\\sqrt{y}).\n\\]\nA fdp de \\(Y\\) agora pode ser obtida da fda por diferenciação:\n\\[\n\\begin{aligned}\nf_Y(y) &= \\frac{d}{dy} F_Y(y) \\\\\n&= \\frac{d}{dy} [F_X(\\sqrt{y}) - F_X(-\\sqrt{y})] \\\\\n&= \\frac{1}{2\\sqrt{y}} f_X(\\sqrt{y}) + \\frac{1}{2\\sqrt{y}} f_X(-\\sqrt{y}),\n\\end{aligned}\n\\]\nonde usamos a regra da cadeia para diferenciar \\(F_X(\\sqrt{y})\\) e \\(F_X(-\\sqrt{y})\\). Portanto, a fdp é\n\\[\nf_Y(y) = \\frac{1}{2\\sqrt{y}} (f_X(\\sqrt{y}) + f_X(-\\sqrt{y})).\n\\tag{3.11}\\]\n\n\n\nTeorema 2.1.8\nSeja \\(X\\) com fdp \\(f_X(x)\\), seja \\(Y = g(X)\\), e defina o espaço amostral \\(\\mathcal{X}\\) como em Equação 3.7. Suponha que exista uma partição, \\(A_0, A_1, \\dots, A_k\\), de \\(\\mathcal{X}\\) tal que \\(P(X \\in A_0) = 0\\) e \\(f_X(x)\\) seja contínua em cada \\(A_i\\). Além disso, suponha que existam funções \\(g_1(x), \\dots, g_k(x)\\), definidas em \\(A_1, \\dots, A_k\\), respectivamente, satisfazendo:\n\n\\(g(x) = g_i(x)\\), para \\(x \\in A_i\\),\n\\(g_i(x)\\) é monotônica em \\(A_i\\),\no conjunto \\(\\mathcal{Y} = \\{y : y = g_i(x) \\text{ para algum } x \\in A_i\\}\\) é o mesmo para cada \\(i = 1, \\dots, k\\), e\n\\(g_i^{-1}(y)\\) tem uma derivada contínua em \\(\\mathcal{Y}\\), para cada \\(i = 1, \\dots, k\\).\n\nEntão \\[\nf_Y(y) =\n\\begin{cases}\n\\sum_{i=1}^{k} f_X(g_i^{-1}(y)) \\left| \\frac{d}{dy} g_i^{-1}(y) \\right| & y \\in \\mathcal{Y} \\\\\n0 & \\text{caso contrário}.\n\\end{cases}\n\\]\n\n\n\nExemplo 2.1.9 (Relação Normal-qui quadrado)\nSeja \\(X\\) com distribuição normal padrão,\n\\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\]\nConsidere \\(Y = X^2\\). A função \\(g(x) = x^2\\) é monotônica em \\((-\\infty, 0)\\) e em \\((0, \\infty)\\). O conjunto \\(\\mathcal{Y} = (0, \\infty)\\). Aplicando o Teorema 2.1.8, tomamos\n\\[\n\\begin{aligned}\nA_0 &= \\{0\\}; \\\\\nA_1 &= (-\\infty, 0), \\quad g_1(x) = x^2, \\quad g_1^{-1}(y) = -\\sqrt{y}; \\\\\nA_2 &= (0, \\infty), \\quad g_2(x) = x^2, \\quad g_2^{-1}(y) = \\sqrt{y}.\n\\end{aligned}\n\\]\nA fdp de \\(Y\\) é\n\\[\n\\begin{aligned}\nf_Y(y) &= \\frac{1}{\\sqrt{2\\pi}} e^{-(-\\sqrt{y})^2/2} \\left| -\\frac{1}{2\\sqrt{y}} \\right| + \\frac{1}{\\sqrt{2\\pi}} e^{-(\\sqrt{y})^2/2} \\left| \\frac{1}{2\\sqrt{y}} \\right| \\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sqrt{y}} e^{-y/2}, \\quad 0 &lt; y &lt; \\infty.\n\\end{aligned}\n\\]\nA fdp de \\(Y\\) é uma que encontraremos frequentemente, a de uma variável aleatória qui-quadrado com 1 grau de liberdade. ||\n\n\n\nTeorema 2.1.10 (Transformação integral de probabilidade)\nSeja \\(X\\) com fda contínua \\(F_X(x)\\) e defina a variável aleatória \\(Y\\) como \\(Y = F_X(X)\\). Então \\(Y\\) é uniformemente distribuída em \\((0, 1)\\), isto é, \\(P(Y \\leq y) = y, 0 &lt; y &lt; 1\\).\n\n\n\n\n\n\n\n\n\n\n\nFigura 3.2: Figura 2.1.2 - (a) \\(F(x)\\) estritamente crescente; (b) \\(F(x)\\) não decrescente\n\n\n\n\nComprovação. Para \\(Y = F_X(X)\\) temos, para \\(0 &lt; y &lt; 1\\),\n\\[\n\\begin{aligned}\nP(Y \\leq y) &= P(F_X(X) \\leq y) \\\\\n&= P(F_X^{-1}[F_X(X)] \\leq F_X^{-1}(y)) && (F_X^{-1} \\text{ é crescente}) \\\\\n&= P(X \\leq F_X^{-1}(y)) && (\\text{veja o texto abaixo}) \\\\\n&= F_X(F_X^{-1}(y)) && (\\text{definição de } F_X) \\\\\n&= y. && (\\text{continuidade de } F_X)\n\\end{aligned}\n\\]\nNos pontos extremos temos \\(P(Y \\leq y) = 1\\) para \\(y \\geq 1\\) e \\(P(Y \\leq y) = 0\\) para \\(y \\leq 0\\), mostrando que \\(Y\\) tem uma distribuição uniforme. \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#valores-esperados",
    "href": "cap-2.html#valores-esperados",
    "title": "Transformações e Esperanças",
    "section": "2.2 Valores Esperados",
    "text": "2.2 Valores Esperados\nO valor esperado, ou esperança, de uma variável aleatória é meramente seu valor médio, onde falamos de valor “médio” como aquele que é ponderado de acordo com a distribuição de probabilidade. O valor esperado de uma distribuição pode ser pensado como uma medida de centro, pois pensamos em médias como sendo valores centrais. Ao ponderar os valores da variável aleatória de acordo com a distribuição de probabilidade, esperamos obter um número que resuma um valor típico ou esperado de uma observação da variável aleatória.\n\nDefinição 2.2.1\nO valor esperado ou média de uma variável aleatória \\(g(X)\\), denotado por \\(Eg(X)\\), é\n\\[\nEg(X) =\n\\begin{cases}\n\\int_{-\\infty}^{\\infty} g(x) f_X(x) dx & \\text{se } X \\text{ é contínua} \\\\\n\\sum_{x \\in \\mathcal{X}} g(x) f_X(x) = \\sum_{x \\in \\mathcal{X}} g(x) P(X = x) & \\text{se } X \\text{ é discreta},\n\\end{cases}\n\\]\ndesde que a integral ou a soma exista. Se \\(E|g(X)| = \\infty\\), dizemos que \\(Eg(X)\\) não existe. (Ross (1988) refere-se a isso como a “lei do estatístico inconsciente”. Não achamos isso divertido.)\n\n\nExemplo 2.2.2 (Média exponencial)\nSuponha que \\(X\\) tenha uma distribuição exponencial(\\(\\lambda\\)), ou seja, ela tem fdp dada por\n\\[\nf_X(x) = \\frac{1}{\\lambda} e^{-x/\\lambda}, \\quad 0 \\leq x &lt; \\infty, \\quad \\lambda &gt; 0.\n\\]\nEntão \\(EX\\) é dado por\n\\[\n\\begin{aligned}\nEX &= \\int_{0}^{\\infty} \\frac{1}{\\lambda} x e^{-x/\\lambda} dx \\\\\n&= -xe^{-x/\\lambda} \\Big|_0^\\infty + \\int_{0}^{\\infty} e^{-x/\\lambda} dx && \\text{(integração por partes)} \\\\\n&= \\int_{0}^{\\infty} e^{-x/\\lambda} dx = \\lambda.\n\\end{aligned}\n\\] ||\n\n\nExemplo 2.2.3 (Média binomial)\nSe \\(X\\) tem uma distribuição binomial, sua fmp é dada por\n\\[\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n\n\\]\nonde \\(n\\) é um inteiro positivo, \\(0 \\leq p \\leq 1\\), e para cada par fixo \\(n\\) e \\(p\\) a fmp soma 1. O valor esperado de uma variável aleatória binomial é dado por\n\\[\nEX = \\sum_{x=0}^{n} x \\binom{n}{x} p^x (1-p)^{n-x} = \\sum_{x=1}^{n} x \\binom{n}{x} p^x (1-p)^{n-x}\n\\]\n(o termo \\(x = 0\\) é 0). Usando a identidade \\(x \\binom{n}{x} = n \\binom{n-1}{x-1}\\), temos\n\\[\n\\begin{aligned}\nEX &= \\sum_{x=1}^{n} n \\binom{n-1}{x-1} p^x (1-p)^{n-x} \\\\\n&= \\sum_{y=0}^{n-1} n \\binom{n-1}{y} p^{y+1} (1-p)^{n-(y+1)} && \\text{(substitua } y = x-1\\text{)} \\\\\n&= np \\sum_{y=0}^{n-1} \\binom{n-1}{y} p^y (1-p)^{n-1-y} \\\\\n&= np,\n\\end{aligned}\n\\]\nvisto que a última soma deve ser 1, sendo a soma de todos os valores possíveis de uma fmp binomial(\\(n-1, p\\)). ||\n\n\nExemplo 2.2.4 (Média de Cauchy)\nUm exemplo clássico de uma variável aleatória cujo valor esperado não existe é a variável aleatória de Cauchy, ou seja, aquela com fdp\n\\[\nf_X(x) = \\frac{1}{\\pi} \\frac{1}{1+x^2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\]\nÉ imediato verificar que \\(\\int_{-\\infty}^{\\infty} f_X(x) dx = 1\\), mas \\(E|X| = \\infty\\). Escreva\n\\[\nE|X| = \\int_{-\\infty}^{\\infty} \\frac{|x|}{\\pi} \\frac{1}{1+x^2} dx = \\frac{2}{\\pi} \\int_{0}^{\\infty} \\frac{x}{1+x^2} dx.\n\\]\nPara qualquer número positivo \\(M\\),\n\\[\n\\int_{0}^{M} \\frac{x}{1+x^2} dx = \\frac{\\log(1+x^2)}{2} \\Big|_0^M = \\frac{\\log(1+M^2)}{2}.\n\\]\nAssim,\n\\[\nE|X| = \\lim_{M \\to \\infty} \\frac{2}{\\pi} \\int_{0}^{M} \\frac{x}{1+x^2} dx = \\frac{1}{\\pi} \\lim_{M \\to \\infty} \\log(1+M^2) = \\infty\n\\]\ne \\(EX\\) não existe. ||\n\nO processo de tomar expectativas é uma operação linear, o que significa que a expectativa de uma função linear de \\(X\\) pode ser facilmente avaliada notando que para quaisquer constantes \\(a\\) e \\(b\\),\n\\[\nE(aX + b) = aEX + b.\n\\tag{3.14}\\]\nPor exemplo, se \\(X\\) é binomial(\\(n, p\\)), então \\(EX = np\\), logo\n\\[\nE(X - np) = EX - np = np - np = 0.\n\\]\nO operador esperança, de fato, possui muitas propriedades que podem ajudar a facilitar o esforço de cálculo. A maioria dessas propriedades decorre das propriedades da integral ou da soma e está resumida no teorema a seguir.\n\nTeorema 2.2.5\nSeja \\(X\\) uma variável aleatória e sejam \\(a, b\\) e \\(c\\) constantes. Então, para quaisquer funções \\(g_1(x)\\) e \\(g_2(x)\\) cujas expectativas existam,\n\n\\(E(ag_1(X) + bg_2(X) + c) = aEg_1(X) + bEg_2(X) + c\\).\nSe \\(g_1(x) \\geq 0\\) para todo \\(x\\), então \\(Eg_1(X) \\geq 0\\).\nSe \\(g_1(x) \\geq g_2(x)\\) para todo \\(x\\), então \\(Eg_1(X) \\geq Eg_2(X)\\).\nSe \\(a \\leq g_1(x) \\leq b\\) para todo \\(x\\), então \\(a \\leq Eg_1(X) \\leq b\\).\n\n\n\nComprovação. Forneceremos detalhes apenas para o caso contínuo, sendo o caso discreto similar. Por definição,\n\\[\n\\begin{aligned}\nE(ag_1(X) + bg_2(X) + c) &= \\int_{-\\infty}^{\\infty} (ag_1(x) + bg_2(x) + c)f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} ag_1(x)f_X(x) dx + \\int_{-\\infty}^{\\infty} bg_2(x)f_X(x) dx + \\int_{-\\infty}^{\\infty} c f_X(x) dx\n\\end{aligned}\n\\]\npela aditividade da integral. Como \\(a, b\\) e \\(c\\) são constantes, eles saem de suas respectivas integrais e temos\n\\[\n\\begin{aligned}\nE(ag_1(X) + bg_2(X) + c) &= a \\int_{-\\infty}^{\\infty} g_1(x)f_X(x) dx + b \\int_{-\\infty}^{\\infty} g_2(x)f_X(x) dx + c \\int_{-\\infty}^{\\infty} f_X(x) dx \\\\\n&= aEg_1(X) + bEg_2(x) + c,\n\\end{aligned}\n\\]\nestabelecendo (a). As outras três propriedades são provadas de maneira semelhante. \\(\\square\\)\n\n\nExemplo 2.2.6 (Minimizando a distância)\nO valor esperado de uma variável aleatória tem outra propriedade, que podemos pensar como relacionada à interpretação de \\(EX\\) como um bom palpite para um valor de \\(X\\).\nSuponha que meçamos a distância entre uma variável aleatória \\(X\\) e uma constante \\(b\\) por \\((X - b)^2\\). Quanto mais próximo \\(b\\) estiver de \\(X\\), menor será essa quantidade. Podemos agora determinar o valor de \\(b\\) que minimiza \\(E(X - b)^2\\) e, portanto, nos fornecerá um bom preditor de \\(X\\). (Note que não adianta procurar um valor de \\(b\\) que minimize \\((X - b)^2\\), pois a resposta dependeria de \\(X\\), tornando-o um preditor inútil de \\(X\\).)\nPoderíamos prosseguir com a minimização de \\(E(X - b)^2\\) usando cálculo, mas há um método mais simples. (Veja o Exercício 2.19 para uma prova baseada em cálculo.) Usando a crença de que há algo especial sobre \\(EX\\), escreva\n\\[\n\\begin{aligned}\nE(X - b)^2 &= E(X - EX + EX - b)^2 && \\text{(adicione } \\pm EX \\\\\n&= E((X - EX) + (EX - b))^2 && \\text{(agrupe os termos)} \\\\\n&= E(X - EX)^2 + (EX - b)^2 + 2E((X - EX)(EX - b)),\n\\end{aligned}\n\\]\nonde expandimos o quadrado. Agora, note que\n\\[\nE((X - EX)(EX - b)) = (EX - b)E(X - EX) = 0,\n\\]\nvisto que \\((EX - b)\\) é constante e sai da expectativa, e \\(E(X - EX) = EX - EX = 0\\). Isso significa que\n\\[\nE(X - b)^2 = E(X - EX)^2 + (EX - b)^2.\n\\tag{3.15}\\]\nNão temos controle sobre o primeiro termo no lado direito de Equação 3.15 e o segundo termo, que é sempre maior ou igual a 0, pode ser feito igual a 0 escolhendo \\(b = EX\\). Logo,\n\\[\n\\min_b E(X - b)^2 = E(X - EX)^2.\n\\tag{3.16}\\]\nVeja o Exercício 2.18 para um resultado semelhante sobre a mediana. ||\n\nAo avaliar expectativas de funções não lineares de \\(X\\), podemos proceder de uma de duas maneiras. Pela definição de \\(Eg(X)\\), poderíamos calcular diretamente\n\\[\nEg(X) = \\int_{-\\infty}^{\\infty} g(x)f_X(x) dx.\n\\tag{3.17}\\]\nMas também poderíamos encontrar a fdp \\(f_Y(y)\\) de \\(Y = g(X)\\) e teríamos\n\\[\nEg(X) = EY = \\int_{-\\infty}^{\\infty} y f_Y(y) dy.\n\\tag{3.18}\\]\n\nExemplo 2.2.7 (Relação uniforme-exponencial—II)\nSeja \\(X\\) com uma distribuição uniforme(0,1), ou seja, a fdp de \\(X\\) é dada por\n\\[\nf_X(x) =\n\\begin{cases}\n1 & \\text{se } 0 \\leq x \\leq 1 \\\\\n0 & \\text{caso contrário},\n\\end{cases}\n\\]\ne defina uma nova variável aleatória \\(g(X) = -\\log X\\). Então\n\\[\nEg(X) = E(-\\log X) = \\int_{0}^{1} -\\log x dx = x - x \\log x \\Big|_0^1 = 1.\n\\]\nMas também vimos no Exemplo 2.1.4 que \\(Y = -\\log X\\) tem fda \\(1 - e^{-y}\\) e, portanto, fdp \\(f_Y(y) = \\frac{d}{dy}(1 - e^{-y}) = e^{-y}, 0 &lt; y &lt; \\infty\\), que é um caso especial da fdp exponencial com \\(\\lambda = 1\\). Assim, pelo Exemplo 2.2.2, \\(EY = 1\\). ||",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#momentos-e-funções-geradoras-de-momentos",
    "href": "cap-2.html#momentos-e-funções-geradoras-de-momentos",
    "title": "Transformações e Esperanças",
    "section": "2.3 Momentos e Funções Geradoras de Momentos",
    "text": "2.3 Momentos e Funções Geradoras de Momentos\nOs vários momentos de uma distribuição são uma classe importante de expectativas.\n\nDefinição 2.3.1\nPara cada inteiro \\(n\\), o \\(n\\)-ésimo momento de \\(X\\) (ou \\(F_X(x)\\)), \\(\\mu'_n\\), é\n\\[\n\\mu'_n = EX^n.\n\\]\nO \\(n\\)-ésimo momento central de \\(X\\), \\(\\mu_n\\), é\n\\[\n\\mu_n = E(X - \\mu)^n,\n\\]\nonde \\(\\mu = \\mu'_1 = EX\\).\n\nAlém da média, \\(EX\\), de uma variável aleatória, talvez o momento mais importante seja o segundo momento central, mais comumente conhecido como a variância.\n\nDefinição 2.3.2\nA variância de uma variável aleatória \\(X\\) é seu segundo momento central, \\(Var X = E(X - EX)^2\\). A raiz quadrada positiva de \\(Var X\\) é o desvio padrão de \\(X\\).\n\nA variância fornece uma medida do grau de dispersão de uma distribuição em torno de sua média. Vimos anteriormente no Exemplo 2.2.6 que a quantidade \\(E(X - b)^2\\) é minimizada escolhendo \\(b = EX\\). Agora consideramos o tamanho absoluto desse mínimo. A interpretação atribuída à variância é que valores maiores significam que \\(X\\) é mais variável. No extremo, se \\(Var X = E(X - EX)^2 = 0\\), então \\(X\\) é igual a \\(EX\\) com probabilidade 1, e não há variação em \\(X\\). O desvio padrão tem a mesma interpretação qualitativa: valores pequenos significam que é muito provável que \\(X\\) esteja próximo de \\(EX\\), e valores grandes significam que \\(X\\) é muito variável. O desvio padrão é mais fácil de interpretar no sentido de que a unidade de medida no desvio padrão é a mesma da variável original \\(X\\). A unidade de medida na variância é o quadrado da unidade original.\n\n\n\n\n\n\nFigura 3.3: Densidades exponenciais para \\(\\lambda = 1, \\frac{1}{3}, \\frac{1}{5}\\)\n\n\n\n\nExemplo 2.3.3 (Variância exponencial)\nSeja \\(X\\) com a distribuição exponencial(\\(\\lambda\\)), definida no Exemplo 2.2.2. Calculamos \\(EX = \\lambda\\), e agora podemos calcular a variância por\n\\[\n\\begin{aligned}\nVar X = E(X - \\lambda)^2 &= \\int_{0}^{\\infty} (x - \\lambda)^2 \\frac{1}{\\lambda} e^{-x/\\lambda} dx \\\\\n&= \\int_{0}^{\\infty} (x^2 - 2x\\lambda + \\lambda^2) \\frac{1}{\\lambda} e^{-x/\\lambda} dx.\n\\end{aligned}\n\\]\nPara completar a integração, podemos integrar cada um dos termos separadamente, usando integração por partes nos termos que envolvem \\(x\\) e \\(x^2\\). Ao fazer isso, descobrimos que \\(Var X = \\lambda^2\\). ||\n\nVemos que a variância de uma distribuição exponencial está diretamente relacionada ao parâmetro \\(\\lambda\\). A Figura 3.3 mostra várias distribuições exponenciais correspondentes a diferentes valores de \\(\\lambda\\). Note como a distribuição é mais concentrada em torno de sua média para valores menores de \\(\\lambda\\). O comportamento da variância de uma exponencial, como função de \\(\\lambda\\), é um caso especial do comportamento da variância resumido no teorema a seguir.\n\nTeorema 2.3.4\nSe \\(X\\) é uma variável aleatória com variância finita, então para quaisquer constantes \\(a\\) e \\(b\\),\n\\[\nVar(aX + b) = a^2 Var X.\n\\]\n\n\nComprovação. Da definição, temos\n\\[\n\\begin{aligned}\nVar(aX + b) &= E((aX + b) - E(aX + b))^2 \\\\\n&= E(aX - aEX)^2 && (E(aX + b) = aEX + b) \\\\\n&= a^2 E(X - EX)^2 \\\\\n&= a^2 Var X.\n\\end{aligned}\n\\] \\(\\square\\)\n\nÀs vezes é mais fácil usar uma fórmula alternativa para a variância, dada por\n\\[\nVar X = EX^2 - (EX)^2,\n\\tag{3.19}\\]\nque é facilmente estabelecida notando que\n\\[\n\\begin{aligned}\nVar X &= E(X - EX)^2 = E[X^2 - 2XEX + (EX)^2] \\\\\n&= EX^2 - 2(EX)^2 + (EX)^2 \\\\\n&= EX^2 - (EX)^2,\n\\end{aligned}\n\\]\nonde usamos o fato de que \\(E(X EX) = (EX)(EX) = (EX)^2\\), visto que \\(EX\\) é uma constante. Ilustramos agora alguns cálculos de momentos com uma distribuição discreta.\n\nExemplo 2.3.5 (Variância binomial)\nSeja \\(X \\sim\\) binomial(\\(n, p\\)), ou seja,\n\\[\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n.\n\\]\nVimos anteriormente que \\(EX = np\\). Para calcular \\(Var X\\), primeiro calculamos \\(EX^2\\). Temos\n\\[\nEX^2 = \\sum_{x=0}^{n} x^2 \\binom{n}{x} p^x (1-p)^{n-x}.\n\\tag{3.20}\\]\nPara somar esta série, devemos primeiro manipular o coeficiente binomial de maneira semelhante à usada para \\(EX\\) (Exemplo 2.2.3). Escrevemos\n\\[\nx^2 \\binom{n}{x} = x \\frac{n!}{(x-1)!(n-x)!} = xn \\binom{n-1}{x-1}.\n\\tag{3.21}\\]\nO termo no somatório em Equação 3.20 correspondente a \\(x = 0\\) é zero e, usando Equação 3.21, temos\n\\[\n\\begin{aligned}\nEX^2 &= n \\sum_{x=1}^{n} x \\binom{n-1}{x-1} p^x (1-p)^{n-x} \\\\\n&= n \\sum_{y=0}^{n-1} (y+1) \\binom{n-1}{y} p^{y+1} (1-p)^{n-1-y} && \\text{(ajustando } y = x-1\\text{)} \\\\\n&= np \\sum_{y=0}^{n-1} y \\binom{n-1}{y} p^y (1-p)^{n-1-y} + np \\sum_{y=0}^{n-1} \\binom{n-1}{y} p^y (1-p)^{n-1-y}.\n\\end{aligned}\n\\]\nAgora é fácil ver que a primeira soma é igual a \\((n-1)p\\) (já que é a média de uma binomial(\\(n-1, p\\))), enquanto a segunda soma é igual a 1. Logo,\n\\[\nEX^2 = n(n-1)p^2 + np.\n\\tag{3.22}\\]\nUsando Equação 3.19, temos\n\\[\nVar X = n(n-1)p^2 + np - (np)^2 = -np^2 + np = np(1-p).\n\\] ||\n\nO cálculo de momentos de ordem superior prossegue de maneira análoga, mas geralmente as manipulações matemáticas tornam-se bastante complexas. Em aplicações, momentos de ordem 3 ou 4 são às vezes de interesse, mas geralmente há pouca razão estatística para examinar momentos superiores a estes.\nIntroduzimos agora uma nova função que está associada a uma distribuição de probabilidade, a função geradora de momentos (fgm). Como o próprio nome sugere, a fgm pode ser usada para gerar momentos. Na prática, é mais fácil em muitos casos calcular momentos diretamente do que usar a fgm. No entanto, o principal uso da fgm não é gerar momentos, mas ajudar a caracterizar uma distribuição. Essa propriedade pode levar a resultados extremamente poderosos quando usada adequadamente.\n\nDefinição 2.3.6\nSeja \\(X\\) uma variável aleatória com fda \\(F_X\\). A função geradora de momentos (fgm) de \\(X\\) (ou \\(F_X\\)), denotada por \\(M_X(t)\\), é\n\\[\nM_X(t) = Ee^{tX},\n\\]\ndesde que a esperança exista para \\(t\\) em alguma vizinhança de 0. Ou seja, existe um \\(h &gt; 0\\) tal que, para todo \\(t\\) em \\(-h &lt; t &lt; h\\), \\(Ee^{tX}\\) existe. Se a esperança não existir em uma vizinhança de 0, dizemos que a função geradora de momentos não existe.\n\nMais explicitamente, podemos escrever a fgm de \\(X\\) como\n\\[\nM_X(t) = \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx \\quad \\text{se } X \\text{ é contínua}.\n\\]\nou\n\\[\nM_X(t) = \\sum_{x} e^{tx} P(X = x) \\quad \\text{se } X \\text{ é discreta}.\n\\]\nÉ muito fácil ver como a fgm gera momentos. Resumimos o resultado no seguinte teorema.\n\nTeorema 2.3.7\nSe \\(X\\) tem fgm \\(M_X(t)\\), então\n\\[\nEX^n = M_X^{(n)}(0),\n\\]\nonde definimos \\[\nM_X^{(n)}(0) = \\frac{d^n}{dt^n} M_X(t) \\Big|_{t=0}.\n\\]\nOu seja, o \\(n\\)-ésimo momento é igual à \\(n\\)-ésima derivada de \\(M_X(t)\\) avaliada em \\(t = 0\\).\n\n\nComprovação. Assumindo que podemos diferenciar sob o sinal da integral (veja a próxima seção), temos\n\\[\n\\begin{aligned}\n\\frac{d}{dt} M_X(t) &= \\frac{d}{dt} \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} \\left( \\frac{d}{dt} e^{tx} \\right) f_X(x) dx \\\\\n&= \\int_{-\\infty}^{\\infty} (xe^{tx}) f_X(x) dx \\\\\n&= E X e^{tX}.\n\\end{aligned}\n\\]\nAssim, \\[\n\\frac{d}{dt} M_X(t) \\Big|_{t=0} = E X e^{tX} \\Big|_{t=0} = EX.\n\\]\nProcedendo de maneira análoga, podemos estabelecer que \\[\n\\frac{d^n}{dt^n} M_X(t) \\Big|_{t=0} = E X^n e^{tX} \\Big|_{t=0} = EX^n.\n\\] \\(\\square\\)\n\n\nExemplo 2.3.8 (fgm Gama)\nNo Exemplo 2.1.6 encontramos um caso especial da fdp gama\n\\[\nf(x) = \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} x^{\\alpha-1} e^{-x/\\beta}, \\quad 0 &lt; x &lt; \\infty, \\quad \\alpha &gt; 0, \\quad \\beta &gt; 0,\n\\]\nonde \\(\\Gamma(\\alpha)\\) denota a função gama. A fgm é dada por\n\\[\n\\begin{aligned}\nM_X(t) &= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} e^{tx} x^{\\alpha-1} e^{-x/\\beta} dx \\\\\n&= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} x^{\\alpha-1} e^{-(1/\\beta - t)x} dx \\\\\n&= \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\int_{0}^{\\infty} x^{\\alpha-1} e^{-x/(\\frac{\\beta}{1-\\beta t})} dx.\n\\end{aligned}\n\\tag{3.23}\\]\nReconhecemos agora o integrando em Equação 3.23 como o núcleo de outra fdp gama. (O núcleo de uma função é a parte principal da função, a parte que permanece quando as constantes são desconsideradas.) Usando o fato de que, para quaisquer constantes positivas \\(a\\) e \\(b\\),\n\\[\nf(x) = \\frac{1}{\\Gamma(a)b^a} x^{a-1} e^{-x/b}\n\\]\né uma fdp, temos que\n\\[\n\\int_{0}^{\\infty} \\frac{1}{\\Gamma(a)b^a} x^{a-1} e^{-x/b} dx = 1\n\\]\ne, portanto, \\[\n\\int_{0}^{\\infty} x^{a-1} e^{-x/b} dx = \\Gamma(a)b^a.\n\\tag{3.24}\\]\nAplicando Equação 3.24 a Equação 3.23, temos\n\\[\nM_X(t) = \\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha} \\Gamma(\\alpha) \\left( \\frac{\\beta}{1-\\beta t} \\right)^\\alpha = \\left( \\frac{1}{1-\\beta t} \\right)^\\alpha \\quad \\text{se } t &lt; \\frac{1}{\\beta}.\n\\]\nSe \\(t \\geq 1/\\beta\\), então a quantidade \\((1/\\beta) - t\\), no integrando de Equação 3.23, é não positiva e a integral em Equação 3.24 é infinita. Assim, a fgm da distribuição gama existe apenas se \\(t &lt; 1/\\beta\\).\nA média da distribuição gama é dada por \\[\nEX = \\frac{d}{dt} M_X(t) \\Big|_{t=0} = \\frac{\\alpha\\beta}{(1-\\beta t)^{\\alpha+1}} \\Big|_{t=0} = \\alpha\\beta.\n\\]\nOutros momentos podem ser calculados de maneira semelhante. ||\n\n\nExemplo 2.3.9 (fgm Binomial)\nPara uma segunda ilustração do cálculo de uma função geradora de momentos, consideramos uma distribuição discreta, a distribuição binomial. A fmp binomial(\\(n, p\\)) é dada em Equação 3.3. Então\n\\[\nM_X(t) = \\sum_{x=0}^{n} e^{tx} \\binom{n}{x} p^x (1-p)^{n-x} = \\sum_{x=0}^{n} \\binom{n}{x} (pe^t)^x (1-p)^{n-x}.\n\\]\nA fórmula binomial dá\n\\[\n\\sum_{x=0}^{n} \\binom{n}{x} u^x v^{n-x} = (u+v)^n.\n\\tag{3.25}\\]\nLogo, fazendo \\(u = pe^t\\) e \\(v = 1-p\\), temos \\[\nM_X(t) = [pe^t + (1-p)]^n.\n\\] ||\n\nComo mencionado anteriormente, a utilidade principal da função geradora de momentos não está em sua capacidade de gerar momentos. Em vez disso, sua utilidade decorre do fato de que, em muitos casos, a função geradora de momentos pode caracterizar uma distribuição. Existem, no entanto, algumas dificuldades técnicas associadas ao uso de momentos para caracterizar uma distribuição, que investigaremos agora.\nSe a fgm existe, ela caracteriza um conjunto infinito de momentos. A questão natural é se a caracterização do conjunto infinito de momentos determina exclusivamente uma função de distribuição. A resposta a essa pergunta, infelizmente, é não. Caracterizar o conjunto de momentos não é suficiente para determinar uma distribuição de forma única porque pode haver duas variáveis aleatórias distintas tendo os mesmos momentos.\n\nExemplo 2.3.10 (Momentos não únicos)\nConsidere as duas fdps dadas por\n\\[\nf_1(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}, \\quad 0 \\leq x &lt; \\infty,\n\\]\n\\[\nf_2(x) = f_1(x)[1 + \\sin(2\\pi \\log x)], \\quad 0 \\leq x &lt; \\infty.\n\\]\n(A fdp \\(f_1\\) é um caso especial de uma fdp lognormal.) Pode-se mostrar que se \\(X_1 \\sim f_1(x)\\), então \\[\nEX_1^r = e^{r^2/2}, \\quad r = 0, 1, \\dots,\n\\]\nlogo \\(X_1\\) possui todos os seus momentos. Agora suponha que \\(X_2 \\sim f_2(x)\\). Temos \\[\nEX_2^r = \\int_{0}^{\\infty} x^r f_1(x)[1 + \\sin(2\\pi \\log x)] dx = EX_1^r + \\int_{0}^{\\infty} x^r f_1(x) \\sin(2\\pi \\log x) dx.\n\\]\nNo entanto, a transformação \\(y = \\log x - r\\) mostra que esta última integral é a de uma função ímpar sobre \\((-\\infty, \\infty)\\) e, portanto, é igual a 0 para \\(r = 0, 1, \\dots\\). Assim, embora \\(X_1\\) e \\(X_2\\) tenham fdps distintas, elas têm os mesmos momentos para todo \\(r\\). As duas fdps estão ilustradas na Figura 3.4. ||\n\n\n\n\n\n\nFigura 3.4: Duas fdps com os mesmos momentos: \\(f_1(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}\\) e \\(f_2(x) = f_1(x)[1+\\sin(2\\pi \\log x)]\\)\n\n\n\n\nO problema da não unicidade dos momentos não ocorre se as variáveis aleatórias tiverem suporte limitado. Se esse for o caso, então a sequência infinita de momentos determina unicamente a distribuição. Além disso, se a fgm existe em uma vizinhança de zero, então a distribuição é unicamente determinada, não importa qual seja o seu suporte. Assim, a existência de todos os momentos não é equivalente à existência da função geradora de momentos. O teorema a seguir mostra como uma distribuição pode ser caracterizada.\n\nTeorema 2.3.11\nSejam \\(F_X(x)\\) e \\(F_Y(y)\\) duas fdas cujos momentos todos existem.\n\nSe \\(X\\) e \\(Y\\) têm suporte limitado, então \\(F_X(u) = F_Y(u)\\) para todo \\(u\\) se, e somente se, \\(EX^r = EY^r\\) para todos os inteiros \\(r = 0, 1, 2, \\dots\\).\nSe as funções geradoras de momentos existem e \\(M_X(t) = M_Y(t)\\) para todo \\(t\\) em alguma vizinhança de 0, então \\(F_X(u) = F_Y(u)\\) para todo \\(u\\).\n\n\nNo próximo teorema, que trata de uma sequência de fgms que converge, não tratamos o caso de suporte limitado separadamente. Note que a suposição de unicidade é automaticamente satisfeita se a fgm limite existir em uma vizinhança de 0 (Assuntos Diversos 2.6.1).\n\nTeorema 2.3.12 (Convergência de fgms)\nSuponha que \\(\\{X_i, i = 1, 2, \\dots\\}\\) seja uma sequência de variáveis aleatórias, cada uma com fgm \\(M_{X_i}(t)\\). Além disso, suponha que \\[\n\\lim_{i \\to \\infty} M_{X_i}(t) = M_X(t), \\quad \\text{para todo } t \\text{ em uma vizinhança de 0},\n\\]\ne \\(M_X(t)\\) seja uma fgm. Então existe uma única fda \\(F_X\\) cujos momentos são determinados por \\(M_X(t)\\) e, para todo \\(x\\) onde \\(F_X(x)\\) é contínua, temos \\[\n\\lim_{i \\to \\infty} F_{X_i}(x) = F_X(x).\n\\]\n\nOu seja, a convergência das fgms para uma fgm em \\(|t| &lt; h\\) implica a convergência das fdas.\nAs provas dos Teoremas 2.3.11 e 2.3.12 baseiam-se na teoria das transformadas de Laplace. A equação definidora para \\(M_X(t)\\), ou seja, \\[\nM_X(t) = \\int_{-\\infty}^{\\infty} e^{tx} f_X(x) dx,\n\\tag{3.26}\\]\ndefine uma transformada de Laplace (\\(M_X(t)\\) é a transformada de Laplace de \\(f_X(x)\\)). Um fato fundamental sobre as transformadas de Laplace é a sua unicidade. Se Equação 3.26 for válida para todo \\(t\\) tal que \\(|t| &lt; h\\), onde \\(h\\) é algum número positivo, então dada \\(M_X(t)\\) existe apenas uma função \\(f_X(x)\\) que satisfaz Equação 3.26.\n\n\nExemplo 2.3.13 (Aproximação de Poisson)\nUma aproximação que geralmente é ensinada em cursos elementares de estatística é que as probabilidades binomiais (veja o Exemplo 2.3.5) podem ser aproximadas por probabilidades de Poisson, que são geralmente mais fáceis de calcular. A distribuição binomial é caracterizada por duas quantidades, denotadas por \\(n\\) e \\(p\\). Ensina-se que a aproximação de Poisson é válida “quando \\(n\\) é grande e \\(np\\) é pequeno” e regras práticas às vezes são fornecidas.\nA fmp Poisson(\\(\\lambda\\)) é dada por \\[\nP(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0, 1, 2, \\dots,\n\\]\nonde \\(\\lambda\\) é uma constante positiva. A aproximação afirma que se \\(X \\sim\\) binomial(\\(n, p\\)) e \\(Y \\sim\\) Poisson(\\(\\lambda\\)), com \\(\\lambda = np\\), então \\[\nP(X = x) \\approx P(Y = x)\n\\tag{3.27}\\]\npara \\(n\\) grande e \\(np\\) pequeno. Mostramos agora que as fgms convergem, dando crédito a essa aproximação. Lembre-se que \\(M_X(t) = [pe^t + (1-p)]^n\\). Para a distribuição Poisson(\\(\\lambda\\)), podemos calcular \\(M_Y(t) = e^{\\lambda(e^t - 1)}\\), e se definirmos \\(p = \\lambda/n\\), então \\(M_X(t) \\to M_Y(t)\\) quando \\(n \\to \\infty\\). A validade da aproximação em Equação 3.27 seguirá então do Teorema 2.3.12.\nPrimeiro devemos abrir um parêntese e mencionar um resultado de limite importante, um que tem ampla aplicabilidade em estatística.\n\n\nLema 2.3.14\nSeja \\(a_1, a_2, \\dots\\) uma sequência de números convergindo para \\(a\\), ou seja, \\(\\lim_{n \\to \\infty} a_n = a\\). Então \\[\n\\lim_{n \\to \\infty} \\left( 1 + \\frac{a_n}{n} \\right)^n = e^a.\n\\]\n\nRetornando ao exemplo, temos \\[\nM_X(t) = [pe^t + (1-p)]^n = \\left[ 1 + \\frac{1}{n}(e^t - 1)(np) \\right]^n = \\left[ 1 + \\frac{1}{n}(e^t - 1)\\lambda \\right]^n,\n\\]\nporque \\(\\lambda = np\\). Agora defina \\(a_n = a = (e^t - 1)\\lambda\\), e aplique o Lema 2.3.14 para obter \\[\n\\lim_{n \\to \\infty} M_X(t) = e^{\\lambda(e^t - 1)} = M_Y(t),\n\\]\na função geradora de momentos da Poisson. A aproximação de Poisson pode ser bastante boa mesmo para valores moderados de \\(p\\) e \\(n\\). Na Figura 3.5 mostramos uma função de massa de probabilidade binomial junto com sua aproximação de Poisson, com \\(\\lambda = np\\). A aproximação parece ser satisfatória.\n\n\n\n\n\n\nFigura 3.5: Figura 2.3.3 - Aproximação de Poisson (linha pontilhada) para a binomial (linha sólida), n = 15, p = .3\n\n\n\n||\n\nEncerramos esta seção com um resultado útil relativo às fgms.\n\nTeorema 2.3.15\nPara quaisquer constantes \\(a\\) e \\(b\\), a fgm da variável aleatória \\(aX + b\\) é dada por \\[\nM_{aX+b}(t) = e^{bt} M_X(at).\n\\]\n\n\nComprovação. Por definição, \\[\n\\begin{aligned}\nM_{aX+b}(t) &= E(e^{(aX+b)t}) \\\\\n&= E(e^{aXt} e^{bt}) && \\text{(propriedades de exponenciais)} \\\\\n&= e^{bt} E(e^{(at)X}) && (e^{bt} \\text{ é constante}) \\\\\n&= e^{bt} M_X(at), && \\text{(definição de fgm)}\n\\end{aligned}\n\\] provando o teorema. \\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#diferenciando-sob-o-sinal-de-integral",
    "href": "cap-2.html#diferenciando-sob-o-sinal-de-integral",
    "title": "Transformações e Esperanças",
    "section": "2.4 Diferenciando sob o Sinal de Integral",
    "text": "2.4 Diferenciando sob o Sinal de Integral\nNa seção anterior, encontramos uma instância em que desejamos permutar a ordem de integração e diferenciação. Esta situação é encontrada frequentemente em estatística teórica. O propósito desta seção é caracterizar as condições sob as quais esta operação é legítima. Também discutiremos a permuta da ordem de diferenciação e somatório.\nMuitas dessas condições podem ser estabelecidas usando teoremas padrão do cálculo e provas detalhadas podem ser encontradas na maioria dos livros de cálculo. Portanto, provas detalhadas não serão apresentadas aqui. Primeiro, queremos estabelecer o método de cálculo de\n\\[\n\\frac{d}{d\\theta} \\int_{a(\\theta)}^{b(\\theta)} f(x, \\theta) dx\n\\tag{3.28}\\]\nonde \\(-\\infty &lt; a(\\theta), b(\\theta) &lt; \\infty\\) para todo \\(\\theta\\). A regra para diferenciar Equação 3.28 é chamada de Regra de Leibnitz e é uma aplicação do Teorema Fundamental do Cálculo e da regra da cadeia.\n\nTeorema 2.4.1 (Regra de Leibnitz)\nSe \\(f(x, \\theta)\\), \\(a(\\theta)\\) e \\(b(\\theta)\\) são diferenciáveis em relação a \\(\\theta\\), então \\[\n\\frac{d}{d\\theta} \\int_{a(\\theta)}^{b(\\theta)} f(x, \\theta) dx = f(b(\\theta), \\theta) \\frac{d}{d\\theta} b(\\theta) - f(a(\\theta), \\theta) \\frac{d}{d\\theta} a(\\theta) + \\int_{a(\\theta)}^{b(\\theta)} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\]\n\nObserve que se \\(a(\\theta)\\) e \\(b(\\theta)\\) são constantes, temos um caso especial da Regra de Leibnitz:\n\\[\n\\frac{d}{d\\theta} \\int_{a}^{b} f(x, \\theta) dx = \\int_{a}^{b} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\]\nAssim, em geral, se tivermos a integral de uma função diferenciável sobre um intervalo finito, a diferenciação da integral não representa problemas. Se o intervalo de integração for infinito, no entanto, podem surgir problemas. Note que a permuta de derivada e integral na equação acima iguala uma derivada parcial com uma derivada ordinária. Formalmente, este deve ser o caso, pois o lado esquerdo é uma função apenas de \\(\\theta\\), enquanto o integrando no lado direito é uma função de ambos \\(\\theta\\) e \\(x\\).\nA questão de saber se a permuta da ordem de diferenciação e integração é justificada é, na verdade, uma questão de saber se limites e integração podem ser permutados, já que uma derivada é um tipo especial de limite. Lembre-se que se \\(f(x, \\theta)\\) é diferenciável, então\n\\[\n\\frac{\\partial}{\\partial \\theta} f(x, \\theta) = \\lim_{\\delta \\to 0} \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta},\n\\]\nentão temos\n\\[\n\\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx = \\int_{-\\infty}^{\\infty} \\lim_{\\delta \\to 0} \\left[ \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta} \\right] dx,\n\\]\nenquanto\n\\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx = \\lim_{\\delta \\to 0} \\int_{-\\infty}^{\\infty} \\left[ \\frac{f(x, \\theta + \\delta) - f(x, \\theta)}{\\delta} \\right] dx.\n\\]\nPortanto, se pudermos justificar a permuta da ordem de limites e integração, a diferenciação sob o sinal da integral será justificada. O tratamento deste problema em total generalidade exigirá, infelizmente, o uso da teoria da medida, um tópico que não será abordado neste livro. No entanto, as declarações e conclusões de alguns resultados importantes podem ser dadas. Os seguintes teoremas são todos corolários do Teorema da Convergência Dominada de Lebesgue (veja, por exemplo, Rudin (1976)).\n\nTeorema 2.4.2\nSuponha que a função \\(h(x, y)\\) seja contínua em \\(y_0\\) para cada \\(x\\), e exista uma função \\(g(x)\\) satisfazendo i. \\(|h(x, y)| \\leq g(x)\\) para todos \\(x\\) e \\(y\\) ii. \\(\\int_{-\\infty}^{\\infty} g(x) dx &lt; \\infty\\). Então \\[\n\\lim_{y \\to y_0} \\int_{-\\infty}^{\\infty} h(x, y) dx = \\int_{-\\infty}^{\\infty} \\lim_{y \\to y_0} h(x, y) dx.\n\\]\n\nA condição chave neste teorema é a existência de uma função dominante \\(g(x)\\), com uma integral finita, que garanta que as integrais não se comportem muito mal. Podemos agora aplicar este teorema ao caso que estamos considerando, identificando \\(h(x, y)\\) com a diferença \\((f(x, \\theta + \\delta) - f(x, \\theta))/\\delta\\).\n\nTeorema 2.4.3\nSuponha que \\(f(x, \\theta)\\) seja diferenciável em \\(\\theta = \\theta_0\\), isto é, \\[\n\\lim_{\\delta \\to 0} \\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} = \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0}\n\\] exista para cada \\(x\\), e exista uma função \\(g(x, \\theta_0)\\) e uma constante \\(\\delta_0 &gt; 0\\) tal que i. \\(\\left| \\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} \\right| \\leq g(x, \\theta_0)\\), para todos \\(x\\) e \\(|\\delta| \\leq \\delta_0\\), ii. \\(\\int_{-\\infty}^{\\infty} g(x, \\theta_0) dx &lt; \\infty\\). Então \\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx \\Big|_{\\theta = \\theta_0} = \\int_{-\\infty}^{\\infty} \\left[ \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0} \\right] dx.\n\\tag{3.29}\\]\n\nA condição (i) é semelhante ao que é conhecido como uma condição de Lipschitz, uma condição que impõe suavidade a uma função. Aqui, a condição (i) está efetivamente limitando a variabilidade na primeira derivada; outras restrições de suavidade podem limitar essa variabilidade por uma constante (em vez de uma função \\(g\\)), ou colocar um limite na variabilidade da segunda derivada de \\(f\\).\nA conclusão do Teorema 2.4.3 é um pouco pesada, mas é importante perceber que, embora pareçamos estar tratando \\(\\theta\\) como uma variável, a declaração do teorema é para um valor de \\(\\theta\\). Isto é, para cada valor \\(\\theta_0\\) para o qual \\(f(x, \\theta)\\) é diferenciável em \\(\\theta_0\\) e satisfaz as condições (i) e (ii), a ordem de integração e diferenciação pode ser permutada. Frequentemente, a distinção entre \\(\\theta\\) e \\(\\theta_0\\) não é enfatizada e Equação 3.29 é escrita como\n\\[\n\\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} f(x, \\theta) dx = \\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial \\theta} f(x, \\theta) dx.\n\\tag{3.30}\\]\nTipicamente, \\(f(x, \\theta)\\) é diferenciável em todos os \\(\\theta\\), não apenas em um valor \\(\\theta_0\\). Neste caso, a condição (i) do Teorema 2.4.3 pode ser substituída por outra condição que muitas vezes se mostra mais fácil de verificar. Por uma aplicação do teorema do valor médio, segue que, para \\(x\\) e \\(\\theta_0\\) fixos, e \\(|\\delta| \\leq \\delta_0\\),\n\\[\n\\frac{f(x, \\theta_0 + \\delta) - f(x, \\theta_0)}{\\delta} = \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta_0 + \\delta^*(x)}\n\\]\npara algum número \\(\\delta^*(x), |\\delta^*(x)| \\leq \\delta_0\\). Portanto, a condição (i) será satisfeita se encontrarmos uma \\(g(x, \\theta)\\) que satisfaça a condição (ii) e\n\\[\n\\left| \\frac{\\partial}{\\partial \\theta} f(x, \\theta) \\Big|_{\\theta = \\theta'} \\right| \\leq g(x, \\theta) \\quad \\text{para todos } \\theta' \\text{ tais que } |\\theta' - \\theta| \\leq \\delta_0.\n\\tag{3.31}\\]\nNote que em Equação 3.31 \\(\\delta_0\\) é implicitamente uma função de \\(\\theta\\), como é o caso no Teorema 2.4.3. Isto é permitido, já que o teorema é aplicado a cada valor de \\(\\theta\\) individualmente. De Equação 3.31 obtemos o seguinte corolário.\n\nCorolário 2.4.4\nSuponha que \\(f(x, \\theta)\\) seja diferenciável em \\(\\theta\\) e exista uma função \\(g(x, \\theta)\\) tal que Equação 3.31 seja satisfeita e \\(\\int_{-\\infty}^{\\infty} g(x, \\theta) dx &lt; \\infty\\). Então Equação 3.30 se mantém.\n\nObserve que tanto a condição (i) do Teorema 2.4.3 quanto Equação 3.31 impõem um requisito de uniformidade nas funções a serem limitadas; algum tipo de uniformidade é geralmente necessário antes que derivadas e integrais possam ser permutadas.\n\nExemplo 2.4.5 (Intercambiando integração e diferenciação—I)\nSeja \\(X\\) com a fdp exponencial(\\(\\lambda\\)) dada por \\(f(x) = (1/\\lambda)e^{-x/\\lambda}, 0 &lt; x &lt; \\infty\\), e suponha que queiramos calcular\n\\[\n\\frac{d}{d\\lambda} EX^n = \\frac{d}{d\\lambda} \\int_{0}^{\\infty} x^n \\left( \\frac{1}{\\lambda} \\right) e^{-x/\\lambda} dx,\n\\tag{3.32}\\]\npara um inteiro \\(n &gt; 0\\). Se pudéssemos mover a diferenciação para dentro da integral, teríamos\n\\[\n\\begin{aligned}\n\\frac{d}{d\\lambda} EX^n &= \\int_{0}^{\\infty} \\frac{\\partial}{\\partial \\lambda} x^n \\left( \\frac{1}{\\lambda} \\right) e^{-x/\\lambda} dx \\\\\n&= \\int_{0}^{\\infty} \\frac{x^n}{\\lambda^2} \\left( \\frac{x}{\\lambda} - 1 \\right) e^{-x/\\lambda} dx \\\\\n&= \\frac{1}{\\lambda^2} EX^{n+1} - \\frac{1}{\\lambda} EX^n.\n\\end{aligned}\n\\tag{3.33}\\]\nPara justificar a permuta de integração e diferenciação, limitamos a derivada de \\(x^n(1/\\lambda)e^{-x/\\lambda}\\). Agora\n\\[\n\\left| \\frac{\\partial}{\\partial \\lambda} \\frac{x^n e^{-x/\\lambda}}{\\lambda} \\right| = \\frac{x^n e^{-x/\\lambda}}{\\lambda^2} \\left| \\frac{x}{\\lambda} - 1 \\right| \\leq \\frac{x^n e^{-x/\\lambda}}{\\lambda^2} \\left( \\frac{x}{\\lambda} + 1 \\right). \\quad (\\text{visto que } \\frac{x}{\\lambda} &gt; 0)\n\\]\nPara alguma constante \\(\\delta_0\\) satisfazendo \\(0 &lt; \\delta_0 &lt; \\lambda\\), tome\n\\[\ng(x, \\lambda) = \\frac{x^n e^{-x/(\\lambda + \\delta_0)}}{(\\lambda - \\delta_0)^2} \\left( \\frac{x}{\\lambda - \\delta_0} + 1 \\right).\n\\]\nTemos então\n\\[\n\\left| \\frac{\\partial}{\\partial \\lambda} \\left( \\frac{x^n e^{-x/\\lambda}}{\\lambda} \\right) \\Big|_{\\lambda = \\lambda'} \\right| \\leq g(x, \\lambda) \\quad \\text{para todos } \\lambda' \\text{ tais que } |\\lambda' - \\lambda| \\leq \\delta_0.\n\\]\nComo a distribuição exponencial possui todos os seus momentos, \\(\\int_{-\\infty}^{\\infty} g(x, \\lambda) dx &lt; \\infty\\) contanto que \\(\\lambda - \\delta_0 &gt; 0\\), então a permuta de integração e diferenciação é justificada. ||\n\nA propriedade ilustrada para a distribuição exponencial vale para uma grande classe de densidades, que serão abordadas na Seção 3.4. Observe que Equação 3.33 nos dá uma relação de recorrência para os momentos da distribuição exponencial,\n\\[\nEX^{n+1} = \\lambda EX^n + \\lambda^2 \\frac{d}{d\\lambda} EX^n,\n\\tag{3.34}\\]\ntornando o cálculo do \\((n+1)\\)-ésimo momento relativamente fácil. Este tipo de relacionamento existe para outras distribuições. Em particular, se \\(X\\) tem uma distribuição normal com média \\(\\mu\\) e variância 1, então ela tem fdp \\(f(x) = (1/\\sqrt{2\\pi})e^{-(x-\\mu)^2/2}\\), então\n\\[\nEX^{n+1} = \\mu EX^n + \\frac{d}{d\\mu} EX^n.\n\\]\nIlustramos mais uma permuta de diferenciação e integração, uma envolvendo a função geradora de momentos.\n\nExemplo 2.4.6 (Intercambiando integração e diferenciação—II)\nNovamente, seja \\(X\\) com uma distribuição normal com média \\(\\mu\\) e variância 1, e considere a fgm de \\(X\\),\n\\[\nM_X(t) = Ee^{tX} = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{tx} e^{-(x-\\mu)^2/2} dx.\n\\]\nNa Seção 2.3 foi afirmado que podemos calcular momentos por diferenciação de \\(M_X(t)\\), e a diferenciação sob o sinal da integral foi justificada:\n\\[\n\\frac{d}{dt} M_X(t) = \\frac{d}{dt} Ee^{tX} = E \\frac{\\partial}{\\partial t} e^{tX} = E(X e^{tX}).\n\\tag{3.35}\\]\nPodemos aplicar os resultados desta seção para justificar as operações em Equação 3.35. Observe que ao aplicar o Teorema 2.4.3 ou o Corolário 2.4.4 aqui, identificamos \\(t\\) com a variável \\(\\theta\\) no Teorema 2.4.3. O parâmetro \\(\\mu\\) é tratado como uma constante. Pelo Corolário 2.4.4, devemos encontrar uma função \\(g(x, t)\\), com integral finita, que satisfaça\n\\[\n\\left| \\frac{\\partial}{\\partial t} e^{tx} e^{-(x-\\mu)^2/2} \\Big|_{t=t'} \\right| \\leq g(x, t) \\quad \\text{para todos } t' \\text{ tais que } |t' - t| \\leq \\delta_0.\n\\tag{3.36}\\]\nFazendo o óbvio, temos\n\\[\n\\left| \\frac{\\partial}{\\partial t} e^{tx} e^{-(x-\\mu)^2/2} \\right| = |x e^{tx} e^{-(x-\\mu)^2/2}| \\leq |x| e^{tx} e^{-(x-\\mu)^2/2}.\n\\]\nÉ mais fácil definir nossa função \\(g(x, t)\\) separadamente para \\(x \\geq 0\\) e \\(x &lt; 0\\). Tomamos\n\\[\ng(x, t) =\n\\begin{cases}\n|x| e^{(t-\\delta_0)x} e^{-(x-\\mu)^2/2} & \\text{se } x &lt; 0 \\\\\n|x| e^{(t+\\delta_0)x} e^{-(x-\\mu)^2/2} & \\text{se } x \\geq 0.\n\\end{cases}\n\\]\nÉ claro que esta função satisfaz Equação 3.36; resta verificar que sua integral é finita. Para \\(x \\geq 0\\) temos\n\\[\ng(x, t) = x e^{-(x^2 - 2x(\\mu+t+\\delta_0) + \\mu^2)/2}.\n\\]\nAgora completamos o quadrado no expoente, ou seja, escrevemos\n\\[\n\\begin{aligned}\nx^2 - 2x(\\mu + t + \\delta_0) + \\mu^2 &= x^2 - 2x(\\mu + t + \\delta_0) + (\\mu + t + \\delta_0)^2 - (\\mu + t + \\delta_0)^2 + \\mu^2 \\\\\n&= (x - (\\mu + t + \\delta_0))^2 + \\mu^2 - (\\mu + t + \\delta_0)^2,\n\\end{aligned}\n\\]\ne assim, para \\(x \\geq 0\\),\n\\[\ng(x, t) = x e^{-[x - (\\mu + t + \\delta_0)]^2/2} e^{-[\\mu^2 - (\\mu + t + \\delta_0)^2]/2}.\n\\]\nComo o último fator exponencial nesta expressão não depende de \\(x\\), \\(\\int_{0}^{\\infty} g(x, t) dx\\) é essencialmente o cálculo da média de uma distribuição normal com média \\(\\mu + t + \\delta_0\\), exceto que a integração é apenas sobre \\([0, \\infty)\\). No entanto, segue que a integral é finita porque a distribuição normal tem uma média finita (a ser mostrada no Capítulo 3). Um desenvolvimento semelhante para \\(x &lt; 0\\) mostra que \\(\\int_{-\\infty}^{0} g(x, t) dx &lt; \\infty\\). Portanto, encontramos uma função integrável satisfazendo Equação 3.36 e a operação em Equação 3.35 é justificada. ||\n\nVoltamo-nos agora para a questão de quando é possível permutar diferenciação e somatório, uma operação que desempenha um papel importante em distribuições discretas. É claro que estamos preocupados apenas com somas infinitas, já que uma derivada sempre pode ser levada para dentro de uma soma finita.\n\nExemplo 2.4.7 (Intercambiando somatório e diferenciação)\nSeja \\(X\\) uma variável aleatória discreta com a distribuição geométrica\n\\[\nP(X = x) = \\theta(1-\\theta)^x, \\quad x = 0, 1, \\dots, \\quad 0 &lt; \\theta &lt; 1.\n\\]\nTemos que \\(\\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x = 1\\) e, desde que as operações sejam justificadas,\n\\[\n\\begin{aligned}\n\\frac{d}{d\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x &= \\sum_{x=0}^{\\infty} \\frac{d}{d\\theta} \\theta(1-\\theta)^x \\\\\n&= \\sum_{x=0}^{\\infty} [(1-\\theta)^x - \\theta x(1-\\theta)^{x-1}] \\\\\n&= \\frac{1}{\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x - \\frac{1}{1-\\theta} \\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x.\n\\end{aligned}\n\\]\nComo \\(\\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x = 1\\) para todo \\(0 &lt; \\theta &lt; 1\\), sua derivada é zero. Então temos\n\\[\n\\frac{1}{\\theta} \\sum_{x=0}^{\\infty} \\theta(1-\\theta)^x - \\frac{1}{1-\\theta} \\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x = 0.\n\\tag{3.37}\\]\nAgora a primeira soma em Equação 3.37 é igual a 1 e a segunda soma é \\(EX\\), logo Equação 3.37 torna-se\n\\[\n\\frac{1}{\\theta} - \\frac{1}{1-\\theta} EX = 0,\n\\]\nou\n\\[\nEX = \\frac{1-\\theta}{\\theta}.\n\\]\nNós, em essência, somamos a série \\(\\sum_{x=0}^{\\infty} x\\theta(1-\\theta)^x\\) por diferenciação. ||\n\nA justificativa de levar a derivada para dentro do somatório é mais direta do que o caso da integração. O teorema a seguir fornece os detalhes.\n\nTeorema 2.4.8\nSuponha que a série \\(\\sum_{x=0}^{\\infty} h(\\theta, x)\\) convirja para todos os \\(\\theta\\) em um intervalo \\((a, b)\\) de números reais e i. \\(\\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) seja contínua em \\(\\theta\\) para cada \\(x\\), ii. \\(\\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) convirja uniformemente em cada subintervalo fechado e limitado de \\((a, b)\\). Então \\[\n\\frac{d}{d\\theta} \\sum_{x=0}^{\\infty} h(\\theta, x) = \\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x).\n\\tag{3.38}\\]\n\nA condição de convergência uniforme é a chave a ser verificada para estabelecer que a diferenciação pode ser levada para dentro do somatório. Lembre-se que uma série converge uniformemente se sua sequência de somas parciais convergir uniformemente, um fato que usamos no exemplo a seguir.\n\nExemplo 2.4.9 (Continuação do Exercício 2.4.7)\nPara aplicar o Teorema 2.4.8 identificamos\n\\[\nh(\\theta, x) = \\theta(1-\\theta)^x,\n\\]\ne\n\\[\n\\frac{\\partial}{\\partial \\theta} h(\\theta, x) = (1-\\theta)^x - \\theta x(1-\\theta)^{x-1},\n\\]\ne verificamos que \\(\\sum_{x=0}^{\\infty} \\frac{\\partial}{\\partial \\theta} h(\\theta, x)\\) converge uniformemente. Defina \\(S_n(\\theta)\\) por\n\\[\nS_n(\\theta) = \\sum_{x=0}^{n} [(1-\\theta)^x - \\theta x(1-\\theta)^{x-1}].\n\\]\nA convergência será uniforme em \\([c, d] \\subset (0, 1)\\) se, dado \\(\\varepsilon &gt; 0\\), pudermos encontrar um \\(N\\) tal que\n\\[\nn &gt; N \\implies |S_n(\\theta) - S_{\\infty}(\\theta)| &lt; \\varepsilon \\quad \\text{para todos } \\theta \\in [c, d].\n\\]\nLembre-se da soma parcial da série geométrica (1.5.3). Se \\(y \\neq 1\\), então podemos escrever\n\\[\n\\sum_{k=0}^{n} y^k = \\frac{1 - y^{n+1}}{1 - y}.\n\\]\nAplicando isto, temos\n\\[\n\\sum_{x=0}^{n} (1-\\theta)^x = \\frac{1 - (1-\\theta)^{n+1}}{\\theta}\n\\]\n\\[\n\\sum_{x=0}^{n} \\theta x(1-\\theta)^{x-1} = \\theta \\sum_{x=0}^{n} - \\frac{\\partial}{\\partial \\theta} (1-\\theta)^x = -\\theta \\frac{d}{d\\theta} \\sum_{x=0}^{n} (1-\\theta)^x = -\\theta \\frac{d}{d\\theta} \\left[ \\frac{1 - (1-\\theta)^{n+1}}{\\theta} \\right].\n\\]\nAqui nós (justificadamente) puxamos a derivada através da soma finita. Calcular esta derivada resulta em\n\\[\n\\sum_{x=0}^{n} \\theta x(1-\\theta)^{x-1} = \\frac{(1 - (1-\\theta)^{n+1}) - (n+1)\\theta(1-\\theta)^n}{\\theta},\n\\]\ne, consequentemente,\n\\[\n\\begin{aligned}\nS_n(\\theta) &= \\frac{1 - (1-\\theta)^{n+1}}{\\theta} - \\frac{(1 - (1-\\theta)^{n+1}) - (n+1)\\theta(1-\\theta)^n}{\\theta} \\\\\n&= (n+1)(1-\\theta)^n.\n\\end{aligned}\n\\]\nÉ claro que, para \\(0 &lt; \\theta &lt; 1\\), \\(S_{\\infty} = \\lim_{n \\to \\infty} S_n(\\theta) = 0\\). Como \\(S_n(\\theta)\\) é contínua, a convergência é uniforme em qualquer intervalo limitado e fechado. Portanto, a série de derivadas converge uniformemente e a permuta de diferenciação e somatório é justificada. ||\n\nEncerramos esta seção com um teorema que é semelhante ao Teorema 2.4.8, mas trata do caso de permutar a ordem de somatório e integração.\n\nTeorema 2.4.10\nSuponha que a série \\(\\sum_{x=0}^{\\infty} h(\\theta, x)\\) convirja uniformemente em \\([a, b]\\) e que, para cada \\(x\\), \\(h(\\theta, x)\\) seja uma função contínua de \\(\\theta\\). Então \\[\n\\int_{a}^{b} \\sum_{x=0}^{\\infty} h(\\theta, x) d\\theta = \\sum_{x=0}^{\\infty} \\int_{a}^{b} h(\\theta, x) d\\theta.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#assuntos-diversos",
    "href": "cap-2.html#assuntos-diversos",
    "title": "Transformações e Esperanças",
    "section": "2.6 Assuntos Diversos",
    "text": "2.6 Assuntos Diversos\n\n2.6.1 Unicidade de Sequências de Momentos\nUma distribuição não é necessariamente determinada por seus momentos. Mas se \\(\\sum_{r=1}^{\\infty} \\mu'_r t^r/r!\\) possui um raio de convergência positivo, onde \\(X \\sim F_X\\) e \\(EX^r = \\mu'_r\\), então a sequência de momentos é única e, portanto, a distribuição é unicamente determinada (Billingsley 1995, Seção 30). A convergência desta soma também implica que a função geradora de momentos existe em um intervalo e, portanto, a função geradora de momentos determina a distribuição.\nUma condição suficiente para que a sequência de momentos seja única é a Condição de Carleman (Chung 1974). Se \\(X \\sim F_X\\) e denotamos \\(EX^r = \\mu'_r\\), então a sequência de momentos é única se\n\\[\n\\sum_{r=1}^{\\infty} \\frac{1}{(\\mu'_{2r})^{1/(2r)}} = +\\infty.\n\\tag{3.39}\\]\nEsta condição é, em geral, difícil de verificar.\nFeller (1971) apresenta um desenvolvimento muito completo das transformadas de Laplace, das quais as fgms são um caso especial. Em particular, Feller mostra (similarmente a Billingsley) que sempre que\n\\[\nM_X(t) = \\sum_{r=0}^{\\infty} \\frac{\\mu'_r t^r}{r!}\n\\]\nconverge em um intervalo \\(-t_0 \\leq t &lt; t_0, t_0 &gt; 0\\), a distribuição \\(F_X\\) é unicamente determinada. Assim, quando a fgm existe, a sequência de momentos determina a distribuição \\(F_X\\) univocamente.\nDeve estar claro que usar a fgm para determinar a distribuição é uma tarefa difícil. Um método melhor é através do uso de funções características, que são explicadas abaixo. Embora as funções características simplifiquem a caracterização de uma distribuição, elas necessitam da compreensão de análise complexa. Ganha-se por um lado e perde-se por outro.\n\n\n2.6.2 Outras Funções Geradoras\nAlém da função geradora de momentos, há uma série de outras funções geradoras disponíveis. Na maioria dos casos, a função característica é a mais útil destas. Exceto por circunstâncias raras, as outras funções geradoras são menos úteis, mas há situações em que elas podem facilitar os cálculos.\nFunção geradora de cumulantes Para uma variável aleatória \\(X\\), a função geradora de cumulantes é a função \\(\\log[M_X(t)]\\). Esta função pode ser usada para gerar os cumulantes de \\(X\\), que são definidos (de forma um tanto indireta) como os coeficientes na série de Taylor da função geradora de cumulantes (veja o Exercício 2.32).\nFunção geradora de momentos fatoriais A função geradora de momentos fatoriais de \\(X\\) é definida como \\(Et^X\\), se a esperança existir. O nome advém do fato de que esta função satisfaz\n\\[\n\\frac{d^r}{dt^r} Et^X \\Big|_{t=1} = E\\{X(X-1)\\dots(X-r+1)\\},\n\\]\nonde o lado direito é um momento fatorial. Se \\(X\\) é uma variável aleatória discreta, então podemos escrever\n\\[\nEt^X = \\sum_{x} t^x P(X = x),\n\\]\ne a função geradora de momentos fatoriais é chamada de função geradora de probabilidades, visto que os coeficientes da série de potências fornecem as probabilidades. Isto é, para obter a probabilidade de que \\(X = k\\), calcula-se\n\\[\n\\frac{1}{k!} \\frac{d^k}{dt^k} Et^X \\Big|_{t=0} = P(X = k).\n\\]\n\n\n2.6.3 A Função Geradora de Momentos Caracteriza uma Distribuição?\nEm um artigo com o título acima, McCullagh (1994) analisa um par de densidades semelhantes às do Exemplo 2.3.10, mas que possuem fgms:\n\\[\nf_1 = n(0,1) \\quad \\text{e} \\quad f_2 = f_1(x) \\left[ 1 + \\frac{1}{2} \\sin(2\\pi x) \\right]\n\\]\ncom funções geradoras de cumulantes\n\\[\nK_1(t) = t^2/2 \\quad \\text{e} \\quad K_2(t) = K_1(t) + \\log \\left[ 1 + \\frac{1}{2} e^{-2\\pi^2} \\sin(2\\pi t) \\right].\n\\]\nEle observa que, embora as densidades sejam visivelmente dessemelhantes, as cgfs são virtualmente idênticas, com diferença máxima inferior a \\(1,34 \\times 10^{-9}\\) em todo o intervalo (menos que o tamanho de um pixel). Portanto, a resposta à pergunta feita no título é “sim para fins matemáticos, mas um retumbante não para fins numéricos”. Em contraste, Waller (1995) ilustra que, embora as fgms falhem em distinguir numericamente as distribuições, as funções características fazem um excelente trabalho. (Waller et al. (1995) e Luceño (1997) investigam mais a fundo a utilidade da função característica na obtenção numérica das fdas.) Veja o Exercício 2.37 para detalhes.\nFunção característica Talvez a mais útil de todos esses tipos de funções seja a função característica. A função característica de \\(X\\) é definida por\n\\[\n\\phi_X(t) = Ee^{itX},\n\\]\nonde \\(i\\) é o número complexo \\(\\sqrt{-1}\\), portanto a esperança acima requer integração complexa. A função característica faz muito mais do que a fgm faz. Quando os momentos de \\(F_X\\) existem, \\(\\phi_X\\) pode ser usada para gerá-los, de forma muito semelhante a uma fgm. A função característica sempre existe e determina completamente a distribuição. Isto é, cada fda tem uma única função característica. Assim, podemos enunciar um teorema como o Teorema 2.3.11, por exemplo, mas sem ressalvas.\n\n\nTeorema 2.6.1 (Convergência de Funções Características)\nSuponha que \\(X_k, k = 1, 2, \\dots\\), seja uma sequência de variáveis aleatórias, cada uma com função característica \\(\\phi_{X_k}(t)\\). Além disso, suponha que \\[\n\\lim_{k \\to \\infty} \\phi_{X_k}(t) = \\phi_X(t), \\quad \\text{para todo } t \\text{ em uma vizinhança de 0}\n\\] e \\(\\phi_X(t)\\) seja uma função característica. Então, para todo \\(X\\) onde \\(F_X(x)\\) é contínua, \\[\n\\lim_{k \\to \\infty} F_{X_k}(x) = F_X(x).\n\\]\n\nUm tratamento completo das funções geradoras é dado por Feller (1968). Funções características podem ser encontradas em quase qualquer texto avançado de probabilidade; veja Billingsley (1995) ou Resnick (1999).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  },
  {
    "objectID": "cap-2.html#exercícios",
    "href": "cap-2.html#exercícios",
    "title": "Transformações e Esperanças",
    "section": "2.5 Exercícios",
    "text": "2.5 Exercícios\n2.1 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\). Mostre que a fdp integra 1. (a) \\(Y = X^3\\) e \\(f_X(x) = 42x^5(1-x), 0 &lt; x &lt; 1\\). (b) \\(Y = 4X + 3\\) e \\(f_X(x) = 7e^{-7x}, 0 &lt; x &lt; \\infty\\). (c) \\(Y = X^2\\) e \\(f_X(x) = 30x^2(1-x)^2, 0 &lt; x &lt; 1\\). (Veja o Exemplo 12.6.2 no apêndice de Álgebra Computacional.)\n2.2 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\). (a) \\(Y = X^2\\) e \\(f_X(x) = 1, 0 &lt; x &lt; 1\\). (b) \\(Y = -\\log X\\) e \\(X\\) tem fdp \\[\nf_X(x) = \\frac{(n+m+1)!}{n!m!} x^n (1-x)^m, \\quad 0 &lt; x &lt; 1, \\quad m, n \\text{ inteiros positivos}.\n\\] (c) \\(Y = e^X\\) e \\(X\\) tem fdp \\[\nf_X(x) = \\frac{1}{\\sigma^2} x e^{-(x/\\sigma)^2/2}, \\quad 0 &lt; x &lt; \\infty, \\quad \\sigma^2 \\text{ uma constante positiva}.\n\\]\n2.3 Suponha que \\(X\\) tenha a fmp geométrica, \\(f_X(x) = \\frac{1}{3} \\left(\\frac{2}{3}\\right)^x, x = 0, 1, 2, \\dots\\). Determine a distribuição de probabilidade de \\(Y = X/(X+1)\\). Note que aqui tanto \\(X\\) quanto \\(Y\\) são variáveis aleatórias discretas. Para especificar a distribuição de probabilidade de \\(Y\\), especifique sua fmp.\n2.4 Seja \\(\\lambda\\) uma constante positiva fixa, e defina a função \\(f(x)\\) por \\(f(x) = \\frac{1}{2}\\lambda e^{-\\lambda x}\\) se \\(x \\geq 0\\) e \\(f(x) = \\frac{1}{2}\\lambda e^{\\lambda x}\\) se \\(x &lt; 0\\). (a) Verifique que \\(f(x)\\) é uma fdp. (b) Se \\(X\\) é uma variável aleatória com fdp dada por \\(f(x)\\), encontre \\(P(X &lt; t)\\) para todo \\(t\\). Avalie todas as integrais. (c) Encontre \\(P(|X| &lt; t)\\) para todo \\(t\\). Avalie todas as integrais.\n2.5 Use o Teorema 2.1.8 para encontrar a fdp de \\(Y\\) no Exemplo 2.1.2. Mostre que a mesma resposta é obtida diferenciando a fda dada em (2.1.6).\n2.6 Em cada um dos seguintes itens, encontre a fdp de \\(Y\\) e mostre que a fdp integra 1. (a) \\(f_X(x) = \\frac{1}{2} e^{-|x|}, -\\infty &lt; x &lt; \\infty; Y = |X|^3\\). (b) \\(f_X(x) = \\frac{3}{8}(x+1)^2, -1 &lt; x &lt; 1; Y = 1 - X^2\\). (c) \\(f_X(x) = \\frac{3}{8}(x+1)^2, -1 &lt; x &lt; 1; Y = 1 - X^2\\) se \\(X \\leq 0\\) e \\(Y = 1 - X\\) se \\(X &gt; 0\\).\n2.7 Seja \\(X\\) com fdp \\(f_X(x) = \\frac{2}{9}(x+1), -1 \\leq x \\leq 2\\). (a) Encontre a fdp de \\(Y = X^2\\). Note que o Teorema 2.1.8 não é diretamente aplicável neste problema. (b) Mostre que o Teorema 2.1.8 permanece válido se os conjuntos \\(A_0, A_1, \\dots, A_k\\) contiverem \\(\\mathcal{X}\\), e aplique a extensão para resolver a parte (a) usando \\(A_0 = \\emptyset, A_1 = (-2, 0)\\) e \\(A_2 = (0, 2)\\).\n2.8 Em cada um dos seguintes itens, mostre que a função dada é uma fda e encontre \\(F_X^{-1}(y)\\). (a) \\(F_X(x) = \\begin{cases} 0 & \\text{se } x &lt; 0 \\\\ 1 - e^{-x} & \\text{se } x \\geq 0. \\end{cases}\\) (b) \\(F_X(x) = \\begin{cases} e^x/2 & \\text{se } x &lt; 0 \\\\ 1/2 & \\text{se } 0 \\leq x &lt; 1 \\\\ 1 - (e^{1-x}/2) & \\text{se } 1 \\leq x. \\end{cases}\\) (c) \\(F_X(x) = \\begin{cases} e^x/4 & \\text{se } x &lt; 0 \\\\ 1 - (e^{-x}/4) & \\text{se } x \\geq 0. \\end{cases}\\) Note que, na parte (c), \\(F_X(x)\\) é descontínua, mas (2.1.13) ainda é a definição apropriada de \\(F_X^{-1}(y)\\).\n2.9 Se a variável aleatória \\(X\\) tem fdp \\[\nf(x) = \\begin{cases} \\frac{x-1}{2} & 1 &lt; x &lt; 3 \\\\ 0 & \\text{caso contrário}, \\end{cases}\n\\] encontre uma função monotônica \\(u(x)\\) tal que a variável aleatória \\(Y = u(X)\\) tenha uma distribuição uniforme(0,1).\n2.10 No Teorema 2.1.10, a transformação integral de probabilidade foi provada, relacionando a fda uniforme a qualquer fda contínua. Neste exercício, investigamos a relação entre variáveis aleatórias discretas e variáveis aleatórias uniformes. Seja \\(X\\) uma variável aleatória discreta com fda \\(F_X(x)\\) e defina a variável aleatória \\(Y\\) como \\(Y = F_X(X)\\). (a) Prove que \\(Y\\) é estocasticamente maior que uma uniforme(0,1); isto é, se \\(U \\sim \\text{uniforme}(0,1)\\), então \\[\nP(Y &gt; y) \\geq P(U &gt; y) = 1 - y, \\quad \\text{para todo } y, 0 &lt; y &lt; 1,\n\\] \\[\nP(Y &gt; y) &gt; P(U &gt; y) = 1 - y, \\quad \\text{para algum } y, 0 &lt; y &lt; 1.\n\\] (Lembre-se que estocasticamente maior foi definido no Exercício 1.49.) (b) Equivalentemente, mostre que a fda de \\(Y\\) satisfaz \\(F_Y(y) \\leq y\\) para todo \\(0 &lt; y &lt; 1\\) e \\(F_Y(y) &lt; y\\) para algum \\(0 &lt; y &lt; 1\\). (Dica: Seja \\(x_0\\) um ponto de salto de \\(F_X\\), e defina \\(y_0 = F_X(x_0)\\). Mostre que \\(P(Y \\leq y_0) = y_0\\). Agora estabeleça a desigualdade considerando \\(y = y_0 + \\varepsilon\\). Imagens das fdas ajudarão.)\n2.11 Seja \\(X\\) com a fdp normal padrão, \\(f_X(x) = (1/\\sqrt{2\\pi})e^{-x^2/2}\\). (a) Encontre \\(EX^2\\) diretamente, e então usando a fdp de \\(Y = X^2\\) do Exemplo 2.1.7 e calculando \\(EY\\). (b) Encontre a fdp de \\(Y = |X|\\), e encontre sua média e variância.\n2.12 Um triângulo retângulo aleatório pode ser construído da seguinte maneira. Seja \\(X\\) um ângulo aleatório cuja distribuição é uniforme em \\((0, \\pi/2)\\). Para cada \\(X\\), construa um triângulo como ilustrado abaixo. Aqui, \\(Y = \\text{altura do triângulo retângulo}\\). Para uma constante fixa \\(d\\), encontre a distribuição de \\(Y\\) e \\(EY\\).\n\n\n\n\n\n\nFigura 3.6: Figura 2.5.1 - Triângulo retângulo aleatório\n\n\n\n2.13 Considere uma sequência de lançamentos de moedas independentes, cada um com probabilidade \\(p\\) de ser Cara. Defina uma variável aleatória \\(X\\) como o comprimento da sequência (de Caras ou Coras) iniciada pela primeira tentativa. (Por exemplo, \\(X = 3\\) se TTTC ou CCCK for observado.) Encontre a distribuição de \\(X\\) e encontre \\(EX\\).\n2.14 (a) Seja \\(X\\) uma variável aleatória contínua e não negativa [\\(f(x) = 0\\) para \\(x &lt; 0\\)]. Mostre que \\[\nEX = \\int_0^\\infty [1 - F_X(x)] dx,\n\\] onde \\(F_X(x)\\) é a fda de \\(X\\). (b) Seja \\(X\\) uma variável aleatória discreta cujo intervalo são os inteiros não negativos. Mostre que \\[\nEX = \\sum_{k=0}^\\infty (1 - F_X(k)),\n\\] onde \\(F_X(k) = P(X \\leq k)\\). Compare isso com a parte (a).\n2.15 Betteley (1977) fornece uma lei de adição interessante para expectativas. Sejam \\(X\\) e \\(Y\\) duas variáveis aleatórias quaisquer e defina \\[\nX \\land Y = \\min(X, Y) \\quad \\text{e} \\quad X \\lor Y = \\max(X, Y).\n\\] De forma análoga à lei de probabilidade \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\), mostre que \\[\nE(X \\lor Y) = EX + EY - E(X \\land Y).\n\\] (Dica: Estabeleça que \\(X + Y = (X \\lor Y) + (X \\land Y)\\).)\n2.16 Use o resultado do Exercício 2.14 para encontrar a duração média de certas chamadas telefônicas, onde assumimos que a duração, \\(T\\), de uma chamada particular pode ser descrita probabilisticamente por \\(P(T &gt; t) = ae^{-\\lambda t} + (1-a)e^{-\\mu t}\\), onde \\(a, \\lambda\\) e \\(\\mu\\) são constantes, \\(0 &lt; a &lt; 1, \\lambda &gt; 0, \\mu &gt; 0\\).\n2.17 Uma mediana de uma distribuição é um valor \\(m\\) tal que \\(P(X \\leq m) \\geq 1/2\\) e \\(P(X \\geq m) \\geq 1/2\\). (Se \\(X\\) é contínua, \\(m\\) satisfaz \\(\\int_{-\\infty}^m f(x) dx = \\int_m^\\infty f(x) dx = 1/2\\).) Encontre a mediana das seguintes distribuições. (a) \\(f(x) = 3x^2, 0 &lt; x &lt; 1\\) (b) \\(f(x) = \\frac{1}{\\pi(1+x^2)}, -\\infty &lt; x &lt; \\infty\\)\n2.18 Mostre que se \\(X\\) é uma variável aleatória contínua, então \\[\n\\min_a E|X - a| = E|X - m|,\n\\] onde \\(m\\) é a mediana de \\(X\\) (veja o Exercício 2.17).\n2.19 Prove que \\[\n\\frac{d}{da} E(X - a)^2 = 0 \\iff EX = a,\n\\] diferenciando a integral. Verifique, usando cálculo, que \\(a = EX\\) é de fato um mínimo. Liste as suposições sobre \\(F_X\\) e \\(f_X\\) que são necessárias.\n2.20 Um casal decide continuar a ter filhos até que uma filha nasça. Qual é o número esperado de filhos deste casal? (Dica: Veja o Exemplo 1.5.4.)\n2.21 Prove a regra de “duas vias” para expectativas, equação (2.2.5), que diz \\(Eg(X) = EY\\), onde \\(Y = g(X)\\). Assuma que \\(g(x)\\) é uma função monotônica.\n2.22 Seja \\(X\\) com a fdp \\[\nf(x) = \\frac{4}{\\beta^3\\sqrt{\\pi}} x^2 e^{-x^2/\\beta^2}, \\quad 0 &lt; x &lt; \\infty, \\quad \\beta &gt; 0.\n\\] (a) Verifique que \\(f(x)\\) é uma fdp. (b) Encontre \\(EX\\) e \\(Var X\\).\n2.23 Seja \\(X\\) com a fdp \\[\nf(x) = \\frac{1}{2}(1+x), \\quad -1 &lt; x &lt; 1.\n\\] (a) Encontre a fdp de \\(Y = X^2\\). (b) Encontre \\(EY\\) e \\(Var Y\\).\n2.24 Calcule \\(EX\\) e \\(Var X\\) para cada uma das seguintes distribuições de probabilidade. (a) \\(f_X(x) = ax^{a-1}, 0 &lt; x &lt; 1, a &gt; 0\\) (b) \\(f_X(x) = 1/n, x = 1, 2, \\dots, n, n &gt; 0\\) um inteiro (c) \\(f_X(x) = \\frac{3}{2}(x-1)^2, 0 &lt; x &lt; 2\\)\n2.25 Suponha que a fdp \\(f_X(x)\\) de uma variável aleatória \\(X\\) seja uma função par. (\\(f_X(x)\\) é uma função par se \\(f_X(x) = f_X(-x)\\) para todo \\(x\\).) Mostre que (a) \\(X\\) e \\(-X\\) são identicamente distribuídas. (b) \\(M_X(t)\\) é simétrica em torno de zero.\n2.26 Seja \\(f(x)\\) uma fdp e seja \\(a\\) um número tal que, para todo \\(\\varepsilon &gt; 0, f(a+\\varepsilon) = f(a-\\varepsilon)\\). Tal fdp é dita ser simétrica em torno do ponto a. (a) Dê três exemplos de fdps simétricas. (b) Mostre que se \\(X \\sim f(x)\\), simétrica, então a mediana de \\(X\\) (veja o Exercício 2.17) é o número \\(a\\). (c) Mostre que se \\(X \\sim f(x)\\), simétrica, e \\(EX\\) existe, então \\(EX = a\\). (d) Mostre que \\(f(x) = e^{-x}, x \\geq 0\\), não é uma fdp simétrica. (e) Mostre que para a fdp na parte (d), a mediana é menor que a média.\n2.27 Seja \\(f(x)\\) uma fdp e seja \\(a\\) um número tal que, se \\(a \\geq x \\geq y\\) então \\(f(a) \\geq f(x) \\geq f(y)\\) e, se \\(a \\leq x \\leq y\\) então \\(f(a) \\geq f(x) \\geq f(y)\\). Tal fdp é chamada de unimodal com um moda igual a \\(a\\). (a) Dê um exemplo de uma fdp unimodal para a qual a moda é única. (b) Dê um exemplo de uma fdp unimodal para a qual a moda não é única. (c) Mostre que se \\(f(x)\\) é tanto simétrica (veja o Exercício 2.26) quanto unimodal, então o ponto de simetria é uma moda. (d) Considere a fdp \\(f(x) = e^{-x}, x \\geq 0\\). Mostre que esta fdp é unimodal. Qual é sua moda?\n2.28 Seja \\(\\mu_n\\) o \\(n\\)-ésimo momento central de uma variável aleatória \\(X\\). Duas quantidades de interesse, além da média e variância, são \\[\n\\alpha_3 = \\frac{\\mu_3}{(\\mu_2)^{3/2}} \\quad \\text{e} \\quad \\alpha_4 = \\frac{\\mu_4}{\\mu_2^2}.\n\\] O valor \\(\\alpha_3\\) é chamado de assimetria e \\(\\alpha_4\\) é chamado de curtose. A assimetria mede a falta de simetria na fdp (veja o Exercício 2.26). A curtose, embora mais difícil de interpretar, mede o pico ou achatamento da fdp. (a) Mostre que se uma fdp é simétrica em torno de um ponto \\(a\\), então \\(\\alpha_3 = 0\\). (b) Calcule \\(\\alpha_3\\) para \\(f(x) = e^{-x}, x \\geq 0\\), uma fdp que é assimétrica à direita. (c) Calcule \\(\\alpha_4\\) para cada uma das seguintes fdps e comente sobre o pico de cada uma. \\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty\n\\] \\[\nf(x) = \\frac{1}{2}, \\quad -1 &lt; x &lt; 1\n\\] \\[\nf(x) = \\frac{1}{2} e^{-|x|}, \\quad -\\infty &lt; x &lt; \\infty\n\\] Ruppert (1987) usa funções de influência (Seção 10.6.4) para explorar ainda mais o significado de curtose e Groeneveld (1991) as usa para explorar a assimetria; veja também Balanda e MacGillivray (1988) para mais sobre a interpretação de \\(\\alpha_4\\).\n2.29 Ao calcular momentos de distribuições discretas, muitas vezes é mais fácil trabalhar com os momentos fatoriais (veja Assuntos Diversos 2.6.2). (a) Calcule o momento fatorial \\(E[X(X-1)]\\) para as distribuições binomial e Poisson. (b) Use os resultados da parte (a) para calcular as variâncias da distribuição binomial e Poisson. (c) Uma distribuição discreta particularmente desagradável é a beta-binomial, com fmp \\[\nP(Y = y) = \\binom{n}{y} \\frac{\\Gamma(y+a)\\Gamma(n-y+b)\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)\\Gamma(n+a+b)}, \\quad y = 0, 1, \\dots, n.\n\\] onde \\(n, a\\) e \\(b\\) são inteiros positivos. Use momentos fatoriais para calcular a variância da beta binomial. (Veja o Exercício 4.34 para outra abordagem deste cálculo.)\n2.30 Encontre a função geradora de momentos correspondente a (a) \\(f(x) = \\frac{1}{c}, 0 &lt; x &lt; c\\) (b) \\(f(x) = \\frac{2x}{c^2}, 0 &lt; x &lt; c\\) (c) \\(f(x) = \\frac{1}{2\\beta} e^{-|x-\\alpha|/\\beta}, -\\infty &lt; x &lt; \\infty, -\\infty &lt; \\alpha &lt; \\infty, \\beta &gt; 0\\) (d) \\(P(X = x) = \\binom{r+x-1}{x} p^r(1-p)^x, x = 0, 1, \\dots, 0 &lt; p &lt; 1, r &gt; 0\\) um inteiro\n2.31 Existe uma distribuição para a qual \\(M_X(t) = t/(1-t), |t| &lt; 1\\)? Se sim, encontre-a. Se não, prove.\n2.32 Seja \\(M_X(t)\\) a função geradora de momentos de \\(X\\), e defina \\(S(t) = \\log(M_X(t))\\). Mostre que \\[\n\\frac{d}{dt} S(t) \\Big|_{t=0} = EX \\quad \\text{e} \\quad \\frac{d^2}{dt^2} S(t) \\Big|_{t=0} = Var X.\n\\]\n2.33 Em cada um dos seguintes casos, verifique a expressão dada para a função geradora de momentos e, em cada caso, use a fgm para calcular \\(EX\\) e \\(Var X\\). (a) \\(P(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, M_X(t) = e^{\\lambda(e^t-1)}, x = 0, 1, \\dots; \\lambda &gt; 0\\) (b) \\(P(X = x) = p(1-p)^x, M_X(t) = \\frac{p}{1-(1-p)e^t}, x = 0, 1, \\dots; 0 &lt; p &lt; 1\\) (c) \\(f_X(x) = \\frac{e^{-(x-\\mu)^2/(2\\sigma^2)}}{\\sqrt{2\\pi}\\sigma}, M_X(t) = e^{\\mu t + \\sigma^2t^2/2}, -\\infty &lt; x &lt; \\infty; -\\infty &lt; \\mu &lt; \\infty, \\sigma &gt; 0\\)\n2.34 Uma distribuição não pode ser unicamente determinada por uma coleção finita de momentos, como mostra este exemplo de Romano e Siegel (1986). Seja \\(X\\) com distribuição normal, ou seja, \\(X\\) tem fdp \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\quad -\\infty &lt; x &lt; \\infty.\n\\] Defina uma variável aleatória discreta \\(Y\\) por \\[\nP(Y = \\sqrt{3}) = P(Y = -\\sqrt{3}) = 1/6, \\quad P(Y = 0) = 2/3.\n\\] Mostre que \\[\nEX^r = EY^r \\quad \\text{para } r = 1, 2, 3, 4, 5.\n\\] (Romano e Siegel (1986) apontam que para qualquer \\(n\\) finito existe uma variável aleatória discreta, e portanto não normal, cujos primeiros \\(n\\) momentos são iguais aos de \\(X\\).)\n2.35 Preencha as lacunas no Exemplo 2.3.10. (a) Mostre que se \\(X_1 \\sim f_1(x)\\), então \\[\nEX_1^r = e^{r^2/2}, \\quad r = 0, 1, \\dots.\n\\] Logo \\(f_1(x)\\) possui todos os seus momentos, e todos os momentos são finitos. (b) Agora mostre que \\[\n\\int_0^\\infty x^r f_1(x) \\sin(2\\pi \\log x) dx = 0,\n\\] para todos os inteiros positivos \\(r\\), logo \\(EX_1^r = EX_2^r\\) para todo \\(r\\). (Romano e Siegel (1986) discutem uma versão extrema deste exemplo, onde uma classe inteira de fdps distintas tem os mesmos momentos. Além disso, Berg (1988) mostrou que este comportamento de momentos pode surgir com transformadas mais simples da distribuição normal, como \\(X^3\\).)\n2.36 A distribuição lognormal, na qual o Exemplo 2.3.10 se baseia, tem uma propriedade interessante. Se tivermos a fdp \\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2}, \\quad 0 \\leq x &lt; \\infty,\n\\] então o Exercício 2.35 mostra que todos os momentos existem e são finitos. No entanto, esta distribuição não possui uma função geradora de momentos, isto é, \\[\nM_X(t) = \\int_0^\\infty \\frac{e^{tx}}{\\sqrt{2\\pi}x} e^{-(\\log x)^2/2} dx\n\\] não existe. Prove isso.\n2.37 Referindo-se à situação descrita em Assuntos Diversos 2.6.3: (a) Trace as fdps \\(f_1\\) e \\(f_2\\) para ilustrar sua diferença. (b) Trace as funções geradoras de cumulantes \\(K_1\\) e \\(K_2\\) para ilustrar sua semelhança. (c) Calcule as funções geradoras de momentos das fdps \\(f_1\\) e \\(f_2\\). Elas são semelhantes ou diferentes? (d) Como as fdps \\(f_1\\) e \\(f_2\\) se relacionam com as fdps descritas no Exemplo 2.3.10?\n2.38 Seja \\(X\\) com a distribuição binomial negativa com fmp \\[\nf(x) = \\binom{r+x-1}{x} p^r(1-p)^x, \\quad x = 0, 1, 2, \\dots\n\\] onde \\(0 &lt; p &lt; 1\\) e \\(r &gt; 0\\) é um inteiro. (a) Calcule a fgm de \\(X\\). (b) Defina uma nova variável aleatória por \\(Y = 2pX\\). Mostre que, conforme \\(p \\downarrow 0\\), a fgm de \\(Y\\) converge para a de uma variável aleatória qui-quadrado com \\(2r\\) graus de liberdade, mostrando que \\[\n\\lim_{p \\to 0} M_Y(t) = \\left( \\frac{1}{1-2t} \\right)^r, \\quad |t| &lt; 1/2.\n\\]\n2.39 Em cada um dos seguintes casos, calcule as derivadas indicadas, justificando todas as operações. (a) \\(\\frac{d}{dx} \\int_0^x e^{-\\lambda t} dt\\) (b) \\(\\frac{d}{d\\lambda} \\int_0^\\infty e^{-\\lambda t} dt\\) (c) \\(\\frac{d}{dt} \\int_t^1 \\frac{1}{x^2} dx\\) (d) \\(\\frac{d}{dt} \\int_1^\\infty \\frac{1}{(x-t)^2} dx\\)\n2.40 Prove \\[\n\\sum_{k=0}^x \\binom{n}{k} p^k(1-p)^{n-k} = (n-x) \\binom{n}{x} \\int_0^{1-p} t^{n-x-1}(1-t)^x dt.\n\\] (Dica: Integre por partes ou diferencie ambos os lados em relação a \\(p\\).)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transformações e Esperanças</span>"
    ]
  }
]