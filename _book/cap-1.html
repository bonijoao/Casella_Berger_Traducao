<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-BR" xml:lang="pt-BR"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Teoria da Probabilidade – Inferência Estatística</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./cap-2.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-91a075d8818a95db6941a9bd21f60062.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./cap-1.html"><span class="chapter-title">Teoria da Probabilidade</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Procurar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Inferência Estatística</a> 
        <div class="sidebar-tools-main">
    <a href="./#" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-git"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Procurar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Inferência Estatística</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-1.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Teoria da Probabilidade</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Transformações e Esperanças</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Famílias Comuns de Distribuições</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Múltiplas Variáveis Aleatórias</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Propriedades de uma Amostra Aleatória</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Princípios de Redução de Dados</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Estimação Pontual</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Teste de Hipóteses</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Estimação por Intervalo</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Avaliações Assintóticas</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-11.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Análise de Variância e Regressão</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cap-12.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Modelos de Regressão</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul class="collapse">
  <li><a href="#teoria-dos-conjuntos" id="toc-teoria-dos-conjuntos" class="nav-link active" data-scroll-target="#teoria-dos-conjuntos">1.1 Teoria dos Conjuntos</a></li>
  <li><a href="#fundamentos-da-probabilidade" id="toc-fundamentos-da-probabilidade" class="nav-link" data-scroll-target="#fundamentos-da-probabilidade">1.2 Fundamentos da Probabilidade</a></li>
  <li><a href="#probabilidade-condicional-e-independência" id="toc-probabilidade-condicional-e-independência" class="nav-link" data-scroll-target="#probabilidade-condicional-e-independência">1.3 Probabilidade Condicional e Independência</a></li>
  <li><a href="#variáveis-aleatórias" id="toc-variáveis-aleatórias" class="nav-link" data-scroll-target="#variáveis-aleatórias">1.4 Variáveis Aleatórias</a></li>
  <li><a href="#funções-de-distribuição" id="toc-funções-de-distribuição" class="nav-link" data-scroll-target="#funções-de-distribuição">1.5 Funções de Distribuição</a></li>
  <li><a href="#funções-de-densidade-e-de-massa" id="toc-funções-de-densidade-e-de-massa" class="nav-link" data-scroll-target="#funções-de-densidade-e-de-massa">1.6 Funções de Densidade e de Massa</a></li>
  <li><a href="#exercícios" id="toc-exercícios" class="nav-link" data-scroll-target="#exercícios">1.7 Exercícios</a></li>
  <li><a href="#assuntos-diversos" id="toc-assuntos-diversos" class="nav-link" data-scroll-target="#assuntos-diversos">1.8 Assuntos Diversos</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Teoria da Probabilidade</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="chapter-intro">
<p>“Você nunca pode, por exemplo, prever o que um único homem fará, mas pode dizer com precisão o que uma média fará. Os indivíduos variam, mas as porcentagens permanecem constantes. Assim diz o estatístico.”</p>
<div class="chapter-intro-quote">
<p><strong>Sherlock Holmes</strong> <em>O Signo dos Quatro</em></p>
</div>
</div>
<p>O tema da teoria da probabilidade é a fundação sobre a qual toda a estatística é construída, fornecendo um meio para modelar populações, experimentos ou quase qualquer outra coisa que possa ser considerada um fenômeno aleatório. Por meio desses modelos, os estatísticos são capazes de tirar inferências sobre populações, inferências baseadas no exame de apenas uma parte do todo.</p>
<p>A teoria da probabilidade tem uma história longa e rica, que remonta pelo menos ao século XVII, quando, a pedido de seu amigo, o Chevalier de Méré, Pascal e Fermat desenvolveram uma formulação matemática para as probabilidades em jogos de azar.</p>
<p>O objetivo deste capítulo não é fornecer uma introdução exaustiva à teoria da probabilidade; tal tentativa seria imprudente em um espaço tão curto. Em vez disso, tentamos delinear algumas das ideias básicas da teoria da probabilidade que são fundamentais para o estudo da estatística.</p>
<p>Assim como a estatística se baseia na fundação da teoria da probabilidade, a teoria da probabilidade, por sua vez, se baseia na teoria dos conjuntos, que é onde começamos.</p>
<section id="teoria-dos-conjuntos" class="level2">
<h2 class="anchored" data-anchor-id="teoria-dos-conjuntos">1.1 Teoria dos Conjuntos</h2>
<p>Um dos principais objetivos de um estatístico é tirar conclusões sobre uma população de objetos realizando um experimento. O primeiro passo nesse esforço é identificar os possíveis resultados ou, na terminologia estatística, o espaço amostral.</p>
<section id="definição-1.1.1---espaço-amostral" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.1.1---espaço-amostral">Definição 1.1.1 - Espaço Amostral</h3>
<p>O conjunto, <span class="math inline">\(S\)</span>, de todos os resultados possíveis de um experimento particular é chamado de <em>espaço amostral</em> do experimento.</p>
</section>
<p>Se o experimento consiste em lançar uma moeda, o espaço amostral contém dois resultados, cara e coroa; portanto,</p>
<p><span class="math display">\[
S = \{H, T\}.
\]</span></p>
<p>Se, por outro lado, o experimento consiste em observar as notas do SAT reportadas de alunos selecionados aleatoriamente em uma certa universidade, o espaço amostral seria o conjunto de inteiros positivos entre 200 e 800 que são múltiplos de dez — isto é, <span class="math inline">\(S = \{200, 210, 220, \dots, 780, 790, 800\}\)</span>. Finalmente, considere um experimento onde a observação é o tempo de reação a um determinado estímulo. Aqui, o espaço amostral consistiria em todos os números positivos, isto é, <span class="math inline">\(S = (0, \infty)\)</span>.</p>
<p>Podemos classificar os espaços amostrais em dois tipos, de acordo com o número de elementos que eles contêm. Espaços amostrais podem ser <em>enumeráveis</em> ou <em>não enumeráveis</em>; se os elementos de um espaço amostral podem ser colocados em correspondência biunívoca (1 para 1) com um subconjunto dos inteiros, o espaço amostral é enumerável. É claro que, se o espaço amostral contém apenas um número finito de elementos, ele é enumerável. Assim, os espaços amostrais do lançamento da moeda e das notas do SAT são ambos enumeráveis (de fato, finitos), enquanto o espaço amostral do tempo de reação é não enumerável, uma vez que os números reais positivos não podem ser colocados em correspondência biunívoca com os inteiros. Se, no entanto, medíssemos o tempo de reação arredondando para o segundo mais próximo, então o espaço amostral seria (em segundos) <span class="math inline">\(S = \{0, 1, 2, 3, \dots\}\)</span>, que é então enumerável.</p>
<p>Essa distinção entre espaços amostrais enumeráveis e não enumeráveis é importante apenas na medida em que dita a maneira pela qual as probabilidades podem ser atribuídas. Na maior parte das vezes, isso não causa problemas, embora o tratamento matemático das situações seja diferente. Em um nível filosófico, poderia ser argumentado que só podem existir espaços amostrais enumeráveis, uma vez que as medições não podem ser feitas com precisão infinita. (Um espaço amostral consistindo, digamos, de todos os números de dez dígitos é um espaço amostral enumerável.) Embora na prática isso seja verdade, métodos probabilísticos e estatísticos associados a espaços amostrais não enumeráveis são, em geral, menos trabalhosos do que aqueles para espaços amostrais enumeráveis e fornecem uma aproximação próxima da situação verdadeira (enumerável).</p>
<p>Uma vez definido o espaço amostral, estamos em posição de considerar coleções de possíveis resultados de um experimento.</p>
<section id="definição-1.1.2---evento" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.1.2---evento">Definição 1.1.2 - Evento</h3>
<p>Um <em>evento</em> é qualquer coleção de possíveis resultados de um experimento, isto é, qualquer subconjunto de <span class="math inline">\(S\)</span> (incluindo o próprio <span class="math inline">\(S\)</span>).</p>
</section>
<p>Seja <span class="math inline">\(A\)</span> um evento, um subconjunto de <span class="math inline">\(S\)</span>. Dizemos que o evento <span class="math inline">\(A\)</span> ocorre se o resultado do experimento estiver no conjunto <span class="math inline">\(A\)</span>. Ao falar de probabilidades, geralmente falamos da probabilidade de um evento, em vez de um conjunto. Mas podemos usar os termos de forma intercambiável.</p>
<p>Primeiro, precisamos definir formalmente as duas relações a seguir, que nos permitem ordenar e igualar conjuntos:</p>
<p><span class="math display">\[
\begin{align*}
A \subset B &amp;\iff x \in A \Rightarrow x \in B; &amp;(\text{continência}) \\
A = B &amp;\iff A \subset B \text{ e } B \subset A. &amp;(\text{igualdade})
\end{align*}
\]</span></p>
<p>Dados dois eventos (ou conjuntos) <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, temos as seguintes operações elementares de conjuntos:</p>
<p><strong>União:</strong> A união de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, escrita <span class="math inline">\(A \cup B\)</span>, é o conjunto de elementos que pertencem a <span class="math inline">\(A\)</span> ou a <span class="math inline">\(B\)</span> ou a ambos:</p>
<p><span class="math display">\[
A \cup B = \{x : x \in A \text{ ou } x \in B\}.
\]</span></p>
<p><strong>Interseção:</strong> A interseção de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, escrita <span class="math inline">\(A \cap B\)</span>, é o conjunto de elementos que pertencem a ambos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>:</p>
<p><span class="math display">\[
A \cap B = \{x : x \in A \text{ e } x \in B\}.
\]</span></p>
<p><strong>Complementar:</strong> O complementar de <span class="math inline">\(A\)</span>, escrito <span class="math inline">\(A^c\)</span>, é o conjunto de todos os elementos que não estão em <span class="math inline">\(A\)</span>:</p>
<p><span class="math display">\[
A^c = \{x : x \notin A\}.
\]</span></p>
<section id="exemplo-1.1.3-operações-com-eventos" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.1.3-operações-com-eventos">Exemplo 1.1.3 (Operações com eventos)</h3>
<p>Considere o experimento de selecionar uma carta aleatoriamente de um baralho padrão e anotar seu naipe: paus (C), ouros (D), copas (H) ou espadas (S). O espaço amostral é</p>
<p><span class="math display">\[
S = \{C, D, H, S\},
\]</span></p>
<p>e alguns eventos possíveis são</p>
<p><span class="math display">\[
A = \{C, D\} \quad \text{e} \quad B = \{D, H, S\}.
\]</span></p>
<p>A partir desses eventos, podemos formar</p>
<p><span class="math display">\[
A \cup B = \{C, D, H, S\}, \quad A \cap B = \{D\}, \quad \text{e} \quad A^c = \{H, S\}.
\]</span></p>
<p>Além disso, note que <span class="math inline">\(A \cup B = S\)</span> (o evento <span class="math inline">\(S\)</span>) e <span class="math inline">\((A \cup B)^c = \emptyset\)</span>, onde <span class="math inline">\(\emptyset\)</span> denota o <em>conjunto vazio</em> (o conjunto que não consiste em nenhum elemento).</p>
</section>
<p>As operações elementares de conjuntos podem ser combinadas, de certa forma semelhante à maneira como a adição e a multiplicação podem ser combinadas. Desde que tenhamos cuidado, podemos tratar conjuntos como se fossem números. Podemos agora enunciar as seguintes propriedades úteis das operações de conjuntos.</p>
<section id="teorema-1.1.4" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.1.4">Teorema 1.1.4</h3>
<p><em>Para quaisquer três eventos, <span class="math inline">\(A, B\)</span> e <span class="math inline">\(C\)</span>, definidos em um espaço amostral <span class="math inline">\(S\)</span>,</em></p>
<ul>
<li><p><strong>a. Comutatividade</strong> <span class="math display">\[
\begin{align*}
A \cup B &amp;= B \cup A, \\
A \cap B &amp;= B \cap A;
\end{align*}
\]</span></p></li>
<li><p><strong>b. Associatividade</strong> <span class="math display">\[
\begin{align*}
A \cup (B \cup C) &amp;= (A \cup B) \cup C, \\
A \cap (B \cap C) &amp;= (A \cap B) \cap C;
\end{align*}
\]</span></p></li>
<li><p><strong>c.&nbsp;Leis Distributivas</strong> <span class="math display">\[
\begin{align*}
A \cap (B \cup C) &amp;= (A \cap B) \cup (A \cap C), \\
A \cup (B \cap C) &amp;= (A \cup B) \cap (A \cup C);
\end{align*}
\]</span></p></li>
<li><p><strong>d.&nbsp;Leis de DeMorgan</strong> <span class="math display">\[
\begin{align*}
(A \cup B)^c &amp;= A^c \cap B^c, \\
(A \cap B)^c &amp;= A^c \cup B^c.
\end{align*}
\]</span></p></li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>A prova de grande parte deste teorema é deixada como Exercício 1.3. Além disso, os Exercícios 1.9 e 1.10 generalizam o teorema. Para ilustrar a técnica, no entanto, provaremos a Lei Distributiva:</p>
<p><span class="math display">\[
A \cap (B \cup C) = (A \cap B) \cup (A \cap C).
\]</span></p>
<p>(Você pode estar familiarizado com o uso de diagramas de Venn para “provar” teoremas na teoria dos conjuntos. Advertimos que, embora os diagramas de Venn sejam às vezes úteis para visualizar uma situação, eles não constituem uma prova formal.) Para provar que dois conjuntos são iguais, deve-se demonstrar que cada conjunto contém o outro. Formalmente, então,</p>
<p><span class="math display">\[
\begin{align*}
A \cap (B \cup C) &amp;= \{x \in S : x \in A \text{ e } x \in (B \cup C)\}; \\
(A \cap B) \cup (A \cap C) &amp;= \{x \in S : x \in (A \cap B) \text{ ou } x \in (A \cap C)\}.
\end{align*}
\]</span></p>
<p>Primeiro mostramos que <span class="math inline">\(A \cap (B \cup C) \subset (A \cap B) \cup (A \cap C)\)</span>. Seja <span class="math inline">\(x \in (A \cap (B \cup C))\)</span>. Pela definição de interseção, deve ser que <span class="math inline">\(x \in A\)</span> e <span class="math inline">\(x \in (B \cup C)\)</span>, isto é, <span class="math inline">\(x \in B\)</span> ou <span class="math inline">\(x \in C\)</span>. Como <span class="math inline">\(x\)</span> também deve estar em <span class="math inline">\(A\)</span>, temos que <span class="math inline">\(x \in (A \cap B)\)</span> ou <span class="math inline">\(x \in (A \cap C)\)</span>; portanto,</p>
<p><span class="math display">\[
x \in ((A \cap B) \cup (A \cap C)),
\]</span></p>
<p>e a continência está estabelecida. Agora assuma <span class="math inline">\(x \in ((A \cap B) \cup (A \cap C))\)</span>. Isso implica que <span class="math inline">\(x \in (A \cap B)\)</span> ou <span class="math inline">\(x \in (A \cap C)\)</span>. Se <span class="math inline">\(x \in (A \cap B)\)</span>, então <span class="math inline">\(x\)</span> está em ambos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>. Visto que <span class="math inline">\(x \in B, x \in (B \cup C)\)</span> e assim <span class="math inline">\(x \in (A \cap (B \cup C))\)</span>. Se, por outro lado, <span class="math inline">\(x \in (A \cap C)\)</span>, o argumento é similar, e novamente concluímos que <span class="math inline">\(x \in (A \cap (B \cup C))\)</span>. Assim, estabelecemos <span class="math inline">\((A \cap B) \cup (A \cap C) \subset A \cap (B \cup C)\)</span>, mostrando a continência na outra direção e, portanto, provando a Lei Distributiva. <span class="math inline">\(\square\)</span></p>
</div>
<p>As operações de união e interseção podem ser estendidas para coleções infinitas de conjuntos também. Se <span class="math inline">\(A_1, A_2, A_3, \dots\)</span> é uma coleção de conjuntos, todos definidos em um espaço amostral <span class="math inline">\(S\)</span>, então</p>
<p><span class="math display">\[
\bigcup_{i=1}^{\infty} A_i = \{x \in S : x \in A_i \text{ para algum } i\},
\]</span> <span class="math display">\[
\bigcap_{i=1}^{\infty} A_i = \{x \in S : x \in A_i \text{ para todo } i\}.
\]</span></p>
<p>Por exemplo, seja <span class="math inline">\(S = (0, 1]\)</span> e defina <span class="math inline">\(A_i = [(1/i), 1]\)</span>. Então</p>
<p><span class="math display">\[
\begin{align*}
\bigcup_{i=1}^{\infty} A_i &amp;= \bigcup_{i=1}^{\infty} [(1/i), 1] &amp;&amp;= \{x \in (0, 1] : x \in [(1/i), 1] \text{ para algum } i\} \\
&amp; &amp;&amp;= \{x \in (0, 1]\} &amp;&amp;= (0, 1]; \\
\bigcap_{i=1}^{\infty} A_i &amp;= \bigcap_{i=1}^{\infty} [(1/i), 1] &amp;&amp;= \{x \in (0, 1] : x \in [(1/i), 1] \text{ para todo } i\} \\
&amp; &amp;&amp;= \{x \in (0, 1] : x \in [1, 1]\} &amp;&amp;= \{1\}. \quad \text{(o ponto 1)}
\end{align*}
\]</span></p>
<p>Também é possível definir uniões e interseções sobre coleções não enumeráveis de conjuntos. Se <span class="math inline">\(\Gamma\)</span> é um conjunto de índices (um conjunto de elementos a serem usados como índices), então</p>
<p><span class="math display">\[
\bigcup_{\alpha \in \Gamma} A_{\alpha} = \{x \in S : x \in A_{\alpha} \text{ para algum } \alpha\},
\]</span> <span class="math display">\[
\bigcap_{\alpha \in \Gamma} A_{\alpha} = \{x \in S : x \in A_{\alpha} \text{ para todo } \alpha\}.
\]</span></p>
<p>Se, por exemplo, tomarmos <span class="math inline">\(\Gamma = \{\text{todos os números reais positivos}\}\)</span> e <span class="math inline">\(A_{\alpha} = (0, \alpha]\)</span>, então <span class="math inline">\(\cup_{\alpha \in \Gamma} A_{\alpha} = (0, \infty)\)</span> é uma união não enumerável. Embora uniões e interseções não enumeráveis não desempenhem um papel importante na estatística, elas às vezes fornecem um mecanismo útil para obter uma resposta (veja a Seção 8.2.3).</p>
<p>Finalmente, discutimos a ideia de uma partição do espaço amostral.</p>
<section id="definição-1.1.5---disjuntos" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.1.5---disjuntos">Definição 1.1.5 - Disjuntos</h3>
<p>Dois eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são <em>disjuntos</em> (ou <em>mutuamente exclusivos</em>) se <span class="math inline">\(A \cap B = \emptyset\)</span>. Os eventos <span class="math inline">\(A_1, A_2, \dots\)</span> são <em>disjuntos dois a dois</em> (ou <em>mutuamente exclusivos</em>) se <span class="math inline">\(A_i \cap A_j = \emptyset\)</span> para todo <span class="math inline">\(i \ne j\)</span>.</p>
</section>
<p>Conjuntos disjuntos são conjuntos sem pontos em comum. Se desenharmos um diagrama de Venn para dois conjuntos disjuntos, os conjuntos não se sobrepõem. A coleção</p>
<p><span class="math display">\[
A_i = [i, i+1), \quad i = 0, 1, 2, \dots,
\]</span></p>
<p>consiste em conjuntos disjuntos dois a dois. Note ainda que <span class="math inline">\(\cup_{i=0}^{\infty} A_i = [0, \infty)\)</span>.</p>
<section id="definição-1.1.6---partição" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.1.6---partição">Definição 1.1.6 - Partição</h3>
<p>Se <span class="math inline">\(A_1, A_2, \dots\)</span> são disjuntos dois a dois e <span class="math inline">\(\cup_{i=1}^{\infty} A_i = S\)</span>, então a coleção <span class="math inline">\(A_1, A_2, \dots\)</span> forma uma <em>partição</em> de <span class="math inline">\(S\)</span>.</p>
</section>
<p>Os conjuntos <span class="math inline">\(A_i = [i, i+1)\)</span> formam uma partição de <span class="math inline">\([0, \infty)\)</span>. Em geral, partições são muito úteis, permitindo-nos dividir o espaço amostral em pedaços pequenos e não sobrepostos.</p>
</section>
<section id="fundamentos-da-probabilidade" class="level2">
<h2 class="anchored" data-anchor-id="fundamentos-da-probabilidade">1.2 Fundamentos da Probabilidade</h2>
<p>Quando um experimento é realizado, a realização do experimento é um resultado no espaço amostral. Se o experimento é realizado um número de vezes, diferentes resultados podem ocorrer a cada vez ou alguns resultados podem se repetir. Essa “frequência de ocorrência” de um resultado pode ser pensada como uma probabilidade. Resultados mais prováveis ocorrem com mais frequência. Se os resultados de um experimento podem ser descritos probabilisticamente, estamos a caminho de analisar o experimento estatisticamente.</p>
<p>Nesta seção, descrevemos alguns dos fundamentos da teoria da probabilidade. Não definimos probabilidades em termos de frequências, mas, em vez disso, adotamos a abordagem axiomática matematicamente mais simples. Como será visto, a abordagem axiomática não se preocupa com as interpretações das probabilidades, mas preocupa-se apenas que as probabilidades sejam definidas por uma função que satisfaça os axiomas. Interpretações das probabilidades são outra questão. A “frequência de ocorrência” de um evento é um exemplo de uma <em>interpretação particular</em> de probabilidade. Outra interpretação possível é subjetiva, onde, em vez de pensar em probabilidade como frequência, podemos pensar nela como uma crença na chance de um evento ocorrer.</p>
<section id="fundações-axiomáticas" class="level3">
<h3 class="anchored" data-anchor-id="fundações-axiomáticas">1.2.1 Fundações Axiomáticas</h3>
<p>Para cada evento <span class="math inline">\(A\)</span> no espaço amostral <span class="math inline">\(S\)</span>, queremos associar a <span class="math inline">\(A\)</span> um número entre zero e um que será chamado de <em>probabilidade</em> de <span class="math inline">\(A\)</span>, denotado por <span class="math inline">\(P(A)\)</span>. Pareceria natural definir o domínio de <span class="math inline">\(P\)</span> (o conjunto onde os argumentos da função <span class="math inline">\(P(\cdot)\)</span> são definidos) como todos os subconjuntos de <span class="math inline">\(S\)</span>; isto é, para cada <span class="math inline">\(A \subset S\)</span> definimos <span class="math inline">\(P(A)\)</span> como a probabilidade de que <span class="math inline">\(A\)</span> ocorra. Infelizmente, as coisas não são tão simples. Existem algumas dificuldades técnicas a serem superadas. Não nos deteremos nessas tecnicalidades; embora sejam importantes, geralmente são de maior interesse para probabilistas do que para estatísticos. No entanto, uma compreensão firme de estatística requer pelo menos uma familiaridade passageira com o seguinte.</p>
</section>
<section id="definição-1.2.1---sigma-álgebra" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.2.1---sigma-álgebra">Definição 1.2.1 - Sigma-álgebra</h3>
<p>Uma coleção de subconjuntos de <span class="math inline">\(S\)</span> é chamada de <em>sigma-álgebra</em> (ou <em>corpo de Borel</em>), denotada por <span class="math inline">\(\mathcal{B}\)</span>, se satisfaz as três propriedades a seguir: a. <span class="math inline">\(\emptyset \in \mathcal{B}\)</span> (o conjunto vazio é um elemento de <span class="math inline">\(\mathcal{B}\)</span>). b. Se <span class="math inline">\(A \in \mathcal{B}\)</span>, então <span class="math inline">\(A^c \in \mathcal{B}\)</span> (<span class="math inline">\(\mathcal{B}\)</span> é fechada sob complementação). c.&nbsp;Se <span class="math inline">\(A_1, A_2, \dots \in \mathcal{B}\)</span>, então <span class="math inline">\(\cup_{i=1}^{\infty} A_i \in \mathcal{B}\)</span> (<span class="math inline">\(\mathcal{B}\)</span> é fechada sob uniões enumeráveis).</p>
</section>
<p>O conjunto vazio <span class="math inline">\(\emptyset\)</span> é um subconjunto de qualquer conjunto. Assim, <span class="math inline">\(\emptyset \subset S\)</span>. A propriedade (a) afirma que este subconjunto está sempre em uma sigma-álgebra. Uma vez que <span class="math inline">\(S = \emptyset^c\)</span>, as propriedades (a) e (b) implicam que <span class="math inline">\(S\)</span> está sempre em <span class="math inline">\(\mathcal{B}\)</span> também. Além disso, das Leis de DeMorgan, segue-se que <span class="math inline">\(\mathcal{B}\)</span> é fechada sob interseções enumeráveis. Se <span class="math inline">\(A_1, A_2, \dots \in \mathcal{B}\)</span>, então <span class="math inline">\(A_1^c, A_2^c, \dots \in \mathcal{B}\)</span> pela propriedade (b), e portanto <span class="math inline">\(\cup_{i=1}^{\infty} A_i^c \in \mathcal{B}\)</span>. No entanto, usando a Lei de DeMorgan (como no Exercício 1.9), temos</p>
<p><span class="math display">\[
\left( \bigcup_{i=1}^{\infty} A_i^c \right)^c = \bigcap_{i=1}^{\infty} A_i.
\]</span></p>
<p>Assim, novamente pela propriedade (b), <span class="math inline">\(\cap_{i=1}^{\infty} A_i \in \mathcal{B}\)</span>. Associadas ao espaço amostral <span class="math inline">\(S\)</span>, podemos ter muitas sigma-álgebras diferentes. Por exemplo, a coleção dos dois conjuntos <span class="math inline">\(\{\emptyset, S\}\)</span> é uma sigma-álgebra, geralmente chamada de <em>sigma-álgebra trivial</em>. A única sigma-álgebra com a qual nos preocuparemos é a menor que contém todos os conjuntos abertos em um dado espaço amostral <span class="math inline">\(S\)</span>.</p>
<section id="exemplo-1.2.2-sigma-álgebrai" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.2-sigma-álgebrai">Exemplo 1.2.2 (Sigma-álgebra—I)</h3>
<p>Se <span class="math inline">\(S\)</span> é finito ou enumerável, essas tecnicalidades realmente não surgem, pois definimos para um dado espaço amostral <span class="math inline">\(S\)</span>,</p>
<p><span class="math display">\[
\mathcal{B} = \{\text{todos os subconjuntos de } S, \text{ incluindo } S \text{ ele mesmo}\}.
\]</span></p>
<p>Se <span class="math inline">\(S\)</span> tem <span class="math inline">\(n\)</span> elementos, existem <span class="math inline">\(2^n\)</span> conjuntos em <span class="math inline">\(\mathcal{B}\)</span> (veja Exercício 1.14). Por exemplo, se <span class="math inline">\(S = \{1, 2, 3\}\)</span>, então <span class="math inline">\(\mathcal{B}\)</span> é a seguinte coleção de <span class="math inline">\(2^3 = 8\)</span> conjuntos:</p>
<p><span class="math display">\[
\begin{matrix}
\{1\} &amp; \{1, 2\} &amp; \{1, 2, 3\} \\
\{2\} &amp; \{1, 3\} &amp; \emptyset \\
\{3\} &amp; \{2, 3\} &amp;
\end{matrix}
\]</span></p>
</section>
<p>Em geral, se <span class="math inline">\(S\)</span> é não enumerável, não é uma tarefa fácil descrever <span class="math inline">\(\mathcal{B}\)</span>. No entanto, <span class="math inline">\(\mathcal{B}\)</span> é escolhida para conter qualquer conjunto de interesse.</p>
<section id="exemplo-1.2.3-sigma-álgebraii" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.3-sigma-álgebraii">Exemplo 1.2.3 (Sigma-álgebra—II)</h3>
<p>Seja <span class="math inline">\(S = (-\infty, \infty)\)</span>, a reta real. Então <span class="math inline">\(\mathcal{B}\)</span> é escolhida para conter todos os conjuntos da forma</p>
<p><span class="math display">\[
[a, b], \quad (a, b], \quad (a, b), \quad \text{e} \quad [a, b)
\]</span></p>
<p>para todos os números reais <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>. Além disso, pelas propriedades de <span class="math inline">\(\mathcal{B}\)</span>, segue-se que <span class="math inline">\(\mathcal{B}\)</span> contém todos os conjuntos que podem ser formados tomando uniões (possivelmente infinitas enumeráveis) e interseções de conjuntos das variedades acima.</p>
</section>
<p>Estamos agora em posição de definir uma função de probabilidade.</p>
<section id="definição-1.2.4---função-de-probabilidade" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.2.4---função-de-probabilidade">Definição 1.2.4 - Função de Probabilidade</h3>
<p>Dado um espaço amostral <span class="math inline">\(S\)</span> e uma sigma-álgebra associada <span class="math inline">\(\mathcal{B}\)</span>, uma <em>função de probabilidade</em> é uma função <span class="math inline">\(P\)</span> com domínio <span class="math inline">\(\mathcal{B}\)</span> que satisfaz 1. <span class="math inline">\(P(A) \ge 0\)</span> para todo <span class="math inline">\(A \in \mathcal{B}\)</span>. 2. <span class="math inline">\(P(S) = 1\)</span>. 3. Se <span class="math inline">\(A_1, A_2, \dots \in \mathcal{B}\)</span> são disjuntos dois a dois, então <span class="math inline">\(P(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} P(A_i)\)</span>.</p>
</section>
<p>As três propriedades dadas na Definição 1.2.4 são geralmente referidas como os <em>Axiomas da Probabilidade</em> (ou os Axiomas de Kolmogorov, em homenagem a A. Kolmogorov, um dos pais da teoria da probabilidade). Qualquer função <span class="math inline">\(P\)</span> que satisfaça os Axiomas de Probabilidade é chamada de <em>função de probabilidade</em>. A definição axiomática não tenta dizer qual função particular <span class="math inline">\(P\)</span> escolher; ela apenas requer que <span class="math inline">\(P\)</span> satisfaça os axiomas. Para qualquer espaço amostral, muitas funções de probabilidade diferentes podem ser definidas. Qual delas reflete o que é provável de ser observado em um experimento particular ainda precisa ser discutido.</p>
<section id="exemplo-1.2.5-definindo-probabilidadesi" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.5-definindo-probabilidadesi">Exemplo 1.2.5 (Definindo probabilidades—I)</h3>
<p>Considere o experimento simples de lançar uma moeda justa, então <span class="math inline">\(S = \{H, T\}\)</span>. Por uma moeda “justa”, queremos dizer uma moeda balanceada que tem igual probabilidade de cair com a face para cima ou para baixo, e, portanto, a função de probabilidade razoável é aquela que atribui probabilidades iguais a cara e coroa, isto é,</p>
<p><span class="math display">\[
P(\{H\}) = P(\{T\}).
\]</span></p>
<p>Note que (1.2.2) não decorre dos Axiomas de Probabilidade, mas é de fora dos axiomas. Usamos uma interpretação de simetria da probabilidade (ou apenas intuição) para impor o requisito de que cara e coroa sejam igualmente prováveis. Como <span class="math inline">\(S = \{H\} \cup \{T\}\)</span>, temos, pelo Axioma 1, <span class="math inline">\(P(\{H\} \cup \{T\}) = 1\)</span>. Além disso, <span class="math inline">\(\{H\}\)</span> e <span class="math inline">\(\{T\}\)</span> são disjuntos, então <span class="math inline">\(P(\{H\} \cup \{T\}) = P(\{H\}) + P(\{T\})\)</span> e</p>
<p><span class="math display">\[
P(\{H\}) + P(\{T\}) = 1.
\]</span></p>
<p>Resolvendo simultaneamente (1.2.2) e (1.2.3), temos <span class="math inline">\(P(\{H\}) = P(\{T\}) = \frac{1}{2}\)</span>. Como (1.2.2) é baseado em nosso conhecimento do experimento particular, e não nos axiomas, quaisquer valores não negativos para <span class="math inline">\(P(\{H\})\)</span> e <span class="math inline">\(P(\{T\})\)</span> que satisfaçam (1.2.3) definem uma função de probabilidade legítima. Por exemplo, poderíamos escolher <span class="math inline">\(P(\{H\}) = \frac{1}{9}\)</span> e <span class="math inline">\(P(\{T\}) = \frac{8}{9}\)</span>.</p>
</section>
<p>Precisamos de métodos gerais para definir funções de probabilidade que saibamos que sempre satisfarão os Axiomas de Kolmogorov. Não queremos ter que verificar os Axiomas para cada nova função de probabilidade, como fizemos no Exemplo 1.2.5. O seguinte fornece um método comum de definir uma função de probabilidade legítima.</p>
<section id="teorema-1.2.6" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.2.6">Teorema 1.2.6</h3>
<p>Seja <span class="math inline">\(S = \{s_1, \dots, s_n\}\)</span> um conjunto finito. Seja <span class="math inline">\(\mathcal{B}\)</span> qualquer sigma-álgebra de subconjuntos de <span class="math inline">\(S\)</span>. Sejam <span class="math inline">\(p_1, \dots, p_n\)</span> números não negativos que somam 1. Para qualquer <span class="math inline">\(A \in \mathcal{B}\)</span>, defina <span class="math inline">\(P(A)\)</span> por</p>
<p><span class="math display">\[
P(A) = \sum_{\{i : s_i \in A\}} p_i.
\]</span></p>
<p>(A soma sobre um conjunto vazio é definida como 0.) Então <span class="math inline">\(P\)</span> é uma função de probabilidade em <span class="math inline">\(\mathcal{B}\)</span>. Isso permanece verdadeiro se <span class="math inline">\(S = \{s_1, s_2, \dots\}\)</span> é um conjunto enumerável.</p>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Daremos a prova para <span class="math inline">\(S\)</span> finito. Para qualquer <span class="math inline">\(A \in \mathcal{B}, P(A) = \sum_{\{i : s_i \in A\}} p_i \ge 0\)</span>, porque todo <span class="math inline">\(p_i \ge 0\)</span>. Assim, o Axioma 1 é verdadeiro. Agora,</p>
<p><span class="math display">\[
P(S) = \sum_{\{i : s_i \in S\}} p_i = \sum_{i=1}^n p_i = 1.
\]</span></p>
<p>Assim, o Axioma 2 é verdadeiro. Sejam <span class="math inline">\(A_1, \dots, A_k\)</span> eventos disjuntos dois a dois. (<span class="math inline">\(\mathcal{B}\)</span> contém apenas um número finito de conjuntos, então precisamos considerar apenas uniões disjuntas finitas.) Então,</p>
<p><span class="math display">\[
P\left( \bigcup_{i=1}^k A_i \right) = \sum_{\{j : s_j \in \cup_{i=1}^k A_i\}} p_j = \sum_{i=1}^k \sum_{\{j : s_j \in A_i\}} p_j = \sum_{i=1}^k P(A_i).
\]</span></p>
<p>A primeira e a terceira igualdades são verdadeiras pela definição de <span class="math inline">\(P(A)\)</span>. A disjunção dos <span class="math inline">\(A_i\)</span>s garante que a segunda igualdade é verdadeira, porque os mesmos <span class="math inline">\(p_j\)</span>s aparecem exatamente uma vez em cada lado da igualdade. Assim, o Axioma 3 é verdadeiro e os Axiomas de Kolmogorov são satisfeitos. <span class="math inline">\(\square\)</span></p>
</div>
<p>A realidade física do experimento pode ditar a atribuição de probabilidade, como o próximo exemplo ilustra.</p>
<section id="exemplo-1.2.7-definindo-probabilidadesii" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.7-definindo-probabilidadesii">Exemplo 1.2.7 (Definindo probabilidades—II)</h3>
<p>O jogo de dardos é jogado lançando um dardo em um alvo e recebendo uma pontuação correspondente ao número atribuído à região em que o dardo cai. Para um jogador novato, parece razoável assumir que a probabilidade de o dardo atingir uma região específica é proporcional à área da região. Assim, uma região maior tem uma probabilidade maior de ser atingida. Referindo-se à Figura 1.2.1, vemos que o alvo de dardos tem raio <span class="math inline">\(r\)</span> e a distância entre os anéis é <span class="math inline">\(r/5\)</span>. Se fizermos a suposição de que o alvo é sempre atingido (veja o Exercício 1.7 para uma variação sobre isso), então temos</p>
<p><span class="math display">\[
P(\text{marcar } i \text{ pontos}) = \frac{\text{Área da região } i}{\text{Área do alvo de dardos}}.
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-1_2_1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Figura 1.2.1 - Alvo de dardos para o Exemplo 1.2.7</figcaption>
</figure>
</div>
<p>Por exemplo,</p>
<p><span class="math display">\[
P(\text{marcar } 1 \text{ ponto}) = \frac{\pi r^2 - \pi(4r/5)^2}{\pi r^2} = 1 - \left( \frac{4}{5} \right)^2.
\]</span></p>
<p>É fácil derivar a fórmula geral, e descobrimos que</p>
<p><span class="math display">\[
P(\text{marcar } i \text{ pontos}) = \frac{(6-i)^2 - (5-i)^2}{5^2}, \quad i = 1, \dots, 5,
\]</span></p>
<p>independente de <span class="math inline">\(\pi\)</span> e <span class="math inline">\(r\)</span>. A soma das áreas das regiões disjuntas é igual à área do alvo de dardos. Assim, as probabilidades que foram atribuídas aos cinco resultados somam 1, e, pelo Teorema 1.2.6, esta é uma função de probabilidade (veja Exercício 1.8).</p>
</section>
<p>Antes de deixarmos o desenvolvimento axiomático da probabilidade, há mais um ponto a considerar. O Axioma 3 da Definição 1.2.4, que é comumente conhecido como o Axioma da Aditividade Enumerável, não é universalmente aceito entre os estatísticos. De fato, pode-se argumentar que os axiomas devem ser simples, autoevidentes. Comparando o Axioma 3 com os outros axiomas, que são simples e autoevidentes, isso pode nos levar a duvidar se é razoável assumir a verdade do Axioma 3.</p>
<p>O Axioma da Aditividade Enumerável é rejeitado por uma escola de estatísticos liderada por deFinetti (1972), que opta por substituir este axioma pelo Axioma da Aditividade Finita.</p>
<p><em>Axioma da Aditividade Finita:</em> Se <span class="math inline">\(A \in \mathcal{B}\)</span> e <span class="math inline">\(B \in \mathcal{B}\)</span> são disjuntos, então</p>
<p><span class="math display">\[
P(A \cup B) = P(A) + P(B).
\]</span></p>
<p>Embora este axioma possa não ser inteiramente autoevidente, é certamente mais simples do que o Axioma da Aditividade Enumerável (e é implicado por ele – veja Exercício 1.12).</p>
<p>Assumir apenas a aditividade finita, embora talvez mais plausível, pode levar a complicações inesperadas na teoria estatística – complicações que, a este nível, não necessariamente aumentam a compreensão do assunto. Portanto, prosseguimos sob a suposição de que o Axioma da Aditividade Enumerável é válido.</p>
<section id="o-cálculo-de-probabilidades" class="level3">
<h3 class="anchored" data-anchor-id="o-cálculo-de-probabilidades">1.2.2 O Cálculo de Probabilidades</h3>
<p>A partir dos Axiomas da Probabilidade, podemos construir muitas propriedades da função de probabilidade, propriedades que são bastante úteis no cálculo de probabilidades mais complicadas. Algumas dessas manipulações serão discutidas em detalhes nesta seção; outras serão deixadas como exercícios.</p>
<p>Começamos com algumas propriedades (bastante autoevidentes) da função de probabilidade quando aplicadas a um único evento.</p>
</section>
<section id="teorema-1.2.8" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.2.8">Teorema 1.2.8</h3>
<p><em>Se P é uma função de probabilidade e A é qualquer conjunto em <span class="math inline">\(\mathcal{B}\)</span>, então</em></p>
<ul>
<li><strong>a.</strong> <span class="math inline">\(P(\emptyset) = 0\)</span>, onde <span class="math inline">\(\emptyset\)</span> é o conjunto vazio;</li>
<li><strong>b.</strong> <span class="math inline">\(P(A) \le 1\)</span>;</li>
<li><strong>c.</strong> <span class="math inline">\(P(A^c) = 1 - P(A)\)</span>.</li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>É mais fácil provar (c) primeiro. Os conjuntos <span class="math inline">\(A\)</span> e <span class="math inline">\(A^c\)</span> formam uma partição do espaço amostral, isto é, <span class="math inline">\(S = A \cup A^c\)</span>. Portanto,</p>
<p><span class="math display">\[
P(A \cup A^c) = P(S) = 1
\]</span></p>
<p>pelo segundo axioma. Além disso, <span class="math inline">\(A\)</span> e <span class="math inline">\(A^c\)</span> são disjuntos, então pelo terceiro axioma,</p>
<p><span class="math display">\[
P(A \cup A^c) = P(A) + P(A^c).
\]</span></p>
<p>Combinando (1.2.4) e (1.2.5) obtemos (c). Como <span class="math inline">\(P(A^c) \ge 0\)</span>, (b) é imediatamente implicado por (c). Para provar (a), usamos um argumento semelhante em <span class="math inline">\(S = S \cup \emptyset\)</span>. (Lembre-se que tanto <span class="math inline">\(S\)</span> quanto <span class="math inline">\(\emptyset\)</span> estão sempre em <span class="math inline">\(\mathcal{B}\)</span>.) Como <span class="math inline">\(S\)</span> e <span class="math inline">\(\emptyset\)</span> são disjuntos, temos</p>
<p><span class="math display">\[
1 = P(S) = P(S \cup \emptyset) = P(S) + P(\emptyset),
\]</span></p>
<p>e assim <span class="math inline">\(P(\emptyset) = 0\)</span>. <span class="math inline">\(\square\)</span></p>
</div>
<p>O Teorema 1.2.8 contém propriedades que são tão básicas que também têm o sabor de axiomas, embora tenhamos provado formalmente usando apenas os Axiomas de Kolmogorov originais. O próximo teorema, que é semelhante em espírito ao Teorema 1.2.8, contém afirmações que não são tão autoevidentes.</p>
<section id="teorema-1.2.9" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.2.9">Teorema 1.2.9</h3>
<p><em>Se P é uma função de probabilidade e A e B são quaisquer conjuntos em <span class="math inline">\(\mathcal{B}\)</span>, então</em></p>
<ul>
<li><strong>a.</strong> <span class="math inline">\(P(B \cap A^c) = P(B) - P(A \cap B)\)</span>;</li>
<li><strong>b.</strong> <span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span>;</li>
<li><strong>c.</strong> Se <span class="math inline">\(A \subset B\)</span>, então <span class="math inline">\(P(A) \le P(B)\)</span>.</li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Para estabelecer (a), note que para quaisquer conjuntos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> temos</p>
<p><span class="math display">\[
B = \{B \cap A\} \cup \{B \cap A^c\},
\]</span></p>
<p>e portanto</p>
<p><span class="math display">\[
P(B) = P(\{B \cap A\} \cup \{B \cap A^c\}) = P(B \cap A) + P(B \cap A^c),
\]</span></p>
<p>onde a última igualdade em (1.2.6) decorre do fato de que <span class="math inline">\(B \cap A\)</span> e <span class="math inline">\(B \cap A^c\)</span> são disjuntos. Reorganizando (1.2.6) obtemos (a). Para estabelecer (b), usamos a identidade</p>
<p><span class="math display">\[
A \cup B = A \cup \{B \cap A^c\}.
\]</span></p>
<p>Um diagrama de Venn mostrará por que (1.2.7) é válida, embora uma prova formal não seja difícil (veja Exercício 1.2). Usando (1.2.7) e o fato de que <span class="math inline">\(A\)</span> e <span class="math inline">\(B \cap A^c\)</span> são disjuntos (visto que <span class="math inline">\(A\)</span> e <span class="math inline">\(A^c\)</span> o são), temos</p>
<p><span class="math display">\[
P(A \cup B) = P(A) + P(B \cap A^c) = P(A) + P(B) - P(A \cap B)
\]</span></p>
<p>a partir de (a). Se <span class="math inline">\(A \subset B\)</span>, então <span class="math inline">\(A \cap B = A\)</span>. Portanto, usando (a), temos</p>
<p><span class="math display">\[
0 \le P(B \cap A^c) = P(B) - P(A),
\]</span></p>
<p>estabelecendo (c). <span class="math inline">\(\square\)</span></p>
</div>
<p>A fórmula (b) do Teorema 1.2.9 fornece uma desigualdade útil para a probabilidade de uma interseção. Como <span class="math inline">\(P(A \cup B) \le 1\)</span>, temos de (1.2.8), após algum rearranjo,</p>
<p><span class="math display">\[
P(A \cap B) \ge P(A) + P(B) - 1.
\]</span></p>
<p>Esta desigualdade é um caso especial do que é conhecido como <em>Desigualdade de Bonferroni</em> (Miller 1981 é uma boa referência). A Desigualdade de Bonferroni nos permite limitar a probabilidade de um evento simultâneo (a interseção) em termos das probabilidades dos eventos individuais.</p>
<section id="exemplo-1.2.10-desigualdade-de-bonferroni" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.10-desigualdade-de-bonferroni">Exemplo 1.2.10 (Desigualdade de Bonferroni)</h3>
<p>A Desigualdade de Bonferroni é particularmente útil quando é difícil (ou até impossível) calcular a probabilidade da interseção, mas se deseja alguma ideia do tamanho dessa probabilidade. Suponha que <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> sejam dois eventos e cada um tenha probabilidade 0,95. Então a probabilidade de que ambos ocorram é limitada inferiormente por</p>
<p><span class="math display">\[
P(A \cap B) \ge P(A) + P(B) - 1 = 0,95 + 0,95 - 1 = 0,90.
\]</span></p>
<p>Note que, a menos que as probabilidades dos eventos individuais sejam suficientemente grandes, o limite de Bonferroni é um número negativo inútil (embora correto!).</p>
</section>
<p>Encerramos esta seção com um teorema que fornece alguns resultados úteis para lidar com uma coleção de conjuntos.</p>
<section id="teorema-1.2.11" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.2.11">Teorema 1.2.11</h3>
<p><em>Se P é uma função de probabilidade, então</em></p>
<ul>
<li><strong>a.</strong> <span class="math inline">\(P(A) = \sum_{i=1}^{\infty} P(A \cap C_i)\)</span> para qualquer partição <span class="math inline">\(C_1, C_2, \dots\)</span>;</li>
<li><strong>b.</strong> <span class="math inline">\(P(\cup_{i=1}^{\infty} A_i) \le \sum_{i=1}^{\infty} P(A_i)\)</span> para quaisquer conjuntos <span class="math inline">\(A_1, A_2, \dots\)</span>. (Desigualdade de Boole)</li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Visto que <span class="math inline">\(C_1, C_2, \dots\)</span> formam uma partição, temos que <span class="math inline">\(C_i \cap C_j = \emptyset\)</span> para todo <span class="math inline">\(i \ne j\)</span>, e <span class="math inline">\(S = \cup_{i=1}^{\infty} C_i\)</span>. Portanto,</p>
<p><span class="math display">\[
A = A \cap S = A \cap \left( \bigcup_{i=1}^{\infty} C_i \right) = \bigcup_{i=1}^{\infty} (A \cap C_i),
\]</span></p>
<p>onde a última igualdade segue da Lei Distributiva (Teorema 1.1.4). Nós, portanto, temos</p>
<p><span class="math display">\[
P(A) = P\left( \bigcup_{i=1}^{\infty} (A \cap C_i) \right).
\]</span></p>
<p>Agora, como os <span class="math inline">\(C_i\)</span> são disjuntos, os conjuntos <span class="math inline">\(A \cap C_i\)</span> também são disjuntos, e das propriedades de uma função de probabilidade temos</p>
<p><span class="math display">\[
P\left( \bigcup_{i=1}^{\infty} (A \cap C_i) \right) = \sum_{i=1}^{\infty} P(A \cap C_i),
\]</span></p>
<p>estabelecendo (a). Para estabelecer (b), primeiro construímos uma coleção disjunta <span class="math inline">\(A_1^*, A_2^*, \dots\)</span>, com a propriedade de que <span class="math inline">\(\cup_{i=1}^{\infty} A_i^* = \cup_{i=1}^{\infty} A_i\)</span>. Definimos <span class="math inline">\(A_i^*\)</span> por</p>
<p><span class="math display">\[
A_1^* = A_1, \quad A_i^* = A_i \setminus \left( \bigcup_{j=1}^{i-1} A_j \right), \quad i = 2, 3, \dots,
\]</span></p>
<p>onde a notação <span class="math inline">\(A \setminus B\)</span> denota a parte de <span class="math inline">\(A\)</span> que não intersecta com <span class="math inline">\(B\)</span>. Em símbolos mais familiares, <span class="math inline">\(A \setminus B = A \cap B^c\)</span>. Deve ser fácil ver que <span class="math inline">\(\cup_{i=1}^{\infty} A_i^* = \cup_{i=1}^{\infty} A_i\)</span>, e portanto temos</p>
<p><span class="math display">\[
P\left( \bigcup_{i=1}^{\infty} A_i \right) = P\left( \bigcup_{i=1}^{\infty} A_i^* \right) = \sum_{i=1}^{\infty} P(A_i^*),
\]</span></p>
<p>onde a última igualdade segue uma vez que os <span class="math inline">\(A_i^*\)</span> são disjuntos. Para ver isso, escrevemos</p>
<p><span class="math display">\[
\begin{align*}
A_i^* \cap A_k^* &amp;= \left\{ A_i \cap \left( \bigcup_{j=1}^{i-1} A_j \right)^c \right\} \cap \left\{ A_k \cap \left( \bigcup_{j=1}^{k-1} A_j \right)^c \right\} \quad (\text{definição de } A_i^*) \\
&amp;= \left\{ A_i \cap \left( \bigcap_{j=1}^{i-1} A_j^c \right) \right\} \cap \left\{ A_k \cap \left( \bigcap_{j=1}^{k-1} A_j^c \right) \right\} \quad (\text{Leis de DeMorgan})
\end{align*}
\]</span></p>
<p>Agora, se <span class="math inline">\(i &gt; k\)</span>, a primeira interseção acima estará contida no conjunto <span class="math inline">\(A_k^c\)</span>, que terá uma interseção vazia com <span class="math inline">\(A_k\)</span>. Se <span class="math inline">\(k &gt; i\)</span>, o argumento é semelhante. Além disso, por construção <span class="math inline">\(A_i^* \subset A_i\)</span>, então <span class="math inline">\(P(A_i^*) \le P(A_i)\)</span> e temos</p>
<p><span class="math display">\[
\sum_{i=1}^{\infty} P(A_i^*) \le \sum_{i=1}^{\infty} P(A_i),
\]</span></p>
<p>estabelecendo (b). <span class="math inline">\(\square\)</span></p>
</div>
<p>Existe uma similaridade entre a Desigualdade de Boole e a Desigualdade de Bonferroni. De fato, elas são essencialmente a mesma coisa. Se aplicarmos a Desigualdade de Boole a <span class="math inline">\(A^c\)</span>, temos</p>
<p><span class="math display">\[
P\left( \bigcup_{i=1}^n A_i^c \right) \le \sum_{i=1}^n P(A_i^c),
\]</span></p>
<p>e usando os fatos de que <span class="math inline">\(\cup A_i^c = (\cap A_i)^c\)</span> e <span class="math inline">\(P(A_i^c) = 1 - P(A_i)\)</span>, obtemos</p>
<p><span class="math display">\[
1 - P\left( \bigcap_{i=1}^n A_i \right) \le n - \sum_{i=1}^n P(A_i).
\]</span></p>
<p>Isso se torna, ao reorganizar os termos,</p>
<p><span class="math display">\[
P\left( \bigcap_{i=1}^n A_i \right) \ge \sum_{i=1}^n P(A_i) - (n-1),
\]</span></p>
<p>que é uma versão mais geral da Desigualdade de Bonferroni de (1.2.9).</p>
<section id="contagem" class="level3">
<h3 class="anchored" data-anchor-id="contagem">1.2.3 Contagem</h3>
<p>O processo elementar de contagem pode se tornar bastante sofisticado quando colocado nas mãos de um estatístico. Na maioria das vezes, métodos de contagem são usados para construir atribuições de probabilidade em espaços amostrais finitos, embora possam ser usados para responder a outras perguntas também.</p>
</section>
<section id="exemplo-1.2.12-loteria-i" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.12-loteria-i">Exemplo 1.2.12 (Loteria-I)</h3>
<p>Por vários anos, a loteria do estado de Nova York operou de acordo com o seguinte esquema. A partir dos números <span class="math inline">\(1, 2, \dots, 44\)</span>, uma pessoa pode escolher quaisquer seis para seu bilhete. O número vencedor é então decidido selecionando aleatoriamente seis números dentre os quarenta e quatro. Para calcular a probabilidade de ganhar, devemos primeiro contar quantos grupos diferentes de seis números podem ser escolhidos a partir dos quarenta e quatro.</p>
</section>
<section id="exemplo-1.2.13-torneio" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.13-torneio">Exemplo 1.2.13 (Torneio)</h3>
<p>Em um torneio de eliminação simples, como o torneio de tênis U.S. Open, os jogadores avançam apenas se vencerem (ao contrário de torneios de eliminação dupla ou todos contra todos). Se tivermos 16 participantes, podemos estar interessados no número de caminhos que um jogador em particular pode tomar para a vitória, onde um caminho é considerado uma sequência de oponentes.</p>
</section>
<p>Problemas de contagem, em geral, parecem complicados, e muitas vezes devemos fazer nossa contagem sujeita a muitas restrições. A maneira de resolver tais problemas é dividi-los em uma série de tarefas simples que são fáceis de contar, e empregar regras conhecidas de combinação de tarefas. O teorema a seguir é um primeiro passo em tal processo e às vezes é conhecido como o Teorema Fundamental da Contagem.</p>
<section id="teorema-1.2.14" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.2.14">Teorema 1.2.14</h3>
<p><em>Se um trabalho consiste em <span class="math inline">\(k\)</span> tarefas separadas, a i-ésima das quais pode ser feita de <span class="math inline">\(n_i\)</span> maneiras, <span class="math inline">\(i = 1, \dots, k\)</span>, então o trabalho inteiro pode ser feito de <span class="math inline">\(n_1 \times n_2 \times \dots \times n_k\)</span> maneiras.</em></p>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Basta provar o teorema para <span class="math inline">\(k=2\)</span> (veja Exercício 1.15). A prova é apenas uma questão de contagem cuidadosa. A primeira tarefa pode ser feita de <span class="math inline">\(n_1\)</span> maneiras, e para cada uma dessas maneiras temos <span class="math inline">\(n_2\)</span> escolhas para a segunda tarefa. Assim, podemos fazer o trabalho em</p>
<p><span class="math display">\[
\underbrace{(1 \times n_2) + (1 \times n_2) + \dots + (1 \times n_2)}_{n_1 \text{ termos}} = n_1 \times n_2
\]</span></p>
<p>maneiras, estabelecendo o teorema para <span class="math inline">\(k=2\)</span>. <span class="math inline">\(\square\)</span></p>
</div>
<section id="exemplo-1.2.15-loteriaii" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.15-loteriaii">Exemplo 1.2.15 (Loteria—II)</h3>
<p>Embora o Teorema Fundamental da Contagem seja um lugar razoável para começar, em aplicações geralmente há mais aspectos de um problema a considerar. Por exemplo, na loteria do estado de Nova York, o primeiro número pode ser escolhido de 44 maneiras e o segundo número de 43 maneiras, totalizando <span class="math inline">\(44 \times 43 = 1.892\)</span> maneiras de escolher os dois primeiros números. No entanto, se uma pessoa tem permissão para escolher o mesmo número duas vezes, então os dois primeiros números podem ser escolhidos de <span class="math inline">\(44 \times 44 = 1.936\)</span> maneiras.</p>
</section>
<p>A distinção feita no Exemplo 1.2.15 é entre contar <em>com reposição</em> e contar <em>sem reposição</em>. Há um segundo elemento crucial em qualquer problema de contagem: se a ordem das tarefas é importante. Para ilustrar com o exemplo da loteria, suponha que os números vencedores sejam selecionados na ordem 12, 37, 35, 9, 13, 22. Uma pessoa que selecionou 9, 12, 13, 22, 35, 37 se qualifica como vencedora? Em outras palavras, a ordem na qual a tarefa é realizada realmente importa? Levando todas essas considerações em conta, podemos construir uma tabela <span class="math inline">\(2 \times 2\)</span> de possibilidades:</p>
<table class="caption-top table">
<caption>Possivel Método de Contar</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Sem reposição</th>
<th style="text-align: center;">Com reposição</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Ordenado</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Não ordenado</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Antes de começarmos a contar, a seguinte definição nos dá uma notação extremamente útil.</p>
<section id="definição-1.2.16" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.2.16">Definição 1.2.16</h3>
<p>Para um inteiro positivo <span class="math inline">\(n\)</span>, <span class="math inline">\(n!\)</span> (lê-se <span class="math inline">\(n\)</span> fatorial) é o produto de todos os inteiros positivos menores ou iguais a <span class="math inline">\(n\)</span>. Isto é, <span class="math display">\[
n! = n \times (n-1) \times (n-2) \times \dots \times 3 \times 2 \times 1.
\]</span> Além disso, definimos <span class="math inline">\(0! = 1\)</span>.</p>
</section>
<p>Vamos agora considerar todos os possíveis bilhetes de loteria sob cada um desses quatro casos.</p>
<ol type="1">
<li><p><strong>Ordenado, sem reposição:</strong> Pelo Teorema Fundamental da Contagem, o primeiro número pode ser selecionado de 44 maneiras, o segundo de 43 maneiras, etc. Portanto, existem <span class="math display">\[
44 \times 43 \times 42 \times 41 \times 40 \times 39 = \frac{44!}{38!} = 5.082.517.440
\]</span> bilhetes possíveis.</p></li>
<li><p><strong>Ordenado, com reposição:</strong> Como cada número pode agora ser selecionado de 44 maneiras (porque o número escolhido é reposto), existem <span class="math display">\[
44 \times 44 \times 44 \times 44 \times 44 \times 44 = 44^6 = 7.256.313.856
\]</span> bilhetes possíveis.</p></li>
<li><p><strong>Não ordenado, sem reposição:</strong> Sabemos o número de bilhetes possíveis quando a ordem deve ser considerada, então o que devemos fazer é dividir as ordenações redundantes. Novamente pelo Teorema Fundamental, seis números podem ser organizados de <span class="math inline">\(6 \times 5 \times 4 \times 3 \times 2 \times 1\)</span> maneiras, então o número total de bilhetes não ordenados é</p></li>
</ol>
<p><span class="math display">\[
\frac{44 \times 43 \times 42 \times 41 \times 40 \times 39}{6 \times 5 \times 4 \times 3 \times 2 \times 1} = \frac{44!}{6! 38!} = 7.059.052.
\]</span> Esta forma de contar desempenha um papel central em grande parte da estatística — tanto, de fato, que ganhou sua própria notação.</p>
<section id="definição-1.2.17" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.2.17">Definição 1.2.17</h3>
<p>Para inteiros não negativos <span class="math inline">\(n\)</span> e <span class="math inline">\(r\)</span>, onde <span class="math inline">\(n \ge r\)</span>, definimos o símbolo <span class="math inline">\(\binom{n}{r}\)</span>, lido <span class="math inline">\(n\)</span> escolhe <span class="math inline">\(r\)</span>, como <span class="math display">\[
\binom{n}{r} = \frac{n!}{r!(n-r)!}.
\]</span></p>
</section>
<p>Em nosso exemplo da loteria, o número de bilhetes possíveis (não ordenados, sem reposição) é <span class="math inline">\(\binom{44}{6}\)</span>. Esses números também são referidos como <em>coeficientes binomiais</em>, por razões que ficarão claras no Capítulo 3.</p>
<ol start="4" type="1">
<li><strong>Não ordenado, com reposição:</strong> Este é o caso mais difícil de contar. Você pode primeiro supor que a resposta é <span class="math inline">\(44^6 / (6 \times 5 \times 4 \times 3 \times 2 \times 1)\)</span>, mas isso não está correto (é muito pequeno). Para contar neste caso, é mais fácil pensar em colocar 6 marcadores nos 44 números. De fato, podemos pensar nos 44 números definindo compartimentos nos quais podemos colocar os seis marcadores, M, como mostrado nesta figura.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-contagem.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption>Figura representando marcadores (M) em compartimentos numerados</figcaption>
</figure>
</div>
<p>O número de bilhetes possíveis é então igual ao número de maneiras que podemos colocar os 6 marcadores nos 44 compartimentos. Mas isso pode ser ainda mais reduzido observando que tudo o que precisamos acompanhar é o arranjo dos marcadores e das paredes dos compartimentos. Note ainda que as duas paredes mais externas não desempenham nenhum papel. Assim, temos que contar todos os arranjos de 43 paredes (44 compartimentos geram 45 paredes, mas desconsideramos as duas paredes das extremidades) e 6 marcadores. Temos <span class="math inline">\(43 + 6 = 49\)</span> objetos, que podem ser arranjados de <span class="math inline">\(49!\)</span> maneiras. No entanto, para eliminar as ordenações redundantes, devemos dividir tanto por <span class="math inline">\(6!\)</span> quanto por <span class="math inline">\(43!\)</span>, de modo que o número total de arranjos é</p>
<p><span class="math display">\[
\frac{49!}{6! 43!} = 13.983.816.
\]</span></p>
<p>Embora todas as derivações precedentes tenham sido feitas em termos de um exemplo, deve ser fácil ver que elas valem em geral. Por completude, podemos resumir essas situações na Tabela 1.2.1.</p>
<p><strong>Tabela 1.2.1. Número de arranjos possíveis de tamanho <span class="math inline">\(r\)</span> a partir de <span class="math inline">\(n\)</span> objetos</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Sem reposição</th>
<th style="text-align: center;">Com reposição</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Ordenado</strong></td>
<td style="text-align: center;"><span class="math inline">\(\frac{n!}{(n-r)!}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n^r\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Não ordenado</strong></td>
<td style="text-align: center;"><span class="math inline">\(\binom{n}{r}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\binom{n+r-1}{r}\)</span></td>
</tr>
</tbody>
</table>
<section id="enumerando-resultados" class="level3">
<h3 class="anchored" data-anchor-id="enumerando-resultados">1.2.4 Enumerando Resultados</h3>
<p>As técnicas de contagem da seção anterior são úteis quando o espaço amostral <span class="math inline">\(S\)</span> é um conjunto finito e todos os resultados em <span class="math inline">\(S\)</span> são igualmente prováveis. Então, probabilidades de eventos podem ser calculadas simplesmente contando o número de resultados no evento. Para ver isso, suponha que <span class="math inline">\(S = \{s_1, \dots, s_N\}\)</span> é um espaço amostral finito. Dizer que todos os resultados são igualmente prováveis significa que <span class="math inline">\(P(\{s_i\}) = 1/N\)</span> para cada resultado <span class="math inline">\(s_i\)</span>. Então, usando o Axioma 3 da Definição 1.2.4, temos, para qualquer evento <span class="math inline">\(A\)</span>,</p>
<p><span class="math display">\[
P(A) = \sum_{s_i \in A} P(\{s_i\}) = \sum_{s_i \in A} \frac{1}{N} = \frac{ \text{ Número de elementos em } A}{ \text{ Número de elementos em } S}.
\]</span></p>
<p>Para grandes espaços amostrais, as técnicas de contagem podem ser usadas para calcular tanto o numerador quanto o denominador desta expressão.</p>
</section>
<section id="exemplo-1.2.18-pôquer" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.18-pôquer">Exemplo 1.2.18 (Pôquer)</h3>
<p>Considere escolher uma mão de pôquer de cinco cartas de um baralho padrão de 52 cartas de baralho. Obviamente, estamos amostrando sem reposição do baralho. Mas para especificar os resultados possíveis (mãos possíveis), devemos decidir se pensamos na mão sendo dada sequencialmente (ordenada) ou toda de uma vez (não ordenada). Se desejamos calcular probabilidades para eventos que dependem da ordem, como a probabilidade de um ás nas duas primeiras cartas, então devemos usar os resultados ordenados. Mas se nossos eventos não dependem da ordem, podemos usar os resultados não ordenados. Para este exemplo, usaremos os resultados não ordenados, então o espaço amostral consiste em todas as mãos de cinco cartas que podem ser escolhidas do baralho de 52 cartas. Existem <span class="math inline">\(\binom{52}{5} = 2.598.960\)</span> mãos possíveis. Se o baralho for bem embaralhado e as cartas forem dadas aleatoriamente, é razoável atribuir probabilidade <span class="math inline">\(1/2.598.960\)</span> a cada mão possível. Calculamos agora algumas probabilidades contando resultados em eventos. Qual é a probabilidade de ter quatro ases? Quantas mãos diferentes existem com quatro ases? Se especificarmos que quatro das cartas são ases, então há 48 maneiras diferentes de especificar a quinta carta. Assim,</p>
<p><span class="math display">\[
P(\text{quatro ases}) = \frac{48}{2.598.960},
\]</span></p>
<p>menos de 1 chance em 50.000. Apenas uma contagem ligeiramente mais complicada, usando o Teorema 1.2.14, nos permite calcular a probabilidade de ter uma quadra (quatro cartas do mesmo valor). Existem 13 maneiras de especificar qual denominação haverá quatro. Depois de especificarmos esses quatro, existem 48 maneiras de especificar a quinta. Assim, o número total de mãos com uma quadra é <span class="math inline">\((13)(48)\)</span> e</p>
<p><span class="math display">\[
P(\text{quadra}) = \frac{(13)(48)}{2.598.960} = \frac{624}{2.598.960}.
\]</span></p>
<p>Para calcular a probabilidade de exatamente um par (não dois pares, não trinca, etc.) combinamos algumas das técnicas de contagem. O número de mãos com exatamente um par é</p>
<p><span class="math display">\[
13 \binom{4}{2} \binom{12}{3} 4^3 = 1.098.240.
\]</span></p>
<p>A expressão (1.2.11) vem do Teorema 1.2.14 porque:</p>
<ul>
<li><p><span class="math inline">\(13\)</span> é o número de maneiras de especificar a denominação para o par,</p></li>
<li><p><span class="math inline">\(\binom{4}{2}\)</span> é o número de maneiras de especificar as duas cartas daquela denominação,</p></li>
<li><p><span class="math inline">\(\binom{12}{3}\)</span> é o número de maneiras de especificar as outras três denominações,</p></li>
<li><p><span class="math inline">\(4^3\)</span> é o número de maneiras de especificar as outras três cartas dessas denominações.</p></li>
</ul>
<p>Assim,</p>
<p><span class="math display">\[
P(\text{exatamente um par}) = \frac{1.098.240}{2.598.960}.
\]</span></p>
</section>
<p>Ao amostrar sem reposição, como no Exemplo 1.2.18, se queremos calcular a probabilidade de um evento que não depende da ordem, podemos usar tanto o espaço amostral ordenado quanto o não ordenado. Cada resultado no espaço amostral não ordenado corresponde a <span class="math inline">\(r!\)</span> resultados no espaço amostral ordenado. Assim, ao contar resultados no espaço amostral ordenado, usamos um fator de <span class="math inline">\(r!\)</span> tanto no numerador quanto no denominador que cancelará para dar a mesma probabilidade como se contássemos no espaço amostral não ordenado. A situação é diferente se amostramos com reposição. Cada resultado no espaço amostral não ordenado corresponde a <em>alguns</em> resultados no espaço amostral ordenado, mas o número de resultados difere.</p>
<section id="exemplo-1.2.19-amostragem-com-reposição" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.19-amostragem-com-reposição">Exemplo 1.2.19 (Amostragem com reposição)</h3>
<p>Considere amostrar <span class="math inline">\(r=2\)</span> itens de <span class="math inline">\(n=3\)</span> itens, com reposição. Os resultados nos espaços amostrais ordenados e não ordenados são estes:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Não ordenado</strong></td>
<td style="text-align: center;"><span class="math inline">\(\{1,1\}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\{2,2\}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\{3,3\}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\{1,2\}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\{1,3\}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\{2,3\}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Ordenado</strong></td>
<td style="text-align: center;"><span class="math inline">\((1,1)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((2,2)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((3,3)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((1,2), (2,1)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((1,3), (3,1)\)</span></td>
<td style="text-align: center;"><span class="math inline">\((2,3), (3,2)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Probabilidade</strong></td>
<td style="text-align: center;"><span class="math inline">\(1/9\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1/9\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1/9\)</span></td>
<td style="text-align: center;"><span class="math inline">\(2/9\)</span></td>
<td style="text-align: center;"><span class="math inline">\(2/9\)</span></td>
<td style="text-align: center;"><span class="math inline">\(2/9\)</span></td>
</tr>
</tbody>
</table>
<p>As probabilidades vêm da consideração dos nove resultados no espaço amostral ordenado como sendo igualmente prováveis. Isto corresponde à interpretação comum de “amostragem com reposição”; a saber, um dos três itens é escolhido, cada um com probabilidade 1/3; o item é anotado e reposto; os itens são misturados e novamente um dos três itens é escolhido, cada um com probabilidade 1/3. Vê-se que os seis resultados no espaço amostral não ordenado não são igualmente prováveis sob este tipo de amostragem. A fórmula para o número de resultados no espaço amostral não ordenado é útil para enumerar os resultados, mas os resultados ordenados devem ser usados para calcular probabilidades corretamente.</p>
</section>
<p>Alguns autores argumentam que é apropriado atribuir probabilidades iguais aos resultados não ordenados quando “distribuindo aleatoriamente <span class="math inline">\(r\)</span> bolas indistinguíveis em <span class="math inline">\(n\)</span> urnas distinguíveis”. Isto é, uma urna é escolhida aleatoriamente e uma bola colocada nela, e isso é repetido <span class="math inline">\(r\)</span> vezes. A ordem em que as bolas são colocadas não é registrada, então, no final, um resultado como <span class="math inline">\(\{1,3\}\)</span> significa uma bola na urna 1 e uma bola na urna 3. Mas aqui está o problema com essa interpretação. Suponha que duas pessoas observem este processo, e o Observador 1 registra a ordem em que as bolas são colocadas, mas o Observador 2 não. O Observador 1 atribuirá probabilidade <span class="math inline">\(2/9\)</span> ao evento <span class="math inline">\(\{1,3\}\)</span>. O Observador 2, que está observando exatamente o mesmo processo, também deve atribuir probabilidade <span class="math inline">\(2/9\)</span> a este evento. Mas se os seis resultados não ordenados são escritos em pedaços de papel idênticos e um é escolhido aleatoriamente para determinar a colocação das bolas, então os resultados não ordenados têm, cada um, probabilidade <span class="math inline">\(1/6\)</span>. Então o Observador 2 atribuirá probabilidade <span class="math inline">\(1/6\)</span> ao evento <span class="math inline">\(\{1,3\}\)</span>. A confusão surge porque a frase “com reposição” tipicamente será interpretada com o tipo sequencial de amostragem que descrevemos acima, levando a atribuir uma probabilidade <span class="math inline">\(2/9\)</span> ao evento <span class="math inline">\(\{1,3\}\)</span>. Esta é a maneira correta de proceder, pois as probabilidades devem ser determinadas pelo mecanismo de amostragem, não se as bolas são distinguíveis ou indistinguíveis.</p>
<section id="exemplo-1.2.20-calculando-uma-média" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.2.20-calculando-uma-média">Exemplo 1.2.20 (Calculando uma média)</h3>
<p>Como uma ilustração da abordagem distinguível/indistinguível, suponha que vamos calcular todas as médias possíveis de quatro números selecionados de</p>
<p><span class="math display">\[
2, 4, 9, 12
\]</span></p>
<p>onde sorteamos os números com reposição. Por exemplo, possíveis sorteios são <span class="math inline">\(\{2, 4, 4, 9\}\)</span> com média 4,75 e <span class="math inline">\(\{4, 4, 9, 9\}\)</span> com média 6,5. Se estamos interessados apenas na média dos números amostrados, a ordenação não é importante e, assim, o número total de amostras distintas é obtido contando de acordo com amostragem não ordenada, com reposição. O número total de amostras distintas é <span class="math inline">\(\binom{4+4-1}{4}\)</span>. Mas agora, para calcular a distribuição de probabilidade das médias amostrais, devemos contar as diferentes maneiras que uma média particular pode ocorrer. O valor 4,75 pode ocorrer apenas se a amostra contiver um 2, dois 4s e um 9. O número de amostras possíveis que têm esta configuração é dado na seguinte tabela:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-1_2_2.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Figura 1.2.2 - Histograma das médias de amostras com reposição dos quatro números {2, 4, 4, 9}</figcaption>
</figure>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Não ordenado</th>
<th style="text-align: left;">Ordenado</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\{2, 4, 4, 9\}\)</span></td>
<td style="text-align: left;"><span class="math inline">\((2, 4, 4, 9), (2, 4, 9, 4), (2, 9, 4, 4), (4, 2, 4, 9),\)</span> <br> <span class="math inline">\((4, 2, 9, 4), (4, 4, 2, 9), (4, 4, 9, 2), (4, 9, 2, 4),\)</span> <br> <span class="math inline">\((4, 9, 4, 2), (9, 2, 4, 4), (9, 4, 2, 4), (9, 4, 4, 2)\)</span></td>
</tr>
</tbody>
</table>
<p>O número total de amostras ordenadas é <span class="math inline">\(n^n = 4^4 = 256\)</span>, então a probabilidade de sortear a amostra não ordenada <span class="math inline">\(\{2, 4, 4, 9\}\)</span> é 12/256. Compare isso com a probabilidade que teríamos obtido se considerássemos as amostras não ordenadas como igualmente prováveis — teríamos atribuído probabilidade <span class="math inline">\(1/\binom{n+n-1}{n} = 1/\binom{7}{4} = 1/35\)</span> a <span class="math inline">\(\{2, 4, 4, 9\}\)</span> e a qualquer outra amostra não ordenada. Para contar o número de amostras ordenadas que resultariam em <span class="math inline">\(\{2, 4, 4, 9\}\)</span>, argumentamos da seguinte forma. Precisamos enumerar as ordens possíveis dos quatro números <span class="math inline">\(\{2, 4, 4, 9\}\)</span>, então estamos essencialmente usando o método de contagem 1 da Seção 1.2.3. Podemos ordenar a amostra de <span class="math inline">\(4 \times 3 \times 2 \times 1 = 24\)</span> maneiras. Mas há um pouco de contagem dupla aqui, já que não podemos distinguir os dois 4s. Por exemplo, as 24 maneiras contariam <span class="math inline">\(\{9, 4, 2, 4\}\)</span> duas vezes (o que estaria OK se os 4s fossem diferentes). Para corrigir isso, dividimos por <span class="math inline">\(2!\)</span> (existem <span class="math inline">\(2!\)</span> maneiras de organizar os dois 4s) e obtemos <span class="math inline">\(24/2 = 12\)</span> amostras ordenadas. Em geral, se existem <span class="math inline">\(k\)</span> lugares e temos <span class="math inline">\(m\)</span> números diferentes repetidos <span class="math inline">\(k_1, k_2, \dots, k_m\)</span> vezes, então o número de amostras ordenadas é <span class="math display">\[
\frac{k!}{k_1! k_2! \dots k_m!}.
\]</span> Este tipo de contagem está relacionado à <em>distribuição multinomial</em>, que veremos na Seção 4.6. A Figura 1.2.2 é um histograma da distribuição de probabilidade das médias amostrais, refletindo a contagem multinomial das amostras. Há também mais um refinamento que é refletido na Figura 1.2.2. É possível que duas amostras não ordenadas diferentes resultem na mesma média. Por exemplo, as amostras não ordenadas <span class="math inline">\(\{4, 4, 12, 12\}\)</span> e <span class="math inline">\(\{2, 9, 9, 12\}\)</span> ambas resultam em uma média de 8. A primeira amostra tem probabilidade 6/256 e a segunda tem probabilidade 12/256, dando ao valor 8 uma probabilidade de <span class="math inline">\(18/256 = .07\)</span>. Veja o Exemplo A.0.1 no Apêndice A para detalhes sobre a construção de tal histograma. O cálculo que fizemos neste exemplo é uma versão elementar de uma técnica estatística muito importante conhecida como <em>bootstrap</em> (Efron e Tibshirani 1993). Voltaremos ao bootstrap na Seção 10.1.4.</p>
</section>
</section>
<section id="probabilidade-condicional-e-independência" class="level2">
<h2 class="anchored" data-anchor-id="probabilidade-condicional-e-independência">1.3 Probabilidade Condicional e Independência</h2>
<p>Todas as probabilidades com as quais lidamos até agora foram probabilidades incondicionais. Um espaço amostral foi definido e todas as probabilidades foram calculadas com respeito a esse espaço amostral. Em muitos casos, no entanto, estamos em uma posição de atualizar o espaço amostral com base em novas informações. Nesses casos, queremos ser capazes de atualizar os cálculos de probabilidade para calcular <em>probabilidades condicionais</em>.</p>
<section id="exemplo-1.3.1-quatro-ases" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.1-quatro-ases">Exemplo 1.3.1 (Quatro ases)</h3>
<p>Quatro cartas são distribuídas do topo de um baralho bem embaralhado. Qual é a probabilidade de que sejam os quatro ases? Podemos calcular essa probabilidade pelos métodos da seção anterior. O número de grupos distintos de quatro cartas é <span class="math display">\[
\binom{52}{4} = 270.725.
\]</span> Apenas um desses grupos consiste nos quatro ases e cada grupo é igualmente provável, então a probabilidade de serem distribuídos os quatro ases é <span class="math inline">\(1/270.725\)</span>. Também podemos calcular essa probabilidade por um argumento de “atualização”, como segue. A probabilidade de que a primeira carta seja um ás é <span class="math inline">\(4/52\)</span>. <em>Dado que a primeira carta é um ás</em>, a probabilidade de que a segunda carta seja um ás é <span class="math inline">\(3/51\)</span> (há 3 ases e 51 cartas restantes). Continuando com esse argumento, obtemos a probabilidade desejada como <span class="math display">\[
\frac{4}{52} \times \frac{3}{51} \times \frac{2}{50} \times \frac{1}{49} = \frac{1}{270.725}.
\]</span></p>
</section>
<p>Em nosso segundo método de resolver o problema, atualizamos o espaço amostral após cada distribuição de uma carta; calculamos probabilidades condicionais.</p>
<section id="definição-1.3.2" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.3.2">Definição 1.3.2</h3>
<p>Se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são eventos em <span class="math inline">\(S\)</span>, e <span class="math inline">\(P(B) &gt; 0\)</span>, então a <em>probabilidade condicional</em> de <span class="math inline">\(A\)</span> dado <span class="math inline">\(B\)</span>, escrita <span class="math inline">\(P(A|B)\)</span>, é <span class="math display">\[
P(A|B) = \frac{P(A \cap B)}{P(B)}.
\]</span></p>
</section>
<p>Note que o que acontece no cálculo da probabilidade condicional é que <span class="math inline">\(B\)</span> se torna o espaço amostral: <span class="math inline">\(P(B|B) = 1\)</span>. A intuição é que nosso espaço amostral original, <span class="math inline">\(S\)</span>, foi atualizado para <span class="math inline">\(B\)</span>. Todas as outras ocorrências são então calibradas com respeito à sua relação com <span class="math inline">\(B\)</span>. Em particular, note o que acontece com probabilidades condicionais de conjuntos disjuntos. Suponha que <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> sejam disjuntos, então <span class="math inline">\(P(A \cap B) = 0\)</span>. Segue então que <span class="math inline">\(P(A|B) = P(B|A) = 0\)</span>.</p>
<section id="exemplo-1.3.3-continuação-do-exemplo-1.3.1" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.3-continuação-do-exemplo-1.3.1">Exemplo 1.3.3 (Continuação do Exemplo 1.3.1)</h3>
<p>Embora a probabilidade de obter todos os quatro ases seja bem pequena, vejamos como as probabilidades condicionais mudam dado que alguns ases já foram retirados. Quatro cartas serão novamente distribuídas de um baralho bem embaralhado, e agora calculamos <span class="math display">\[
P(\text{4 ases em 4 cartas} | i \text{ ases em } i \text{ cartas}), \quad i = 1, 2, 3.
\]</span> O evento <span class="math inline">\(\{4 \text{ ases em 4 cartas}\}\)</span> é um subconjunto do evento <span class="math inline">\(\{i \text{ ases em } i \text{ cartas}\}\)</span>. Assim, da definição de probabilidade condicional, (1.3.1), sabemos que <span class="math display">\[
\begin{align*}
P(\text{4 ases em 4 cartas} | i \text{ ases em } i \text{ cartas}) &amp;= \frac{P(\{4 \text{ ases em 4 cartas}\} \cap \{i \text{ ases em } i \text{ cartas}\})}{P(i \text{ ases em } i \text{ cartas})} \\
&amp;= \frac{P(4 \text{ ases em 4 cartas})}{P(i \text{ ases em } i \text{ cartas})}.
\end{align*}
\]</span> O numerador já foi calculado, e o denominador pode ser calculado com um argumento semelhante. O número de grupos distintos de <span class="math inline">\(i\)</span> cartas é <span class="math inline">\(\binom{52}{i}\)</span>, e <span class="math display">\[
P(i \text{ ases em } i \text{ cartas}) = \frac{\binom{4}{i}}{\binom{52}{i}}.
\]</span> Portanto, a probabilidade condicional é dada por <span class="math display">\[
P(\text{4 ases em 4 cartas} | i \text{ ases em } i \text{ cartas}) = \frac{\frac{\binom{4}{4}}{\binom{52}{4}}}{\frac{\binom{4}{i}}{\binom{52}{i}}} = \frac{(4-i)! 48!}{(52-i)!} = \frac{1}{\binom{52-i}{4-i}}.
\]</span> Para <span class="math inline">\(i = 1, 2\)</span> e <span class="math inline">\(3\)</span>, as probabilidades condicionais são <span class="math inline">\(.00005, .00082\)</span> e <span class="math inline">\(.02041\)</span>, respectivamente.</p>
</section>
<p>Para qualquer <span class="math inline">\(B\)</span> para o qual <span class="math inline">\(P(B) &gt; 0\)</span>, é simples verificar que a função de probabilidade <span class="math inline">\(P(\cdot|B)\)</span> satisfaz os Axiomas de Kolmogorov (veja Exercício 1.35). Você pode suspeitar que exigir <span class="math inline">\(P(B) &gt; 0\)</span> é redundante. Quem iria querer condicionar em um evento de probabilidade 0? Curiosamente, às vezes essa é uma maneira particularmente útil de pensar nas coisas. No entanto, adiaremos essas considerações até o Capítulo 4. Probabilidades condicionais podem ser entidades particularmente escorregadias e, às vezes, requerem reflexão cuidadosa. Considere o seguinte conto frequentemente narrado.</p>
<section id="exemplo-1.3.4-três-prisioneiros" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.4-três-prisioneiros">Exemplo 1.3.4 (Três prisioneiros)</h3>
<p>Três prisioneiros, A, B e C, estão no corredor da morte. O governador decide perdoar um dos três e escolhe aleatoriamente o prisioneiro a ser perdoado. Ele informa o diretor da prisão de sua escolha, mas solicita que o nome seja mantido em segredo por alguns dias. No dia seguinte, A tenta fazer com que o diretor lhe diga quem foi perdoado. O diretor se recusa. A então pergunta qual de B ou C será executado. O diretor pensa por um momento, depois diz a A que B será executado. <strong>Raciocínio do diretor:</strong> Cada prisioneiro tem uma chance de <span class="math inline">\(\frac{1}{3}\)</span> de ser perdoado. Claramente, ou B ou C deve ser executado, então não dei a A nenhuma informação sobre se A será perdoado. <strong>Raciocínio de A:</strong> Dado que B será executado, então ou A ou C será perdoado. Minha chance de ser perdoado aumentou para <span class="math inline">\(\frac{1}{2}\)</span>. Deve ficar claro que o raciocínio do diretor está correto, mas vejamos o porquê. Sejam <span class="math inline">\(A, B\)</span> e <span class="math inline">\(C\)</span> os eventos de que A, B ou C é perdoado, respectivamente. Sabemos que <span class="math inline">\(P(A) = P(B) = P(C) = \frac{1}{3}\)</span>. Seja <span class="math inline">\(\mathcal{W}\)</span> o evento de que o diretor diz que B morrerá. Usando (1.3.1), A pode atualizar sua probabilidade de ser perdoado para <span class="math display">\[
P(A|\mathcal{W}) = \frac{P(A \cap \mathcal{W})}{P(\mathcal{W})}.
\]</span> O que está acontecendo pode ser resumido nesta tabela:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Prisioneiro perdoado</th>
<th style="text-align: left;">Diretor diz a A</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">B morre</td>
<td style="text-align: left;">cada um com igual</td>
</tr>
<tr class="even">
<td style="text-align: left;">A</td>
<td style="text-align: left;">C morre</td>
<td style="text-align: left;">probabilidade</td>
</tr>
<tr class="odd">
<td style="text-align: left;">B</td>
<td style="text-align: left;">C morre</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">C</td>
<td style="text-align: left;">B morre</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Usando esta tabela, podemos calcular <span class="math display">\[
\begin{align*}
P(\mathcal{W}) &amp;= P(\text{diretor diz B morre}) \\
&amp;= P(\text{diretor diz B morre e A perdoado}) \\
&amp;\quad + P(\text{diretor diz B morre e C perdoado}) \\
&amp;\quad + P(\text{diretor diz B morre e B perdoado}) \\
&amp;= \frac{1}{6} + \frac{1}{3} + 0 = \frac{1}{2}.
\end{align*}
\]</span> Assim, usando o raciocínio do diretor, temos <span class="math display">\[
P(A|\mathcal{W}) = \frac{P(A \cap \mathcal{W})}{P(\mathcal{W})} = \frac{P(\text{diretor diz B morre e A perdoado})}{P(\text{diretor diz B morre})} = \frac{1/6}{1/2} = \frac{1}{3}.
\]</span> No entanto, um A interpreta falsamente o evento <span class="math inline">\(\mathcal{W}\)</span> como igual ao evento <span class="math inline">\(B^c\)</span> e calcula <span class="math display">\[
P(A|B^c) = \frac{P(A \cap B^c)}{P(B^c)} = \frac{1/3}{2/3} = \frac{1}{2}.
\]</span> Vemos que probabilidades condicionais podem ser bastante escorregadias e exigem interpretação cuidadosa. Para algumas outras variações deste problema, veja o Exercício 1.37.</p>
</section>
<p>Reexpressando (1.3.1) dá uma forma útil para calcular probabilidades de interseção, <span class="math display">\[
P(A \cap B) = P(A|B)P(B), \quad (1.3.3)
\]</span> que é essencialmente a fórmula que foi usada no Exemplo 1.3.1. Podemos tirar proveito da simetria de (1.3.3) e também escrever <span class="math display">\[
P(A \cap B) = P(B|A)P(A). \quad (1.3.4)
\]</span> Quando confrontados com cálculos aparentemente difíceis, podemos dividir nossos cálculos de acordo com (1.3.3) ou (1.3.4), o que for mais fácil. Além disso, podemos igualar os lados direitos dessas equações para obter (após rearranjo) <span class="math display">\[
P(A|B) = P(B|A)\frac{P(A)}{P(B)}, \quad (1.3.5)
\]</span> que nos dá uma fórmula para “inverter” probabilidades condicionais. A Equação (1.3.5) é frequentemente chamada de <em>Regra de Bayes</em> por seu descobridor, Sir Thomas Bayes (embora veja Stigler 1983). A Regra de Bayes tem uma forma mais geral do que (1.3.5), uma que se aplica a partições de um espaço amostral. Tomamos, portanto, o seguinte como a definição da Regra de Bayes.</p>
<section id="teorema-1.3.5-regra-de-bayes" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.3.5-regra-de-bayes">Teorema 1.3.5 (Regra de Bayes)</h3>
<p><em>Seja <span class="math inline">\(A_1, A_2, \dots\)</span> uma partição do espaço amostral, e seja <span class="math inline">\(B\)</span> qualquer conjunto. Então, para cada <span class="math inline">\(i = 1, 2, \dots\)</span>,</em> <span class="math display">\[
P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^{\infty} P(B|A_j)P(A_j)}.
\]</span></p>
</section>
<section id="exemplo-1.3.6-codificação" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.6-codificação">Exemplo 1.3.6 (Codificação)</h3>
<p>Quando mensagens codificadas são enviadas, às vezes ocorrem erros na transmissão. Em particular, o código Morse usa “pontos” e “traços”, que são conhecidos por ocorrer na proporção de 3:4. Isso significa que para qualquer símbolo dado, <span class="math display">\[
P(\text{ponto enviado}) = \frac{3}{7} \quad \text{e} \quad P(\text{traço enviado}) = \frac{4}{7}.
\]</span> Suponha que há interferência na linha de transmissão e, com probabilidade <span class="math inline">\(\frac{1}{8}\)</span>, um ponto é erroneamente recebido como um traço, e vice-versa. Se recebermos um ponto, podemos ter certeza de que um ponto foi enviado? Usando a Regra de Bayes, podemos escrever <span class="math display">\[
P(\text{ponto enviado} | \text{ponto recebido}) = P(\text{ponto recebido} | \text{ponto enviado}) \frac{P(\text{ponto enviado})}{P(\text{ponto recebido})}.
\]</span> Agora, a partir da informação dada, sabemos que <span class="math inline">\(P(\text{ponto enviado}) = \frac{3}{7}\)</span> e <span class="math inline">\(P(\text{ponto recebido} | \text{ponto enviado}) = \frac{7}{8}\)</span>. Além disso, também podemos escrever <span class="math display">\[
\begin{align*}
P(\text{ponto recebido}) &amp;= P(\text{ponto recebido} \cap \text{ponto enviado}) + P(\text{ponto recebido} \cap \text{traço enviado}) \\
&amp;= P(\text{ponto recebido} | \text{ponto enviado})P(\text{ponto enviado}) \\
&amp;\quad + P(\text{ponto recebido} | \text{traço enviado})P(\text{traço enviado}) \\
&amp;= \frac{7}{8} \times \frac{3}{7} + \frac{1}{8} \times \frac{4}{7} = \frac{25}{56}.
\end{align*}
\]</span> Combinando esses resultados, temos que a probabilidade de receber corretamente um ponto é <span class="math display">\[
P(\text{ponto enviado} | \text{ponto recebido}) = \frac{(7/8) \times (3/7)}{25/56} = \frac{21}{25}.
\]</span></p>
</section>
<p>Em alguns casos, pode acontecer que a ocorrência de um evento particular, <span class="math inline">\(B\)</span>, não tenha efeito sobre a probabilidade de outro evento, <span class="math inline">\(A\)</span>. Simbolicamente, estamos dizendo que <span class="math display">\[
P(A|B) = P(A). \quad (1.3.6)
\]</span> Se isso vale, então pela Regra de Bayes (1.3.5) e usando (1.3.6) temos <span class="math display">\[
P(B|A) = P(A|B)\frac{P(B)}{P(A)} = P(A)\frac{P(B)}{P(A)} = P(B), \quad (1.3.7)
\]</span> então a ocorrência de <span class="math inline">\(A\)</span> não tem efeito sobre <span class="math inline">\(B\)</span>. Além disso, como <span class="math inline">\(P(B|A)P(A) = P(A \cap B)\)</span>, segue-se que <span class="math display">\[
P(A \cap B) = P(A)P(B),
\]</span> o que tomamos como a definição de independência estatística.</p>
<section id="definição-1.3.7" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.3.7">Definição 1.3.7</h3>
<p>Dois eventos, <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, são <em>estatisticamente independentes</em> se <span class="math display">\[
P(A \cap B) = P(A)P(B). \quad (1.3.8)
\]</span></p>
</section>
<p>Note que a independência poderia ter sido equivalentemente definida por (1.3.6) ou (1.3.7) (desde que <span class="math inline">\(P(A) &gt; 0\)</span> ou <span class="math inline">\(P(B) &gt; 0\)</span>). A vantagem de (1.3.8) é que ela trata os eventos simetricamente e será mais fácil de generalizar para mais de dois eventos. Muitos jogos de azar fornecem modelos de eventos independentes. Os giros de uma roleta e os lançamentos de um par de dados são ambas séries de eventos independentes.</p>
<section id="exemplo-1.3.8-chevalier-de-méré" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.8-chevalier-de-méré">Exemplo 1.3.8 (Chevalier de Méré)</h3>
<p>O jogador introduzido no início do capítulo, o Chevalier de Méré, estava particularmente interessado no evento de que ele poderia lançar pelo menos um 6 em 4 lançamentos de um dado. Nós temos <span class="math display">\[
\begin{align*}
P(\text{pelo menos um 6 em 4 lançamentos}) &amp;= 1 - P(\text{nenhum seis em 4 lançamentos}) \\
&amp;= 1 - \prod_{i=1}^4 P(\text{nenhum seis no lançamento } i),
\end{align*}
\]</span> onde a última igualdade decorre da independência dos lançamentos. Em qualquer lançamento, a probabilidade de <em>não</em> rolar um seis é <span class="math inline">\(\frac{5}{6}\)</span>, então <span class="math display">\[
P(\text{pelo menos um 6 em 4 lançamentos}) = 1 - \left( \frac{5}{6} \right)^4 = .518.
\]</span></p>
</section>
<p>A independência de <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> implica independência dos complementos também. De fato, temos o seguinte teorema.</p>
<section id="teorema-1.3.9" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.3.9">Teorema 1.3.9</h3>
<p><em>Se A e B são eventos independentes, então os seguintes pares também são independentes:</em> * <strong>a.</strong> <span class="math inline">\(A\)</span> e <span class="math inline">\(B^c\)</span>, * <strong>b.</strong> <span class="math inline">\(A^c\)</span> e <span class="math inline">\(B\)</span>, * <strong>c.</strong> <span class="math inline">\(A^c\)</span> e <span class="math inline">\(B^c\)</span>.</p>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Provaremos apenas (a), deixando o restante como Exercício 1.40. Para provar (a) devemos mostrar que <span class="math inline">\(P(A \cap B^c) = P(A)P(B^c)\)</span>. Do Teorema 1.2.9a temos <span class="math display">\[
\begin{align*}
P(A \cap B^c) &amp;= P(A) - P(A \cap B) \\
&amp;= P(A) - P(A)P(B) \quad (A \text{ e } B \text{ são independentes}) \\
&amp;= P(A)(1 - P(B)) \\
&amp;= P(A)P(B^c). \quad \square
\end{align*}
\]</span></p>
</div>
<p>A independência de mais de dois eventos pode ser definida de maneira semelhante a (1.3.8), mas devemos ter cuidado. Por exemplo, podemos pensar que poderíamos dizer <span class="math inline">\(A, B\)</span> e <span class="math inline">\(C\)</span> são independentes se <span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span>. No entanto, esta não é a condição correta.</p>
<section id="exemplo-1.3.10-lançando-dois-dados" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.10-lançando-dois-dados">Exemplo 1.3.10 (Lançando dois dados)</h3>
<p>Seja um experimento consistindo em lançar dois dados. Para este experimento, o espaço amostral é <span class="math display">\[
S = \{(1,1), (1,2), \dots, (1,6), (2,1), \dots, (2,6), \dots, (6,1), \dots, (6,6)\};
\]</span> isto é, <span class="math inline">\(S\)</span> consiste nos 36 pares ordenados formados a partir dos números 1 a 6. Defina os seguintes eventos: * <span class="math inline">\(A = \{\text{duplas aparecem}\} = \{(1,1), (2,2), (3,3), (4,4), (5,5), (6,6)\}\)</span>, * <span class="math inline">\(B = \{\text{a soma está entre 7 e 10}\}\)</span>, * <span class="math inline">\(C = \{\text{a soma é 2 ou 7 ou 8}\}\)</span>.</p>
<p>As probabilidades podem ser calculadas contando entre os 36 resultados possíveis. Nós temos <span class="math display">\[
P(A) = \frac{1}{6}, \quad P(B) = \frac{1}{2}, \quad \text{e} \quad P(C) = \frac{1}{3}.
\]</span> Além disso, <span class="math display">\[
\begin{align*}
P(A \cap B \cap C) &amp;= P(\text{a soma é 8, composta de duplos 4s}) \\
&amp;= \frac{1}{36} \\
&amp;= \frac{1}{6} \times \frac{1}{2} \times \frac{1}{3} \\
&amp;= P(A)P(B)P(C).
\end{align*}
\]</span> No entanto, <span class="math display">\[
P(B \cap C) = P(\text{soma igual a 7 ou 8}) = \frac{11}{36} \ne P(B)P(C).
\]</span> Similarmente, pode ser mostrado que <span class="math inline">\(P(A \cap B) \ne P(A)P(B)\)</span>; portanto, o requisito <span class="math inline">\(P(A \cap B \cap C) = P(A)P(B)P(C)\)</span> não é uma condição forte o suficiente para garantir independência dois a dois.</p>
</section>
<p>Uma segunda tentativa de uma definição geral de independência, à luz do exemplo anterior, pode ser definir <span class="math inline">\(A, B\)</span> e <span class="math inline">\(C\)</span> como independentes se todos os pares forem independentes. Infelizmente, esta condição também falha.</p>
<section id="exemplo-1.3.11-letras" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.11-letras">Exemplo 1.3.11 (Letras)</h3>
<p>Seja o espaço amostral <span class="math inline">\(S\)</span> consistindo nas <span class="math inline">\(3!\)</span> permutações das letras a, b e c junto com as três triplas de cada letra. Assim, <span class="math display">\[
S = \begin{Bmatrix} \text{aaa} &amp; \text{bbb} &amp; \text{ccc} \\ \text{abc} &amp; \text{bca} &amp; \text{cba} \\ \text{acb} &amp; \text{bac} &amp; \text{cab} \end{Bmatrix}.
\]</span> Além disso, seja cada elemento de <span class="math inline">\(S\)</span> ter probabilidade <span class="math inline">\(\frac{1}{9}\)</span>. Defina <span class="math display">\[
A_i = \{\text{o } i\text{-ésimo lugar na tripla é ocupado por a}\}.
\]</span> É então fácil contar que <span class="math display">\[
P(A_i) = \frac{1}{3}, \quad i = 1, 2, 3,
\]</span> e <span class="math display">\[
P(A_1 \cap A_2) = P(A_1 \cap A_3) = P(A_2 \cap A_3) = \frac{1}{9},
\]</span> então os <span class="math inline">\(A_i\)</span>s são independentes dois a dois. Mas <span class="math display">\[
P(A_1 \cap A_2 \cap A_3) = \frac{1}{9} \ne P(A_1)P(A_2)P(A_3),
\]</span> então os <span class="math inline">\(A_i\)</span>s não satisfazem o requisito de probabilidade.</p>
</section>
<p>Os dois exemplos anteriores mostram que a independência simultânea (ou mútua) de uma coleção de eventos requer uma definição extremamente forte. A seguinte definição funciona.</p>
<section id="definição-1.3.12" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.3.12">Definição 1.3.12</h3>
<p>Uma coleção de eventos <span class="math inline">\(A_1, \dots, A_n\)</span> são <em>mutuamente independentes</em> se para qualquer subcoleção <span class="math inline">\(A_{i_1}, \dots, A_{i_k}\)</span>, temos <span class="math display">\[
P\left( \bigcap_{j=1}^k A_{i_j} \right) = \prod_{j=1}^k P(A_{i_j}).
\]</span></p>
</section>
<section id="exemplo-1.3.13-três-lançamentos-de-moedai" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.3.13-três-lançamentos-de-moedai">Exemplo 1.3.13 (Três lançamentos de moeda—I)</h3>
<p>Considere o experimento de lançar uma moeda três vezes. Um ponto amostral para este experimento deve indicar o resultado de cada lançamento. Por exemplo, HHT poderia indicar que duas caras e depois uma coroa foram observadas. O espaço amostral para este experimento tem oito pontos, a saber,</p>
<p><span class="math display">\[
\{\text{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT}\}.
\]</span></p>
<p>Seja <span class="math inline">\(H_i, i = 1, 2, 3\)</span>, o evento de que o <span class="math inline">\(i\)</span>-ésimo lançamento é uma cara. Por exemplo,</p>
<p><span class="math display">\[
H_1 = \{\text{HHH, HHT, HTH, HTT}\}.
\]</span></p>
<p>Se atribuirmos probabilidade <span class="math inline">\(\frac{1}{8}\)</span> a cada ponto amostral, então, usando enumerações como (1.3.9), vemos que <span class="math inline">\(P(H_1) = P(H_2) = P(H_3) = \frac{1}{2}\)</span>. Isso diz que a moeda é justa e tem igual probabilidade de dar cara ou coroa em cada lançamento. Sob este modelo de probabilidade, os eventos <span class="math inline">\(H_1, H_2\)</span> e <span class="math inline">\(H_3\)</span> também são mutuamente independentes. Para verificar isso, notamos que</p>
<p><span class="math display">\[
P(H_1 \cap H_2 \cap H_3) = P(\{\text{HHH}\}) = \frac{1}{8} = \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = P(H_1)P(H_2)P(H_3).
\]</span></p>
<p>Para verificar a condição na Definição 1.3.12, devemos também verificar cada par. Por exemplo,</p>
<p><span class="math display">\[
P(H_1 \cap H_2) = P(\{\text{HHH, HHT}\}) = \frac{2}{8} = \frac{1}{2} \cdot \frac{1}{2} = P(H_1)P(H_2).
\]</span></p>
<p>A igualdade também é verdadeira para os outros dois pares. Assim, <span class="math inline">\(H_1, H_2\)</span> e <span class="math inline">\(H_3\)</span> são mutuamente independentes. Ou seja, a ocorrência de uma cara em qualquer lançamento não tem efeito em nenhum dos outros lançamentos. Pode ser verificado que a atribuição de probabilidade <span class="math inline">\(\frac{1}{8}\)</span> para cada ponto amostral é o único modelo de probabilidade que tem <span class="math inline">\(P(H_1) = P(H_2) = P(H_3) = \frac{1}{2}\)</span> e <span class="math inline">\(H_1, H_2\)</span> e <span class="math inline">\(H_3\)</span> mutuamente independentes.</p>
</section>
</section>
<section id="variáveis-aleatórias" class="level2">
<h2 class="anchored" data-anchor-id="variáveis-aleatórias">1.4 Variáveis Aleatórias</h2>
<p>Em muitos experimentos, é mais fácil lidar com uma variável resumo do que com a estrutura de probabilidade original. Por exemplo, em uma pesquisa de opinião, podemos decidir perguntar a 50 pessoas se elas concordam ou discordam de uma certa questão. Se registrarmos um “1” para concordo e “0” para discordo, o espaço amostral para este experimento tem <span class="math inline">\(2^{50}\)</span> elementos, cada um uma string ordenada de 1s e 0s de comprimento 50. Devemos ser capazes de reduzir isso a um tamanho razoável! Pode ser que a única quantidade de interesse seja o número de pessoas que concordam (equivalentemente, discordam) de 50, e, se definirmos uma variável <span class="math inline">\(X\)</span> = número de 1s registrados em 50, capturamos a essência do problema. Note que o espaço amostral para <span class="math inline">\(X\)</span> é o conjunto de inteiros <span class="math inline">\(\{0, 1, 2, \dots, 50\}\)</span> e é muito mais fácil de lidar do que o espaço amostral original. Ao definir a quantidade <span class="math inline">\(X\)</span>, definimos um mapeamento (uma função) do espaço amostral original para um novo espaço amostral, geralmente um conjunto de números reais. Em geral, temos a seguinte definição.</p>
<section id="definição-1.4.1---variável-aleatória" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.4.1---variável-aleatória">Definição 1.4.1 - Variável Aleatória</h3>
<p>Uma <em>variável aleatória</em> é uma função de um espaço amostral <span class="math inline">\(S\)</span> para os números reais.</p>
</section>
<section id="exemplo-1.4.2-variáveis-aleatórias" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.4.2-variáveis-aleatórias">Exemplo 1.4.2 (Variáveis aleatórias)</h3>
<p>Em alguns experimentos, variáveis aleatórias são usadas implicitamente; alguns exemplos são:</p>
<p><strong>Exemplos de variáveis aleatórias</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Experimento</th>
<th style="text-align: left;">Variável aleatória</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Lançar dois dados</td>
<td style="text-align: left;"><span class="math inline">\(X =\)</span> soma dos números</td>
</tr>
<tr class="even">
<td style="text-align: left;">Lançar uma moeda 25 vezes</td>
<td style="text-align: left;"><span class="math inline">\(X =\)</span> número de caras em 25 lançamentos</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Aplicar diferentes quantidades de fertilizante em plantas de milho</td>
<td style="text-align: left;"><span class="math inline">\(X =\)</span> produtividade/acre</td>
</tr>
</tbody>
</table>
<p>Ao definir uma variável aleatória, também definimos um novo espaço amostral (a imagem da variável aleatória). Devemos verificar formalmente se nossa função de probabilidade, definida no espaço amostral original, pode ser usada para a variável aleatória. Suponha que temos um espaço amostral <span class="math display">\[
S = \{s_1, \dots, s_n\}
\]</span> com uma função de probabilidade <span class="math inline">\(P\)</span> e definimos uma variável aleatória <span class="math inline">\(X\)</span> com imagem <span class="math inline">\(\mathcal{X} = \{x_1, \dots, x_m\}\)</span>. Definimos uma função de probabilidade <span class="math inline">\(P_X\)</span> em <span class="math inline">\(\mathcal{X}\)</span> da seguinte maneira. Observaremos <span class="math inline">\(X = x_i\)</span> se e somente se o resultado do experimento aleatório for um <span class="math inline">\(s_j \in S\)</span> tal que <span class="math inline">\(X(s_j) = x_i\)</span>. Assim, <span class="math display">\[
P_X(X = x_i) = P(\{s_j \in S : X(s_j) = x_i\}). \quad (1.4.1)
\]</span> Note que o lado esquerdo de (1.4.1), a função <span class="math inline">\(P_X\)</span>, é uma <em>probabilidade induzida</em> em <span class="math inline">\(\mathcal{X}\)</span>, definida em termos da função original <span class="math inline">\(P\)</span>. A Equação (1.4.1) define formalmente uma função de probabilidade, <span class="math inline">\(P_X\)</span>, para a variável aleatória <span class="math inline">\(X\)</span>. É claro que temos que verificar se <span class="math inline">\(P_X\)</span> satisfaz os Axiomas de Kolmogorov, mas essa é uma tarefa muito difícil (veja o Exercício 1.45). Devido à equivalência em (1.4.1), simplesmente escreveremos <span class="math inline">\(P(X = x_i)\)</span> em vez de <span class="math inline">\(P_X(X = x_i)\)</span>. <em>Uma nota sobre notação:</em> Variáveis aleatórias sempre serão denotadas com letras maiúsculas e os valores realizados da variável (ou sua imagem) serão denotados pelas letras minúsculas correspondentes. Assim, a variável aleatória <span class="math inline">\(X\)</span> pode assumir o valor <span class="math inline">\(x\)</span>.</p>
</section>
<section id="exemplo-1.4.3-três-lançamentos-de-moedaii" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.4.3-três-lançamentos-de-moedaii">Exemplo 1.4.3 (Três lançamentos de moeda—II)</h3>
<p>Considere novamente o experimento de lançar uma moeda honesta três vezes do Exemplo 1.3.13. Defina a variável aleatória <span class="math inline">\(X\)</span> como o número de caras obtidas nos três lançamentos. Uma enumeração completa do valor de <span class="math inline">\(X\)</span> para cada ponto no espaço amostral é</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(s\)</span></th>
<th style="text-align: center;">HHH</th>
<th style="text-align: center;">HHT</th>
<th style="text-align: center;">HTH</th>
<th style="text-align: center;">THH</th>
<th style="text-align: center;">TTH</th>
<th style="text-align: center;">THT</th>
<th style="text-align: center;">HTT</th>
<th style="text-align: center;">TTT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(X(s)\)</span></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>A imagem da variável aleatória <span class="math inline">\(X\)</span> é <span class="math inline">\(\mathcal{X} = \{0, 1, 2, 3\}\)</span>. Assumindo que todos os oito pontos em <span class="math inline">\(S\)</span> têm probabilidade <span class="math inline">\(\frac{1}{8}\)</span>, simplesmente contando na exibição acima vemos que a função de probabilidade induzida em <span class="math inline">\(\mathcal{X}\)</span> é dada por</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(x\)</span></th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(P_X(X=x)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{8}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{8}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{8}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{8}\)</span></td>
</tr>
</tbody>
</table>
<p>Por exemplo, <span class="math inline">\(P_X(X=1) = P(\{\text{HTT, THT, TTH}\}) = \frac{3}{8}\)</span>.</p>
</section>
<section id="exemplo-1.4.4-distribuição-de-uma-variável-aleatória" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.4.4-distribuição-de-uma-variável-aleatória">Exemplo 1.4.4 (Distribuição de uma variável aleatória)</h3>
<p>Pode ser possível determinar <span class="math inline">\(P_X\)</span> mesmo se uma listagem completa, como no Exemplo 1.4.3, não for possível. Seja <span class="math inline">\(S\)</span> as <span class="math inline">\(2^{50}\)</span> strings de 50 zeros e uns, <span class="math inline">\(X =\)</span> número de 1s, e <span class="math inline">\(\mathcal{X} = \{0, 1, 2, \dots, 50\}\)</span>, como mencionado no início desta seção. Suponha que cada uma das <span class="math inline">\(2^{50}\)</span> strings seja igualmente provável. A probabilidade de que <span class="math inline">\(X = 27\)</span> pode ser obtida contando todas as strings com 27 uns no espaço amostral original. Como cada string é igualmente provável, segue-se que <span class="math display">\[
P_X(X = 27) = \frac{\# \text{ strings com 27 1s}}{\# \text{ strings}} = \frac{\binom{50}{27}}{2^{50}}.
\]</span> Em geral, para qualquer <span class="math inline">\(i \in \mathcal{X}\)</span>, <span class="math display">\[
P_X(X = i) = \frac{\binom{50}{i}}{2^{50}}.
\]</span></p>
</section>
<p>As ilustrações anteriores tinham tanto um <span class="math inline">\(S\)</span> finito quanto um <span class="math inline">\(\mathcal{X}\)</span> finito, e a definição de <span class="math inline">\(P_X\)</span> foi direta. Tal também é o caso se <span class="math inline">\(\mathcal{X}\)</span> é enumerável. Se <span class="math inline">\(\mathcal{X}\)</span> é não enumerável, definimos a função de probabilidade induzida, <span class="math inline">\(P_X\)</span>, de uma maneira semelhante a (1.4.1). Para qualquer conjunto <span class="math inline">\(A \subset \mathcal{X}\)</span>, <span class="math display">\[
P_X(X \in A) = P(\{s \in S : X(s) \in A\}). \quad (1.4.2)
\]</span> Isso define uma função de probabilidade legítima para a qual os Axiomas de Kolmogorov podem ser verificados. (Para ser preciso, usamos (1.4.2) para definir probabilidades apenas para uma certa sigma-álgebra de subconjuntos de <span class="math inline">\(\mathcal{X}\)</span>. Mas não nos preocuparemos com essas tecnicalidades.)</p>
</section>
<section id="funções-de-distribuição" class="level2">
<h2 class="anchored" data-anchor-id="funções-de-distribuição">1.5 Funções de Distribuição</h2>
<p>A cada variável aleatória <span class="math inline">\(X\)</span>, associamos uma função chamada função de distribuição acumulada de <span class="math inline">\(X\)</span>.</p>
<section id="definição-1.5.1" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.5.1">Definição 1.5.1</h3>
<p>A <em>função de distribuição acumulada</em> ou <em>fda</em> (cdf - <em>cumulative distribution function</em> em inglês) de uma variável aleatória <span class="math inline">\(X\)</span>, denotada por <span class="math inline">\(F_X(x)\)</span>, é definida por <span class="math display">\[
F_X(x) = P_X(X \le x), \quad \text{para todo } x.
\]</span></p>
</section>
<section id="exemplo-1.5.2-lançando-três-moedas" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.5.2-lançando-três-moedas">Exemplo 1.5.2 (Lançando três moedas)</h3>
<p>Considere o experimento de lançar três moedas justas, e seja <span class="math inline">\(X =\)</span> número de caras observadas. A fda de <span class="math inline">\(X\)</span> é</p>
<p><span class="math display">\[
F_X(x) = \begin{cases}
0 &amp; \text{se } -\infty &lt; x &lt; 0 \\
\frac{1}{8} &amp; \text{se } 0 \le x &lt; 1 \\
\frac{1}{2} &amp; \text{se } 1 \le x &lt; 2 \\
\frac{7}{8} &amp; \text{se } 2 \le x &lt; 3 \\
1 &amp; \text{se } 3 \le x &lt; \infty.
\end{cases} \quad (1.5.1)
\]</span></p>
<p>A função escada <span class="math inline">\(F_X(x)\)</span> é grafada na Figura 1.5.1. Há vários pontos a notar na Figura 1.5.1. <span class="math inline">\(F_X\)</span> é definida para todos os valores de <span class="math inline">\(x\)</span>, não apenas aqueles em <span class="math inline">\(\mathcal{X} = \{0, 1, 2, 3\}\)</span>. Assim, por exemplo,</p>
<p><span class="math display">\[
F_X(2.5) = P(X \le 2.5) = P(X = 0, 1, \text{ou } 2) = \frac{7}{8}.
\]</span></p>
<p>Note que <span class="math inline">\(F_X\)</span> tem saltos nos valores de <span class="math inline">\(x_i \in \mathcal{X}\)</span> e o tamanho do salto em <span class="math inline">\(x_i\)</span> é igual a <span class="math inline">\(P(X = x_i)\)</span>. Além disso, <span class="math inline">\(F_X(x) = 0\)</span> para <span class="math inline">\(x &lt; 0\)</span> uma vez que <span class="math inline">\(X\)</span> não pode ser negativo, e <span class="math inline">\(F_X(x) = 1\)</span> para <span class="math inline">\(x \ge 3\)</span> uma vez que <span class="math inline">\(x\)</span> é certo ser menor ou igual a tal valor.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-1_5_1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Figura 1.5.1 - Cdf do Exemplo 1.5.2</figcaption>
</figure>
</div>
<p>Como é aparente na Figura 1.5.1, <span class="math inline">\(F_X\)</span> pode ser descontínua, com saltos em certos valores de <span class="math inline">\(x\)</span>. A propósito, na maneira como <span class="math inline">\(F_X\)</span> é definida, no entanto, nos pontos de salto <span class="math inline">\(F_X\)</span> assume o valor no topo do salto. (Note as diferentes desigualdades em (1.5.1).) Isso é conhecido como <em>continuidade à direita</em> — a função é contínua quando um ponto é abordado pela direita. A propriedade de continuidade à direita é uma consequência da definição da fda. Em contraste, se tivéssemos definido <span class="math inline">\(F_X(x) = P_X(X &lt; x)\)</span> (note a desigualdade estrita), <span class="math inline">\(F_X\)</span> seria então <em>contínua à esquerda</em>. O tamanho do salto em qualquer ponto <span class="math inline">\(x\)</span> é igual a <span class="math inline">\(P(X = x)\)</span>. Toda fda satisfaz certas propriedades, algumas das quais são óbvias quando pensamos na definição de <span class="math inline">\(F_X(x)\)</span> em termos de probabilidades.</p>
</section>
<section id="teorema-1.5.3" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.5.3">Teorema 1.5.3</h3>
<p><em>A função <span class="math inline">\(F(x)\)</span> é uma fda se e somente se as três condições seguintes forem satisfeitas:</em> * <strong>a.</strong> <span class="math inline">\(\lim_{x \to -\infty} F(x) = 0\)</span> e <span class="math inline">\(\lim_{x \to \infty} F(x) = 1\)</span>. * <strong>b.</strong> <span class="math inline">\(F(x)\)</span> é uma função não decrescente de <span class="math inline">\(x\)</span>. * <strong>c.</strong> <span class="math inline">\(F(x)\)</span> é contínua à direita; isto é, para todo número <span class="math inline">\(x_0\)</span>, <span class="math inline">\(\lim_{x \downarrow x_0} F(x) = F(x_0)\)</span>.</p>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span><em>Esboço da prova:</em> Para provar a necessidade, as três propriedades podem ser verificadas escrevendo <span class="math inline">\(F\)</span> em termos da função de probabilidade (veja Exercício 1.48). Para provar a suficiência, ou seja, que se uma função <span class="math inline">\(F\)</span> satisfaz as três condições do teorema então existe alguma variável aleatória, é muito mais difícil. Deve ser estabelecido que existe um espaço amostral <span class="math inline">\(S\)</span>, uma função de probabilidade <span class="math inline">\(P\)</span> em <span class="math inline">\(S\)</span>, e uma variável aleatória <span class="math inline">\(X\)</span> definida em <span class="math inline">\(S\)</span> tal que <span class="math inline">\(F\)</span> é a fda de <span class="math inline">\(X\)</span>. <span class="math inline">\(\square\)</span></p>
</div>
<section id="exemplo-1.5.4-lançando-até-obter-uma-cara" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.5.4-lançando-até-obter-uma-cara">Exemplo 1.5.4 (Lançando até obter uma cara)</h3>
<p>Suponha que fazemos um experimento que consiste em lançar uma moeda até que uma cara apareça. Seja <span class="math inline">\(p =\)</span> probabilidade de uma cara em qualquer lançamento dado, e defina uma variável aleatória <span class="math inline">\(X =\)</span> número de lançamentos necessários para obter uma cara. Então, para qualquer <span class="math inline">\(x = 1, 2, \dots\)</span>,</p>
<p><span class="math display">\[
P(X = x) = (1-p)^{x-1}p, \quad (1.5.2)
\]</span></p>
<p>uma vez que devemos obter <span class="math inline">\(x-1\)</span> coroas seguidas por uma cara para que o evento ocorra e todas as tentativas são independentes. A partir de (1.5.2) calculamos, para qualquer inteiro positivo <span class="math inline">\(x\)</span>,</p>
<p><span class="math display">\[
P(X \le x) = \sum_{i=1}^x P(X=i) = \sum_{i=1}^x (1-p)^{i-1}p. \quad (1.5.3)
\]</span></p>
<p>A soma parcial da série geométrica é</p>
<p><span class="math display">\[
\sum_{k=1}^n t^{k-1} = \frac{1-t^n}{1-t}, \quad t \ne 1, \quad (1.5.4)
\]</span></p>
<p>um fato que pode ser estabelecido por indução (veja Exercício 1.50). Aplicando (1.5.4) à nossa probabilidade, descobrimos que a fda da variável aleatória <span class="math inline">\(X\)</span> é</p>
<p><span class="math display">\[
\begin{align*}
F_X(x) &amp;= P(X \le x) \\
&amp;= \frac{1-(1-p)^x}{1-(1-p)}p \\
&amp;= 1 - (1-p)^x, \quad x = 1, 2, \dots .
\end{align*}
\]</span></p>
<p>A fda <span class="math inline">\(F_X(x)\)</span> é plana entre os inteiros não negativos, como no Exemplo 1.5.2. É fácil mostrar que se <span class="math inline">\(0 &lt; p &lt; 1\)</span>, então <span class="math inline">\(F_X(x)\)</span> satisfaz as condições do Teorema 1.5.3. Primeiro,</p>
<p><span class="math display">\[
\lim_{x \to -\infty} F_X(x) = 0
\]</span></p>
<p>uma vez que <span class="math inline">\(F_X(x) = 0\)</span> para todo <span class="math inline">\(x &lt; 0\)</span>, e</p>
<p><span class="math display">\[
\lim_{x \to \infty} F_X(x) = \lim_{x \to \infty} 1 - (1-p)^x = 1,
\]</span></p>
<p>onde <span class="math inline">\(x\)</span> passa apenas por valores inteiros quando este limite é tomado. Para verificar a propriedade (b), simplesmente notamos que a soma em (1.5.3) contém mais termos <em>positivos</em> conforme <span class="math inline">\(x\)</span> aumenta. Finalmente, para verificar (c), note que, para qualquer <span class="math inline">\(x\)</span>, <span class="math inline">\(F_X(x+\epsilon) = F_X(x)\)</span> se <span class="math inline">\(\epsilon &gt; 0\)</span> é suficientemente pequeno. Portanto,</p>
<p><span class="math display">\[
\lim_{\epsilon \downarrow 0} F_X(x+\epsilon) = F_X(x),
\]</span></p>
<p>então <span class="math inline">\(F_X(x)\)</span> é contínua à direita. <span class="math inline">\(F_X(x)\)</span> é a fda de uma distribuição chamada <em>distribuição geométrica</em> (após a série) e é retratada na Figura 1.5.2.</p>
</section>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-1_5_2.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Figura 1.5.2 - Cdf geométrica, p = .3</figcaption>
</figure>
</div>
<section id="exemplo-1.5.5-cdf-contínua" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.5.5-cdf-contínua">Exemplo 1.5.5 (Cdf contínua)</h3>
<p>Um exemplo de uma fda contínua é a função</p>
<p><span class="math display">\[
F_X(x) = \frac{1}{1+e^{-x}}, \quad (1.5.5)
\]</span></p>
<p>que satisfaz as condições do Teorema 1.5.3. Por exemplo,</p>
<p><span class="math display">\[
\lim_{x \to -\infty} F_X(x) = 0 \quad \text{visto que} \quad \lim_{x \to -\infty} e^{-x} = \infty
\]</span></p>
<p>e</p>
<p><span class="math display">\[
\lim_{x \to \infty} F_X(x) = 1 \quad \text{visto que} \quad \lim_{x \to \infty} e^{-x} = 0.
\]</span></p>
<p>Diferenciando <span class="math inline">\(F_X(x)\)</span> resulta</p>
<p><span class="math display">\[
\frac{d}{dx} F_X(x) = \frac{e^{-x}}{(1+e^{-x})^2} &gt; 0,
\]</span></p>
<p>mostrando que <span class="math inline">\(F_X(x)\)</span> é crescente. <span class="math inline">\(F_X\)</span> não é apenas contínua à direita, mas também contínua. Esta é um caso especial da <em>distribuição logística</em>.</p>
</section>
<section id="exemplo-1.5.6-cdf-com-saltos" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.5.6-cdf-com-saltos">Exemplo 1.5.6 (Cdf com saltos)</h3>
<p>Se <span class="math inline">\(F_X\)</span> não é uma função contínua de <span class="math inline">\(x\)</span>, é possível que seja uma mistura de pedaços contínuos e saltos. Por exemplo, se modificarmos <span class="math inline">\(F_X(x)\)</span> de (1.5.5) para ser, para algum <span class="math inline">\(\epsilon, 1 &gt; \epsilon &gt; 0\)</span>,</p>
<p><span class="math display">\[
F_Y(y) = \begin{cases}
\frac{1-\epsilon}{1+e^{-y}} &amp; \text{se } y &lt; 0 \\
\epsilon + \frac{(1-\epsilon)}{1+e^{-y}} &amp; \text{se } y \ge 0,
\end{cases} \quad (1.5.6)
\]</span></p>
<p>então <span class="math inline">\(F_Y(y)\)</span> é a fda de uma variável aleatória <span class="math inline">\(Y\)</span> (veja Exercício 1.47). A função <span class="math inline">\(F_Y\)</span> tem um salto de altura <span class="math inline">\(\epsilon\)</span> em <span class="math inline">\(y=0\)</span> e, de outra forma, é contínua. Este modelo pode ser apropriado se estivéssemos observando a leitura de um medidor, uma leitura que poderia (teoricamente) estar em qualquer lugar entre <span class="math inline">\(-\infty\)</span> e <span class="math inline">\(\infty\)</span>. Este medidor particular, no entanto, às vezes trava em 0. Poderíamos então modelar nossas observações com <span class="math inline">\(F_Y\)</span>, onde <span class="math inline">\(\epsilon\)</span> é a probabilidade de que o medidor trave.</p>
</section>
<p>Se uma fda é contínua ou tem saltos corresponde à variável aleatória associada ser contínua ou não. De fato, a associação é tal que é conveniente definir variáveis aleatórias contínuas desta maneira.</p>
<section id="definição-1.5.7" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.5.7">Definição 1.5.7</h3>
<p>Uma variável aleatória <span class="math inline">\(X\)</span> é <em>contínua</em> se <span class="math inline">\(F_X(x)\)</span> é uma função contínua de <span class="math inline">\(x\)</span>. Uma variável aleatória <span class="math inline">\(X\)</span> é <em>discreta</em> se <span class="math inline">\(F_X(x)\)</span> é uma função escada de <span class="math inline">\(x\)</span>.</p>
</section>
<p>Fechamos esta seção com um teorema declarando formalmente que <span class="math inline">\(F_X\)</span> determina completamente a distribuição de probabilidade de uma variável aleatória <span class="math inline">\(X\)</span>. Isso é verdade se <span class="math inline">\(P(X \in A)\)</span> é definida apenas para eventos <span class="math inline">\(A\)</span> em <span class="math inline">\(\mathcal{B}^1\)</span>, a menor sigma-álgebra contendo todos os intervalos de números reais da forma <span class="math inline">\((a, b), [a, b), (a, b]\)</span>, e <span class="math inline">\([a, b]\)</span>. Se probabilidades são definidas para uma classe maior de eventos, é possível que duas variáveis aleatórias tenham a mesma distribuição de probabilidade, mas não a mesma probabilidade para todo evento (veja Chung 1974, página 27). Neste livro, como na maioria das aplicações estatísticas, estamos preocupados apenas com eventos que são intervalos, uniões enumeráveis ou interseções de intervalos, etc. Então não consideramos tais casos patológicos. Primeiro precisamos da noção de duas variáveis aleatórias sendo identicamente distribuídas.</p>
<section id="definição-1.5.8" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.5.8">Definição 1.5.8</h3>
<p>As variáveis aleatórias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são <em>identicamente distribuídas</em> se, para todo conjunto <span class="math inline">\(A \in \mathcal{B}^1, P(X \in A) = P(Y \in A)\)</span>.</p>
</section>
<p>Note que duas variáveis aleatórias que são identicamente distribuídas não são necessariamente iguais. Isto é, a Definição 1.5.8 não diz que <span class="math inline">\(X=Y\)</span>.</p>
<section id="exemplo-1.5.9-variáveis-aleatórias-identicamente-distribuídas" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.5.9-variáveis-aleatórias-identicamente-distribuídas">Exemplo 1.5.9 (Variáveis aleatórias identicamente distribuídas)</h3>
<p>Considere o experimento de lançar uma moeda justa três vezes como no Exemplo 1.4.3. Defina as variáveis aleatórias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> por</p>
<p><span class="math display">\[
X = \text{número de caras observadas} \quad \text{e} \quad Y = \text{número de coroas observadas}.
\]</span></p>
<p>A distribuição de <span class="math inline">\(X\)</span> é dada no Exemplo 1.4.3, e é facilmente verificado que a distribuição de <span class="math inline">\(Y\)</span> é exatamente a mesma. Isto é, para cada <span class="math inline">\(k = 0, 1, 2, 3\)</span>, temos <span class="math inline">\(P(X=k) = P(Y=k)\)</span>. Então <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são identicamente distribuídas. No entanto, para nenhum ponto amostral temos <span class="math inline">\(X(s) = Y(s)\)</span>.</p>
</section>
<section id="teorema-1.5.10" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.5.10">Teorema 1.5.10</h3>
<p>As duas declarações seguintes são equivalentes:</p>
<ul>
<li><p><strong>a.</strong> <em>As variáveis aleatórias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são identicamente distribuídas.</em></p></li>
<li><p><strong>b.</strong> <em><span class="math inline">\(F_X(x) = F_Y(x)\)</span> para todo <span class="math inline">\(x\)</span>.</em></p></li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Para mostrar a equivalência devemos mostrar que cada declaração implica a outra. Primeiro mostramos que (a) <span class="math inline">\(\Rightarrow\)</span> (b). Como <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> são identicamente distribuídas, para qualquer conjunto <span class="math inline">\(A \in \mathcal{B}^1, P(X \in A) = P(Y \in A)\)</span>. Em particular, para cada <span class="math inline">\(x\)</span>, o conjunto <span class="math inline">\((-\infty, x]\)</span> está em <span class="math inline">\(\mathcal{B}^1\)</span>, e</p>
<p><span class="math display">\[
F_X(x) = P(X \in (-\infty, x]) = P(Y \in (-\infty, x]) = F_Y(x).
\]</span></p>
<p>A implicação inversa, que (b) <span class="math inline">\(\Rightarrow\)</span> (a), é muito mais difícil de provar. O argumento acima mostrou que se as probabilidades <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> concordaram em todos os conjuntos, então elas concordaram em intervalos. Agora devemos provar o oposto; isto é, se as probabilidades <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> concordam em todos os intervalos, então elas concordam em todos os conjuntos. Isso requer uso pesado de sigma-álgebras; não entraremos nesses detalhes aqui. Basta dizer que é necessário provar apenas que as duas funções de probabilidade concordam em todos os intervalos (Chung 1974, Seção 2.2). <span class="math inline">\(\square\)</span></p>
</div>
</section>
<section id="funções-de-densidade-e-de-massa" class="level2">
<h2 class="anchored" data-anchor-id="funções-de-densidade-e-de-massa">1.6 Funções de Densidade e de Massa</h2>
<p>Associada a uma variável aleatória <span class="math inline">\(X\)</span> e sua fda <span class="math inline">\(F_X\)</span> existe outra função, chamada de <em>função de densidade de probabilidade</em> (fdp) ou <em>função de massa de probabilidade</em> (fmp). Os termos fdp e fmp referem-se, respectivamente, aos casos contínuo e discreto. Tanto fdp quanto fmp dizem respeito a “probabilidades pontuais” de variáveis aleatórias.</p>
<section id="definição-1.6.1" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.6.1">Definição 1.6.1</h3>
<p>A <em>função de massa de probabilidade</em> (fmp) de uma variável aleatória discreta <span class="math inline">\(X\)</span> é dada por <span class="math display">\[
f_X(x) = P(X = x) \quad \text{para todo } x.
\]</span></p>
</section>
<section id="exemplo-1.6.2-probabilidades-geométricas" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.6.2-probabilidades-geométricas">Exemplo 1.6.2 (Probabilidades geométricas)</h3>
<p>Para a distribuição geométrica do Exemplo 1.5.4, temos a fmp <span class="math display">\[
f_X(x) = P(X = x) = \begin{cases} (1-p)^{x-1}p &amp; \text{para } x = 1, 2, \dots \\ 0 &amp; \text{caso contrário.} \end{cases}
\]</span> Lembre-se que <span class="math inline">\(P(X = x)\)</span> ou, equivalentemente, <span class="math inline">\(f_X(x)\)</span> é o tamanho do salto na fda em <span class="math inline">\(x\)</span>. Podemos usar a fmp para calcular probabilidades. Como agora podemos medir a probabilidade de um único ponto, precisamos apenas somar todos os pontos no evento apropriado. Assim, para inteiros positivos <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, com <span class="math inline">\(a \le b\)</span>, temos <span class="math display">\[
P(a \le X \le b) = \sum_{k=a}^b f_X(k) = \sum_{k=a}^b (1-p)^{k-1}p.
\]</span></p>
</section>
<p>Como um caso especial disso, obtemos <span class="math display">\[
P(X \le b) = \sum_{k=1}^b f_X(k) = F_X(b). \quad (1.6.1)
\]</span></p>
<p>Uma convenção amplamente aceita, que adotaremos, é usar uma letra maiúscula para a fda e a letra minúscula correspondente para a fmp ou fdp. Devemos ser um pouco mais cuidadosos em nossa definição de fdp e no caso contínuo. Se tentarmos ingenuamente calcular <span class="math inline">\(P(X = x)\)</span> para uma variável aleatória contínua, obtemos o seguinte. Visto que <span class="math inline">\(\{X = x\} \subset \{x - \epsilon &lt; X \le x\}\)</span> para qualquer <span class="math inline">\(\epsilon &gt; 0\)</span>, temos do Teorema 1.2.9(c) que <span class="math display">\[
P(X = x) \le P(x - \epsilon &lt; X \le x) = F_X(x) - F_X(x - \epsilon)
\]</span> para qualquer <span class="math inline">\(\epsilon &gt; 0\)</span>. Portanto, <span class="math display">\[
0 \le P(X = x) \le \lim_{\epsilon \downarrow 0} [F_X(x) - F_X(x - \epsilon)] = 0
\]</span> pela continuidade de <span class="math inline">\(F_X\)</span>. No entanto, se entendermos o propósito da fdp, sua definição ficará clara. Do Exemplo 1.6.2, vemos que uma fmp nos dá “probabilidades pontuais”. No caso discreto, podemos somar valores da fmp para obter a fda (como em (1.6.1)). O procedimento análogo no caso contínuo é substituir integrais por somas, e obtemos <span class="math display">\[
P(X \le x) = F_X(x) = \int_{-\infty}^x f_X(t) \, dt.
\]</span> Usando o Teorema Fundamental do Cálculo, se <span class="math inline">\(f_X(x)\)</span> é contínua, temos a relação adicional <span class="math display">\[
\frac{d}{dx} F_X(x) = f_X(x). \quad (1.6.2)
\]</span> Note que a analogia com o caso discreto é quase exata. Nós “somamos” as “probabilidades pontuais” <span class="math inline">\(f_X(x)\)</span> para obter probabilidades de intervalo.</p>
<section id="definição-1.6.3" class="level3 definition">
<h3 class="anchored" data-anchor-id="definição-1.6.3">Definição 1.6.3</h3>
<p>A <em>função de densidade de probabilidade</em> ou <em>fdp</em>, <span class="math inline">\(f_X(x)\)</span>, de uma variável aleatória contínua <span class="math inline">\(X\)</span> é a função que satisfaz <span class="math display">\[
F_X(x) = \int_{-\infty}^x f_X(t) \, dt \quad \text{para todo } x. \quad (1.6.3)
\]</span></p>
</section>
<p><em>Uma nota sobre notação:</em> A expressão “<span class="math inline">\(X\)</span> tem uma distribuição dada por <span class="math inline">\(F_X(x)\)</span>” é abreviada simbolicamente por “<span class="math inline">\(X \sim F_X(x)\)</span>”, onde lemos o símbolo “<span class="math inline">\(\sim\)</span>” como “é distribuído como”. Podemos similarmente escrever <span class="math inline">\(X \sim f_X(x)\)</span> ou, se <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> têm a mesma distribuição, <span class="math inline">\(X \sim Y\)</span>. No caso contínuo, podemos ser um pouco desleixados sobre a especificação de probabilidades de intervalo. Visto que <span class="math inline">\(P(X = x) = 0\)</span> se <span class="math inline">\(X\)</span> é uma variável aleatória contínua, <span class="math display">\[
P(a &lt; X &lt; b) = P(a &lt; X \le b) = P(a \le X &lt; b) = P(a \le X \le b).
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig/fig-1_6_1.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Figura 1.6.1 - Área sob a curva logística</figcaption>
</figure>
</div>
<p>Deve ficar claro que a fdp (ou fmp) contém a mesma informação que a fda. Sendo este o caso, podemos usar uma para resolver problemas e devemos tentar escolher a mais simples.</p>
<section id="exemplo-1.6.4-probabilidades-logísticas" class="level3 example">
<h3 class="anchored" data-anchor-id="exemplo-1.6.4-probabilidades-logísticas">Exemplo 1.6.4 (Probabilidades logísticas)</h3>
<p>Para a distribuição logística do Exemplo 1.5.5, temos <span class="math display">\[
F_X(x) = \frac{1}{1+e^{-x}}
\]</span> e, portanto, <span class="math display">\[
f_X(x) = \frac{d}{dx} F_X(x) = \frac{e^{-x}}{(1+e^{-x})^2}.
\]</span> A área sob a curva <span class="math inline">\(f_X(x)\)</span> nos dá probabilidades de intervalo (veja Figura 1.6.1): <span class="math display">\[
\begin{align*}
P(a &lt; X &lt; b) &amp;= F_X(b) - F_X(a) \\
&amp;= \int_{-\infty}^b f_X(x) \, dx - \int_{-\infty}^a f_X(x) \, dx \\
&amp;= \int_{a}^b f_X(x) \, dx.
\end{align*}
\]</span></p>
</section>
<p>Existem realmente apenas dois requisitos para uma fdp (ou fmp), ambos consequências imediatas da definição.</p>
<section id="teorema-1.6.5" class="level3 theorem">
<h3 class="anchored" data-anchor-id="teorema-1.6.5">Teorema 1.6.5</h3>
<p>Uma função <span class="math inline">\(f_X(x)\)</span> é uma fdp (ou fmp) de uma variável aleatória <span class="math inline">\(X\)</span> se e somente se</p>
<ul>
<li><p><strong>a.</strong> <span class="math inline">\(f_X(x) \ge 0\)</span> para todo <span class="math inline">\(x\)</span>.</p></li>
<li><p><strong>b.</strong> <span class="math inline">\(\sum_x f_X(x) = 1\)</span> (fmp) ou <span class="math inline">\(\int_{-\infty}^{\infty} f_X(x) \, dx = 1\)</span> (fdp).</p></li>
</ul>
</section>
<div class="proof">
<p><span class="proof-title"><em>Comprovação</em>. </span>Se <span class="math inline">\(f_X(x)\)</span> é uma fdp (ou fmp), então as duas propriedades são imediatas das definições. Em particular, para uma fdp, usando (1.6.3) e o Teorema 1.5.3, temos <span class="math display">\[
1 = \lim_{x \to \infty} F_X(x) = \int_{-\infty}^{\infty} f_X(t) \, dt.
\]</span> A implicação inversa é igualmente fácil de provar. Uma vez que temos <span class="math inline">\(f_X(x)\)</span>, podemos definir <span class="math inline">\(F_X(x)\)</span> e apelar para o Teorema 1.5.3. <span class="math inline">\(\square\)</span></p>
</div>
<p>De um ponto de vista puramente matemático, qualquer função não negativa com uma integral positiva finita (ou soma) pode ser transformada em uma fdp ou fmp. Por exemplo, se <span class="math inline">\(h(x)\)</span> é qualquer função não negativa que é positiva em um conjunto <span class="math inline">\(A\)</span>, 0 em outro lugar, e <span class="math display">\[
\int_{\{x \in A\}} h(x) \, dx = K &lt; \infty
\]</span> para alguma constante <span class="math inline">\(K &gt; 0\)</span>, então a função <span class="math inline">\(f_X(x) = h(x)/K\)</span> é uma fdp de uma variável aleatória <span class="math inline">\(X\)</span> assumindo valores em <span class="math inline">\(A\)</span>. Na verdade, a relação (1.6.3) nem sempre é válida porque <span class="math inline">\(F_X(x)\)</span> pode ser contínua mas não diferenciável. De fato, existem variáveis aleatórias contínuas para as quais a integral não existe para <em>nenhuma</em> <span class="math inline">\(f_X(x)\)</span>. Estes casos são bastante patológicos e vamos ignorá-los. Assim, neste texto, vamos assumir que (1.6.3) é válida para qualquer variável aleatória contínua. Em textos mais avançados (por exemplo, Billingsley 1995, Seção 31) uma variável aleatória é chamada <em>absolutamente contínua</em> se (1.6.3) é válida.</p>
</section>
<section id="exercícios" class="level2">
<h2 class="anchored" data-anchor-id="exercícios">1.7 Exercícios</h2>
<p><strong>1.1</strong> Para cada um dos seguintes experimentos, descreva o espaço amostral. (a) Lançar uma moeda quatro vezes. (b) Contar o número de folhas danificadas por insetos em uma planta. (c) Medir a vida útil (em horas) de uma marca particular de lâmpada. (d) Registrar os pesos de ratos de 10 dias de idade. (e) Observar a proporção de defeituosos em um carregamento de componentes eletrônicos.</p>
<p><strong>1.2</strong> Verifique as seguintes identidades. (a) <span class="math inline">\(A \setminus B = A \setminus (A \cap B) = A \cap B^c\)</span> (b) <span class="math inline">\(B = (B \cap A) \cup (B \cap A^c)\)</span> (c) <span class="math inline">\(B \setminus A = B \cap A^c\)</span> (d) <span class="math inline">\(A \cup B = A \cup (B \cap A^c)\)</span></p>
<p><strong>1.3</strong> Termine a prova do Teorema 1.1.4. Para quaisquer eventos <span class="math inline">\(A, B\)</span> e <span class="math inline">\(C\)</span> definidos em um espaço amostral <span class="math inline">\(S\)</span>, mostre que (a) <span class="math inline">\(A \cup B = B \cup A\)</span> e <span class="math inline">\(A \cap B = B \cap A\)</span>. (comutatividade) (b) <span class="math inline">\(A \cup (B \cup C) = (A \cup B) \cup C\)</span> e <span class="math inline">\(A \cap (B \cap C) = (A \cap B) \cap C\)</span>. (associatividade) (c) <span class="math inline">\((A \cup B)^c = A^c \cap B^c\)</span> e <span class="math inline">\((A \cap B)^c = A^c \cup B^c\)</span>. (Leis de DeMorgan)</p>
<p><strong>1.4</strong> Para eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span>, encontre fórmulas para as probabilidades dos seguintes eventos em termos das quantidades <span class="math inline">\(P(A), P(B)\)</span> e <span class="math inline">\(P(A \cap B)\)</span>. (a) ou <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span> ou ambos (b) ou <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span>, mas não ambos (c) pelo menos um de <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span> (d) no máximo um de <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span></p>
<p><strong>1.5</strong> Aproximadamente um terço de todos os gêmeos humanos são idênticos (um ovo) e dois terços são fraternos (dois ovos). Gêmeos idênticos são necessariamente do mesmo sexo, com masculino e feminino sendo igualmente prováveis. Entre gêmeos fraternos, aproximadamente um quarto são ambos do sexo feminino, um quarto são ambos do sexo masculino e metade são um macho e uma fêmea. Finalmente, entre todos os nascimentos nos EUA, aproximadamente 1 em 90 é um nascimento de gêmeos. Defina os seguintes eventos: <span class="math display">\[
\begin{align*}
A &amp;= \{\text{um nascimento nos EUA resulta em gêmeas do sexo feminino}\} \\
B &amp;= \{\text{um nascimento nos EUA resulta em gêmeos idênticos}\} \\
C &amp;= \{\text{um nascimento nos EUA resulta em gêmeos}\}
\end{align*}
\]</span> (a) Declare, em palavras, o evento <span class="math inline">\(A \cap B \cap C\)</span>. (b) Encontre <span class="math inline">\(P(A \cap B \cap C)\)</span>.</p>
<p><strong>1.6</strong> Duas moedas, uma com <span class="math inline">\(P(\text{cara}) = u\)</span> e uma com <span class="math inline">\(P(\text{cara}) = w\)</span>, devem ser lançadas juntas independentemente. Defina <span class="math display">\[
\begin{align*}
p_0 &amp;= P(0 \text{ caras ocorrem}), \\
p_1 &amp;= P(1 \text{ cara ocorre}), \\
p_2 &amp;= P(2 \text{ caras ocorrem}).
\end{align*}
\]</span> Podem <span class="math inline">\(u\)</span> e <span class="math inline">\(w\)</span> serem escolhidos de tal forma que <span class="math inline">\(p_0 = p_1 = p_2\)</span>? Prove sua resposta.</p>
<p><strong>1.7</strong> Refira-se ao jogo de dardos do Exemplo 1.2.7. Suponha que não assumimos que a probabilidade de atingir o alvo de dardos é 1, mas sim que é proporcional à área do alvo. Assuma que o alvo de dardos é montado em uma parede que é atingida com probabilidade 1, e a parede tem área <span class="math inline">\(A\)</span>. (a) Usando o fato de que a probabilidade de atingir uma região é proporcional à área, construa uma função de probabilidade para <span class="math inline">\(P(\text{marcar } i \text{ pontos}), i = 0, \dots, 5\)</span>. (Sem pontos são marcados se o alvo de dardos não for atingido.) (b) Mostre que a distribuição de probabilidade condicional <span class="math inline">\(P(\text{marcar } i \text{ pontos}|\text{alvo é atingido})\)</span> é exatamente a distribuição de probabilidade do Exemplo 1.2.7.</p>
<p><strong>1.8</strong> Novamente refira-se ao jogo de dardos explicado no Exemplo 1.2.7. (a) Derive a fórmula geral para a probabilidade de marcar <span class="math inline">\(i\)</span> pontos. (b) Mostre que <span class="math inline">\(P(\text{marcar } i \text{ pontos})\)</span> é uma função decrescente de <span class="math inline">\(i\)</span>, isto é, conforme os pontos aumentam, a probabilidade de marcar os pontos diminui. (c) Mostre que <span class="math inline">\(P(\text{marcar } i \text{ pontos})\)</span> é uma função de probabilidade de acordo com os Axiomas de Kolmogorov.</p>
<p><strong>1.9</strong> Prove a versão geral das Leis de DeMorgan. Seja <span class="math inline">\(\{A_{\alpha} : \alpha \in \Gamma\}\)</span> uma coleção (possivelmente não enumerável) de conjuntos. Prove que (a) <span class="math inline">\((\cup_{\alpha} A_{\alpha})^c = \cap_{\alpha} A_{\alpha}^c\)</span>. (b) <span class="math inline">\((\cap_{\alpha} A_{\alpha})^c = \cup_{\alpha} A_{\alpha}^c\)</span>.</p>
<p><strong>1.10</strong> Formule e prove uma versão das Leis de DeMorgan que se aplica a uma coleção finita de conjuntos <span class="math inline">\(A_1, \dots, A_n\)</span>.</p>
<p><strong>1.11</strong> Seja <span class="math inline">\(S\)</span> um espaço amostral. (a) Mostre que a coleção <span class="math inline">\(\mathcal{B} = \{\emptyset, S\}\)</span> é uma sigma-álgebra. (b) Seja <span class="math inline">\(\mathcal{B} = \{\text{todos os subconjuntos de } S, \text{ incluindo } S \text{ ele mesmo}\}\)</span>. Mostre que <span class="math inline">\(\mathcal{B}\)</span> é uma sigma-álgebra. (c) Mostre que a interseção de duas sigma-álgebras é uma sigma-álgebra.</p>
<p><strong>1.12</strong> Foi observado na Seção 1.2.1 que estatísticos que seguem a escola de deFinetti não aceitam o Axioma da Aditividade Enumerável, aderindo em vez disso ao Axioma da Aditividade Finita. (a) Mostre que o Axioma da Aditividade Enumerável implica Aditividade Finita. (b) Mostre que, por si só, o Axioma da Aditividade Finita não implica Aditividade Enumerável. Para ajudar, suponha que complementamos com o seguinte. Seja <span class="math inline">\(A_1 \supset A_2 \supset \dots \supset A_n \supset \dots\)</span> uma sequência infinita de conjuntos aninhados cujo limite é o conjunto vazio, o que denotamos por <span class="math inline">\(A_n \downarrow \emptyset\)</span>. Considere o seguinte: <em>Axioma da Continuidade:</em> Se <span class="math inline">\(A_n \downarrow \emptyset\)</span>, então <span class="math inline">\(P(A_n) \to 0\)</span>. Prove que o Axioma da Continuidade e o Axioma da Aditividade Finita implicam Aditividade Enumerável.</p>
<p><strong>1.13</strong> Se <span class="math inline">\(P(A) = \frac{1}{3}\)</span> e <span class="math inline">\(P(B^c) = \frac{1}{4}\)</span>, podem <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> ser disjuntos? Explique.</p>
<p><strong>1.14</strong> Suponha que um espaço amostral <span class="math inline">\(S\)</span> tenha <span class="math inline">\(n\)</span> elementos. Prove que o número de subconjuntos que podem ser formados a partir dos elementos de <span class="math inline">\(S\)</span> é <span class="math inline">\(2^n\)</span>.</p>
<p><strong>1.15</strong> Termine a prova do Teorema 1.2.14. Use o resultado estabelecido para <span class="math inline">\(k=2\)</span> como a base de um argumento de indução.</p>
<p><strong>1.16</strong> Quantos conjuntos diferentes de iniciais podem ser formados se cada pessoa tiver um sobrenome e (a) exatamente dois nomes próprios? (b) ou um ou dois nomes próprios? (Respostas: (a) <span class="math inline">\(26^3\)</span> (b) <span class="math inline">\(26^3 + 26^2\)</span> (c) <span class="math inline">\(26^4 + 26^3 + 26^2\)</span>)</p>
<p><strong>1.17</strong> No jogo de dominó, cada peça é marcada com dois números. As peças são simétricas de modo que o par numérico não é ordenado (assim, por exemplo, <span class="math inline">\((2, 6) = (6, 2)\)</span>). Quantas peças diferentes podem ser formadas usando os números <span class="math inline">\(1, 2, \dots, n\)</span>? (Answer: <span class="math inline">\(n(n + 1)/2\)</span>)</p>
<p><strong>1.18</strong> Se <span class="math inline">\(n\)</span> bolas são colocadas aleatoriamente em <span class="math inline">\(n\)</span> células, encontre a probabilidade de que exatamente uma célula permaneça vazia. (Answer: <span class="math inline">\(\binom{n}{2} n!/n^n\)</span>)</p>
<p><strong>1.19</strong> Se uma função multivariada tem derivadas parciais contínuas, a ordem na qual as derivadas são calculadas não importa. Assim, por exemplo, a função <span class="math inline">\(f(x, y)\)</span> de duas variáveis tem parciais terceiras iguais <span class="math display">\[
\frac{\partial^3}{\partial x^2 \partial y} f(x, y) = \frac{\partial^3}{\partial y \partial x^2} f(x, y).
\]</span> (a) Quantas quartas derivadas parciais tem uma função de três variáveis? (b) Prove que uma função de <span class="math inline">\(n\)</span> variáveis tem <span class="math inline">\(\binom{n+r-1}{r}\)</span> <span class="math inline">\(r\)</span>-ésimas derivadas parciais.</p>
<p><strong>1.20</strong> Meu telefone toca 12 vezes por semana, as chamadas sendo distribuídas aleatoriamente entre os 7 dias. Qual é a probabilidade de que eu receba pelo menos uma chamada a cada dia? (Resposta: .2285)</p>
<p><strong>1.21</strong> Um armário contém <span class="math inline">\(n\)</span> pares de sapatos. Se <span class="math inline">\(2r\)</span> sapatos são escolhidos ao acaso (<span class="math inline">\(2r &lt; n\)</span>), qual é a probabilidade de que não haja nenhum par correspondente na amostra? (Resposta: <span class="math inline">\(\binom{n}{2r} 2^{2r} / \binom{2n}{2r}\)</span>)</p>
<p><strong>1.22</strong> (a) Em um sorteio de loteria contendo os 366 dias do ano (incluindo 29 de fevereiro), qual é a probabilidade de que os primeiros 180 dias sorteados (sem reposição) sejam distribuídos uniformemente entre os 12 meses? (b) Qual é a probabilidade de que os primeiros 30 dias sorteados não contenham nenhum de setembro? (Respostas: (a) <span class="math inline">\(.167 \times 10^{-8}\)</span> (b) <span class="math inline">\(\binom{336}{30} / \binom{366}{30}\)</span>)</p>
<p><strong>1.23</strong> Duas pessoas lançam cada uma uma moeda honesta <span class="math inline">\(n\)</span> vezes. Encontre a probabilidade de que eles obtenham o mesmo número de caras. (Resposta: <span class="math inline">\(\binom{2n}{n} (\frac{1}{4})^n\)</span>)</p>
<p><strong>1.24</strong> Dois jogadores, A e B, alternadamente e independentemente lançam uma moeda e o primeiro jogador a obter uma cara ganha. Assuma que o jogador A lança primeiro. (a) Se a moeda é honesta, qual é a probabilidade de que A vença? (b) Suponha que <span class="math inline">\(P(\text{cara}) = p\)</span>, não necessariamente <span class="math inline">\(\frac{1}{2}\)</span>. Qual é a probabilidade de que A vença? (c) Mostre que para todo <span class="math inline">\(p, 0 &lt; p &lt; 1, P(\text{A vence}) &gt; \frac{1}{2}\)</span>. (Dica: Tente escrever <span class="math inline">\(P(\text{A vence})\)</span> em termos dos eventos <span class="math inline">\(E_1, E_2, \dots\)</span>, onde <span class="math inline">\(E_i = \{\text{primeira cara aparece no i-ésimo lançamento}\}\)</span>.) (Respostas: (a) 2/3 (b) <span class="math inline">\(\frac{p}{1-(1-p)^2}\)</span>)</p>
<p><strong>1.25</strong> Os Smith têm dois filhos. Pelo menos um deles é menino. Qual é a probabilidade de que ambos os filhos sejam meninos? (Veja Gardner 1961 para uma discussão completa deste problema.)</p>
<p><strong>1.26</strong> Um dado honesto é lançado até que um 6 apareça. Qual é a probabilidade de que ele deva ser lançado mais de cinco vezes?</p>
<p><strong>1.27</strong> Verifique as seguintes identidades para <span class="math inline">\(n \ge 2\)</span>. (a) <span class="math inline">\(\sum_{k=0}^n (-1)^k \binom{n}{k} = 0\)</span> (b) <span class="math inline">\(\sum_{k=1}^n k \binom{n}{k} = n 2^{n-1}\)</span> (c) <span class="math inline">\(\sum_{k=1}^n (-1)^{k+1} k \binom{n}{k} = 0\)</span></p>
<p><strong>1.28</strong> Uma maneira de aproximar fatoriais grandes é através do uso da <em>Fórmula de Stirling</em>: <span class="math display">\[
n! \approx \sqrt{2\pi n} n^n e^{-n},
\]</span> uma derivação completa da qual é difícil. Em vez disso, prove o fato mais fácil, <span class="math display">\[
\lim_{n \to \infty} \frac{n!}{n^{n+(1/2)} e^{-n}} = \text{uma constante}.
\]</span> (Dica: Feller 1968 procede usando a monotonicidade do logaritmo para estabelecer que <span class="math display">\[
\int_{k-1}^k \log x \, dx &lt; \log k &lt; \int_k^{k+1} \log x \, dx, \quad k = 1, \dots, n,
\]</span> e consequentemente <span class="math display">\[
\int_0^n \log x \, dx &lt; \log n! &lt; \int_1^{n+1} \log x \, dx.
\]</span> Agora compare <span class="math inline">\(\log n!\)</span> com a média das duas integrais. Veja Exercício 5.35 para outra derivação.)</p>
<p><strong>1.29</strong> (a) Para a situação do Exemplo 1.2.20, enumere as amostras ordenadas que compõem as amostras não ordenadas <span class="math inline">\(\{4, 4, 12, 12\}\)</span> e <span class="math inline">\(\{2, 9, 9, 12\}\)</span>. (b) Enumere as amostras ordenadas que compõem as amostras não ordenadas <span class="math inline">\(\{4, 4, 12, 12\}\)</span> e <span class="math inline">\(\{2, 9, 9, 12\}\)</span>. (Nota: Parece haver um erro de digitação no livro original repetindo a pergunta, mas a segunda parte geralmente se refere a calcular as probabilidades associadas ou comparar os tamanhos).</p>
<p><strong>1.29 (Correção baseada no contexto do Exemplo 1.2.20)</strong> (a) Para a situação do Exemplo 1.2.20, enumere as amostras ordenadas que compõem as amostras não ordenadas <span class="math inline">\(\{4, 4, 12, 12\}\)</span> e <span class="math inline">\(\{2, 9, 9, 12\}\)</span>. (c) Suponha que tivéssemos uma coleção de seis números, <span class="math inline">\(\{1, 2, 7, 8, 14, 20\}\)</span>. Qual é a probabilidade de sortear, com reposição, a amostra não ordenada <span class="math inline">\(\{2, 7, 7, 8, 14, 14\}\)</span>? (d) Verifique que uma amostra não ordenada de tamanho <span class="math inline">\(k\)</span>, de <span class="math inline">\(m\)</span> números diferentes repetidos <span class="math inline">\(k_1, k_2, \dots, k_m\)</span> vezes, tem <span class="math inline">\(\frac{k!}{k_1! k_2! \dots k_m!}\)</span> componentes ordenados, onde <span class="math inline">\(k_1 + k_2 + \dots + k_m = k\)</span>. (e) Use o resultado da parte anterior para estabelecer a identidade <span class="math display">\[
\sum_{k_1, k_2, \dots, k_m : k_1 + k_2 + \dots + k_m = k} \frac{k!}{k_1! k_2! \dots k_m!} = \binom{k+m-1}{k}.
\]</span></p>
<p><strong>1.30</strong> Para a coleção de seis números, <span class="math inline">\(\{1, 2, 7, 8, 14, 20\}\)</span>, desenhe um histograma da distribuição de todas as médias amostrais possíveis calculadas a partir de amostras sorteadas com reposição.</p>
<p><strong>1.31</strong> Para a situação do Exemplo 1.2.20, a média do conjunto original de números <span class="math inline">\(\{2, 4, 9, 12\}\)</span> é <span class="math inline">\(\frac{27}{4}\)</span>, que tem a maior probabilidade. (a) Prove que, em geral, se amostramos com reposição do conjunto <span class="math inline">\(\{x_1, x_2, \dots, x_n\}\)</span>, o resultado com média <span class="math inline">\((x_1 + x_2 + \dots + x_n)/n\)</span> é o mais provável, tendo probabilidade <span class="math inline">\(n!/n^n\)</span>. (b) Use a Fórmula de Stirling (Exercício 1.28) para mostrar que <span class="math inline">\(n!/n^n \approx \sqrt{2\pi n} / e^n\)</span> (Hall 1992, Apêndice I). (c) Mostre que a probabilidade de que um <span class="math inline">\(x_i\)</span> particular esteja faltando em um resultado é <span class="math inline">\((1 - \frac{1}{n})^n \to e^{-1}\)</span> quando <span class="math inline">\(n \to \infty\)</span>.</p>
<p><strong>1.32</strong> Um empregador está prestes a contratar um novo empregado de um grupo de <span class="math inline">\(N\)</span> candidatos, cujo potencial futuro pode ser classificado em uma escala de 1 a <span class="math inline">\(N\)</span>. O empregador procede de acordo com as seguintes regras: (a) Cada candidato é visto em sucessão (em ordem aleatória) e uma decisão é tomada se contrata ou não o candidato. (b) Tendo rejeitado <span class="math inline">\(m-1\)</span> candidatos (<span class="math inline">\(m &gt; 1\)</span>), o empregador pode contratar o <span class="math inline">\(m\)</span>-ésimo candidato apenas se o <span class="math inline">\(m\)</span>-ésimo candidato for melhor do que os <span class="math inline">\(m-1\)</span> anteriores. Suponha que um candidato é contratado na <span class="math inline">\(i\)</span>-ésima tentativa. Qual é a probabilidade de que o melhor candidato tenha sido contratado?</p>
<p><strong>1.33</strong> Suponha que 5% dos homens e 0,25% das mulheres são daltônicos. Uma pessoa é escolhida aleatoriamente e essa pessoa é daltônica. Qual é a probabilidade de que a pessoa seja do sexo masculino? (Assuma que homens e mulheres estão em igual número.)</p>
<p><strong>1.34</strong> Duas ninhadas de uma espécie particular de roedor nasceram, uma com dois filhotes de pêlo castanho e um de pêlo cinza (ninhada 1), e a outra com três de pêlo castanho e dois de pêlo cinza (ninhada 2). Selecionamos uma ninhada aleatoriamente e depois selecionamos uma prole aleatoriamente da ninhada selecionada. (a) Qual é a probabilidade de que o animal escolhido tenha pêlo castanho? (b) Dado que uma prole de pêlo castanho foi selecionada, qual é a probabilidade de que a amostragem tenha sido da ninhada 1?</p>
<p><strong>1.35</strong> Prove que se <span class="math inline">\(P(\cdot)\)</span> é uma função de probabilidade legítima e <span class="math inline">\(B\)</span> é um conjunto com <span class="math inline">\(P(B) &gt; 0\)</span>, então <span class="math inline">\(P(\cdot|B)\)</span> também satisfaz os Axiomas de Kolmogorov.</p>
<p><strong>1.36</strong> Se a probabilidade de atingir um alvo é <span class="math inline">\(\frac{1}{5}\)</span>, e dez tiros são disparados independentemente, qual é a probabilidade de o alvo ser atingido pelo menos duas vezes? Qual é a probabilidade condicional de que o alvo seja atingido pelo menos duas vezes, dado que é atingido pelo menos uma vez?</p>
<p><strong>1.37</strong> Aqui olhamos para algumas variações do Exemplo 1.3.4. (a) No cálculo do diretor no Exemplo 1.3.4 foi assumido que se A fosse perdoado, então com igual probabilidade o diretor diria a A que B ou C morreria. No entanto, isso não precisa ser o caso. O diretor pode atribuir probabilidades <span class="math inline">\(\gamma\)</span> e <span class="math inline">\(1-\gamma\)</span> a esses eventos, como mostrado aqui:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Prisioneiro perdoado</th>
<th style="text-align: left;">Diretor diz a A</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A</td>
<td style="text-align: left;">B morre</td>
<td style="text-align: left;">com probabilidade <span class="math inline">\(\gamma\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">A</td>
<td style="text-align: left;">C morre</td>
<td style="text-align: left;">com probabilidade <span class="math inline">\(1-\gamma\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">B</td>
<td style="text-align: left;">C morre</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">C</td>
<td style="text-align: left;">B morre</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Calcule <span class="math inline">\(P(A|\mathcal{W})\)</span> como uma função de <span class="math inline">\(\gamma\)</span>. Para quais valores de <span class="math inline">\(\gamma\)</span> é <span class="math inline">\(P(A|\mathcal{W})\)</span> menor que, igual a, ou maior que <span class="math inline">\(\frac{1}{3}\)</span>? (b) Suponha novamente que <span class="math inline">\(\gamma = \frac{1}{2}\)</span>, como no texto. Depois que o diretor diz a A que B vai morrer, A pensa um pouco e percebe que seu cálculo original era falso. No entanto, A então tem uma ideia brilhante. A pede ao diretor se ele pode trocar de destino com C. O diretor, pensando que nenhuma informação foi passada, concorda. Prove que o raciocínio de A agora está correto e que sua probabilidade de sobrevivência saltou para <span class="math inline">\(\frac{2}{3}\)</span>! Um problema semelhante, mas um pouco mais complicado, o “problema de Monty Hall”, é discutido por Selvin (1975). O problema nesta guisa ganhou uma quantidade razoável de notoriedade quando apareceu em uma revista de domingo (vos Savant 1990) juntamente com uma resposta correta, mas com explicação questionável. O debate que se seguiu foi até relatado na primeira página do Sunday New York Times (Tierney 1991). Uma análise completa e um tanto divertida é dada por Morgan et al.&nbsp;(1991) (veja também a resposta de vos Savant 1991). Chun (1999) praticamente esgota o problema com uma análise muito completa.</p>
<p><strong>1.38</strong> Prove cada uma das seguintes afirmações. (Assuma que qualquer evento condicionante tem probabilidade positiva.) (a) Se <span class="math inline">\(P(B) = 1\)</span>, então <span class="math inline">\(P(A|B) = P(A)\)</span> para qualquer <span class="math inline">\(A\)</span>. (b) Se <span class="math inline">\(A \subset B\)</span>, então <span class="math inline">\(P(B|A) = 1\)</span> e <span class="math inline">\(P(A|B) = P(A)/P(B)\)</span>. (c) Se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são mutuamente exclusivos, então <span class="math display">\[
P(A|A \cup B) = \frac{P(A)}{P(A) + P(B)}.
\]</span> (d) <span class="math inline">\(P(A \cap B \cap C) = P(A|B \cap C)P(B|C)P(C)\)</span>.</p>
<p><strong>1.39</strong> Um par de eventos <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> não pode ser simultaneamente <em>mutuamente exclusivo</em> e <em>independente</em>. Prove que se <span class="math inline">\(P(A) &gt; 0\)</span> e <span class="math inline">\(P(B) &gt; 0\)</span>, então: (a) Se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são mutuamente exclusivos, eles não podem ser independentes. (b) Se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> são independentes, eles não podem ser mutuamente exclusivos.</p>
<p><strong>1.40</strong> Termine a prova do Teorema 1.3.9 provando as partes (b) e (c).</p>
<p><strong>1.41</strong> Como no Exemplo 1.3.6, considere sinais de telégrafo “ponto” e “traço” enviados na proporção 3:4, onde transmissões erráticas fazem com que um ponto se torne um traço com probabilidade <span class="math inline">\(\frac{1}{4}\)</span> e um traço se torne um ponto com probabilidade <span class="math inline">\(\frac{1}{3}\)</span>. (a) Se um traço é recebido, qual é a probabilidade de que um traço tenha sido enviado? (b) Assumindo independência entre sinais, se a mensagem ponto-ponto foi recebida, qual é a distribuição de probabilidade das quatro mensagens possíveis que poderiam ter sido enviadas?</p>
<p><strong>1.42</strong> A <em>identidade de inclusão-exclusão</em> da Miscelânea 1.8.1 recebe seu nome do fato de que é provada pelo método de inclusão e exclusão (Feller 1968, Seção IV.1). Aqui vamos entrar nos detalhes. A probabilidade <span class="math inline">\(P(\cup_{i=1}^n A_i)\)</span> é a soma das probabilidades de todos os pontos amostrais que estão contidos em pelo menos um dos <span class="math inline">\(A_i\)</span>s. O método de inclusão e exclusão é uma receita para contar esses pontos. (a) Seja <span class="math inline">\(E_k\)</span> o conjunto de todos os pontos amostrais que estão contidos em exatamente <span class="math inline">\(k\)</span> dos eventos <span class="math inline">\(A_1, A_2, \dots, A_n\)</span>. Mostre que <span class="math inline">\(P(\cup_{i=1}^n A_i) = \sum_{i=1}^n P(E_i)\)</span>. (b) Se <span class="math inline">\(E_1\)</span> não é vazio, mostre que <span class="math inline">\(P(E_1) = \sum_{i=1}^n P(A_i)\)</span>. (c) Sem perda de generalidade, assuma que <span class="math inline">\(E_k\)</span> está contido em <span class="math inline">\(A_1, A_2, \dots, A_k\)</span>. Mostre que <span class="math inline">\(P(E_k)\)</span> aparece <span class="math inline">\(k\)</span> vezes na soma <span class="math inline">\(P_1\)</span>, <span class="math inline">\(\binom{k}{2}\)</span> vezes na soma <span class="math inline">\(P_2\)</span>, <span class="math inline">\(\binom{k}{3}\)</span> vezes na soma <span class="math inline">\(P_3\)</span>, etc. (d) Mostre que <span class="math display">\[
k - \binom{k}{2} + \binom{k}{3} - \dots \pm \binom{k}{k} = 1.
\]</span> (Veja Exercício 1.27.) (e) Mostre que as partes (a) – (c) implicam <span class="math inline">\(\sum_{i=1}^n P(E_i) = P_1 - P_2 = \dots \pm P_n\)</span>, estabelecendo a identidade de inclusão-exclusão.</p>
<p><strong>1.43</strong> Para a <em>identidade de inclusão-exclusão</em> da Miscelânea 1.8.1: (a) Derive a Desigualdade de Boole e a Desigualdade de Bonferroni a partir da identidade de inclusão-exclusão. (b) Mostre que os <span class="math inline">\(P_i\)</span> satisfazem <span class="math inline">\(P_i \ge P_j\)</span> se <span class="math inline">\(i \ge j\)</span> e que a sequência de limites na Miscelânea 1.8.1 melhora à medida que o número de termos aumenta. (c) Tipicamente, conforme o número de termos no limite aumenta, o limite se torna mais útil. No entanto, Schwager (1984) adverte que existem alguns casos onde não há muita melhora, em particular se os <span class="math inline">\(A_i\)</span>s são altamente correlacionados. Examine o que acontece com a sequência de limites no caso extremo quando <span class="math inline">\(A_i = A\)</span> para todo <span class="math inline">\(i\)</span>. (Veja Worsley 1982 e a correspondência de Worsley 1985 e Schwager 1985.)</p>
<p><strong>1.44</strong> Testes padronizados fornecem uma aplicação interessante da teoria da probabilidade. Suponha primeiro que um teste consiste em 20 questões de múltipla escolha, cada uma com 4 respostas possíveis. Se o aluno chuta em cada questão, então a realização do exame pode ser modelada como uma sequência de 20 eventos independentes. Encontre a probabilidade de que o aluno acerte pelo menos 10 questões, dado que ele está chutando.</p>
<p><strong>1.45</strong> Mostre que a função de probabilidade induzida definida em (1.4.1) define uma função de probabilidade legítima que satisfaz os Axiomas de Kolmogorov.</p>
<p><strong>1.46</strong> Sete bolas são distribuídas aleatoriamente em sete células. Seja <span class="math inline">\(X_i = \text{o número de células contendo exatamente } i \text{ bolas}\)</span>. Qual é a distribuição de probabilidade de <span class="math inline">\(X_3\)</span>? (Isto é, encontre <span class="math inline">\(P(X_3 = x)\)</span> para cada <span class="math inline">\(x\)</span> possível.)</p>
<p><strong>1.47</strong> Prove que as seguintes funções são cdfs. (a) <span class="math inline">\(\frac{1}{2} + \frac{1}{\pi} \tan^{-1}(x), x \in (-\infty, \infty)\)</span> (b) <span class="math inline">\((1 + e^{-x})^{-1}, x \in (-\infty, \infty)\)</span> (c) <span class="math inline">\(e^{-e^{-x}}, x \in (-\infty, \infty)\)</span> (d) <span class="math inline">\(1 - e^{-x}, x \in (0, \infty)\)</span> (e) a função definida em (1.5.6)</p>
<p><strong>1.48</strong> Prove a parte de necessidade do Teorema 1.5.3.</p>
<p><strong>1.49</strong> Uma cdf <span class="math inline">\(F_X\)</span> é <em>estocasticamente maior</em> que uma cdf <span class="math inline">\(F_Y\)</span> se <span class="math inline">\(F_X(t) \le F_Y(t)\)</span> para todo <span class="math inline">\(t\)</span> e <span class="math inline">\(F_X(t) &lt; F_Y(t)\)</span> para algum <span class="math inline">\(t\)</span>. Prove que se <span class="math inline">\(X \sim F_X\)</span> e <span class="math inline">\(Y \sim F_Y\)</span>, então <span class="math display">\[
P(X &gt; t) \ge P(Y &gt; t) \quad \text{para todo } t
\]</span> e <span class="math display">\[
P(X &gt; t) &gt; P(Y &gt; t) \quad \text{para algum } t,
\]</span> isto é, <span class="math inline">\(X\)</span> tende a ser maior que <span class="math inline">\(Y\)</span>.</p>
<p><strong>1.50</strong> Verifique a fórmula (1.5.4), a fórmula para a soma parcial da série geométrica.</p>
<p><strong>1.51</strong> Uma loja de eletrodomésticos recebe um carregamento de 30 fornos de microondas, 5 dos quais são (desconhecidos pelo gerente) defeituosos. O gerente da loja seleciona 4 fornos aleatoriamente, sem reposição, para testar a fim de ver se eles são defeituosos. Seja <span class="math inline">\(X = \text{número de defeituosos encontrados}\)</span>. Calcule a fmp e a cdf de <span class="math inline">\(X\)</span> e plote a cdf.</p>
<p><strong>1.52</strong> Seja <span class="math inline">\(X\)</span> uma variável aleatória contínua com pdf <span class="math inline">\(f(x)\)</span> e cdf <span class="math inline">\(F(x)\)</span>. Para um número fixo <span class="math inline">\(x_0\)</span>, defina a função <span class="math display">\[
g(x) = \begin{cases} f(x)/[1 - F(x_0)] &amp; x \ge x_0 \\ 0 &amp; x &lt; x_0. \end{cases}
\]</span> Prove que <span class="math inline">\(g(x)\)</span> é uma pdf. (Assuma que <span class="math inline">\(F(x_0) &lt; 1\)</span>.)</p>
<p><strong>1.53</strong> Um certo rio inunda todos os anos. Suponha que a marca de água baixa é definida em 1 e a marca de água alta <span class="math inline">\(Y\)</span> tem função de distribuição <span class="math display">\[
F_Y(y) = P(Y \le y) = 1 - \frac{1}{y^2}, \quad 1 \le y &lt; \infty.
\]</span> (a) Verifique que <span class="math inline">\(F_Y(y)\)</span> é uma cdf. (b) Encontre <span class="math inline">\(f_Y(y)\)</span>, a pdf de <span class="math inline">\(Y\)</span>. (c) Se a marca de água baixa é redefinida em 0 e usamos uma unidade de medida que é <span class="math inline">\(\frac{1}{10}\)</span> daquela dada anteriormente, a marca de água alta se torna <span class="math inline">\(Z = 10(Y - 1)\)</span>. Encontre <span class="math inline">\(F_Z(z)\)</span>.</p>
<p><strong>1.54</strong> Para cada uma das seguintes, determine o valor de <span class="math inline">\(c\)</span> que faz de <span class="math inline">\(f(x)\)</span> uma pdf. (a) <span class="math inline">\(f(x) = c \sin x, 0 &lt; x &lt; \pi/2\)</span> (b) <span class="math inline">\(f(x) = c e^{-|x|}, -\infty &lt; x &lt; \infty\)</span></p>
<p><strong>1.55</strong> Um dispositivo eletrônico tem tempo de vida denotado por <span class="math inline">\(T\)</span>. O dispositivo tem valor <span class="math inline">\(V = 5\)</span> se ele falhar antes do tempo <span class="math inline">\(t = 3\)</span>; caso contrário, ele tem valor <span class="math inline">\(V = 2T\)</span>. Encontre a cdf de <span class="math inline">\(V\)</span>, se <span class="math inline">\(T\)</span> tem pdf <span class="math display">\[
f_T(t) = \frac{1}{1.5} e^{-t/(1.5)}, \quad t &gt; 0.
\]</span></p>
</section>
<section id="assuntos-diversos" class="level2">
<h2 class="anchored" data-anchor-id="assuntos-diversos">1.8 Assuntos Diversos</h2>
<section id="bonferroni-e-além" class="level3">
<h3 class="anchored" data-anchor-id="bonferroni-e-além">1.8.1 Bonferroni e Além</h3>
<p>O limite de Bonferroni de (1.2.10), ou Desigualdade de Boole (Teorema 1.2.11), fornece limites simples para a probabilidade de uma interseção ou união. Esses limites podem ser tornados cada vez mais precisos com a seguinte expansão.</p>
<p>Para conjuntos <span class="math inline">\(A_1, A_2, \dots, A_n\)</span>, criamos um novo conjunto de interseções aninhadas como segue. Seja <span class="math display">\[
P_1 = \sum_{i=1}^n P(A_i)
\]</span> <span class="math display">\[
P_2 = \sum_{1 \le i &lt; j \le n} P(A_i \cap A_j)
\]</span> <span class="math display">\[
P_3 = \sum_{1 \le i &lt; j &lt; k \le n} P(A_i \cap A_j \cap A_k)
\]</span> <span class="math display">\[
\vdots
\]</span> <span class="math display">\[
P_n = P(A_1 \cap A_2 \cap \dots \cap A_n).
\]</span></p>
<p>Então a <em>identidade de inclusão-exclusão</em> diz que <span class="math display">\[
P(A_1 \cup A_2 \cup \dots \cup A_n) = P_1 - P_2 + P_3 - P_4 + \dots \pm P_n.
\]</span> Além disso, os <span class="math inline">\(P_i\)</span> são ordenados de tal forma que <span class="math inline">\(P_i \ge P_j\)</span> se <span class="math inline">\(i \le j\)</span>, e temos a sequência de limites superiores e inferiores <span class="math display">\[
\begin{align*}
P_1 \ge P(\cup_{i=1}^n A_i) &amp;\ge P_1 - P_2 \\
P_1 - P_2 + P_3 \ge P(\cup_{i=1}^n A_i) &amp;\ge P_1 - P_2 + P_3 - P_4 \\
\vdots
\end{align*}
\]</span></p>
<p>Veja Exercícios 1.42 e 1.43 para detalhes. Esses limites tornam-se cada vez mais apertados à medida que o número de termos aumenta, e eles fornecem um refinamento dos limites originais de Bonferroni. Aplicações desses limites incluem a aproximação de probabilidades de sequências (<em>runs</em>) (Karlin e Ost 1988) e procedimentos de comparações múltiplas (Naiman e Wynn 1992).</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiada");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiada");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Inferência Estatística">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Inferência Estatística</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./cap-2.html" class="pagination-link" aria-label="Transformações e Esperanças">
        <span class="nav-page-text"><span class="chapter-title">Transformações e Esperanças</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>